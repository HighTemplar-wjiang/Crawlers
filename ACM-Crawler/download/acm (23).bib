@proceedings{10.1145/3313831,
title = {CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Aloha!We are excited to welcome you to CHI 2020 in beautiful Honolulu, Hawai'i!Although CHI has strong origins in the USA, it has never been to Hawai'i. We see this rather "unusual" location for a conference as both an acknowledgement of the role underrepresented regions play in the field of Human-Computer Interaction as well as a symbol for more outreach to the rest of the world.The ACM CHI Conference on Human Factors in Computing Systems is the premier international conference of Human-Computer Interaction. CHI - pronounced "kai" - is a place where researchers and practitioners gather from across the world to discuss the latest in interactive technology. We are a multicultural community from highly diverse backgrounds who together investigate new and creative ways for people to interact.CHI has a rich history of bringing together people from different disciplines, cultures, sectors, communities and backgrounds. Through CHI, designers, researchers and practitioners come together with the common purpose of creating technology that works for people and society.We are increasingly realizing how our technology use is changing how we delineate work and pleasure, how it is advancing our productivity but at the same time threatening our wellbeing. In choosing a beautiful location like Hawai'i, we hope we highlight the importance of work-life balance and also elicit new discussions on such critical perspectives about the future of interactive technology.Thanks to our massive numbers of volunteers and help from ACM and its SIGCHI members, we are excited to present a vibrant technical and social programme for you to experience. Over six days, participants can join and continue to engage with the CHI community and explore technology and world-class research, and engage in discussions with designers, researchers, students, and practitioners!Ho'omalu-o means "to conserve; to use or manage wisely" in the Hawaiian language. One of our goals for CHI 2020 is to make more sustainable choices wherever we can, recognising, of course, that any travel, especially to locations like ours, has a significant impact on the environment. Working with the Sustainability Chairs, we have chosen recycled, biodegradable or eco-friendly products and engaged with local suppliers, wherever possible. We have implemented options to reduce travel related to the conference organisation by using videoconference meetings as much as possible. We have worked with the CHI Steering and Executive Committee to identify future opportunities to reduce travel and to reduce the number of meetings. We have removed the conference bag and gifts by default and encouraged the selection of more sustainable food choices (including the decision not to serve red meat). We have also chosen reusable or compostable crockery and cutlery where possible and are donating any remaining food to a homeless shelter to avoid food waste.Furthermore, we have chosen to locate all activities in or near the Convention Centre and negotiated deals with hotels nearby to reduce the need for transportation. The Convention Centre itself is the first and only public assembly convention centre to earn LEED v.4 O+M Gold Certification in the United States. In the spirit of Ho'omaluo- , we have also decided to set the default temperature in the venue higher to reduce air condition energy usage.A particular highlight is the Interactivity programme, which will be launched at the Reception on Monday evening, giving a live glimpse into the future with hands-on prototypes, design experiences as well as inspirational technologies.We are also excited to continue the commitment to making CHI, and CHI content, more widely accessible. We will be live-streaming even more paper sessions. We also provide a nursing room, all-gender bathrooms, badge pronouns, a desensitization room and a prayer room.},
location = {Honolulu, HI, USA}
}

@inproceedings{10.1145/3313831.3376813,
author = {Wang, Ruotong and Harper, F. Maxwell and Zhu, Haiyi},
title = {Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376813},
doi = {10.1145/3313831.3376813},
abstract = {Algorithmic decision-making systems are increasingly used throughout the public and private sectors to make important decisions or assist humans in making these decisions with real social consequences. While there has been substantial research in recent years to build fair decision-making algorithms, there has been less research seeking to understand the factors that affect people's perceptions of fairness in these systems, which we argue is also important for their broader acceptance. In this research, we conduct an online experiment to better understand perceptions of fairness, focusing on three sets of factors: algorithm outcomes, algorithm development and deployment procedures, and individual differences. We find that people rate the algorithm as more fair when the algorithm predicts in their favor, even surpassing the negative effects of describing algorithms that are very biased against particular demographic groups. We find that this effect is moderated by several variables, including participants' education level, gender, and several aspects of the development procedure. Our findings suggest that systems that evaluate algorithmic fairness through users' feedback must consider the possibility of "outcome favorability" bias.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {perceived fairness, algorithmoutcome, algorithm development, algorithmic decision-making},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376525,
author = {Kristensson, Per Ola and Lilley, James and Black, Rolf and Waller, Annalu},
title = {A Design Engineering Approach for Quantitatively Exploring Context-Aware Sentence Retrieval for Nonspeaking Individuals with Motor Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376525},
doi = {10.1145/3313831.3376525},
abstract = {Nonspeaking individuals with motor disabilities typically have very low communication rates. This paper proposes a design engineering approach for quantitatively exploring context-aware sentence retrieval as a promising complementary input interface, working in tandem with a word-prediction keyboard. We motivate the need for complementary design engineering methodology in the design of augmentative and alternative communication and explain how such methods can be used to gain additional design insights. We then study the theoretical performance envelopes of a context-aware sentence retrieval system, identifying potential keystroke savings as a function of the parameters of the subsystems, such as the accuracy of the underlying auto-complete word prediction algorithm and the accuracy of sensed context information under varying assumptions. We find that context-aware sentence retrieval has the potential to provide users with considerable improvements in keystroke savings under reasonable parameter assumptions of the underlying subsystems. This highlights how complementary design engineering methods can reveal additional insights into design for augmentative and alternative communication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {sentence prediction, text entry, context-aware text entry, information retrieval, augmentative and alternative communication, design engineering},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376682,
author = {El Ali, Abdallah and Yang, Xingyu and Ananthanarayan, Swamy and R\"{o}ggla, Thomas and Jansen, Jack and Hartcher-O'Brien, Jess and Jansen, Kaspar and Cesar, Pablo},
title = {ThermalWear: Exploring Wearable On-Chest Thermal Displays to Augment Voice Messages with Affect},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376682},
doi = {10.1145/3313831.3376682},
abstract = {Voice is a rich modality for conveying emotions, however emotional prosody production can be situationally or medically impaired. Since thermal displays have been shown to evoke emotions, we explore how thermal stimulation can augment perception of neutrally-spoken voice messages with affect. We designed ThermalWear, a wearable on-chest thermal display, then tested in a controlled study (N=12) the effects of fabric, thermal intensity, and direction of change. Thereafter, we synthesized 12 neutrally-spoken voice messages, validated (N=7) them, then tested (N=12) if thermal stimuli can augment their perception with affect. We found warm and cool stimuli (a) can be perceived on the chest, and quickly without fabric (4.7-5s) (b) do not incur discomfort (c) generally increase arousal of voice messages and (d) increase / decrease message valence, respectively. We discuss how thermal displays can augment voice perception, which can enhance voice assistants and support individuals with emotional prosody impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {wearable, emotion, thermal, chest, voice, prosody, display, affect},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376420,
author = {McNutt, Andrew and Kindlmann, Gordon and Correll, Michael},
title = {Surfacing Visualization Mirages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376420},
doi = {10.1145/3313831.3376420},
abstract = {Dirty data and deceptive design practices can undermine, invert, or invalidate the purported messages of charts and graphs. These failures can arise silently: a conclusion derived from a particular visualization may look plausible unless the analyst looks closer and discovers an issue with the backing data, visual specification, or their own assumptions. We term such silent but significant failures . We describe a conceptual model of mirages and show how they can be generated at every stage of the visual analytics process. We adapt a methodology from software testing, , as a way of automatically surfacing potential mirages at the visual encoding stage of analysis through modifications to the underlying data and chart specification. We show that metamorphic testing can reliably identify mirages across a variety of chart types with relatively little prior knowledge of the data or the domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {deceptive visualization, information visualization, visualization testing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376403,
author = {Qiu, Sihang and Gadiraju, Ujwal and Bozzon, Alessandro},
title = {Improving Worker Engagement Through Conversational Microtask Crowdsourcing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376403},
doi = {10.1145/3313831.3376403},
abstract = {The rise in popularity of conversational agents has enabled humans to interact with machines more naturally. Recent work has shown that crowd workers in microtask marketplaces can complete a variety of human intelligence tasks (HITs) using conversational interfaces with similar output quality compared to the traditional Web interfaces. In this paper, we investigate the effectiveness of using conversational interfaces to improve worker engagement in microtask crowdsourcing. We designed a text-based conversational agent that assists workers in task execution, and tested the performance of workers when interacting with agents having different conversational styles. We conducted a rigorous experimental study on Amazon Mechanical Turk with 800 unique workers, to explore whether the output quality, worker engagement and the perceived cognitive load of workers can be affected by the conversational agent and its conversational styles. Our results show that conversational interfaces can be effective in engaging workers, and a suitable conversational style has potential to improve worker engagement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user engagement, conversational style, cognitive task load, microtask crowdsourcing, conversational interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376388,
author = {Spillane, Brendan and Hoe, Isla and Brady, Mike and Wade, Vincent and Lawless, S\'{e}amus},
title = {Tabloidization versus Credibility: Short Term Gain for Long Term Pain},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376388},
doi = {10.1145/3313831.3376388},
abstract = {Print news agencies have been under pressure from falling sales and advertising revenue and increased competition. As the Internet became the dominant medium, news agencies invested heavily in their websites and apps, providing their news for free, rather than selling a print edition. Reducing the cost of production and removing access barriers such as geographic location had the potential to increase readership and advertising, covering costs and maintaining profits. Unfortunately, this business model has for the most part failed. Many higher quality news agencies are now implementing paywalls on their news websites to once again monetize their product. Others have begun to emulate the look and feel of tabloid news websites to increase readership and stickiness and advertising revenue. This study shows the negative impact of such visual tabloidization on initial impressions of credibility, which may have long term detrimental effects on the news agency.The authors would like to dedicate this paper to the memory of Professor S\'{e}amus "Shay" Lawless, the supervisor of this work who died on May 16th 2019 after fulfilling his dream of summiting Mount Everest.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {first impressions, credibility, tabloidization, news website design, news website aesthetics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376524,
author = {August, Tal and Card, Dallas and Hsieh, Gary and Smith, Noah A. and Reinecke, Katharina},
title = {Explain like I Am a Scientist: The Linguistic Barriers of Entry to r/Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376524},
doi = {10.1145/3313831.3376524},
abstract = {As an online community for discussing research findings, r/science has the potential to contribute to science outreach and communication with a broad audience. Yet previous work suggests that most of the active contributors on r/science are science-educated people rather than a lay general public. One potential reason is that r/science contributors might use a different, more specialized language than used in other subreddits. To investigate this possibility, we analyzed the language used in more than 68 million posts and comments from 12 subreddits from 2018. We show that r/science uses a specialized language that is distinct from other subreddits. Transient (newer) authors of posts and comments on r/science use less specialized language than more frequent authors, and those that leave the community use less specialized language than those that stay, even when comparing their first comments. These findings suggest that the specialized language used in r/science has a gatekeeping effect, preventing participation by people whose language does not align with that used in r/science. By characterizing r/science's specialized language, we contribute guidelines and tools for increasing the number of contributors in r/science.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {science communication, social computing, reddit},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376340,
author = {Mayer, Sven and Reinhardt, Jens and Schweigert, Robin and Jelke, Brighten and Schwind, Valentin and Wolf, Katrin and Henze, Niels},
title = {Improving Humans' Ability to Interpret Deictic Gestures in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376340},
doi = {10.1145/3313831.3376340},
abstract = {Collaborative Virtual Environments (CVEs) offer unique opportunities for human communication. Humans can interact with each other over a distance in any environment and visual embodiment they want. Although deictic gestures are especially important as they can guide other humans' attention, humans make systematic errors when using and interpreting them. Recent work suggests that the interpretation of vertical deictic gestures can be significantly improved by warping the pointing arm. In this paper, we extend previous work by showing that models enable to also improve the interpretation of deictic gestures at targets all around the user. Through a study with 28 participants in a CVE, we analyzed the errors users make when interpreting deictic gestures. We derived a model that rotates the arm of a pointing user's avatar to improve the observing users' accuracy. A second study with 24 participants shows that we can improve observers' accuracy by 22.9%. As our approach is not noticeable for users, it improves their accuracy without requiring them to learn a new interaction technique or distracting from the experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {deictic, ray tracing, virtual reality, correction model},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3334480.3386152,
author = {Strohmeier, Paul},
title = {SIGCHI Outstanding Dissertation Award: Shaping Material Experiences},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3386152},
doi = {10.1145/3334480.3386152},
abstract = {When interacting with materials, we infer many of their properties through tactile stimuli. These stimuli are caused by our manual interaction with the material, they are therefore closely coupled to our actions. Similarly, if we are subjected to a vibrotactile stimulus with a frequency directly coupled to our actions, we do not experience vibration - instead we experience this as a material property. My thesis explores this phenomenon of 'material experience' in three parts. Part I contributes two novel devices, a flexible phone which provides haptic feedback as it is being deformed, and a system which can track a finger and simultaniously provide haptic feedback. Part II investigates how vibration is perceived, when coupled to motion: what are the effects of varying feedback parameters and what are the effects of different types of motion? Part III reflects and contextualizes the findings presented in the previous sections. In this extended abstract I briefly outline the most important aspects of my thesis and questions I've left unanswered, while also reflecting on the writing process.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383152,
author = {Morales Gonz\'{a}lez, Rafael and Freeman, Euan and Georgiou, Orestis},
title = {Levi-Loop: A Mid-Air Gesture Controlled Levitating Particle Game},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383152},
doi = {10.1145/3334480.3383152},
abstract = {Acoustic levitation offers a novel alternative to traditional volumetric displays. With state-of-the-art hand-tracking technology, direct interaction and manipulation of levitating objects in 3D is now possible. Further, adding game-elements like completing simple tasks can encourage participant exploration of new technologies. We have therefore developed a gesture controlled levitating particle game, akin to the classic wire-loop game, that combines all these elements (levitation, hand-tracking, and gameplay) together with physical obstacles. Further, we have designed a gesture input set that constrains false triggering gestures and dropping of the levitating particle.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {gesture input, ultrasound, wire-loop, acoustic levitation, game},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383136,
author = {Huang, Hsin-Yu and Ning, Chih-Wei and Wang, Po-Yao (Cosmos) and Cheng, Jen-Hao and Cheng, Lung-Pan},
title = {Haptic-Go-Round: A Surrounding Platform for Encounter-Type Haptic in Virtual Reality Experiences},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383136},
doi = {10.1145/3334480.3383136},
abstract = {We present Haptic-go-round, a surrounding platform that allows deploying props and devices to provide haptic feedbacks in any direction in virtual reality experiences. The key component of Haptic-go-round is a motorized turntable that rotates the correct haptic device to the right direction at the right time to match what users are about to touch. We implemented a working platform including plug-and-play prop cartridges and a software interface that allow experience designers to agilely add their haptic components and use the platform for their applications.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {props, encounter-type haptic feedback, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383105,
author = {Nilsen, Erik and Safran, Elizabeth and Drake, Peter and Sebok, Bryan},
title = {Playing a Serious Game for Earthquake Preparedness: Effects of Resource Richness and Avatar Choice},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383105},
doi = {10.1145/3334480.3383105},
abstract = {This study investigates the potential for learning about and motivating earthquake preparedness through video game play. 112 participants played a custom-built video game for between 5 and 30 minutes in an experiment involving two avatar selection conditions (choice vs. random assignment) and two avatar power conditions (more resources vs. fewer resources). We assessed pre- and post-test changes in levels of self-efficacy, outcome expectation, and intent to act relating to various preparedness and response actions. We found that playing the game increases these scores significantly in all game conditions immediately after play. Where avatar characteristics were significant, more resources led to higher scores. However, contrary to our predictions, randomly assigned avatars led to higher increases in scores than when players chose and named their avatar. Future studies are planned to explore a variety of other game features designed to maximize motivation and behavior change in young adults.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {self efficacy, earthquake preparedness, serious game, social cognition, avatar},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383091,
author = {Claudino Daffara, Stephanie and Brewer, Anna and Thoravi Kumaravel, Balasaravanan and Hartmann, Bjoern},
title = {Living Paper: Authoring AR Narratives Across Digital and Tangible Media},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383091},
doi = {10.1145/3334480.3383091},
abstract = {Storytelling is an important means for children to build literacy while sharing beliefs, values, and cultural norms. Our work investigates how augmented reality (AR) can fit into creative storytelling practices. We introduce Living Paper, a system for authoring AR narratives that span both digital and tangible media. Our augmented storybook prototype integrates animated AR characters from hand drawings with programmable LED lights that shine through the pages. Living Paper combines the flexibility of digital objects with the tangibility of physical cues to enable the creation of immersive and shareable stories.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {storytelling, tangible interfaces, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383089,
author = {Pomykalski, Patryk and Wo\'{z}niak, Miko\l{}aj P. and Wo\'{z}niak, Pawe\l{} W. and Grudzie\'{n}, Krzysztof and Zhao, Shengdong and Romanowski, Andrzej},
title = {Considering Wake Gestures for Smart Assistant Use},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383089},
doi = {10.1145/3334480.3383089},
abstract = {Smart speakers have become an almost ubiquitous technology as they enable users to access conversational agents easily. Yet, the agents can only be activated using specific voice commands, i.e. a wake word. This, in turn, requires the device to constantly listen to and process sound, which represents a privacy issue for some users. Further, using the trigger word for the agent in a conversation with another human may lead to accidental triggers. Here, we propose using gestural triggers for conversational agents. We conducted gesture elicitation to identify five candidate gestures. We then conducted a user study to investigate the acceptability and effort required to perform the gestures. Initial results indicate that the snap gesture shows the most potential. Our work contributes initial insights on using smart speakers with ubiquitous sensing.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {gesture, smart assistant, gesture elicitation, smart speaker, gestural input},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383079,
author = {Qian, Jing and Young-Ng, Meredith and Li, Xiangyu and Cheung, Angel and Yang, Fumeng and Huang, Jeff},
title = {Portalware: A Smartphone-Wearable Dual-Display System for Expanding the Free-Hand Interaction Region in Augmented Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383079},
doi = {10.1145/3334480.3383079},
abstract = {Free-hand manipulation in smartphone augmented reality (AR) enables users to directly interact with virtual contents using their hands. However, human hands can ergonomically move in a broader range than a smartphone's field of view (FOV) can capture, requiring users to be aware of the limited usable interaction and viewing regions at all times. We present Portalware, a smartphone-wearable dual-display system that expands the usable interaction region for free-hand manipulation and enables users to receive visual feedback outside the smartphone's view. The wearable is a lightweight, low-cost display that shares the same AR environment in real-time with the smartphone.This setup empowers AR applications such as mid-air drawing and object manipulation by providing a 180-degree horizontal interaction region in front of the user. Other potential applications include wearing the smartphone like a pendant while using Portalware to continue interacting with AR objects. Without having to hold their phone up with their hand, users can benefit from resting their arms as needed. Finally, we discuss usability explorations, potential interactions, and future plans for empirical studies.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {wearable, 3D manipulation, free-hand manipulation, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383036,
author = {Eguchi, Soya and Yazaki, Yukako and Kato, Riku and Arita, Yusaku and Moriya, Takumi and Tanaka, Hiroya},
title = {Proto-Chair: Posture-Sensing Smart Furniture with 3D-Printed Auxetics},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383036},
doi = {10.1145/3334480.3383036},
abstract = {Public space/furniture are amongst the new domains to apply a data-driven approach of design intervention and improvements. Open space is essentially dynamic, livable and interactive. Various types of people spend time for various purposes. Therefore, the "Measure-Test-Refine" loop is applicable for improving open spaces gradually.In this research, we developed our original smart chair called "Proto-Chair" that can contribute to the new design method of public space. Our chair is made with 3D-printed soft auxetic patterns. It is morphable allowing users to sit in various ways. Also, our chair is equipped with two sensors, which collect data stream to distinguish four different states of the chair. Long-term sensor stream can be stored and used to refine the furniture.In this paper, we propose our concept, prototypes, sensing methods and results of experiments. We also introduce our future vision of a sensor-based public design platform.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {3D printing, morphing design, implicit interaction, auxetic pattern, public furniture},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383025,
author = {Upadhyay, Pooja},
title = {Comparing Non-Visual and Visual Information Foraging on The Web},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383025},
doi = {10.1145/3334480.3383025},
abstract = {Graphical user web interfaces (GUIs) afford visual consumption and sensemaking of information, but present challenges for auditory, and often sequential, information seeking for people using screen readers. Information foraging theory illustrates that users' information behavior is guided by the use of information scent (mostly visual in GUIs) to assess value and cost of accessing information relevant to their goal, and rational decisions to maximize gain of information. Previous research about adaptive browsing behavior of screen reader users is associated with a lack of webpage usability. In this study, we observed and compared the information seeking behavior of ten sighted and ten screen reader users. Findings show that screen reader users demonstrate adapted mental models of the visual information search interface. Additionally, their adaptive search result exploration strategies in the context of query intent highlight key concern areas in specific parts of the search process.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {information retrieval, information behavior, assistive technology, adaptive browsing strategies, accessibility, non-visual web access, non-visual search behavior, non-visual information foraging},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383021,
author = {Zhang, Min and Bandara, Arosha K. and Price, Blaine and Pike, Graham and Walkington, Zoe and Elphick, Camilla and Frumkin, Lara and Philpot, Richard and Levine, Mark and Stuart, Avelie and Nuseibeh, Bashar},
title = {Designing Technologies for Community Policing},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383021},
doi = {10.1145/3334480.3383021},
abstract = {Community policing faces a combination of new challenges and opportunities due to both citizens and police adopting new digital technologies. However, there is limited scholarly work providing evidence for how technologies assist citizens' interactions with the police. This paper reports preliminary findings from interviews with 13 participants, both citizens and police officers, in England. We recognize four key types of actors in the current practice of community policing, alongside existing technologies and challenges faced by citizens and the police. We conclude with three design implications for improving citizen-police engagement.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {collective action, community policing, crime, trust},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383012,
author = {Mottelson, Aske and Djurslev, Anders Thrue},
title = {Disseminating Scientific Development Through Artistic Practice: The HCI History Poster},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383012},
doi = {10.1145/3334480.3383012},
abstract = {This paper presents two contributions: (i) an algorithm for generating visualizations of the historical interfield relations of a topic within a scientific corpus by parsing scientific literature and linking it using citation metrics, and (ii) a poster generated using aforementioned algorithm, that depicts the historical development of 'interaction' within the field of Human-Computer Interaction, based on all CHI papers and their citation data from Google Scholar. Furthermore, we discuss possibilities and limitations of disseminating scientific developments through artistic practice.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {poster, visualization, art history, scientometrics, HCI},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383008,
author = {Mechtley, Adam},
title = {API as Curriculum: Designing High-Level API Affordances as Instructional Scaffolds},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383008},
doi = {10.1145/3334480.3383008},
abstract = {APIs have been recognized in the CHI community and beyond as designed objects worthy of usability analysis. Some work in this vein has investigated the learnability of APIs in particular. Drawing on activity theory, we argue that APIs can also potentially have broader learning consequences for their users. By mediating interactions with code, APIs can shape their users' understanding of computing problems. We thus suggest that, by envisioning high-level API affordances as scaffolds, API designers can not only enhance users' productivity, but they can also help drive adoption of software components attempting to radically innovate on their past inheritance. We propose scaffold design recommendations that can augment existing API usability frameworks.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {application programming interface, data-oriented design, computing education, API usability},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383003,
author = {Shin, Jaeeun and Cho, Jundong and Lee, Sangwon},
title = {Please Touch Color: Tactile-Color Texture Design for The Visually Impaired},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383003},
doi = {10.1145/3334480.3383003},
abstract = {This study aims at developing a 3D tactile system to help visually impaired people recognize colors via texture perception when they appreciate art paintings. The system is designed based on fundamentals of color perception, tactile acuity, and braille information. The scheme of tactile-color texture was designed to be intuitively learnable for the visually impaired, who has a lack of color perception. The result of focus interviews showed that visually impaired people could significantly distinguish and recognize the variation of color by grating textures. The study of color perception from grating texture indicates tactile efficiency of color recognition as a method for appreciating art painting. Regarding the practical approach not only can be used to improve accessibilities for blind people of art museums but can be references to develop 3D printed haptic devices.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {color recognition, the visually impaired, cross-modal association, accessibility, haptic perception, universal design, 3D printed model},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382996,
author = {Mohaddesi, Omid and Machado, Tiago and Harteveld, Casper},
title = {Learning from Gamettes: Imitating Human Behavior in Supply Chain Decisions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382996},
doi = {10.1145/3334480.3382996},
abstract = {Gamettes are playful tools for agent-based participatory simulation and have shown to be valid for collecting rich behavioral data from human decision-makers. However, there is still a question that how such data can be used to create or update agent-based and behavioral models. In this paper, we evaluate and compare the performance of different methods for imitating human behavior. We use extracted data from gamettes in an empirical study on supply chain decisions, and compare the performance of a nonlinear regression model with two imitation learning algorithms. Our results demonstrate that each method is capable of modeling and thus predicting human behavior by considering multiple trajectories from different players.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {supply chain, imitation learning, human behavior, decision-making, gamette},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382974,
author = {Olson, Danielle Marie and Soliman, Nouran and Wang, Angela and Price, Magdalena and Sahu, Rita and Harrell, D. Fox},
title = {Breakbeat Narratives: A Personalized, Conversational Interactive Storytelling System for Museum Education},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382974},
doi = {10.1145/3334480.3382974},
abstract = {We introduce a novel interactive narrative exhibit supporting general public learning about Hip Hop culture and history developed as a collaboration of the MIT Center for Advanced Virtuality, the Universal Hip Hop Museum, and Microsoft and supported by the TunesMap Educational Foundation and internationally known Afrofuturist artists Black Kirby. The exhibit's narrative system is personalized by categorizing users based on evaluating their input data light of a social psychology-based model based in musical identity theory. The system uses user input to determine which interactive narrative and customized music playlist to present to the user. The system has been deployed as the central interactive display within the [R]Evolution of Hip Hop for an exhibit of the Universal Hip Hop Museum. Future work will involve analysis of user feedback data from the thousands of local and international exhibit visitors to determine the impact of personalization on visitor engagement, satisfaction, and learning.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {interactive narrative technologies, personalization, learning, educational technology, museums},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382933,
author = {Ikematsu, Kaori and Tsubouchi, Kota and Yamanaka, Shota},
title = {PredicTaps: Latency Reduction Technique for Single-Taps Based on Recognition for Single-Tap or Double-Tap},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382933},
doi = {10.1145/3334480.3382933},
abstract = {In general, a system with touch input waits for a certain period of time (typically 350 -- 500 ms) for a subsequent tap to determine whether the initial tap was a single tap or the first tap of a double tap. This results in latency of hundreds of milliseconds for a single-tap event. To reduce the latency, we propose a novel machine-learning-based tap recognition method called "PredicTaps". In the PredicTaps method, by using touch-event data gathered from the capacitive touch surface, the system immediately predicts whether a detected tap is a single tap or the first tap of a double tap. Then, in accordance with the prediction, the system determines whether to execute a single-tap event immediately or wait for a subsequent second tap. This paper reports the feasibility study of PredicTaps.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {touch inputs, double-tap, single-tap, latency},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382923,
author = {Freeman, Guo and Zamanifard, Samaneh and Maloney, Divine and Adkins, Alexandra},
title = {My Body, My Avatar: How People Perceive Their Avatars in Social Virtual Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382923},
doi = {10.1145/3334480.3382923},
abstract = {The perception and experience of avatars has been critical to understand the social dynamics in virtual environments, online gaming, and collaborative systems. How would emerging sociotechnical systems further complicate the role of avatars in our online social lives? In this paper we focus on how people perceive and understand their avatars in social virtual reality (VR) - 3D virtual spaces where multiple users can interact with one another through VR head-mounted displays (HMDs). Based on 30 interviews, we identified three key themes emerging in people's perceptions and experiences of their avatars across various social VR applications. Our study contributes to further improving social VR technologies and better understanding emerging social interaction dynamics and consequences within social VR.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {avatar, social virtual reality, virtual worlds},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382898,
author = {Dove, Graham and Seals, Ayanna and Nov, Oded},
title = {Socially-Informed Sorting for Guiding Personal Finance Choices},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382898},
doi = {10.1145/3334480.3382898},
abstract = {Planning for personal financial security is complex, and better-informed investors are likely to make better investment choices. However, the number of alternatives presented by most personal finance platforms pose novices a dual challenge of choice overload coupled with a lack of domain knowledge. We present a study investigating socially-informed sorting, in which users are offered subtle guidance in the form of visual and textual cues that aim to encourage information-seeking when choosing between large numbers of options. We evaluate this approach in an online experiment in which participants go through ten rounds of retirement saving budget allocation, making choices among 77 different funds. While we found that this technique increased novice investors' information-seeking, and offered significant benefit in terms of return performance, it may also be detrimental for more experienced investors. We discuss these findings in light of prior research.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {personal finance, social search, choice overload},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382877,
author = {DiCosola III, Blake M. and Neff, Gina},
title = {Using Social Comparisons to Facilitate Healthier Choices in Online Grocery Shopping Contexts},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382877},
doi = {10.1145/3334480.3382877},
abstract = {This exploratory research examines how we might nudge consumers towards making healthier food choices in online grocery shopping or other digitally mediated food consumption contexts. Our pilot study investigated how different forms of social comparisons could be used to encourage consumers to reduce the number of calories contained in their online grocery basket. Our findings show that participants who were less interested in trying new diets were more willing to reduce calories when presented with a comparison to people unlike them, an out-group member comparison, while those who were interested in trying new diets were more willing to reduce calories regardless of social comparison type. These findings imply that one size does not fit all when nudging. More research is needed to see how social comparisons influence the effectiveness of digital health behavior projects.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {consumer behavior, shopping, social influence, digital, food, health, nudging, intervention, decision making, online, nutrition, diet, persuasive communication, choice},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382867,
author = {Lee, Juyoung and Lee, Myungho and Kim, Gerard Jounghyun and Hwang, Jae-In},
title = {Effects of Virtual Gait Visualization in Walk-in-Place on Body Ownership and Presence},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382867},
doi = {10.1145/3334480.3382867},
abstract = {We investigate the effects of different ways of visualizing the virtual gait of the avatar in the context of Walk-in-Place (WIP) based navigation in a virtual environment (VE). In our study, participants navigated through a VE using the WIP method while inhabiting an avatar. We varied the leg motions of the avatar while performing the WIP gesture: (1) Fixed Body the legs stood still; (2) Prerecorded Animation the legs moved in a fixed predetermined pace (plausible but not in accordance to that of the user in general); (3) Synchronized Motion the legs moved according (synchronized) to the those of the users. Our results indicate that the sense of presence improved significantly by visualizing the leg movement, synchronized or not. This in turn further enhanced the sense of body ownership especially when the leg motion was synchronized to that of the user (Synchronized Motion). However, a significant level of simulation sickness was reported when the virtual leg motion did not match the user's (Fixed Body and Prerecorded Animation). We discuss the implications for representing the avatar locomotion in immersive virtual environments.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {presence, virtual reality, body ownership, walk-in-place},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382856,
author = {Kim, Jung-Hwa and Jeong, Jin-Woo},
title = {A Preliminary Study on Performance Evaluation of Multi-View Multi-Modal Gaze Estimation under Challenging Conditions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382856},
doi = {10.1145/3334480.3382856},
abstract = {In this paper, we address gaze estimation under practical and challenging conditions. Multi-view and multi-modal learning have been considered useful for various complex tasks; however, an in-depth analysis or a large-scale dataset on multi-view, multi-modal gaze estimation under a long-distance setup with a low illumination is still very limited. To address these limitations, first, we construct a dataset of images captured under challenging conditions. And we propose a simple deep learning architecture that can handle multi-view multi-modal data for gaze estimation. Finally, we conduct a performance evaluation of the proposed network with the constructed dataset to understand the effects of multiple views of a user and multi-modality (RGB, depth, and infrared). We report various findings from our preliminary experimental results and expect this would be helpful for gaze estimation studies to deal with challenging conditions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {multi-modal interaction, deep neural networks, multi-view learning, gaze estimation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382834,
author = {Hoskin, Elizabeth and Singh, Aditi and Oddy, Nicola and Schneider, Adrian L. Jessup and Trepanier, Gabrielle and Trudel, Chantal and Girouard, Audrey},
title = {Assessing the Experience of People with Autism at the Canada Science and Technology Museum},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382834},
doi = {10.1145/3334480.3382834},
abstract = {To provide universal accessibility, public community spaces such as museums must be designed considering the experience of all patrons, including visitors living with Autism Spectrum Disorder. To develop a better understanding of the experience of visitors with autism at the Canada Science and Technology Museum, we invited four school children and one adult male for a visit, all of whom identified as being on the spectrum. They were joined by their support persons. We interviewed the adult, his caregiver and the teaching staff accompanying the school children. We analyzed our interviews and observation notes using thematic analysis to formulate key findings and suggestions to enhance the experience for autistic people. They include adding elements at a variety of developmental levels, offering options to reduce sensory stimulation, improving navigational resources and providing more resources for support persons.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {website efficacy, autism spectrum disorder, accessibility, wayfinding, museum experience},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381657,
author = {van Greevenbroek, Roos and Kallina, Emma and Klotz, Tobias and Snitter, Luke},
title = {Make Some Noise for Nature: A Multisensory Public Display Game Experience},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381657},
doi = {10.1145/3334480.3381657},
abstract = {The rate at which species are becoming extinct has never been this fast and human impact on the environment is the main reason. To promote behavioural change, we developed a game to raise awareness amongst the generation of young creatives, and provide them with knowledge about everyday behaviours that are beneficial for, or threatening to a specific endangered animal. Using a human-centred design process, we gathered user requirements and developed a multisensory educational group game in which players have to cooperate to control an animal and avoid harmful or collect helpful items using voice and movement. Users who played the game during a final Wizard-of-Oz user test found the game highly engaging, successful in raising awareness, and reported increased motivation to take action in their personal lives. Our innovative game could be of great value in decreasing human-induced animal extinction.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {extinct animals, behavioural change, voice ui, multisensor, environment, educational, group game},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381653,
author = {Yang, Szu-Yu and John, Swaroop},
title = {Team Bingo: A Game That Increases Physical Activity and Social Interaction for Seniors in a Community Setting},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381653},
doi = {10.1145/3334480.3381653},
abstract = {In the United States, the community center is one of the essential resources for seniors by providing seniors programs and services, such as meals, information, transportation, and recreation. For seniors, it is necessary to have a good social network and continuous physical activities to maintain good overall health. Currently, although some older adults depend on community centers to meet these needs, they still sometimes feel less connected with others. In this paper, we design the game, Team Bingo, that aims to reduce social isolation and increase physical activity among seniors in a community setting.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {community centre, games, physical activity, seniors, socialization},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381438,
author = {Igarashi, Toshiharu},
title = {Medi-Torch: A New Framework for User-Friendly Hepatobiliary Cancer Guidelines for Patients},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381438},
doi = {10.1145/3334480.3381438},
abstract = {Hepatobiliary cancer patients and the high-risk population have a unique need to be constantly acquiring the latest prevention and treatment information. A typical example of an interface for presenting information for hepatobiliary cancer is the clinical guideline and guideline for patients. However, no detailed discussion has been made on the framework guideline for patients.In this paper, we proposed user-friendly hepatobiliary cancer guidelines for patients from previous research and experts review. From the evaluation by general users and experts opinion, it is considered to be sufficiently practical.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {clinical guideline, application of natural language processing, hepatobiliary cancer, guidelines for patients, human-centered design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375210,
author = {Gomez Ruiz, Eduardo and Saha Mitra, Saswati and Lind, Shaun and Khurana, Shyna and Conte, Rafael and Williams, Adam},
title = {Building a Program That Rewards and Gives Back to Drivers},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375210},
doi = {10.1145/3334480.3375210},
abstract = {This paper will introduce Uber's cross-disciplinary insights driven process behind building Uber Pro, a global loyalty program for drivers. Uber Pro's global rollout was preceded by extensive, original research, design and implementation. In this paper, we will cover the discovery phase lightly and go more in depth into the actual user and business decisions that needed to be taken by UX Research in collaboration with Product, Operations and Data Science to ensure we rolled out the right set of benefits in our key markets in a short time and enabled local teams to own the benefits platform to customize further, in an ongoing fashion. As Uber Pro grows to be a record-setting global rewards program, we are committed to developing close ties to customers around the world, via research and analytics that put users first.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {global research, ethnography, data science, drivers, Uber, rewards program},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375203,
author = {Mucha, Henrik and Mevi\ss{}en, Dennis and Robert, Sebastian and Jacobi, Ricarda and Meyer, Kirsten and Heusler, Winfried and Arztmann, Daniel},
title = {Co-Design Futures for AI and Space: A Workbook Sprint},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375203},
doi = {10.1145/3334480.3375203},
abstract = {Artificial Intelligence (AI) is continuously moving into our surroundings. In its various forms, it has the potential to disrupt most aspects of human life. Yet, the discourse around AI has long been by experts and for experts. In this paper, we argue for a participatory approach towards designing human-AI interactions. We outline how we used design methodology to organise an interdisciplinary workshop with a diverse group of students – a workbook sprint with 45 participants from four different programs and 13 countries – to develop speculative design futures in five focus areas. We then provide insights into our findings and share our lessons learned regarding our workshop topic – AI and Space – our process, and our research. We learned that involving non-experts in complex technical discourses – such as AI – through the structural rigour of design methodology is a viable approach. We then conclude by laying out how others might use our findings and initiate their own workbook sprint to explore complex technologies in a human-centred way.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {artificial intelligence, design workbook, co-design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375165,
author = {Daiber, Florian and Degraen, Donald and Zenner, Andr\'{e} and Steinicke, Frank and Ariza N\'{u}\~{n}ez, Oscar Javier and Simeone, Adalberto L.},
title = {Everyday Proxy Objects for Virtual Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375165},
doi = {10.1145/3334480.3375165},
abstract = {Immersive virtual experiences are becoming ubiquitous in our daily lives. Besides visual and auditory feedback, other senses like haptics, smell and taste can enhance immersion in virtual environments. Most solutions presented in the past require specialized hardware to provide appropriate feedback. To mitigate this need, researchers conceptualized approaches leveraging everyday physical objects as proxies instead. Transferring these approaches to varying physical environments and conditions, however, poses significant challenges to a variety of disciplines such as HCI, VR, haptics, tracking, perceptual science, design, etc. This workshop will explore the integration of everyday items for multi-sensory feedback in virtual experiences and sets course for respective future research endeavors. Since the community still seems to lack a cohesive agenda for advancing this domain, the goal of this workshop is to bring together individuals interested in everyday proxy objects to review past work, build a unifying research agenda, share ongoing work, and encourage collaboration.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {everyday objects, immersion, virtual reality, substitutional reality, multi-sensory feedback, proxies},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375048,
author = {Callegaro, Mario and Villar, Ana and Sedley, Aaron},
title = {Online Survey Methodology for User Experience Research: A Framework for Utility and Quality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375048},
doi = {10.1145/3334480.3375048},
abstract = {Online surveys are an extremely popular research method in HCI and UX research. Surveys are often perceived to be easy to create [1] and sometimes used even if they are not the most appropriate method [7]. This course will review state-of-the-art methods, drawing from the past 20 years of research on online surveys [3, 4] and present applications for the user experience and HCI context [8]. Upon completion of the class, attendees will have a framework of survey quality, a roadmap to plan &amp; implement, and resources to extend their knowledge of surveys for HCI and UX research. The instructors have conducted hundreds of surveys that tech companies use on a regular basis to inform business and product decisions. They also consult and reviews surveys on a daily basis. Finally, they regularly teach survey research, and have been instrumental in connecting User Experience Research with survey research principles and measurement best practices.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {probability vs. nonprobability sampling, mobile web surveys, ethical, accessibility, legal considerations for web surveys, total survey error, panel surveys, in product surveys, translation and localization, questionnaire design, cognitive processes of survey response, incentives, web surveys, standardized usability questionnaires},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3386148,
author = {Canfield Smith, David},
title = {SIGCHI Lifetime Research Award Talk: Icons, Metaphor, and End-User Programming},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3386148},
doi = {10.1145/3334480.3386148},
abstract = {Throughout my career I have tried to make computers easier to use-and therefore more useful- for ordinary people. Along the way, I've invented a few things that have proven to be helpful. At the operating system level, I tried to make the interface to applications more intuitive by introducing the concepts of icons and metaphor. Within applications, I tried to make the interface simpler by reducing the number of commands, making them more general ("universal"), and making their options and parameters visible with dialog boxes. I also tried to make it possible for ordinary people to program computers, since as long as people can only use predefined applications, they will be able to access only a fraction of the power of computers.These efforts have all appeared in commercial products, from the Xerox Star office computer to Stagecast Creator's educational software. These innovations have affected the personal computer industry in significant ways.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {end-user programming, dialog boxes, programming by demonstration, user interface, desktop metaphor, educational software, icons, universal commands},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383180,
author = {Tan, Nicole and Ospina, Johan and Clark, Patrick and Sadalgi, Shrenik and Humphreys, Molly},
title = {LightSpace: An Interactive, Projection-Mapped (Doll)House},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383180},
doi = {10.1145/3334480.3383180},
abstract = {The home of the future will be an interface (in itself) much like current, omni-present screen-based, interfaces. Designing the interior of your home will be as gratifying and immediate as a click is today, with modular digital furniture becoming the status quo and their design democratized and in the hands of users.In this paper, we present LightSpace, an exploration for the future of design for the home. LightSpace focuses on a very specific solution to a simple problem – designing and stylizing an entire room with playful delight in mind. With our small-scale proof-of-concept tangible user interface (TUI), we account for the direct physicality of designing within a physical space by allowing users to move mini 3D printed furniture in a projection mapped dollhouse and switch materials using a magical wand (NFC).This exploration acts as a small-scale vehicle for us to investigate the usefulness, feasibility, and possible ubiquity for such an interface in the future.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {projection mapping, interactive, dynamic interfaces, tangible interfaces, spatial augmented reality, nfc},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383088,
author = {Han, Dongqi and Neustaedter, Carman and Tan, Zixuan},
title = {Concerns of Primary Care Physicians for Video-Based Visits},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383088},
doi = {10.1145/3334480.3383088},
abstract = {Video conferencing is now a reality for primary care appointments. Although typical systems akin to Skype have been deployed for video appointments, it is not clear how these systems should be designed to meet the real needs of doctors. We conducted contextual interviews with family physicians to explore how to support video-based appointments with patients. Our findings reveal challenges in different themes and presents insights on design implications to support doctors' control in the workflow, privacy protection, and camera work for mobile devices.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {computer-mediated communication, mobile video communication, primary care appointments},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383078,
author = {Wolters, Maria K. and Li, Shuobing and Wang, Haoyu and Yang, Xinyu and Guo, Yao},
title = {Does the Presence of Privacy Relevant Information Affect App Market Choice?},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383078},
doi = {10.1145/3334480.3383078},
abstract = {While in most countries, Google Play and Apple App Store dominate, Chinese mobile phone users can choose among dozens of different app markets, which differ greatly in the information presented. This makes the Chinese mobile ecosystem a unique case study for investigating whether users actively choose app markets that conform to their preferences. We investigated this question in a survey of 200 Chinese users aged 18-49. Scenarios covered apps that require disclosure of different types of sensitive information (shopping, dating, health), with gaming as a baseline. Users preferred markets that were easy to use and had a wide choice of apps. Only nine users highlighted security as a feature. Despite this, they primarily used only one app market - the pre-installed one. App-market specific features were important for the game scenario, but less important for all others. We suggest that download decisions for most apps are made before users enter an app market, and discuss implications for presenting privacy and security information.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {understanding users, app markets, privacy, security},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383071,
author = {Dhariwal, Manuj and Dhariwal, Shruti},
title = {Let's Chance: Playful Probabilistic Programming for Children},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383071},
doi = {10.1145/3334480.3383071},
abstract = {Probabilistic thinking has been one of the most powerful ideas in the history of science, and it is rapidly gaining even more relevance as it lies at the core of artificial intelligence (AI) systems and machine learning (ML) algorithms that are increasingly pervading our everyday lives. In this paper, we introduce Let's Chance-a novel computational microworld that extends the widely popular Scratch Programming Language with new types of code blocks and representations that make it accessible for children to encounter and tinker with the rich ideas and sophisticated concepts of probabilistic modeling and learning. Using the tool, children can imagine and code their own expressive, playful, and personally meaningful probabilistic projects, such as-generative art, music, or text; chance-based games and stories; interactive visualizations; and even advanced projects for making a computer learn from input data using simple Markov models of probabilistic learning, among many other creative possibilities.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {scratch, creative coding, learning., probabilistic programming, probability, AI education, children},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382994,
author = {Burgess, Cameron and Lockton, Dan and Albert, Maayan and Cardoso Llach, Daniel},
title = {Stamper: An Artboard-Oriented Creative Coding Environment},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382994},
doi = {10.1145/3334480.3382994},
abstract = {Contemporary WYSIWYG (what-you-see-is-what-you-get) design software utilizes digital Artboards which are finite graphics frames that sit atop a scrollable zooming canvas; where many graphics frames can be arbitrarily arranged, scaled and duplicated to explore and juxtapose design ideas. Despite creative practitioners increasingly writing code to explore design spaces, programming environments for Creative Coding regularly only display one graphics frame per program. This hinders the non-linear nature of the creative process where seeing a trail of process work can spark new ideas. We propose bridging this gap and introduce Stamper, an Artboard-Oriented authoring environment for the popular creative coding library p5.js.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {design tools, creative coding, programming, authoring environments},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382986,
author = {Zhang, Qiaoning and Yang, X. Jessie and Robert, Lionel Peter},
title = {Expectations and Trust in Automated Vehicles},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382986},
doi = {10.1145/3334480.3382986},
abstract = {A lack of trust is a major barrier to the adoptions of Automated Vehicles (AVs). Given the ties between expectation and trust, this study employs the expectation-confirmation theory to investigate trust in AVs. An online survey was used to collect data including expectation, perceived performance, and trust in AVs from 443 participants which represent U.S. driver population. Using the polynomial regression and response surface methodology, we found that higher trust is engendered when perceived performance is higher than expectation, and perceived risk can moderate the relationship between expectation confirmation and trust in AVs. Results have important theoretical and practical implications.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {automated vehicles(AVs), trust, expectation confirmation theory, risk, performance},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382948,
author = {Park, Do Eun and Shin, Yee-Jin and Park, EunAh and Choi, In Ae and Song, Woo Yeon and Kim, Jinwoo},
title = {Designing a Voice-Bot to Promote Better Mental Health: UX Design for Digital Therapeutics on ADHD Patients},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382948},
doi = {10.1145/3334480.3382948},
abstract = {Attention Deficit Hyperactivity Disorder (ADHD) child patients face difficulty in maintaining focus of and completing daily tasks due to their impaired executive function. Failure in such aspects leads to the formation of negative self-images as well as sub-optimal relationships with parents. This investigative research presents a voice-bot and conversational agent design intervention supporting both the ADHD child patients and their parents in dealing with daily tasks. We conducted patient's parent interviews, created voice-bot scenario designs and conducted prototyping. Potential therapeutic benefits and assistive technology user experience perspectives are discussed in this paper.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {scaffolding, conversational user interaction, attention deficit hyperactivity disorder (ADHD), assistive technology, executive function, conversational agent},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382941,
author = {Cheung, Victor and Girouard, Audrey},
title = {Exploring Acceptability and Utility of Deformable Interactive Garment Buttons},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382941},
doi = {10.1145/3334480.3382941},
abstract = {Wearable devices have received tremendous interest in fitness and personal assistance sectors. Yet most are still worn as auxiliary hardware; falling short in ubiquity and convenience. We examine the potential of a novel deformable wearable device that embeds interactive technologies into garment buttons, and seek to enhance the form factor of buttons to incorporate deformation and motion as inputs. We surveyed garment buttons in everyday clothing to inform an exploratory study, where we investigated social acceptance and elicited interaction gestures using mockups. Our results indicate people mostly prefer smaller sizes, and regard sleeves as the most comfortable area to operate and look at when seen by others. Based on our findings, we discuss potential context of use, possible applications, and future work.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {wearables, deformable user interfaces, buttons, smart clothing, ubiquitous computing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382895,
author = {Xue, Tong and Ghosh, Surjya and Ding, Gangyi and El Ali, Abdallah and Cesar, Pablo},
title = {Designing Real-Time, Continuous Emotion Annotation Techniques for 360° VR Videos},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382895},
doi = {10.1145/3334480.3382895},
abstract = {With the increasing availability of head-mounted displays (HMDs) that show immersive 360° VR content, it is important to understand to what extent these immersive experiences can evoke emotions. Typically to collect emotion ground truth labels, users rate videos through post-experience self-reports that are discrete in nature. However, post-stimuli self-reports are temporally imprecise, especially after watching 360° videos. In this work, we design six continuous emotion annotation techniques for the Oculus Rift HMD aimed at minimizing workload and distraction. Based on a co-design session with six experts, we contribute HaloLight and DotSize, two continuous annotation methods deemed unobtrusive and easy to understand. We discuss the next challenges for evaluating the usability of these techniques, and reliability of continuous annotations.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {continuous, 360 video, visualization, emotion annotation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382892,
author = {Ragot, Martin and Martin, Nicolas and Cojean, Salom\'{e}},
title = {AI-Generated vs. Human Artworks. A Perception Bias Towards Artificial Intelligence?},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382892},
doi = {10.1145/3334480.3382892},
abstract = {Via generative adversarial networks (GANs), artificial intelligence (AI) has influenced many areas, especially the artistic field, as symbol of a human task. In human-computer interaction (HCI) studies, perception biases against AI, machines, or computers are generally cited. However, experimental evidence is still lacking. This paper presents a wide-scale experiment in which 565 participants are asked to evaluate paintings (which were created by humans or AI) on four dimensions: liking, perceived beauty, novelty, and meaning. A priming effect is evaluated using two between-subject conditions: Artworks presented as created by an AI, and artworks presented as created by a human artist. Finally, the paintings perceived as being drawn by human are evaluated significantly more highly than those perceived as being made by AI. Thus, using such a methodology and sample in an unprecedented way, the results show a negative bias of perception towards AI and a preference bias towards human systems.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {artificial intelligence, authorship, GAN, arts, can, bias, painting, computational creativity, AI},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382881,
author = {Lee, Seul Chan and Nadri, Chihab and Sanghavi, Harsh and Jeon, Myounghoon},
title = {Exploring User Needs and Design Requirements in Fully Automated Vehicles},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382881},
doi = {10.1145/3334480.3382881},
abstract = {An automated driving system is expected to pave the way for a new area of user experience in a vehicle. However, few studies have been conducted on the understanding what people want to do and how the vehicle can support user needs, specifically, in level 5, fully automated vehicles (FAVs). Therefore, the present study aimed at exploring user needs and design requirements for potential activities in FAVs. We conducted expert interviews and focus group interviews to collect data, and the qualitative analysis was applied to elicit user needs and design requirements. Twelve user needs and general design considerations in four categories were found. The findings will contribute to enhancing user experience in future FAVs by considering user needs and design requirements we elicited.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {interview study, fully automated vehicle, automated driving, qualitative analysis, user needs, design requirements},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

