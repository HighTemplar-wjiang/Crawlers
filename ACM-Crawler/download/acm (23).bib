@inproceedings{10.1145/3411764.3446866,
author = {Ens, Barrett and Bach, Benjamin and Cordeil, Maxime and Engelke, Ulrich and Serrano, Marcos and Willett, Wesley and Prouzeau, Arnaud and Anthes, Christoph and B\"{u}schel, Wolfgang and Dunne, Cody and Dwyer, Tim and Grubert, Jens and Haga, Jason H. and Kirshenbaum, Nurit and Kobayashi, Dylan and Lin, Tica and Olaosebikan, Monsurat and Pointecker, Fabian and Saffo, David and Saquib, Nazmus and Schmalstieg, Dieter and Szafir, Danielle Albers and Whitlock, Matt and Yang, Yalong},
title = {Grand Challenges in Immersive Analytics},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3446866},
doi = {10.1145/3411764.3446866},
abstract = {Immersive Analytics is a quickly evolving field that unites several areas such as visualisation, immersive environments, and human-computer interaction to support human data analysis with emerging technologies. This research has thrived over the past years with multiple workshops, seminars, and a growing body of publications, spanning several conferences. Given the rapid advancement of interaction technologies and novel application domains, this paper aims toward a broader research agenda to enable widespread adoption. We present 17 key research challenges developed over multiple sessions by a diverse group of 24 international experts, initiated from a virtual scientific workshop at ACM CHI 2020. These challenges aim to coordinate future work by providing a systematic roadmap of current directions and impending hurdles to facilitate productive and effective applications for Immersive Analytics.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {17},
keywords = {Immersive analytics, data visualisation, grand research challenges, augmented reality, virtual reality},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3446863,
author = {Gilad, Zohar and Amir, Ofra and Levontin, Liat},
title = {The Effects of Warmth and Competence Perceptions on Users' Choice of an AI System},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3446863},
doi = {10.1145/3411764.3446863},
abstract = {People increasingly rely on Artificial Intelligence (AI) based systems to aid decision-making in various domains and often face a choice between alternative systems. We explored the effects of users' perception of AI systems' warmth (perceived intent) and competence (perceived ability) on their choices. In a series of studies, we manipulated AI systems' warmth and competence levels. We show that, similar to the judgments of other people, there is often primacy for warmth over competence. Specifically, when faced with a choice between a high-competence system and a high-warmth system, more participants preferred the high-warmth system. Moreover, the precedence of warmth persisted even when the high-warmth system was overtly deficient in its competence compared to an alternative high competence-low warmth system. The current research proposes that it may be vital for AI systems designers to consider and communicate the system's warmth characteristics to its potential users.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {583},
numpages = {13},
keywords = {Artificial intelligence, Warmth, Competence},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445782,
author = {Rhys Cox, Samuel and Wang, Yunlong and Abdul, Ashraf and von der Weth, Christian and Y. Lim, Brian},
title = {Directed Diversity: Leveraging Language Embedding Distances for Collective Creativity in Crowd Ideation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445782},
doi = {10.1145/3411764.3445782},
abstract = {Crowdsourcing can collect many diverse ideas by prompting ideators individually, but this can generate redundant ideas. Prior methods reduce redundancy by presenting peers’ ideas or peer-proposed prompts, but these require much human coordination. We introduce Directed Diversity, an automatic prompt selection approach that leverages language model embedding distances to maximize diversity. Ideators can be directed towards diverse prompts and away from prior ideas, thus improving their collective creativity. Since there are diverse metrics of diversity, we present a Diversity Prompting Evaluation Framework consolidating metrics from several research disciplines to analyze along the ideation chain — prompt selection, prompt creativity, prompt-ideation mediation, and ideation creativity. Using this framework, we evaluated Directed Diversity in a series of a simulation study and four user studies for the use case of crowdsourcing motivational messages to encourage physical activity. We show that automated diverse prompting can variously improve collective creativity across many nuanced metrics of diversity.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {393},
numpages = {35},
keywords = {Crowdsourcing, Motivational messaging, Diversity, Collective Intelligence, Creativity Support Tool, Ideation, Collective Creativity},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445766,
author = {Mo, George B. and Dudley, John J and Kristensson, Per Ola},
title = {Gesture Knitter: A Hand Gesture Design Tool for Head-Mounted Mixed Reality Applications},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445766},
doi = {10.1145/3411764.3445766},
abstract = {Hand gestures are a natural and expressive input method enabled by modern mixed reality headsets. However, it remains challenging for developers to create custom gestures for their applications. Conventional strategies to bespoke gesture recognition involve either hand-crafting or data-intensive deep-learning. Neither approach is well suited for rapid prototyping of new interactions. This paper introduces a flexible and efficient alternative approach for constructing hand gestures. We present Gesture Knitter: a design tool for creating custom gesture recognizers with minimal training data. Gesture Knitter allows the specification of gesture primitives that can then be combined to create more complex gestures using a visual declarative script. Designers can build custom recognizers by declaring them from scratch or by providing a demonstration that is automatically decoded into its primitive components. Our developer study shows that Gesture Knitter achieves high recognition accuracy despite minimal training data and delivers an expressive and creative design experience.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {291},
numpages = {13},
keywords = {gestures, augmented reality, virtual reality},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445764,
author = {Mu\~{n}oz, Diego and Favilla, Stu and Pedell, Sonja and Murphy, Andrew and Beh, Jeanie and Petrovich, Tanya},
title = {Evaluating an App to Promote a Better Visit Through Shared Activities for People Living with Dementia and Their Families},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445764},
doi = {10.1145/3411764.3445764},
abstract = {This project aims to foster shared positive experiences between people living with moderate to advanced dementia and their visitors as they may struggle to find topics to talk about and engaging things to do together. To promote a better visit, we trialed a previously developed app that includes eight games with twenty-one residents and their partners or carers across four care centers for three months each. Through interviews and data logging, we found that residents preferred games that were closer to their interests and skills, and that gameplay and cooperation fostered meaningful and shared interactions between residents and their visitors. The contribution of this work is twofold: (1) insights and opportunities into dyadic interactions when using an app and into promoting positive social experiences through technology design, and (2) reflections on the challenges of evaluating the benefits of technology for people living with dementia.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {485},
numpages = {13},
keywords = {person-centered care, dyadic interactions, dementia, app evaluation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445760,
author = {Petersen, Gustav B\o{}g and Mottelson, Aske and Makransky, Guido},
title = {Pedagogical Agents in Educational VR: An in the Wild Study},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445760},
doi = {10.1145/3411764.3445760},
abstract = {Pedagogical agents are theorized to increase humans’ effort to understand computerized instructions. Despite the pedagogical promises of VR, the usefulness of pedagogical agents in VR remains uncertain. Based on this gap, and inspired by global efforts to advance remote learning during the COVID-19 pandemic, we conducted an educational VR study in-the-wild (N = 161). With a 2 \texttimes{} 2 + 1 between subjects design, we manipulated the appearance and behavior of a virtual museum guide in an exhibition about viruses. Factual and conceptual learning outcomes as well as subjective learning experience measures were collected. In general, participants reported high enjoyment and had significant knowledge acquisition. We found that the agent’s appearance and behavior impacted factual knowledge gain. We also report an interaction effect between behavioral and visual realism for conceptual knowledge gain. Our findings nuance classical multimedia learning theories and provide directions for employing agents in immersive learning environments.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {482},
numpages = {12},
keywords = {Educational Technology, Immersive Virtual Reality, Pedagogical Agents, Learning, Cognitive Load},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445756,
author = {Dai, Jiamin and Moffatt, Karyn},
title = {Surfacing the Voices of People with Dementia: Strategies for Effective Inclusion of Proxy Stakeholders in Qualitative Research},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445756},
doi = {10.1145/3411764.3445756},
abstract = {Best practices for conducting HCI research on dementia care increasingly involve multiple stakeholders and incorporate diverse viewpoints. When done effectively, involving proxy stakeholders such as family members and professionals can help bring forward the voices of people with dementia. However, concrete practical guidance for navigating the challenges of integrating different perspectives is lacking. We critically reflect on our own recent qualitative fieldwork involving participants with dementia, family caregivers, and facilitators at a local social program for people with dementia, re-examining our interview transcripts and observation notes through content analysis. We illustrate practical approaches to prioritizing participants’ voices through concrete excerpts that demonstrate strategies for better managing dynamics, intervening effectively, and engaging all stakeholders in the research process. Our reflections and proposed guidelines can benefit HCI researchers and practitioners working with vulnerable populations. We hope this work will spur further discussion and critique to strengthen and improve research practices in this domain.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {374},
numpages = {13},
keywords = {stakeholder, proxy, reflections on practice, dementia},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445744,
author = {'Floyd' Mueller, Florian and Patibanda, Rakesh and Byrne, Richard and Li, Zhuying and Wang, Yan and Andres, Josh and Li, Xiang and Marquez, Jonathan and Greuter, Stefan and Duckworth, Jonathan and Marshall, Joe},
title = {Limited Control Over the Body as Intriguing Play Design Resource},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445744},
doi = {10.1145/3411764.3445744},
abstract = {Interest in combining interactive play and the human body, using “bodily play” systems, is increasing. While these systems primarily prioritize a player's control over their bodily actions, we see intriguing possibilities in the pursuit of “limited control over the body” as an intriguing design resource for bodily play systems. In this paper, we use three of our bodily play systems to illustrate how designers can engage with limited control over the body by varying the player's degree of indirect control (for instance, via other bodily activity and external triggers). We also propose four strategies for employing limited control over the body: Exploration, Reflection, Learning and Embracement. We hope our own work and the strategies developed from it will assist designers to employ limited control over the body, ultimately helping people benefit from engaging their bodies through play.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {435},
numpages = {16},
keywords = {Bodily play, control, play, exertion, games, whole-body interaction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445729,
author = {Williamson, Julie and Li, Jie and Vinayagamoorthy, Vinoba and Shamma, David A. and Cesar, Pablo},
title = {Proxemics and Social Interactions in an Instrumented Virtual Reality Workshop},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445729},
doi = {10.1145/3411764.3445729},
abstract = {Virtual environments (VEs) can create collaborative and social spaces, which are increasingly important in the face of remote work and travel reduction. Recent advances, such as more open and widely available platforms, create new possibilities to observe and analyse interaction in VEs. Using a custom instrumented build of Mozilla Hubs to measure position and orientation, we conducted an academic workshop to facilitate a range of typical workshop activities. We analysed social interactions during a keynote, small group breakouts, and informal networking/hallway conversations. Our mixed-methods approach combined environment logging, observations, and semi-structured interviews. The results demonstrate how small and large spaces influenced group formation, shared attention, and personal space, where smaller rooms facilitated more cohesive groups while larger rooms made small group formation challenging but personal space more flexible. Beyond our findings, we show how the combination of data and insights can fuel collaborative spaces’ design and deliver more effective virtual workshops.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {253},
numpages = {13},
keywords = {Interviews., Social Signal Processing, Virtual Environments, Virtual Meetings},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445706,
author = {Chopra, Shaan and Zehrung, Rachael and Shanmugam, Tamil Arasu and Choe, Eun Kyoung},
title = {Living with Uncertainty and Stigma: Self-Experimentation and Support-Seeking around Polycystic Ovary Syndrome},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445706},
doi = {10.1145/3411764.3445706},
abstract = {Polycystic Ovary Syndrome (PCOS) is a condition that causes hormonal imbalance and infertility in women and people with female reproductive organs. PCOS causes different symptoms for different people, with no singular or universal cure. Being a stigmatized and enigmatic condition, it is challenging to discover, diagnose, and manage PCOS. This work aims to inform the design of inclusive health technologies through an understanding of people’s lived experiences and challenges with PCOS. We conducted semi-structured interviews with 10 women diagnosed with PCOS and analyzed a PCOS-specific subreddit forum. We report people’s support-seeking, sense-making, and self-experimentation practices, and find uncertainty and stigma to be key in shaping their unique experiences of the condition. We further identify potential avenues for designing technology to support their diverse needs, such as personalized and contextual tracking, accelerated self-discovery, and co-management, contributing to a growing body of HCI literature on stigmatized topics in women’s health and well-being.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {202},
numpages = {18},
keywords = {Self-Management, Enigmatic, Women’s Health, Self-Tracking, Support, Self-Experimentation, Stigma, Chronic Condition, PCOS},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445703,
author = {Mayer, Sven and Xu, Xiangyu and Harrison, Chris},
title = {Super-Resolution Capacitive Touchscreens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445703},
doi = {10.1145/3411764.3445703},
abstract = {Capacitive touchscreens are near-ubiquitous in today’s touch-driven devices, such as smartphones and tablets. By using rows and columns of electrodes, specialized touch controllers are able to capture a 2D image of capacitance at the surface of a screen. For over a decade, capacitive “pixels” have been around 4 millimeters in size – a surprisingly low resolution that precludes a wide range of interesting applications. In this paper, we show how super-resolution techniques, long used in fields such as biology and astronomy, can be applied to capacitive touchscreen data. By integrating data from many frames, our software-only process is able to resolve geometric details finer than the original sensor resolution. This opens the door to passive tangibles with higher-density fiducials and also recognition of every-day metal objects, such as keys and coins. We built several applications to illustrate the potential of our approach and report the findings of a multipart evaluation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {12},
numpages = {10},
keywords = {Tracking, Tangibles, Capacitive sensing, Touch input, Super-resolution},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445700,
author = {Turmo Vidal, Laia and Zhu, Hui and Waern, Annika and M\'{a}rquez Segura, Elena},
title = {The Design Space of Wearables for Sports and Fitness Practices},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445700},
doi = {10.1145/3411764.3445700},
abstract = {The growing interest in wearables for sports and fitness calls for design knowledge and conceptualizations that can help shape future designs. Towards that end, we present and discuss a design space of wearables for these practices, based on a survey of previous work. Through a thematic analysis of 47 research publications in the domain, we surface core design decisions concerning wearability, technology design, and wearable use in practice. Building on these, we show how the design space takes into account the goals of introducing technology, that design decisions can be either directly designed, or left open for appropriation by end-users; and the social organization of the practice. We characterize prior work based on the design space elements, which yields trends and opportunities for design. Our contributions can help designers think about key design decisions, exploit trends and explore new areas in the domain of wearables for sports and fitness practices.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {267},
numpages = {14},
keywords = {sports, fitness, wearables, social wearables, movement, design space},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445697,
author = {Sidenmark, Ludwig and Potts, Dominic and Bapisch, Bill and Gellersen, Hans},
title = {Radi-Eye: Hands-Free Radial Interfaces for 3D Interaction Using Gaze-Activated Head-Crossing},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445697},
doi = {10.1145/3411764.3445697},
abstract = {Eye gaze and head movement are attractive for hands-free 3D interaction in head-mounted displays, but existing interfaces afford only limited control. Radi-Eye is a novel pop-up radial interface designed to maximise expressiveness with input from only the eyes and head. Radi-Eye provides widgets for discrete and continuous input and scales to support larger feature sets. Widgets can be selected with Look &amp; Cross, using gaze for pre-selection followed by head-crossing as trigger and for manipulation. The technique leverages natural eye-head coordination where eye and head move at an offset unless explicitly brought into alignment, enabling interaction without risk of unintended input. We explore Radi-Eye in three augmented and virtual reality applications, and evaluate the effect of radial interface scale and orientation on performance with Look &amp; Cross. The results show that Radi-Eye provides users with fast and accurate input while opening up a new design space for hands-free fluid interaction.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {740},
numpages = {11},
keywords = {Augmented Reality, Eye-Head Coordination, Virtual Reality, Eye tracking, Gaze interaction, Radial Interface},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445690,
author = {Chang, Ruei-Che and Wang, Wen-Ping and Chiang, Chi-Huan and Wu, Te-Yen and Xu, Zheer and Luo, Justin and Chen, Bing-Yu and Yang, Xing-Dong},
title = {AccessibleCircuits: Adaptive Add-On Circuit Components for People with Blindness or Low Vision},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445690},
doi = {10.1145/3411764.3445690},
abstract = {In this paper, we propose the designs for low cost and 3D-printable add-on components to adapt existing breadboards, circuit components and electronics tools for blind or low vision (BLV) users. Through an initial user study, we identified several barriers to entry for beginners with BLV in electronics and circuit prototyping. These barriers guided the design and development of our add-on components. We focused on developing adaptations that provide additional information about the specific component pins and breadboard holes, modify tools to make them easier to use for users with BLV, and expand non-visual feedback (e.g., audio, tactile) for tasks that require vision. Through a second user study, we demonstrated that our adaptations can effectively overcome the accessibility barriers in breadboard circuit prototyping for users with BLV.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {670},
numpages = {14},
keywords = {Circuit Prototyping, Accessibility, Universal Design, Education Tools, Tangible User Interfaces},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445673,
author = {Bentvelzen, Marit and Niess, Jasmin and Wo\'{z}niak, Miko\l{}aj P. and Wo\'{z}niak, Pawe\l{} W.},
title = {The Development and Validation of the Technology-Supported Reflection Inventory},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445673},
doi = {10.1145/3411764.3445673},
abstract = {Reflection is an often addressed design goal in Human-Computer Interaction (HCI) research. An increasing number of artefacts for reflection have been developed in recent years. However, evaluating if and how an interactive technology helps a user reflect is still complex. This makes it difficult to compare artefacts (or prototypes) for reflection, impeding future design efforts. To address this issue, we developed the Technology-Supported Reflection Inventory (TSRI), which is a scale that evaluates how effectively a system supports reflection. We first created a list of possible scale items based on past work in defining reflection. The items were then reviewed by experts. Next, we performed exploratory factor analysis to reduce the scale to its final length of nine items. Subsequently, we confirmed test-retest validity of our instrument, as well as its construct validity. The TSRI enables researchers and practitioners to compare prototypes designed to support reflection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {366},
numpages = {8},
keywords = {reflection, construal, personal informatics, tracking},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445662,
author = {Nunes, Francisco and Almeida, Jo\~{a}o and Chung, Chia-Fang and Verdezoto, Nervo},
title = {Avoiding Reactions Outside the Home: Challenges, Strategies, and Opportunities to Enhance Dining Out Experiences of People with Food Hypersensitivities},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445662},
doi = {10.1145/3411764.3445662},
abstract = {People with food hypersensitivities experience adverse reactions when eating certain foods and thus need to adapt their diet. When dining out, the challenge is greater as people entrust the care of their allergy, intolerance, or celiac disease, in the hands of staff who might not have enough knowledge to appropriately care for them. This interview study explored how people with food hypersensitivities avoid reactions while eating out, to inspire future digital technology design. Our findings show the social and emotional impact of food hypersensitivities and how people practically cope by investigating restaurants’ safety precautions, correcting orders, or even educating restaurants’ staff. We discuss our findings against the experiences of other people living with chronic conditions and offer design opportunities for digital technologies to enhance dining out experiences of people with food hypersensitivities.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {208},
numpages = {16},
keywords = {health, dining out, food allergies, food intolerance, self-care, qualitative research, Food hypersensitivities, avoiding reactions},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445657,
author = {You, Yue and Kou, Yubo and Ding, Xianghua(Sharon) and Gui, Xinning},
title = {The Medical Authority of AI: A Study of AI-Enabled Consumer-Facing Health Technology},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445657},
doi = {10.1145/3411764.3445657},
abstract = {Recently, consumer-facing health technologies such as Artificial Intelligence (AI)-based symptom checkers (AISCs) have sprung up in everyday healthcare practice. AISCs solicit symptom information from users and provide medical suggestions and possible diagnoses, a responsibility that people usually entrust with real-person authorities such as physicians and expert patients. Thus, the advent of AISCs begs a question of whether and how they transform the notion of medical authority in people's everyday healthcare practice. To answer this question, we conducted an interview study with thirty AISC users. We found that users assess the medical authority of AISCs using various factors including AISCs’ automated decisions and interaction design patterns, associations with established medical authorities like hospitals, and comparisons with other health technologies. We reveal how AISCs are used in healthcare delivery, discuss how AI transforms conventional understandings of medical authority, and derive implications for designing AI-enabled health technology.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {207},
numpages = {16},
keywords = {Medical authority, Consumer-facing health technology, Artificial intelligence, Symptom checkers},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445648,
author = {Head, Andrew and Lo, Kyle and Kang, Dongyeop and Fok, Raymond and Skjonsberg, Sam and Weld, Daniel S. and Hearst, Marti A.},
title = {Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445648},
doi = {10.1145/3411764.3445648},
abstract = {Despite the central importance of research papers to scientific progress, they can be difficult to read. Comprehension is often stymied when the information needed to understand a passage resides somewhere else—in another section, or in another paper. In this work, we envision how interfaces can bring definitions of technical terms and symbols to readers when and where they need them most. We introduce ScholarPhi, an augmented reading interface with four novel features: (1) tooltips that surface position-sensitive definitions from elsewhere in a paper, (2) a filter over the paper that “declutters” it to reveal how the term or symbol is used across the paper, (3) automatic equation diagrams that expose multiple definitions in parallel, and (4) an automatically generated glossary of important terms and symbols. A usability study showed that the tool helps researchers of all experience levels read papers. Furthermore, researchers were eager to have ScholarPhi’s definitions available to support their everyday reading.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {413},
numpages = {18},
keywords = {scientific papers, reading interfaces, nonce words, interactive documents, definitions},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445633,
author = {Osmers, Niklas and Prilla, Michael and Blunk, Oliver and George Brown, Gordon and Jan\ss{}en, Marc and Kahrl, Nicolas},
title = {The Role of Social Presence for Cooperation in Augmented Reality on Head Mounted Devices: A Literature Review},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445633},
doi = {10.1145/3411764.3445633},
abstract = {With growing interest regarding cooperation support using Augmented Reality (AR), social presence has become a popular measure of its quality. While this concept is established throughout cooperation research, its role in AR is still unclear: Some work uses social presence as an indicator for support quality, while others found no impact at all. To clarify this role, we conducted a literature review of recent publications that empirically investigated social presence in cooperative AR. After a thorough selection procedure, we analyzed 19&nbsp;publications according to factors influencing social presence and the impact of social presence on cooperation support. We found that certain interventions support social presence better than others, that social presence has an influence on user's preferences and that the relation between social presence and cooperation quality may depend on the symmetry of the cooperation task. This contributes to existing research by clarifying the role of social presence for cooperative AR and deriving corresponding design recommendations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {457},
numpages = {17},
keywords = {Cooperation, Head Mounted Devices, Presence Questionnaire, Augmented Reality, Literature Review, Social Presence, User Study},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445631,
author = {Ogata, Masa and Koyama, Yuki},
title = {A Computational Approach to Magnetic Force Feedback Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445631},
doi = {10.1145/3411764.3445631},
abstract = {We present a computational approach to haptic design embedded in everyday tangible interaction with digital fabrication. To generate haptic feedback, the use of permanent magnets as the mechanism potentially contributes to simpleness and robustness; however, it is difficult to manually design how magnets should be embedded in the objects. Our approach enables the inverse design of magnetic force feedback; that is, we computationally solve an inverse problem to obtain an optimal arrangement of permanent magnets that renders the user-specified haptic sensation. To solve the inverse problem in a practical manner, we also present techniques on magnetic simulation and optimization. We demonstrate applications to explore the design possibility of augmenting digital fabrication for everyday use.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {284},
numpages = {12},
keywords = {Optimization, Haptics, Inverse design, Digital fabrication, Magnetic force feedback},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445630,
author = {Batool, Amna and Toyama, Kentaro and Veinot, Tiffany and Fatima, Beenish and Naseem, Mustafa},
title = {Detecting Data Falsification by Front-Line Development Workers: A Case Study of Vaccination in Pakistan},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445630},
doi = {10.1145/3411764.3445630},
abstract = {Front-line workers in global development are often responsible for data collection and record-keeping about their own work. The authenticity of such data and the role of mid-level supervisors, however, remains understudied. We report on the case of immunization in Pakistan, where, through interviews with 30 mid-level vaccination managers in Punjab district, we find that data falsification by vaccinators is common, though not necessarily rampant. Because of an intricate protocol for record-keeping, supervisors can detect data falsification, and we find they have devised an array of methods, broadly classifiable into four types: triangulation, supplementary data collection, anomaly detection, and interrogation. We also find that the strategies that supervisors use to detect falsification seem linked to their style of management, with authoritarian supervisors preferring supplementary data collection and spot checks, while supportive supervisors use triangulation. Our findings lead to recommendations for designing technologies intended to monitor and manage front-line data.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {700},
numpages = {14},
keywords = {Supervisors, Mid-level Managers, Healthcare, Front-line Workers, Immunization, Developing Countries, Technology, Supportive Supervision, Data Falsification},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445624,
author = {Liang, Chen and Yu, Chun and Wei, Xiaoying and Xu, Xuhai and Hu, Yongquan and Wang, Yuntao and Shi, Yuanchun},
title = {Auth+Track: Enabling Authentication Free Interaction on Smartphone by Continuous User Tracking},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445624},
doi = {10.1145/3411764.3445624},
abstract = {We propose Auth+Track, a novel authentication model that aims to reduce redundant authentication in everyday smartphone usage. By sparse authentication and continuous tracking of the user’s status, Auth+Track eliminates the “gap” authentication between fragmented sessions and enables “Authentication Free when User is Around”. To instantiate the Auth+Track model, we present PanoTrack, a prototype that integrates body and near field hand information for user tracking. We install a fisheye camera on the top of the phone to achieve a panoramic vision that can capture both user’s body and on-screen hands. Based on the captured video stream, we develop an algorithm to extract 1) features for user tracking, including body keypoints and their temporal and spatial association, near field hand status, and 2) features for user identity assignment. The results of our user studies validate the feasibility of PanoTrack and demonstrate that Auth+Track not only improves the authentication efficiency but also enhances user experiences with better usability.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {2},
numpages = {16},
keywords = {authentication model, continuous user tracking},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445617,
author = {Uriu, Daisuke and Toshima, Kenta and Manabe, Minori and Yazaki, Takeru and Funatsu, Takeshi and Izumihara, Atsushi and Kashino, Zendai and Hiyama, Atsushi and Inami, Masahiko},
title = {Generating the Presence of Remote Mourners: A Case Study of Funeral Webcasting in Japan},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445617},
doi = {10.1145/3411764.3445617},
abstract = {Funerals are irreplaceable events, especially for bereaved family members and relatives. However, the COVID-19 pandemic has prevented many people worldwide from attending their loved ones’ funerals. The authors had the opportunity to assist one family faced with this predicament by webcasting and recording funeral rites held near Tokyo in June, 2020. Using our original 360-degree Telepresence system and smartphones running Zoom, we enabled the deceased’s elder siblings to remotely attend the funeral and did our utmost to make them feel present in the funeral hall. Despite the webcasting via Zoom contributing more to their remote attendances than our system, we discovered thoughtful findings which could be useful for designing remote funeral attendances. From the findings, we also discuss how HCI designers can contribute to this highly sensitive issue, weaving together knowledge from various domains including techno-spiritual practices, thanato-sensitive designs; and other religious and cultural aspects related to death rituals.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {629},
numpages = {14},
keywords = {Telepresence and Telexistence, Death Rituals, 360-degree camera, Thanato-sensitivity, Funeral, Mourning and Memorialization, Techno-spiritual practices},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445603,
author = {Wang, Yihong and Papangelis, Konstantinos and Saker, Michel and Lykourentzou, Ioanna and Khan, Vassilis-Javed and Chamberlain, Alan and Grudin, Jonathan},
title = {An Examination of the Work Practices of Crowdfarms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445603},
doi = {10.1145/3411764.3445603},
abstract = {Crowdsourcing is a new value creation business model. Annual revenue of the Chinese market alone is hundreds of millions of dollars, yet few studies have focused on the practices of the Chinese crowdsourcing workforce, and those that do mainly focus on solo crowdworkers. We have extended our study of solo crowdworker practices to include crowdfarms, a relatively new entry to the gig economy: small companies that carry out crowdwork as a key part of their business. We report here on interviews of people who work in 53 crowdfarms. We describe how crowdfarms procure jobs, carry out macrotasks and microtasks, manage their reputation, and employ different management practices to motivate crowdworkers and customers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {139},
numpages = {14},
keywords = {Work Practices, Crowdsourcing, Crowdfarms},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445588,
author = {Jicol, Crescent and Wan, Chun Hin and Doling, Benjamin and Illingworth, Caitlin H and Yoon, Jinha and Headey, Charlotte and Lutteroth, Christof and Proulx, Michael J and Petrini, Karin and O'Neill, Eamonn},
title = {Effects of Emotion and Agency on Presence in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445588},
doi = {10.1145/3411764.3445588},
abstract = {Arguably one of the most important characteristics of virtual reality (VR) is its ability to induce higher feelings of presence. Still, research has remained inconclusive on how presence is affected by human factors such as emotion and agency. Here we adopt a novel design to investigate their effects by testing virtual environments inducing either happiness or fear, with or without user agency. Results from 121 participants showed that the dominant emotion induced by a virtual environment is positively correlated with presence. In addition, agency had a significant positive effect on presence and, furthermore, moderated the effect of emotion on presence. We show for the first time that the effects of emotion and agency on presence are not straightforward but they can be modelled by separating design factors from subjective measures. We discuss how these findings can explain seemingly conflicting results of related work and their implications for VR design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {529},
numpages = {13},
keywords = {virtual reality, emotion, agency., presence},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445583,
author = {Matulic, Fabrice and Ganeshan, Aditya and Fujiwara, Hiroshi and Vogel, Daniel},
title = {Phonetroller: Visual Representations of Fingers for Precise Touch Input with Mobile Phones in VR},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445583},
doi = {10.1145/3411764.3445583},
abstract = {Smartphone touch screens are potentially attractive for interaction in virtual reality (VR). However, the user cannot see the phone or their hands in a fully immersive VR setting, impeding their ability for precise touch input. We propose mounting a mirror above the phone screen such that the front-facing camera captures the thumbs on or near the screen. This enables the creation of semi-transparent overlays of thumb shadows and inference of fingertip hover points with deep learning, which help the user aim for targets on the phone. A study compares the effect of visual feedback on touch precision in a controlled task and qualitatively evaluates three example applications demonstrating the potential of the technique. The results show that the enabled style of feedback is effective for thumb-size targets, and that the VR experience can be enriched by using smartphones as VR controllers supporting precise touch input.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {129},
numpages = {13},
keywords = {visual feedback, mobile phone, VR, touch input, deep learning},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445582,
author = {Ahuja, Karan and Mayer, Sven and Goel, Mayank and Harrison, Chris},
title = {Pose-on-the-Go: Approximating User Pose with Smartphone Sensor Fusion and Inverse Kinematics},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445582},
doi = {10.1145/3411764.3445582},
abstract = {We present Pose-on-the-Go, a full-body pose estimation system that uses sensors already found in today’s smartphones. This stands in contrast to prior systems, which require worn or external sensors. We achieve this result via extensive sensor fusion, leveraging a phone’s front and rear cameras, the user-facing depth camera, touchscreen, and IMU. Even still, we are missing data about a user’s body (e.g., angle of the elbow joint), and so we use inverse kinematics to estimate and animate probable body poses. We provide a detailed evaluation of our system, benchmarking it against a professional-grade Vicon tracking system. We conclude with a series of demonstration applications that underscore the unique potential of our approach, which could be enabled on many modern smartphones with a simple software update.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {9},
numpages = {12},
keywords = {Smartphone, Body pose, Motion tracking, Motion capture, Mobile},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445579,
author = {Kim, Yelim and Reza, Mohi and McGrenere, Joanna and Yoon, Dongwook},
title = {Designers Characterize Naturalness in Voice User Interfaces: Their Goals, Practices, and Challenges},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445579},
doi = {10.1145/3411764.3445579},
abstract = {This work investigates the practices and challenges of voice user interface (VUI) designers. Existing VUI design guidelines recommend that designers strive for natural human-agent conversation. However, the literature leaves a critical gap regarding how designers pursue naturalness in VUIs and what their struggles are in doing so. Bridging this gap is necessary for identifying designers’ needs and supporting them. Our interviews with 20 VUI designers identified 12 ways that designers characterize and approach naturalness in VUIs. We categorized these characteristics into three groupings based on the types of conversational context that each characteristic contributes to: Social, Transactional, and Core. Our results contribute new findings on designers’ challenges, such as a design dilemma in augmenting task-oriented VUIs with social conversations, difficulties in writing for spoken language, lack of proper tool support for imbuing synthesized voice with expressivity, and implications for developing design tools and guidelines.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {242},
numpages = {13},
keywords = {designers, naturalness, practices, voice user interfaces (VUI), challenges, characterize},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445573,
author = {Chen, Yan and Lee, Sang Won and Oney, Steve},
title = {CoCapture: Effectively Communicating UI Behaviors on Existing Websites by Demonstrating and Remixing},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445573},
doi = {10.1145/3411764.3445573},
abstract = {User Interface (UI) mockups are commonly used as shared context during interface development collaboration. In practice, UI designers often use screenshots and sketches to create mockups of desired UI behaviors for communication. However, in the later stages of UI development, interfaces can be arbitrarily complex, making it labor-intensive to sketch, and static screenshots are limited in the types of interactive and dynamic behaviors they can express. We introduce CoCapture, a system that allows designers to easily create UI behavior mockups on existing web interfaces by demonstrating and remixing, and to accurately describe their requests to helpers by referencing the resulting mockups using hypertext. We showed that participants could more accurately describe UI behaviors with CoCapture than with existing sketch and communication tools and that the resulting descriptions were clear and easy to follow. Our approach can help teams develop UIs efficiently by bridging communication gaps with more accurate visual context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {416},
numpages = {14},
keywords = {UI design communication, Rapid UI prototyping},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445572,
author = {Peng, Yi-Hao and Jang, JiWoong and Bigham, Jeffrey P and Pavel, Amy},
title = {Say It All: Feedback for Improving Non-Visual Presentation Accessibility},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445572},
doi = {10.1145/3411764.3445572},
abstract = {Presenters commonly use slides as visual aids for informative talks. When presenters fail to verbally describe the content on their slides, blind and visually impaired audience members lose access to necessary content, making the presentation difficult to follow. Our analysis of 90 presentation videos revealed that 72% of 610 visual elements (e.g., images, text) were insufficiently described. To help presenters create accessible presentations, we introduce Presentation A11y, a system that provides real-time and post-presentation accessibility feedback. Our system analyzes visual elements on the slide and the transcript of the verbal presentation to provide element-level feedback on what visual content needs to be further described or even removed. Presenters using our system with their own slide-based presentations described more of the content on their slides, and identified &nbsp;3.26 times more accessibility problems to fix after the talk than when using a traditional slide-based presentation interface. Integrating accessibility feedback into content creation tools will improve the accessibility of informational content for all.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {12},
keywords = {Accessibility, Presentation, Slides, Video, Audio description},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445564,
author = {Albaugh, Lea and McCann, James and Hudson, Scott E. and Yao, Lining},
title = {Engineering Multifunctional Spacer Fabrics Through Machine Knitting},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445564},
doi = {10.1145/3411764.3445564},
abstract = {Machine knitting is an increasingly accessible fabrication technology for producing custom soft goods. However, recent machine knitting research has focused on knit shaping, or on adapting hand-knitting patterns. We explore a capability unique to machine knitting: producing multilayer spacer fabrics. These fabrics consist of two face layers connected by a monofilament filler yarn which gives the structure stiffness and volume. We show how to vary knit patterning and yarn parameters in spacer fabrics to produce tactile materials with embedded functionality for forming soft actuated mechanisms and sensors with tunable density, stiffness, material bias, and bristle properties. These soft mechanisms can be rapidly produced on a computationally-controlled v-bed knitting machine and integrated directly into soft objects.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {498},
numpages = {12},
keywords = {Soft Sensors, Textiles, Knitted Mechanisms., Machine Knitting},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445546,
author = {Veras, Rafael and Singh, Gaganpreet and Farhadi-Niaki, Farzin and Udhani, Ritesh and Patekar, Parth Pradeep and Zhou, Wei and Irani, Pourang and Li, Wei},
title = {Elbow-Anchored Interaction: Designing Restful Mid-Air Input},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445546},
doi = {10.1145/3411764.3445546},
abstract = {We designed a mid-air input space for restful interactions on the couch. We observed people gesturing in various postures on a couch and found that posture affects the choice of arm motions when no constraints are imposed by a system. Study participants that sat with the arm rested were more likely to use the forearm and wrist, as opposed to the whole arm. We investigate how a spherical input space, where forearm angles are mapped to screen coordinates, can facilitate restful mid-air input in multiple postures. We present two controlled studies. In the first, we examine how a spherical space compares with a planar space in an elbow-anchored setup, with a shoulder-level input space as baseline. In the second, we examine the performance of a spherical input space in four common couch postures that set unique constraints to the arm. We observe that a spherical model that captures forearm movement facilitates comfortable input across different seated postures.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {737},
numpages = {15},
keywords = {Comfort, Elbow-anchored Input, Variable-posture Gestures, Restful Input, Mid-air Gesture Fatigue, Mid-air Gestures},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445545,
author = {Winters, R. Michael and Walker, Bruce N. and Leslie, Grace},
title = {Can You Hear My Heartbeat?: Hearing an Expressive Biosignal Elicits Empathy},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445545},
doi = {10.1145/3411764.3445545},
abstract = {Interfaces designed to elicit empathy provide an opportunity for HCI with important pro-social outcomes. Recent research has demonstrated that perceiving expressive biosignals can facilitate emotional understanding and connection with others, but this work has been largely limited to visual approaches. We propose that hearing these signals will also elicit empathy, and test this hypothesis with sounding heartbeats. In a lab-based within-subjects study, participants (N = 27) completed an emotion recognition task in different heartbeat conditions. We found that hearing heartbeats changed participants’ emotional perspective and increased their reported ability to “feel what the other was feeling.” From these results, we argue that auditory heartbeats are well-suited as an empathic intervention, and might be particularly useful for certain groups and use-contexts because of its musical and non-visual nature. This work establishes a baseline for empathic auditory interfaces, and offers a method to evaluate the effects of future designs.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {225},
numpages = {11},
keywords = {emotion, physiology, sound, ASD, empathy, heart rate, rhythm, AAC, communication, music, affect},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445535,
author = {Liu, Richen and Gao, Min and Ye, Shunlong and Zhang, Jiang},
title = {IGScript: An Interaction Grammar for Scientific Data Presentation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445535},
doi = {10.1145/3411764.3445535},
abstract = {Most of the existing scientific visualizations toward interpretive grammar aim to enhance customizability in either the computation stage or the rendering stage or both, while few approaches focus on the data presentation stage. Besides, most of these approaches leverage the existing components from the general-purpose programming languages (GPLs) instead of developing a standalone compiler, which pose a great challenge about learning curves for the domain experts who have limited knowledge about programming. In this paper, we propose IGScript, a novel script-based interaction grammar tool, to help build scientific data presentation animations for communication. We design a dual-space interface and a compiler which converts natural language-like grammar statements or scripts into a data story animation to make an interactive customization on script-driven data presentations, and then develop a code generator (decompiler) to translate the interactive data exploration animations back into script codes to achieve statement parameters. IGScript makes the presentation animations editable, e.g., it allows to cut, copy, paste, append, or even delete some animation clips. We demonstrate the usability, customizability, and flexibility of IGScript by a user study, four case studies conducted by using four types of commonly-used scientific data, and performance evaluations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {26},
numpages = {13},
keywords = {interaction grammar, scientific visualization, data presentation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445519,
author = {Baughan, Amanda and Oliveira, Nigini and August, Tal and Yamashita, Naomi and Reinecke, Katharina},
title = {Do Cross-Cultural Differences in Visual Attention Patterns Affect Search Efficiency on Websites?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445519},
doi = {10.1145/3411764.3445519},
abstract = {Prior work in cross-cultural psychology and neuroscience has shown robust variations in visual attention patterns. People from East Asian societies, in which a holistic thinking style predominates, have been found to attend to contextual information in scenes more than Westerners, whose tendency to think analytically expresses itself in greater attention to foreground objects. This paper applies these findings to website design, using an online study to evaluate whether Japanese (N=65) remember more and are faster at finding contextual website information than US Americans (N=84). Our results do not support this hypothesis. Instead, Japanese overall took significantly longer to find information than US participants—a difference that was exacerbated by an increase in website complexity—suggesting that Japanese may holistically take in a website before engaging with detailed information. We discuss implications of these findings for website design and cross-cultural research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {362},
numpages = {12},
keywords = {visual attention, website search efficiency, culture},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445517,
author = {Utz, Christine and Becker, Steffen and Schnitzler, Theodor and Farke, Florian M. and Herbert, Franziska and Schaewitz, Leonie and Degeling, Martin and D\"{u}rmuth, Markus},
title = {Apps Against the Spread: Privacy Implications and User Acceptance of COVID-19-Related Smartphone Apps on Three Continents},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445517},
doi = {10.1145/3411764.3445517},
abstract = {The COVID-19 pandemic has fueled the development of smartphone applications to assist disease management. Many “corona apps” require widespread adoption to be effective, which has sparked public debates about the privacy, security, and societal implications of government-backed health applications. We conducted a representative online study in Germany (n = 1003), the US (n = 1003), and China (n = 1019) to investigate user acceptance of corona apps, using a vignette design based on the contextual integrity framework. We explored apps for contact tracing, symptom checks, quarantine enforcement, health certificates, and mere information. Our results provide insights into data processing practices that foster adoption and reveal significant differences between countries, with user acceptance being highest in China and lowest in the US. Chinese participants prefer the collection of personalized data, while German and US participants favor anonymity. Across countries, contact tracing is viewed more positively than quarantine enforcement, and technical malfunctions negatively impact user acceptance.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {22},
keywords = {COVID-19, digital contact tracing, privacy},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445502,
author = {Schmitz, Martin and M\"{u}ller, Florian and M\"{u}hlh\"{a}user, Max and Riemann, Jan and Le, Huy Viet Viet},
title = {Itsy-Bits: Fabrication and Recognition of 3D-Printed Tangibles with Small Footprints on Capacitive Touchscreens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445502},
doi = {10.1145/3411764.3445502},
abstract = {Tangibles on capacitive touchscreens are a promising approach to overcome the limited expressiveness of touch input. While research has suggested many approaches to detect tangibles, the corresponding tangibles are either costly or have a considerable minimal size. This makes them bulky and unattractive for many applications. At the same time, they obscure valuable display space for interaction. To address these shortcomings, we contribute Itsy-Bits: a fabrication pipeline for 3D printing and recognition of tangibles on capacitive touchscreens with a footprint as small as a fingertip. Each Itsy-Bit consists of an enclosing 3D object and a unique conductive 2D shape on its bottom. Using only raw data of commodity capacitive touchscreens, Itsy-Bits reliably identifies and locates a variety of shapes in different sizes and estimates their orientation. Through example applications and a technical evaluation, we demonstrate the feasibility and applicability of Itsy-Bits for tangibles with small footprints.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {419},
numpages = {12},
keywords = {Touchscreen, Tangibles, Machine Learning, 3D Printing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445492,
author = {Karaosmanoglu, Sukran and Rogers, Katja and Wolf, Dennis and Rukzio, Enrico and Steinicke, Frank and Nacke, Lennart E.},
title = {Feels like Team Spirit: Biometric and Strategic Interdependence in Asymmetric Multiplayer VR Games},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445492},
doi = {10.1145/3411764.3445492},
abstract = {Virtual reality (VR) multiplayer games increasingly use asymmetry (e.g., differences in a person’s capability or the user interface) and resulting interdependence between players to create engagement even when one player has no access to a head-mounted display (HMD). Previous work shows this enhances player experience (PX). Until now, it remains unclear whether and how an asymmetric game design with interdependences creates comparably enjoyable PX for both an HMD and a non-HMD player. In this work, we designed and implemented an asymmetric VR game (different in its user interface) with two types of interdependence: strategic (difference in game information/player capability) and biometric (difference in player’s biometric influence). Our mixed-methods user study (N=30) shows that asymmetries positively impact PX for both player roles, that interdependence strongly affects players’ perception of agency, and that biometric feedback—while subjective—is a valuable game mechanic.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {443},
numpages = {15},
keywords = {asymmetry, virtual reality, multiplayer, strategic, biometric, VR, interdependence},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445486,
author = {Elgarf, Maha and Calvo-Barajas, Natalia and Paiva, Ana and Castellano, Ginevra and Peters, Christopher},
title = {Reward Seeking or Loss Aversion? Impact of Regulatory Focus Theory on Emotional Induction in Children and Their Behavior Towards a Social Robot},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445486},
doi = {10.1145/3411764.3445486},
abstract = {According to psychology research, emotional induction has positive implications in many domains such as therapy and education. Our aim in this paper was to manipulate the Regulatory Focus Theory to assess its impact on the induction of regulatory focus related emotions in children in a pretend play scenario with a social robot. The Regulatory Focus Theory suggests that people follow one of two paradigms while attempting to achieve a goal; by seeking gains (promotion focus - associated with feelings of happiness) or by avoiding losses (prevention focus - associated with feelings of fear). We conducted a study with 69 school children in two different conditions (promotion vs. prevention). We succeeded in inducing happiness emotions in the promotion condition and found a resulting positive effect of the induction on children’s social engagement with the robot. We also discuss the important implications of these results in both educational and child robot interaction fields.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {587},
numpages = {11},
keywords = {social robotics, human robot interaction, emotional induction, social engagement, regulatory focus},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445480,
author = {Holl\"{a}nder, Kai and Colley, Mark and Rukzio, Enrico and Butz, Andreas},
title = {A Taxonomy of Vulnerable Road Users for HCI Based On A Systematic Literature Review},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445480},
doi = {10.1145/3411764.3445480},
abstract = {Recent automotive research often focuses on automated driving, including the interaction between automated vehicles (AVs) and so-called “vulnerable road users” (VRUs). While road safety statistics and traffic psychology at least define VRUs as pedestrians, cyclists, and motorcyclists, many publications on human-vehicle interaction use the term without even defining it. The actual target group remains unclear. Since each group already poses a broad spectrum of research challenges, a one-fits-all solution seems unrealistic and inappropriate, and a much clearer differentiation is required. To foster clarity and comprehensibility, we propose a literature-based taxonomy providing a structured separation of (vulnerable) road users, designed to particularly (but not exclusively) support research on the communication between VRUs and AVs. It consists of two conceptual hierarchies and will help practitioners and researchers by providing a uniform and comparable set of terms needed for the design, implementation, and description of HCI applications.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {158},
numpages = {13},
keywords = {external communication, Automated vehicles, taxonomy, vulnerable road users, eHMIs},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445475,
author = {Pourjafarian, Narjes and Koelle, Marion and Fruchard, Bruno and Mavali, Sahar and Klamka, Konstantin and Groeger, Daniel and Strohmeier, Paul and Steimle, J\"{u}rgen},
title = {BodyStylus: Freehand On-Body Design and Fabrication of Epidermal Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445475},
doi = {10.1145/3411764.3445475},
abstract = {In traditional body-art, designs are adjusted to the body as they are applied, enabling creative improvisation and exploration. Conventional design and fabrication methods of epidermal interfaces, however, separate these steps. With BodyStylus we present the first computer-assisted approach for on-body design and fabrication of epidermal interfaces. Inspired by traditional techniques, we propose a hand-held tool that augments freehand inking with digital support: projected in-situ guidance assists creating valid on-body circuits and aesthetic ornaments that align with the human bodyscape, while pro-active switching between inking and non-inking creates error preventing constraints. We contribute BodyStylus’s design rationale and interaction concept along with an interactive prototype that uses self-sintering conductive ink. Results of two focus group explorations showed that guidance was more appreciated by artists, while constraints appeared more useful to engineers, and that working on the body inspired critical reflection on the relationship between bodyscape, interaction, and designs.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {504},
numpages = {15},
keywords = {On-body design, craft, epidermal devices, on-body fabrication, pen-based interaction, skin, wearable computing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445468,
author = {Zuckerman, Oren and Sadka, Ofir and Gissin, Ron and Erel, Hadas},
title = {TUI as Social Entity: A Study of Joint-Actuation and Turn-Taking-Actuation in Actuated-Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445468},
doi = {10.1145/3411764.3445468},
abstract = {We present an actuated-interface that is not only a tangible interface but also an autonomous object, designed as an independent entity that takes a similar role to the user’s role in an anagram word game. We highlight two leading interaction paradigms: Turn-taking-actuation and Joint-actuation, and evaluate both in a qualitative interaction study with the autonomous actuated-interface. Our findings reveal that all participants perceived the interaction as a social experience. The different interaction paradigms led to different interpretations: Turn-taking-actuation was interpreted as a competitive experience, while Joint-actuation was interpreted as a collaborative experience. The interaction paradigms also influenced the intensity of emotions and perception of control, with Joint-actuation leading to more intense emotions and higher sensitivity to control in the interaction. To conclude, our findings show that it is possible to design an actuated-interface that users perceive both as a tangible interface and as a social entity with its own intent.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {507},
numpages = {12},
keywords = {autonomous behavior, actuated-interface, TUI, self-actuation, social interaction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445459,
author = {Zeng, Eric and Kohno, Tadayoshi and Roesner, Franziska},
title = {What Makes a “Bad” Ad? User Perceptions of Problematic Online Advertising},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445459},
doi = {10.1145/3411764.3445459},
abstract = {Online display advertising on websites is widely disliked by users, with many turning to ad blockers to avoid “bad” ads. Recent evidence suggests that today’s ads contain potentially problematic content, in addition to well-studied concerns about the privacy and intrusiveness of ads. However, we lack knowledge of which types of ad content users consider problematic and detrimental to their browsing experience. Our work bridges this gap: first, we create a taxonomy of 15 positive and negative user reactions to online advertising from a survey of 60 participants. Second, we characterize classes of online ad content that users dislike or find problematic, using a dataset of 500 ads crawled from popular websites, labeled by 1000 participants using our taxonomy. Among our findings, we report that users consider a substantial amount of ads on the web today to be clickbait, untrustworthy, or distasteful, including ads for software downloads, listicles, and health &amp; supplements.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {361},
numpages = {24},
keywords = {dark patterns, deceptive advertising, online advertising},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445456,
author = {Feick, Martin and Kleer, Niko and Zenner, Andr\'{e} and Tang, Anthony and Kr\"{u}ger, Antonio},
title = {Visuo-Haptic Illusions for Linear Translation and Stretching Using Physical Proxies in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445456},
doi = {10.1145/3411764.3445456},
abstract = {Providing haptic feedback when manipulating virtual objects is an essential part of immersive virtual reality experiences; however, it is challenging to replicate all of an object's properties and characteristics. We propose the use of visuo-haptic illusions alongside physical proxies to enhance the scope of proxy-based interactions with virtual objects. In this work, we focus on two manipulation techniques, linear translation and stretching across different distances, and investigate how much discrepancy between the physical proxy and the virtual object may be introduced without participants noticing. In a study with 24 participants, we found that manipulation technique and travel distance significantly affect the detection thresholds, and that visuo-haptic illusions impact performance and accuracy. We show that this technique can be used to enable functional proxy objects that act as stand-ins for multiple virtual objects, illustrating the technique through a showcase VR-DJ application.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {220},
numpages = {13},
keywords = {Haptics, Proxy Objects, Tangible Interfaces, Visuo-haptic Illusions, Virtual Reality},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445447,
author = {Wong, Richmond Y. and Nguyen, Tonya},
title = {Timelines: A World-Building Activity for Values Advocacy},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445447},
doi = {10.1145/3411764.3445447},
abstract = {This paper presents Timelines, a design activity to assist values advocates: people who help others recognize values and ethical concerns as relevant to technical practice. Rather than integrate seamlessly into existing design processes, Timelines aims to create a space for critical reflection and contestation among expert participants (such as technology researchers, practitioners, or students) and a values advocate facilitator to surface the importance and relevance of values and ethical concerns. The activity’s design is motivated by theoretical perspectives from design fiction, scenario planning, and value sensitive design. The activity helps participants surface discussion of broad societal-level changes related to a technology by creating stories from news headlines, and recognize a diversity of experiences situated in the everyday by creating social media posts from different viewpoints. We reflect on how decisions on the activity’s design and facilitation enables it to assist in values advocacy practices.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {616},
numpages = {15},
keywords = {values advocacy, design fiction, values in design, ethics, values work},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445445,
author = {Yang, Xi and Aurisicchio, Marco},
title = {Designing Conversational Agents: A Self-Determination Theory Approach},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445445},
doi = {10.1145/3411764.3445445},
abstract = {Bringing positive experiences to users is one of the key goals when designing conversational agents (CAs). Yet we still lack an understanding of users’ underlying needs to achieve positive experiences and how to support them in design. This research first applies Self-Determination Theory in an interview study to explore how users’ needs of competence, autonomy and relatedness could be supported or undermined in CA experiences. Ten guidelines are then derived from the interview findings. The key findings demonstrate that: competence is affected by users’ knowledge of the CA capabilities and effectiveness of the conversation; autonomy is influenced by flexibility of the conversation, personalisation of the experiences, and control over user data; regarding relatedness, users still have concerns over integrating social features into CAs. The guidelines recommend how to inform users about the system capabilities, design effective and socially appropriate conversations, and support increased system intelligence, customisation, and data transparency.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {16},
keywords = {Relatedness, Conversational Agents, Conversational User Experience, Competence, Autonomy},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445440,
author = {Lee, Kyung-Ryong and Kim, Beom and Kim, Junyoung and Hong, Hwajung and Park, Young-Woo},
title = {ADIO: An Interactive Artifact Physically Representing the Intangible Digital Audiobook Listening Experience in Everyday Living Spaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445440},
doi = {10.1145/3411764.3445440},
abstract = {Although audiobooks are increasingly being used, people tend to perceive audiobook experiences as 'not real reading' due to its intangibility and ephemerality. In this paper, we developed ADIO, a device augmenting audiobook experience through representing personal listening state in the form of an interactive physical bookshelf. ADIO displays a user's listening progress through a pendant's changing length and the user's digital audiobook archive titles. The result of our four-week in-field study with six participants revealed that ADIO provided proof of the user's listening-to, which brought a sense of reading and gave a trigger for recalling the listened-to audiobook content. Additionally, audiobooks' improved visibility reminded participants to listen to them, and ADIO's physical interaction allowed participants to form personal patterns for listening to audiobooks. Our findings proposed new methods for augmenting the audiobook listening experience at three stages and further implications for designing physical curation on users’ digital archives.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {164},
numpages = {12},
keywords = {Digital possession, Data physicalization, Physical interaction, Audiobook},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445437,
author = {Yoo, Jung Eun and Seo, Kwanggyoon and Park, Sanghun and Kim, Jaedong and Lee, Dawon and Noh, Junyong},
title = {Virtual Camera Layout Generation Using a Reference Video},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445437},
doi = {10.1145/3411764.3445437},
abstract = {We propose a method that generates a virtual camera layout of a 3D animation scene by following the cinematic intention of a reference video. From a reference video, cinematic features such as the start frame, end frame, framing, camera movement, and the visual features of the subjects are extracted automatically. The extracted information is used to generate the virtual camera layout, which resembles the camera layout of the reference video. Our method handles stylized as well as human characters with body proportions different from those of humans. We demonstrate the effectiveness of our approach with various reference videos and 3D animation scenes. The user evaluation results show that the generated layouts are comparable to layouts created by the artist, allowing us to assert that our method can provide effective assistance to both novice and professional users when positioning a virtual camera.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {580},
numpages = {11},
keywords = {Cinematography, Content Analysis, Virtual Camera},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445427,
author = {Yu, Junnan and DeVore, Andrea and Roque, Ricarose},
title = {Parental Mediation for Young Children’s Use of Educational Media: A Case Study with Computational Toys and Kits},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445427},
doi = {10.1145/3411764.3445427},
abstract = {Parental mediation literature is mostly situated in the contexts of television, Internet use, video games, and mobile devices, while there is less understanding of how parents mediate their children’s engagement with educational-focused media. We examine parental involvement in young children’s use of a creation-oriented educational media, i.e., coding kits, from a mediation perspective through an interview study. We frame parents’ mediation practices along three dimensions: (1) creative mediation, where parents mediate to support children’s creating and learning with media; (2) preparative mediation, where parents explore and prepare media for children’s engagement; and (3) administrative mediation, where parents administer and regulate their children’s media use. Compared to the restrictive, active, and co-using mediation theory, our proposed framework highlights various supportive practices parents take to help their children learn and create with media. We further connect our findings to Joint Media Engagement and reflect on implications for parent involvement in children’s creation-oriented media design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {475},
numpages = {12},
keywords = {Young Children, Parents, Educational Media, Parental Mediation Theory},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445423,
author = {Gordon, Mitchell L. and Zhou, Kaitlyn and Patel, Kayur and Hashimoto, Tatsunori and Bernstein, Michael S.},
title = {The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445423},
doi = {10.1145/3411764.3445423},
abstract = {Machine learning classifiers for human-facing tasks such as comment toxicity and misinformation often score highly on metrics such as ROC AUC but are received poorly in practice. Why this gap? Today, metrics such as ROC AUC, precision, and recall are used to measure technical performance; however, human-computer interaction observes that evaluation of human-facing systems should account for people’s reactions to the system. In this paper, we introduce a transformation that more closely aligns machine learning classification metrics with the values and methods of user-facing performance measures. The disagreement deconvolution takes in any multi-annotator (e.g., crowdsourced) dataset, disentangles stable opinions from noise by estimating intra-annotator consistency, and compares each test set prediction to the individual stable opinions from each annotator. Applying the disagreement deconvolution to existing social computing datasets, we find that current metrics dramatically overstate the performance of many human-facing machine learning tasks: for example, performance on a comment toxicity task is corrected from .95 to .73 ROC AUC.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {388},
numpages = {14},
location = {Yokohama, Japan},
series = {CHI '21}
}

