@inproceedings{10.1145/3491102.3517603,
author = {Hamid, Aleesha and Arshad, Rabiah and Shahid, Suleman},
title = {What Are You Thinking?: Using CBT and Storytelling to Improve Mental Health Among College Students},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517603},
doi = {10.1145/3491102.3517603},
abstract = {Depression and anxiety among college students have been on the rise globally. Cognitive Behavioural Therapy has emerged as an empirically reinforced and effective treatment. However, factors like cost, lack of resources, misguided prioritization and stigmatization of mental health issues in the Global South limit students’ access to psychotherapy. While technology can bridge this gap, research shows current self-guided mHealth apps for CBT are not always evidence-based and have limited efficacy compared to therapist-guided alternatives. In this paper, we explore whether interactive storytelling and other gamification mechanisms can increase the efficacy of a self-guided mHealth app, while drawing from empirically supported CBT protocols. We designed an mHealth application with contextualised storylines to help students learn psychological concepts and better identify the negative patterns in their thoughts. We present the results of a 3-arm randomized controlled trial conducted to assess the effect of this application compared to active and inactive control conditions.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {441},
numpages = {16},
keywords = {CBT, mHealth application, mental health, storytelling},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517582,
author = {Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun},
title = {AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517582},
doi = {10.1145/3491102.3517582},
abstract = {Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by “unit-testing” sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {385},
numpages = {22},
keywords = {Large Language Models, Human-AI Interaction, Natural Language Processing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517577,
author = {Luo, Yiyue and Wu, Kui and Spielberg, Andrew and Foshey, Michael and Rus, Daniela and Palacios, Tom\'{a}s and Matusik, Wojciech},
title = {Digital Fabrication of Pneumatic Actuators with Integrated Sensing by Machine Knitting},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517577},
doi = {10.1145/3491102.3517577},
abstract = {Soft actuators with integrated sensing have shown utility in a variety of applications such as assistive wearables, robotics, and interactive input devices. Despite their promise, these actuators can be difficult to both design and fabricate. As a solution, we present a workflow for computationally designing and digitally fabricating soft pneumatic actuators via a machine knitting process. Machine knitting is attractive as a fabrication process because it is fast, digital (programmable), and provides access to a rich material library of functional yarns for specified mechanical behavior and integrated sensing. Our method uses elastic stitches to construct non-homogeneous knitting structures, which program the bending of actuators when inflated. Our method also integrates pressure and swept frequency capacitive sensing structures using conductive yarns. The entire knitted structure is fabricated automatically in a single machine run. We further provide a computational design interface for the user to interactively preview actuators’ quasi-static shape when authoring elastic stitches. Our sensing-integrated actuators are cost-effective, easy to design, robust to large actuation, and require minimal manual post-processing. We demonstrate five use-cases of our actuators in relevant application settings.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {175},
numpages = {13},
keywords = {Pneumatic actuators, smart textiles, machine knitting},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517563,
author = {Niu, Shuo and Manon, Hugh S. and Bartolome, Ava and Ha, Nguyen Binh and Veazey, Keegan},
title = {Close-up and Whispering: An Understanding of Multimodal and Parasocial Interactions in YouTube ASMR Videos},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517563},
doi = {10.1145/3491102.3517563},
abstract = {ASMR (Autonomous Sensory Meridian Response) has grown to immense popularity on YouTube and drawn HCI designers’ attention to its effects and applications in design. YouTube ASMR creators incorporate visual elements, sounds, motifs of touching and tasting, and other scenarios in multisensory video interactions to deliver enjoyable and relaxing experiences to their viewers. ASMRtists engage viewers by social, physical, and task attractions. Research has identified the benefits of ASMR in mental wellbeing. However, ASMR remains an understudied phenomenon in the HCI community, constraining designers’ ability to incorporate ASMR in video-based designs. This work annotates and analyzes the interaction modalities and parasocial attractions of 2663 videos to identify unique experiences. YouTube comment sections are also analyzed to compare viewers’ responses to different ASMR interactions. We find that ASMR videos are experiences of multimodal social connection, relaxing physical intimacy, and sensory-rich activity observation. Design implications are discussed to foster future ASMR-augmented video interactions.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {202},
numpages = {18},
keywords = {multimodal, video, ASMR, YouTube, parasocial, experience},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517557,
author = {Kuznetsov, Stacey and Rodriguez Vega, Alejandra and Long, Elenore},
title = {A Study of Solar Cooking: Exploring Climate-Resilient Food Preparation and Opportunities for HCI},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517557},
doi = {10.1145/3491102.3517557},
abstract = {As parts of our planet continue to experience extreme heat waves, it is more urgent than ever for human-food interaction research to examine climate-resilient and sustainable food practices. Our work, conducted in the hottest city in the USA, focuses on solar cooking as a set of creative DIY activities that use extreme heat and mitigate human impact on the environment. We report on a summer-long study whereby 7 enthusiasts built solar ovens from scratch and experimented with solar recipes ranging from slow-cooked pork and chicken to bread, kale chips, brownies, jerky, and fruit rollups. Our findings depict solar cooking as a form of iterative DIY, which, through its challenges and creative workarounds, serves as a point of engagement with both food and extreme heat. We reflect on solar cooking as a climate-resilient food practice and conclude with design considerations for HCI to support solar cooking as a habitual community practice.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {457},
numpages = {8},
keywords = {Solar cooking, food science, DIY, sustainable HCI},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517537,
author = {Subramonyam, Hariharan and Im, Jane and Seifert, Colleen and Adar, Eytan},
title = {Solving Separation-of-Concerns Problems in Collaborative Design of Human-AI Systems through Leaky Abstractions},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517537},
doi = {10.1145/3491102.3517537},
abstract = {In conventional software development, user experience (UX) designers and engineers collaborate through separation of concerns (SoC): designers create human interface specifications, and engineers build to those specifications. However, we argue that Human-AI systems thwart SoC because human needs must shape the design of the AI interface, the underlying AI sub-components, and training data. How do designers and engineers currently collaborate on AI and UX design? To find out, we interviewed 21 industry professionals (UX researchers, AI engineers, data scientists, and managers) across 14 organizations about their collaborative work practices and associated challenges. We find that hidden information encapsulated by SoC challenges collaboration across design and engineering concerns. Practitioners describe inventing ad-hoc representations exposing low-level design and implementation details (which we characterize as leaky abstractions) to “puncture” SoC and share information across expertise boundaries. We identify how leaky abstractions are employed to collaborate at the AI-UX boundary and formalize a process of creating and using leaky abstractions.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {481},
numpages = {21},
keywords = {Human-AI systems, Industry practices, AI applications, UX design, design processes},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517525,
author = {Hu, Yaxin and Qu, Yuxiao and Maus, Adam and Mutlu, Bilge},
title = {Polite or Direct? Conversation Design of a Smart Display for Older Adults Based on Politeness Theory},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517525},
doi = {10.1145/3491102.3517525},
abstract = {Conversational interfaces increasingly rely on human-like dialogue to offer a natural experience. However, relying on dialogue involving multiple exchanges for even simple tasks can overburden users, particularly older adults. In this paper, we explored the use of politeness theory in conversation design to alleviate this burden and improve user experience. To achieve this goal, we categorized the voice interaction offered by a smart display application designed for older adults into seven major speech acts: request, suggest, instruct, comment, welcome, farewell, and repair. We identified face needs for each speech act, applied politeness strategies that best address these needs, and tested the ability of these strategies to shape the perceived politeness of a voice assistant in an online study (n = 64). Based on the findings of this study, we designed direct and polite versions of the system and conducted a field study (n = 15) in which participants used each of the versions for five days at their homes. Based on five factors merged from our qualitative findings, we identified four distinctive user personas—socially oriented follower, socially oriented leader, utility oriented follower, and utility oriented leader—that can inform personalized design of smart displays.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {307},
numpages = {15},
keywords = {smart displays, older adults, multimodal interaction, politeness theory, Conversation design},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517517,
author = {Goyal, Nitesh and Park, Leslie and Vasserman, Lucy},
title = {”You Have to Prove the Threat is Real”: Understanding the Needs of Female Journalists and Activists to Document and Report Online Harassment},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517517},
doi = {10.1145/3491102.3517517},
abstract = {Online harassment is a major societal challenge that impacts multiple communities. Some members of community, like female journalists and activists, bear significantly higher impacts since their profession requires easy accessibility, transparency about their identity, and involves highlighting stories of injustice. Through a multi-phased qualitative research study involving a focus group and interviews with 27 female journalists and activists, we mapped the journey of a target who goes through harassment. We introduce PMCR framework, as a way to focus on needs for Prevention, Monitoring, Crisis and Recovery. We focused on Crisis and Recovery, and designed a tool to satisfy a target’s needs related to documenting evidence of harassment during the crisis and creating reports that could be shared with support networks for recovery. Finally, we discuss users’ feedback to this tool, highlighting needs for targets as they face the burden and offer recommendations to future designers and scholars on how to develop tools that can help targets manage their harassment.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {242},
numpages = {17},
keywords = {Managing Online Harassment, Sensemaking, Activist, Harassment, Perspective API, Gendered Harassment, Online Harassment, Solidarity, Journalist, Feminism, Social Media, PMCR},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517500,
author = {Cila, Nazli},
title = {Designing Human-Agent Collaborations: Commitment, Responsiveness, and Support},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517500},
doi = {10.1145/3491102.3517500},
abstract = {With the advancements in AI, agents (i.e., smart products, robots, software agents) are increasingly capable of working closely together with humans in a variety of ways while benefiting from each other. These human-agent collaborations have gained growing attention in the HCI community; however, the field lacks clear guidelines on how to design the agents’ behaviors in collaborations. In this paper, the qualities that are relevant for designers to create robust and pleasant human-agent collaborations were investigated. Bratman's Shared Cooperative Activity framework was used to identify the core characteristics of collaborations and survey the most important issues in the design of human-agent collaborations, namely code-of-conduct, task delegation, autonomy and control, intelligibility, common ground, offering help and requesting help. The aim of this work is to add structure to this growing and important facet of HCI research and operationalize the concept of human-agent collaboration with concrete design considerations.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {420},
numpages = {18},
keywords = {autonomous agent, Shared Cooperative Activity, design, human-agent collaboration},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517496,
author = {Chou, Yu-Ling and Lin, Yi-Hsiu and Lin, Tzu-Yi and You, Hsin Ying and Chang, Yung-Ju},
title = {Why Did You/I Read but Not Reply? IM Users’ Unresponded-to Read-Receipt Practices and Explanations of Them},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517496},
doi = {10.1145/3491102.3517496},
abstract = {We investigate instant-messaging (IM) users’ sense-making and practices around read-receipts: a feature of IM apps for supporting the awareness of turn-taking, i.e., whether a message recipient has read a message. Using a grounded-theory approach, we highlight the importance of five contextual factors – situational, relational, interactional, conversational, and personal – that shape the variety of IM users’ sense-making about read-receipts and strategies for utilizing them in different settings. This approach yields a 21-part typology comprising five types of senders’ speculation about why their messages with read-receipts have not been answered; eight types of recipients’ causes/reasons behind such non-response; and four types of senders’ and recipients’ subsequent strategies, respectively. Mismatches between senders’ speculations about un-responded-to read-receipted messages (URRMs) and recipients’ self-reported explanations are also discussed as sources of communicative friction. The findings reveal that, beyond indicating turn-taking, read-receipts have been leveraged as a strategic tool for various purposes in interpersonal relations.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {526},
numpages = {15},
keywords = {explanation, turn-taking, responsiveness, instant messaging, texting, seen function, Read receipt, sense-making},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517487,
author = {Chen, Zhilong and Cao, Hancheng and Lan, Xiaochong and Lu, Zhicong and Li, Yong},
title = {Beyond Virtual Bazaar: How Social Commerce Promotes Inclusivity for the Traditionally Underserved Community in Chinese Developing Regions},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517487},
doi = {10.1145/3491102.3517487},
abstract = {The disadvantaged population is often underserved and marginalized in technology engagement: prior works show they are generally more reluctant and experience more barriers in adopting and engaging with mainstream technology. Here, we contribute to the HCI4D and ICTD literature through a novel “counter” case study on Chinese social commerce (e.g., Pinduoduo), which 1) first prospers among the traditionally underserved community from developing regions ahead of the more technologically advantaged communities, and 2) has been heavily engaged by this community. Through 12 in-depth interviews with social commerce users from the traditionally underserved community in Chinese developing regions, we demonstrate how social commerce, acting as a “virtual bazaar”, brings online the traditional offline socioeconomic lives the community has lived for ages, fits into the community’s social, cultural, and economic context, and thus effectively promotes technology inclusivity. Our work provides novel insights and implications for building inclusive technology for the “next billion” population.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {369},
numpages = {15},
keywords = {HCI4D, inclusive, underserved, bazaar, social commerce},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517479,
author = {Zhang, Zheng and Xu, Ying and Wang, Yanhao and Yao, Bingsheng and Ritchie, Daniel and Wu, Tongshuang and Yu, Mo and Wang, Dakuo and Li, Toby Jia-Jun},
title = {StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with Flexible Parental Involvement},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517479},
doi = {10.1145/3491102.3517479},
abstract = {Despite its benefits for children’s skill development and parent-child bonding, many parents do not often engage in interactive storytelling by having story-related dialogues with their child due to limited availability or challenges in coming up with appropriate questions. While recent advances made AI generation of questions from stories possible, the fully-automated approach excludes parent involvement, disregards educational goals, and underoptimizes for child engagement. Informed by need-finding interviews and participatory design (PD) results, we developed StoryBuddy, an AI-enabled system for parents to create interactive storytelling experiences. StoryBuddy’s design highlighted the need for accommodating dynamic user needs between the desire for parent involvement and parent-child bonding and the goal of minimizing parent intervention when busy. The PD revealed varied assessment and educational goals of parents, which StoryBuddy addressed by supporting configuring question types and tracking child progress. A user study validated StoryBuddy’s usability and suggested design insights for future parent-AI collaboration systems.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {218},
numpages = {21},
keywords = {dialogic reading, voice user interfaces, human-AI collaboration, child-agent interactions, interactive storytelling, co-reading},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517476,
author = {Xu, Xuhai and Zou, Tianyuan and Xiao, Han and Li, Yanzhang and Wang, Ruolin and Yuan, Tianyi and Wang, Yuntao and Shi, Yuanchun and Mankoff, Jennifer and Dey, Anind K},
title = {TypeOut: Leveraging Just-in-Time Self-Affirmation for Smartphone Overuse Reduction},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517476},
doi = {10.1145/3491102.3517476},
abstract = {Smartphone overuse is related to a variety of issues such as lack of sleep and anxiety. We explore the application of Self-Affirmation Theory on smartphone overuse intervention in a just-in-time manner. We present TypeOut, a just-in-time intervention technique that integrates two components: an in-situ typing-based unlock process to improve user engagement, and self-affirmation-based typing content to enhance effectiveness. We hypothesize that the integration of typing and self-affirmation content can better reduce smartphone overuse. We conducted a 10-week within-subject field experiment (N=54) and compared TypeOut against two baselines: one only showing the self-affirmation content (a common notification-based intervention), and one only requiring typing non-semantic content (a state-of-the-art method). TypeOut reduces app usage by over 50%, and both app opening frequency and usage duration by over 25%, all significantly outperforming baselines. TypeOut can potentially be used in other domains where an intervention may benefit from integrating self-affirmation exercises with an engaging just-in-time mechanism.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {17},
keywords = {intervention design, Smartphone overuse, self-affirmation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517469,
author = {Wang, Yanan and Wang, Ruobin and Jung, Crescentia and Kim, Yea-Seul},
title = {What Makes Web Data Tables Accessible? Insights and a Tool for Rendering Accessible Tables for People with Visual Impairments},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517469},
doi = {10.1145/3491102.3517469},
abstract = {The data table is a basic but versatile representation to communicate data. From government reports to bank statements, tables effectively carry essential data-driven information by visually organizing data using rows, columns, and other arrangements (e.g., merged cells). However, many tables online neglect the accessibility requirements for people who rely on screen readers, such as people who are blind or have low vision (BLV). First, we consolidated guidelines to understand what makes a table inaccessible for BLV people. We conducted an interview study to understand the importance of tables and identify further design requirements for an accessible table. We built a tool that automatically detects HTML formatted tables online and transforms them into accessible tables. Our evaluative study demonstrates how our tool can help participants understand the table’s structure and layout and support smooth navigation when the table is large and complex.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {595},
numpages = {20},
keywords = {Empirical study that tells us about how people use a system, Accessibility, Data Tables, Artifact or System, Individuals with Disabilities &amp; Assistive Technologies},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517460,
author = {Saha, Manaswi and Patil, Siddhant and Cho, Emily and Cheng, Evie Yu-Yen and Horng, Chris and Chauhan, Devanshi and Kangas, Rachel and McGovern, Richard and Li, Anthony and Heer, Jeffrey and Froehlich, Jon E.},
title = {Visualizing Urban Accessibility: Investigating Multi-Stakeholder Perspectives through a Map-Based Design Probe Study},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517460},
doi = {10.1145/3491102.3517460},
abstract = {Urban accessibility assessments are challenging: they involve varied stakeholders across decision-making contexts while serving a diverse population of people with disabilities. To better support urban accessibility assessment using data visualizations, we conducted a three-part interview study with 25 participants across five stakeholder groups using map visualization probes. We present a multi-stakeholder analysis of visualization needs and sensemaking processes to explore how interactive visualizations can support stakeholder decision making. In particular, we elaborate how stakeholders’ varying levels of familiarity with accessibility, geospatial analysis, and specific geographic locations influences their sensemaking needs. We then contribute 10 design considerations for geovisual analytic tools for urban accessibility communication, planning, policymaking, and advocacy.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {413},
numpages = {14},
keywords = {decision-making, sensemaking, geovisual analysis, physical accessibility, urban tech, visualization},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517459,
author = {Pan, Lihang and Yu, Chun and Li, JiaHui and Huang, Tian and Bi, Xiaojun and Shi, Yuanchun},
title = {Automatically Generating and Improving Voice Command Interface from Operation Sequences on Smartphones},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517459},
doi = {10.1145/3491102.3517459},
abstract = {Using voice commands to automate smartphone tasks (e.g., making a video call) can effectively augment the interactivity of numerous mobile apps. However, creating voice command interfaces requires a tremendous amount of effort in labeling and compiling the graphical user interface (GUI) and the utterance data. In this paper, we propose AutoVCI, a novel approach to automatically generate voice command interface (VCI) from smartphone operation sequences. The generated voice command interface has two distinct features. First, it automatically maps a voice command to GUI operations and fills in parameters accordingly, leveraging the GUI data instead of corpus or hand-written rules. Second, it launches a complementary Q&amp;A dialogue to confirm the intention in case of ambiguity. In addition, the generated voice command interface can learn and evolve from user interactions. It accumulates the history command understanding results to annotate the user’s input and improve its semantic understanding ability. We implemented this approach on Android devices and conducted a two-phase user study with 16 and 67 participants in each phase. Experimental results of the study demonstrated the practical feasibility of AutoVCI.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {208},
numpages = {21},
keywords = {interaction-centered nature language understanding, voice command interface, generation system, operation sequence},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517453,
author = {Kaur, Harmanpreet and McDuff, Daniel and Williams, Alex C. and Teevan, Jaime and Iqbal, Shamsi T.},
title = {“I Didn’t Know I Looked Angry”: Characterizing Observed Emotion and Reported Affect at Work},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517453},
doi = {10.1145/3491102.3517453},
abstract = {With the growing prevalence of affective computing applications, Automatic Emotion Recognition (AER) technologies have garnered attention in both research and industry settings. Initially limited to speech-based applications, AER technologies now include analysis of facial landmarks to provide predicted probabilities of a common subset of emotions (e.g., anger, happiness) for faces observed in an image or video frame. In this paper, we study the relationship between AER outputs and self-reports of affect employed by prior work, in the context of information work at a technology company. We compare the continuous observed emotion output from an AER tool to discrete reported affect obtained via a one-day combined tool-use and diary study (N = 15). We provide empirical evidence showing that these signals do not completely align, and find that using additional workplace context only improves alignment up to 58.6%. These results suggest affect must be studied in the context it is being expressed, and observed emotion signal should not replace internal reported affect for affective computing applications.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {199},
numpages = {18},
keywords = {workplace, Affect, emotion labeling},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517432,
author = {Wei, Jing and Tag, Benjamin and Trippas, Johanne R and Dingler, Tilman and Kostakos, Vassilis},
title = {What Could Possibly Go Wrong When Interacting with Proactive Smart Speakers? A Case Study Using an ESM Application},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517432},
doi = {10.1145/3491102.3517432},
abstract = {Voice user interfaces (VUIs) have made their way into people’s daily lives, from voice assistants to smart speakers. Although VUIs typically just react to direct user commands, increasingly, they incorporate elements of proactive behaviors. In particular, proactive smart speakers have the potential for many applications, ranging from healthcare to entertainment; however, their usability in everyday life is subject to interaction errors. To systematically investigate the nature of errors, we designed a voice-based Experience Sampling Method (ESM) application to run on proactive speakers. We captured 1,213 user interactions in a 3-week field deployment in 13 participants’ homes. Through auxiliary audio recordings and logs, we identify substantial interaction errors and strategies that users apply to overcome those errors. We further analyze the interaction timings and provide insights into the time cost of errors. We find that, even for answering simple ESMs, interaction errors occur frequently and can hamper the usability of proactive speakers and user experience. Our work also identifies multiple facets of VUIs that can be improved in terms of the timing of speech.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {15},
keywords = {Google Home, interaction error, user experience, Voice user interface, voice assistants, smart speakers},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502143,
author = {Fok, Raymond and Zhong, Mingyuan and Ross, Anne Spencer and Fogarty, James and Wobbrock, Jacob O.},
title = {A Large-Scale Longitudinal Analysis of Missing Label Accessibility Failures in Android Apps},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502143},
doi = {10.1145/3491102.3502143},
abstract = {We present the first large-scale longitudinal analysis of missing label accessibility failures in Android apps. We developed a crawler and collected monthly snapshots of 312 apps over 16 months. We use this unique dataset in empirical examinations of accessibility not possible in prior datasets. Key large-scale findings include missing label failures in 55.6% of unique image-based elements, longitudinal improvement in ImageButton elements but not in more prevalent ImageView elements, that 8.8% of unique screens are unreachable without navigating at least one missing label failure, that app failure rate does not improve with number of downloads, and that effective labeling is neither limited to nor guaranteed by large software organizations. We then examine longitudinal data in individual apps, presenting illustrative examples of accessibility impacts of systematic improvements, incomplete improvements, interface redesigns, and accessibility regressions. We discuss these findings and potential opportunities for tools and practices to improve label-based accessibility.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {461},
numpages = {16},
keywords = {large-scale longitudinal analysis, mobile app accessibility},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502142,
author = {Kim, Jin Hee (Heather) and Patil, Shreyas Dilip and Matson, Sarina and Conroy, Melissa and Kao, Cindy Hsin-Liu},
title = {KnitSkin: Machine-Knitted Scaled Skin for Locomotion},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502142},
doi = {10.1145/3491102.3502142},
abstract = {We present KnitSkin, a bio-inspired sleeve that can traverse diverse cylindrical terrains, ranging from a user’s forearm at a wearable scale, to pipes and tree branches at an environmental scale. Fabricated with a machine knitted substrate, the sleeve configures a stepped array of knitted scales that exhibit anisotropic friction. Coupled with the extension of actuators enclosed in the sleeve, the scales enable effective directional locomotion on cylindrical surfaces with varying slopes, textures, and curvatures. KnitSkin’s substrates are characterized by scales whose geometries and materials can be fine-tuned and channels that can accommodate diverse actuators. We introduce the design elements of KnitSkin in which we characterize a series of substrate parameters and their resulting anisotropic behaviors. In evaluating the locomotion, we examine the variables associated with the surface and actuator characteristics. KnitSkin obtains diverse applications across different scales, including wearable interfaces, industrial pipe-monitoring, to agricultural robots.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {391},
numpages = {15},
keywords = {Wearable Robots, Smart Textiles, Mobile Robots, Machine Knitting},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502137,
author = {Thakkar, Parth Kirankumar and He, Shijing and Xu, Shiyu and Huang, Danny Yuxing and Yao, Yaxing},
title = {“It Would Probably Turn into a Social Faux-Pas”: Users’ and Bystanders’ Preferences of Privacy Awareness Mechanisms in Smart Homes},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502137},
doi = {10.1145/3491102.3502137},
abstract = {The opaque data practices in smart home devices have raised significant privacy concerns for smart home users and bystanders. One way to learn about the data practices is through privacy-related notifications. However, how to deliver these notifications to users and bystanders and increase their awareness of data practices is not clear. We surveyed 136 users and 123 bystanders to understand their preferences of receiving privacy-related notifications in smart homes. We further collected their responses to four mechanisms that improve privacy awareness (e.g., Data Dashboard) as well as their selections of mechanisms in four different scenarios (e.g., friend visiting). Our results showed the pros and cons of each privacy awareness mechanism, e.g., Data Dashboard can help reduce bystanders’ dependence on users. We also found some unique benefits of each mechanism (e.g., Ambient Light could provide unobtrusive privacy awareness). We summarized four key design dimensions for future privacy awareness mechanisms design.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {404},
numpages = {13},
keywords = {Notifications, Smart Homes, Privacy Awareness, Privacy, Multi-Stakeholder, Bystanders},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502135,
author = {Daud\'{e}n Roquet, Claudia and Theofanopoulou, Nikki and Freeman, Jaimie L and Schleider, Jessica and Gross, James J and Davis, Katie and Townsend, Ellen and Slovak, Petr},
title = {Exploring Situated &amp; Embodied Support for Youth’s Mental Health: Design Opportunities for Interactive Tangible Device},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502135},
doi = {10.1145/3491102.3502135},
abstract = {The ability to manage emotions effectively is critical to healthy psychological and social development in youth. Prior work has focused on investigating the design of mental health technologies for this population, yet it is still unclear how to help them cope with emotionally difficult situations in-the-moment. In this paper, we aim to explore the appropriation, naturally emerging engagement patterns, and perceived psychological impact of an exemplar interactive tangible device intervention designed to provide in-situ support, when deployed with n=109 youth for 1.5 months. Our findings from semi-structured interviews and co-design workshops with a subset of participants (n=44 and n=25, respectively) suggest the potential of using technology-enabled objects to aid with down-regulation and self-compassion in moments of heightened emotion, to facilitate the practice of cognitive strategies, and to act as emotional companions. Lastly, we discuss design opportunities for integrating situated and embodied support in mental health interventions for youth.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {331},
numpages = {16},
keywords = {emotion regulation, embodiment, tangible interaction, youth, situated support, mental health},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502092,
author = {Zhang, Mingrui Ray and Zhong, Mingyuan and Wobbrock, Jacob O.},
title = {Ga11y: An Automated GIF Annotation System for Visually Impaired Users},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502092},
doi = {10.1145/3491102.3502092},
abstract = {Animated GIF images have become prevalent in internet culture, often used to express richer and more nuanced meanings than static images. But animated GIFs often lack adequate alternative text descriptions, and it is challenging to generate such descriptions automatically, resulting in inaccessible GIFs for blind or low-vision (BLV) users. To improve the accessibility of animated GIFs for BLV users, we provide a system called Ga11y (pronounced “galley”), for creating GIF annotations. Ga11y combines the power of machine intelligence and crowdsourcing and has three components: an Android client for submitting annotation requests, a backend server and database, and a web interface where volunteers can respond to annotation requests. We evaluated three human annotation interfaces and employ the one that yielded the best annotation quality. We also conducted a multi-stage evaluation with 12 BLV participants from the United States and China, receiving positive feedback.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {197},
numpages = {16},
keywords = {human annotation, blind, text description, GIF, low vision, crowdsourcing, images, accessibility.},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502079,
author = {Lam, Kevin C. and Gutwin, Carl and Klarkowski, Madison and Cockburn, Andy},
title = {More Errors vs. Longer Commands: The Effects of Repetition and Reduced Expressiveness on Input Interpretation Error, Learning, and Effort},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502079},
doi = {10.1145/3491102.3502079},
abstract = {Many interactive systems are susceptible to misinterpreting the user’s input actions or gestures. Interpretation errors are common when systems gather a series of signals from the user and then attempt to interpret the user’s intention based on those signals – e.g., gesture identification from a touchscreen, camera, or body-worn electrodes – and previous work has shown that interpretation error can cause significant problems for learning new input commands. Error-reduction strategies from telecommunications, such as repeating a command or increasing the length of the input while reducing its expressiveness, could improve these input mechanisms – but little is known about whether longer command sequences will cause problems for users (e.g., increased effort or reduced learning). We tested performance, learning, and perceived effort in a crowd-sourced study where participants learned and used input mechanisms with different error-reduction techniques. We found that error reduction techniques are feasible, can outperform error-prone ordinary input, and do not negatively affect learning or perceived effort.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {291},
numpages = {17},
keywords = {interpretation error, error correction, input expressiveness, input error},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502075,
author = {Yan, Chuan and Chung, John Joon Young and Kiheon, Yoon and Gingold, Yotam and Adar, Eytan and Hong, Sungsoo Ray},
title = {FlatMagic: Improving Flat Colorization through AI-Driven Design for Digital Comic Professionals},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502075},
doi = {10.1145/3491102.3502075},
abstract = {Creating digital comics involves multiple stages, some creative and some menial. For example, coloring a comic requires a labor-intensive stage known as ‘flatting,’ or masking segments of continuous color, as well as creative shading, lighting, and stylization stages. The use of AI can automate the colorization process, but early efforts have revealed limitations—technical and UX—to full automation. Via a formative study of professionals, we identify flatting as a bottleneck and key target of opportunity for human-guided AI-driven automation. Based on this insight, we built FlatMagic, an interactive, AI-driven flat colorization support tool for Photoshop. Our user studies found that using FlatMagic significantly reduced professionals’ real and perceived effort versus their current practice. While participants effectively used FlatMagic, we also identified potential constraints in interactions with AI and partially automated workflows. We reflect on implications for comic-focused tools and the benefits and pitfalls of intermediate representations and partial automation in designing human-AI collaboration tools for professionals.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {380},
numpages = {17},
keywords = {Human-AI collaboration, automation and control, Intermediate Representation, system for professionals, digital comic colorization},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502074,
author = {Pourjafarian, Narjes and Koelle, Marion and Mjaku, Fjolla and Strohmeier, Paul and Steimle, J\"{u}rgen},
title = {Print-A-Sketch: A Handheld Printer for Physical Sketching of Circuits and Sensors on Everyday Surfaces},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502074},
doi = {10.1145/3491102.3502074},
abstract = {We present Print-A-Sketch, an open-source handheld printer prototype for sketching circuits and sensors. Print-A-Sketch combines desirable properties from free-hand sketching and functional electronic printing. Manual human control of large strokes is augmented with computer control of fine detail. Shared control of Print-A-Sketch supports sketching interactive interfaces on everyday objects – including many objects with materials or sizes which otherwise are difficult to print on. We present an overview of challenges involved in such a system and show how these can be addressed using context-aware, dynamic printing. Continuous sensing ensures quality prints by adjusting inking-rate to hand movement and material properties. Continuous sensing also enables the print to adapt to previously printed traces to support incremental and iterative sketching. Results show good conductivity on many materials and high spatial precision, supporting on-the-fly creation of functional interfaces.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {17},
keywords = {sketching interfaces, Fabrication, printed electronics, new materials, conductive inkjet printing, prototyping},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502065,
author = {Yang, Humphrey and Johnson, Tate and Zhong, Ke and Patel, Dinesh and Olson, Gina and Majidi, Carmel and Islam, Mohammad and Yao, Lining},
title = {ReCompFig: Designing Dynamically Reconfigurable Kinematic Devices Using Compliant Mechanisms and Tensioning Cables},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502065},
doi = {10.1145/3491102.3502065},
abstract = {From creating input devices to rendering tangible information, the field of HCI is interested in using kinematic mechanisms to create human-computer interfaces. Yet, due to fabrication and design challenges, it is often difficult to create kinematic devices that are compact and have multiple reconfigurable motional degrees of freedom (DOFs) depending on the interaction scenarios. In this work, we combine compliant mechanisms (CMs) with tensioning cables to create dynamically reconfigurable kinematic mechanisms. The devices’ kinematics (DOFs) is enabled and determined by the layout of bendable rods. The additional cables function as on-demand motion constraints that can dynamically lock or unlock the mechanism's DOFs as they are tightened or loosened. We provide algorithms and a design tool prototype to help users design such kinematic devices. We also demonstrate various HCI use cases including a kinematic haptic display, a haptic proxy, and a multimodal input device.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {170},
numpages = {14},
keywords = {Haptic proxies, compliant mechanism, kinematic devices, wearables, design tool},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502039,
author = {Nadal, Camille and McCully, Shane and Doherty, Kevin and Sas, Corina and Doherty, Gavin},
title = {The TAC Toolkit: Supporting Design for User Acceptance of Health Technologies from a Macro-Temporal Perspective},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502039},
doi = {10.1145/3491102.3502039},
abstract = {User acceptance is key for the successful uptake and use of health technologies, but also impacted by numerous factors not always easily accessible nor operationalised by designers in practice. This work seeks to facilitate the application of acceptance theory in design practice through the Technology Acceptance (TAC) toolkit: a novel theory-based design tool and method comprising 16 cards, 3 personas, 3 scenarios, a virtual think-space, and a website, which we evaluated through workshops conducted with 21 designers of health technologies. Findings showed that the toolkit revised and extended designers’ knowledge of technology acceptance, fostered their appreciation, empathy and ethical values while designing for acceptance, and contributed towards shaping their future design practice. We discuss implications for considering user acceptance a dynamic, multi-stage process in design practice, and better supporting designers in imagining distant acceptance challenges. Finally, we examine the generative value of the TAC toolkit and its possible future evolution.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {233},
numpages = {18},
keywords = {design cards, technology acceptance lifecycle, technology acceptance, macro-temporal perspective, user-centered design},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502026,
author = {Qian, Jing and Sun, Qi and Wigington, Curtis and Han, Han L. and Sun, Tong and Healey, Jennifer and Tompkin, James and Huang, Jeff},
title = {Dually Noted: Layout-Aware Annotations with Smartphone Augmented Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502026},
doi = {10.1145/3491102.3502026},
abstract = {Sharing annotations encourages feedback, discussion, and knowledge passing among readers and can be beneficial for personal and public use. Prior augmented reality (AR) systems have expanded these benefits to both digital and printed documents. However, despite smartphone AR now being widely available, there is a lack of research about how to use AR effectively for interactive document annotation. We propose Dually Noted, a smartphone-based AR annotation system that recognizes the layout of structural elements in a printed document for real-time authoring and viewing of annotations. We conducted experience prototyping with eight users to elicit potential benefits and challenges within smartphone AR, and this informed the resulting Dually Noted system and annotation interactions with the document elements. AR annotation is often unwieldy, but during a 12-user empirical study our novel structural understanding component allows Dually Noted to improve precise highlighting and annotation interaction accuracy by 13%, increase interaction speed by 42%, and significantly lower cognitive load over a baseline method without document layout understanding. Qualitatively, participants commented that Dually Noted was a swift and portable annotation experience. Overall, our research provides new methods and insights for how to improve AR annotations for physical documents.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {552},
numpages = {15},
keywords = {Annotation, paper, layout structure, augmented reality, smartphone, text, document interaction},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502021,
author = {Horn, Mike and Banerjee, Amartya and Brucker, Matthew},
title = {TunePad Playbooks: Designing Computational Notebooks for Creative Music Coding},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502021},
doi = {10.1145/3491102.3502021},
abstract = {This paper describes the design of an online learning platform that empowers musical creation and performance with Python code. For this platform we have developed an innovative computational notebook paradigm that we call TunePad playbooks. While playbooks borrow ideas from popular computational notebooks like Jupyter, we have designed them from the ground up to support creative musical expression including live performances. After discussing our design principles and features, we share findings from a series of artifact-centered interviews conducted with experienced TunePad users. Our results show how systems like ours might flexibly support a variety of creative workflows, while suggesting opportunities for future work in this area.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {230},
numpages = {12},
keywords = {Computational literacy, playbooks, computational notebooks, design, music},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502019,
author = {Arrambide, Karina and Yoon, John and MacArthur, Cayley and Rogers, Katja and Luz, Alessandra and Nacke, Lennart E.},
title = {“I Don’t Want To Shoot The Android”: Players Translate Real-Life Moral Intuitions to In-Game Decisions in Detroit: Become Human},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502019},
doi = {10.1145/3491102.3502019},
abstract = {In interactive story games, players make decisions that advance and modify the unfolding story. In many cases, these decisions have a moral component. Examining decision-making in these games illuminates whether players mobilize their real-life morality to make in-game decisions and what impact this has in both the game world and real life. Using mixed-methods consisting of semi-structured interviews and the Moral Foundations Questionnaire (MFQ30), we collected data from 19 participants who played the game Detroit: Become Human. We analyzed how participants applied their real-life morals toward in-game decisions using thematic analysis and statistical analysis of the MFQ30 results. Qualitative findings indicate that participants mobilize their moral intuitions to make in-game decisions and how much participants cared about their game characters influenced their choices. We contribute a better understanding of how players react to moral dilemmas in interactive story games for game designers to help them improve player experience.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {15},
keywords = {morality, choice, decision-making, thematic analysis, games, interactive story, moral foundations questionnaire, interactive narrative, moral foundations theory},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502015,
author = {Kimura, Naoki and Gemicioglu, Tan and Womack, Jonathan and Li, Richard and Zhao, Yuhui and Bedri, Abdelkareem and Su, Zixiong and Olwal, Alex and Rekimoto, Jun and Starner, Thad},
title = {SilentSpeller: Towards Mobile, Hands-Free, Silent Speech Text Entry Using Electropalatography},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502015},
doi = {10.1145/3491102.3502015},
abstract = {Speech is inappropriate in many situations, limiting when voice control can be used. Most unvoiced speech text entry systems can not be used while on-the-go due to movement artifacts. Using a dental retainer with capacitive touch sensors, SilentSpeller tracks tongue movement, enabling users to type by spelling words without voicing. SilentSpeller achieves an average 97% character accuracy in offline isolated word testing on a 1164-word dictionary. Walking has little effect on accuracy; average offline character accuracy was roughly equivalent on 107 phrases entered while walking (97.5%) or seated (96.5%). To demonstrate extensibility, the system was tested on 100 unseen words, leading to an average 94% accuracy. Live text entry speeds for seven participants averaged 37 words per minute at 87% accuracy. Comparing silent spelling to current practice suggests that SilentSpeller may be a viable alternative for silent mobile text entry.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {288},
numpages = {19},
keywords = {silent speech interface, text entry, wearable computing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502012,
author = {Li, Tianshi and Reiman, Kayla and Agarwal, Yuvraj and Cranor, Lorrie Faith and Hong, Jason I.},
title = {Understanding Challenges for Developers to Create Accurate Privacy Nutrition Labels},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502012},
doi = {10.1145/3491102.3502012},
abstract = {Apple announced the introduction of app privacy details to their App Store in December 2020, marking the first ever real-world, large-scale deployment of the privacy nutrition label concept, which had been introduced by researchers over a decade earlier. The Apple labels are created by app developers, who self-report their app’s data practices. In this paper, we present the first study examining the usability and understandability of Apple’s privacy nutrition label creation process from the developer’s perspective. By observing and interviewing 12 iOS app developers about how they created the privacy label for a real-world app that they developed, we identified common challenges for correctly and efficiently creating privacy labels. We discuss design implications both for improving Apple’s privacy label design and for future deployment of other standardized privacy notices.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {588},
numpages = {24},
keywords = {Privacy Nutrition Label, Developer Study, iOS Development, Interview, Privacy},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502001,
author = {Gould, Sandy J. J.},
title = {Consumption Experiences in the Research Process},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502001},
doi = {10.1145/3491102.3502001},
abstract = {Data collection is often a laborious enterprise that forms part of the wider craft skill of doing research. In this essay, I try to understand whether parts of research processes in Human-Centred Computing (HCC) have been commodified, with a particular focus on data collection. If data collection has been commodified, do researchers act as producers or consumers in the process? And if researchers are consumers, has data collection become a consumption experience? If so, what are the implications of this? I explore these questions by considering the status of craft and consumption in the research process and by developing examples of consumption experiences. I note the benefits of commodity research artefacts, while highlighting the potentially deleterious effects consumption experiences could have on our ability to generate insights into the relations between people and technology. I finish the paper by relating consumption experiences to contemporary issues in HCC and lay out a programme of empirical work that would help answer some of the questions this paper raises.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {326},
numpages = {17},
keywords = {consumption, data, commodification, data collection, craft, crowdsourcing, commodity data, research methods, science and technology studies},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502000,
author = {Taranta, Eugene Matthew and Maslych, Mykola and Ghamandi, Ryan and LaViola, Joseph},
title = {The Voight-Kampff Machine for Automatic Custom Gesture Rejection Threshold Selection},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502000},
doi = {10.1145/3491102.3502000},
abstract = {Gesture recognition systems using nearest neighbor pattern matching are able to distinguish gesture from non-gesture actions by rejecting input whose recognition scores are poor. However, in the context of gesture customization, where training data is sparse, learning a tight rejection threshold that maximizes accuracy in the presence of continuous high activity (HA) data is a challenging problem. To this end, we present the Voight-Kampff Machine (VKM), a novel approach for rejection threshold selection. VKM uses new synthetic data techniques to select an initial threshold that the system thereafter adjusts based on the training set size and expected gesture production variability. We pair VKM with a state-of-the-art custom gesture segmenter and recognizer to evaluate our system across several HA datasets, where gestures are interleaved with non-gesture actions. Compared to alternative rejection threshold selection techniques, we show that our approach is the only one that consistently achieves high performance.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {556},
numpages = {15},
keywords = {gesture, recognition, rejection, customization},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501997,
author = {Xu, Kefan and Yan, Xinghui and Newman, Mark W},
title = {Understanding People’s Experience for Physical Activity Planning and Exploring the Impact of Historical Records on Plan Creation and Execution},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501997},
doi = {10.1145/3491102.3501997},
abstract = {Making and executing physical activity plans can help people improve their physical activity levels. However, little is known about how people make physical activity plans in everyday settings and how people can be assisted in creating more successful plans. In this paper, we developed and deployed a mobile app as a probe to investigate the in-the-wild physical activity planning experience for 28 days with 17 participants. Additionally, we explored the impact of presenting successful and unsuccessful planning records on participants’ planning behaviors. Based on interviews before, during, and after the deployment, we offer a description of what factors participants considered to fit their exercise plans into their existing routines, as well as factors leading to plan failures and dissatisfaction with planned physical activity. With access to historical records, participants derived insights to improve their plans, including trends in successes and failures. Based on those findings, we discuss the implications for better supporting people to make and execute physical activity plans, including suggestions for incorporating historical records into planning tools.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {232},
numpages = {15},
keywords = {Mobile Health, Personal Informatics, Physical Activity, Qualitative Research, Planning, Self-reflection},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501992,
author = {Liao, Yi-Chi and Todi, Kashyap and Acharya, Aditya and Keurulainen, Antti and Howes, Andrew and Oulasvirta, Antti},
title = {Rediscovering Affordance: A Reinforcement Learning Perspective},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501992},
doi = {10.1145/3491102.3501992},
abstract = {Affordance refers to the perception of possible actions allowed by an object. Despite its relevance to human–computer interaction, no existing theory explains the mechanisms that underpin affordance-formation; that is, how affordances are discovered and adapted via interaction. We propose an integrative theory of affordance-formation based on the theory of reinforcement learning in cognitive sciences. The key assumption is that users learn to associate promising motor actions to percepts via experience when reinforcement signals (success/failure) are present. They also learn to categorize actions (e.g., “rotating” a dial), giving them the ability to name and reason about affordance. Upon encountering novel widgets, their ability to generalize these actions determines their ability to perceive affordances. We implement this theory in a virtual robot model, which demonstrates human-like adaptation of affordance in interactive widgets tasks. While its predictions align with trends in human data, humans are able to adapt affordances faster, suggesting the existence of additional mechanisms.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {362},
numpages = {15},
keywords = {Design, Motion Planning, Theory, Interaction, Adaptation, Affordance, Modeling, Robotics, Action, Reinforcement Learning, Perception, Machine Learning},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501933,
author = {Palani, Srishti and Ledo, David and Fitzmaurice, George and Anderson, Fraser},
title = {”I Don’t Want to Feel like I’m Working in a 1960s Factory”: The Practitioner Perspective on Creativity Support Tool Adoption},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501933},
doi = {10.1145/3491102.3501933},
abstract = {With the rapid development of creativity support tools, creative practitioners (e.g., designers, artists, architects) have to constantly explore and adopt new tools into their practice. While HCI research has focused on developing novel creativity support tools, little is known about creative practitioner’s values when exploring and adopting these tools. We collect and analyze 23 videos, 13 interviews, and 105 survey responses of creative practitioners reflecting on their values to derive a value framework. We find that practitioners value the tools’ functionality, integration into their current workflow, performance, user interface and experience, learning support, costs and emotional connection, in that order. They largely discover tools through personal recommendations. To help unify and encourage reflection from the wider community of CST stakeholders (e.g., systems creators, researchers, marketers, educators), we situate the framework within existing research on systems, creativity support tools and technology adoption.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {379},
numpages = {18},
keywords = {Tool Adoption, Creative Practitioners, Creativity Support Tools},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501857,
author = {Docherty, Niall and Biega, Asia J.},
title = {(Re)Politicizing Digital Well-Being: Beyond User Engagements},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501857},
doi = {10.1145/3491102.3501857},
abstract = {The psychological costs of the attention economy are often considered through the binary of harmful design and healthy use, with digital well-being chiefly characterised as a matter of personal responsibility. This article adopts an interdisciplinary approach to highlight the empirical, ideological, and political limits of embedding this individualised perspective in computational discourses and designs of digital well-being measurement. We will reveal well-being to be a culturally specific and environmentally conditioned concept and will problematize user engagement as a universal proxy for well-being. Instead, the contributing factors of user well-being will be located in environing social, cultural, and political conditions far beyond the control of individual users alone. In doing so, we hope to reinvigorate the issue of digital well-being measurement as a nexus point of political concern, through which multiple disciplines can study experiences of digital ill as symptomatic of wider social inequalities and (capitalist) relations of power.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {573},
numpages = {13},
keywords = {time well-spent, user engagement, measurement, well-being, power},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501844,
author = {Hanton, Ollie and Shen, Zichao and Fraser, Mike and Roudaut, Anne},
title = {FabricatINK: Personal Fabrication of Bespoke Displays Using Electronic Ink from Upcycled E Readers},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501844},
doi = {10.1145/3491102.3501844},
abstract = {Abstract: FabricatINK explores the personal fabrication of irregularly-shaped low-power displays using electronic ink (E ink). E ink is a programmable bicolour material used in traditional form-factors such as E readers. It has potential for more versatile use within the scope of personal fabrication of custom-shaped displays, and it has the promise to be the pre-eminent material choice for this purpose. We appraise technical literature to identify properties of E ink, suited to fabrication. We identify a key roadblock, universal access to E ink as a material, and we deliver a method to circumvent this by upcycling broken electronics. We subsequently present a novel fabrication method for irregularly-shaped E ink displays. We demonstrate our fabrication process and E ink’s versatility through ten prototypes showing different applications and use cases. By addressing E ink as a material for display fabrication, we uncover the potential for users to create custom-shaped truly bistable displays.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {173},
numpages = {15},
keywords = {Display, Prototyping, Free-Form Display, E reader, Fabrication, E ink, Electrophoretic},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501834,
author = {Varanasi, Rama Adithya and Siddarth, Divya and Seshadri, Vivek and Bali, Kalika and Vashistha, Aditya},
title = {Feeling Proud, Feeling Embarrassed: Experiences of Low-Income Women with Crowd Work},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501834},
doi = {10.1145/3491102.3501834},
abstract = {Women’s economic empowerment is central to gender equality. However, work opportunities available to low-income women in patriarchal societies are infrequent. While crowd work has the potential to increase labor participation of such women, much remains unknown about their engagement with crowd work and the resultant opportunities and tensions. To fill this gap, we critically examined the adoption and use of a crowd work platform by low-income women in India. Through a qualitative study, we found that women faced tremendous challenges, for example, in seeking permission from family members to do crowd work, lack of family support and encouragement, and often working in unfavorable environments where they had to hide their work lives. While crowd work took a toll on their physical and emotional wellbeing, it also led to increased confidence, agency, and autonomy. We discuss ways to reduce frictions and tensions in participation of low-income women on crowd work platforms.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {298},
numpages = {18},
keywords = {crowdsourcing app, HCI4D, Women, crowdsourcing work, mobile crowdsourcing, crowd work},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517740,
author = {Wambsganss, Thiemo and Soellner, Matthias and Koedinger, Kenneth R and Leimeister, Jan Marco},
title = {Adaptive Empathy Learning Support in Peer Review Scenarios},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517740},
doi = {10.1145/3491102.3517740},
abstract = {Advances in Natural Language Processing offer techniques to detect the empathy level in texts. To test if individual feedback on certain students’ empathy level in their peer review writing process will help them to write more empathic reviews, we developed ELEA, an adaptive writing support system that provides students with feedback on the cognitive and emotional empathy structures. We compared ELEA to a proven empathy support tool in a peer review setting with 119 students. We found students using ELEA wrote more empathic peer reviews with a higher level of emotional empathy compared to the control group. The high perceived skill learning, the technology acceptance, and the level of enjoyment provide promising results to use such an approach as a feedback application in traditional learning settings. Our results indicate that learning applications based on NLP are able to foster empathic writing skills of students in peer review scenarios.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {227},
numpages = {17},
keywords = {Automated Feedback, Empathy Learning, Educational Applications, Writing Support Systems},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517739,
author = {Oulasvirta, Antti and Jokinen, Jussi P. P. and Howes, Andrew},
title = {Computational Rationality as a Theory of Interaction},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517739},
doi = {10.1145/3491102.3517739},
abstract = {How do people interact with computers? This fundamental question was asked by Card, Moran, and Newell in 1983 with a proposition to frame it as a question about human cognition – in other words, as a matter of how information is processed in the mind. Recently, the question has been reframed as one of adaptation: how do people adapt their interaction to the limits imposed by cognition, device design, and environment? The paper synthesizes advances toward an answer within the theoretical framework of computational rationality. The core assumption is that users act in accordance with what is best for them, given the limits imposed by their cognitive architecture and their experience of the task environment. This theory can be expressed in computational models that explain and predict interaction. The paper reviews the theoretical commitments and emerging applications in HCI, and it concludes by outlining a research agenda for future work.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {359},
numpages = {14},
keywords = {Cognitive modeling, reinforcement learning, interaction, individual differences, computational rationality, adaptation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517733,
author = {Epp, Felix Anand and Kantosalo, Anna and Jain, Nehal and Lucero, Andr\'{e}s and Mekler, Elisa D.},
title = {Adorned in Memes: Exploring the Adoption of Social Wearables in Nordic Student Culture},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517733},
doi = {10.1145/3491102.3517733},
abstract = {Social wearables promise to augment and enhance social interactions. However, despite two decades of HCI research on wearables, we are yet to see widespread adoption of social wearables into everyday life. More in-situ investigations into the social dynamics and cultural practices afforded by wearing interactive technology are needed to understand the drivers and barriers to adoption. To this end, we study social wearables in the context of Nordic student culture and the students’ practice of adorning boiler suits. Through a co-creation process, we designed Digi Merkki, a personalised interactive clothing patch. In a two-week elicitation diary study, we captured how 16 students adopted Digi Merkki into their social practices. We found that Digi Merkki afforded a variety of social interaction strategies, including sharing, spamming, and stealing pictures, which supported meaning-making and community-building. Based on our findings, we articulate “Memetic Expression” as a strong concept for designing social wearables.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {364},
numpages = {18},
keywords = {Social Wearables, Social Computing, Wearable Computing, Field Study, Digital Expression, Social Practices, Adornment, Co-design, Nordic Student Culture, Research through Design, Memes},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517706,
author = {Abtahi, Parastoo and Hough, Sidney Q. and Landay, James A. and Follmer, Sean},
title = {Beyond Being Real: A Sensorimotor Control Perspective on Interactions in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517706},
doi = {10.1145/3491102.3517706},
abstract = {We can create Virtual Reality (VR) interactions that have no equivalent in the real world by remapping spacetime or altering users’ body representation, such as stretching the user’s virtual arm for manipulation of distant objects or scaling up the user’s avatar to enable rapid locomotion. Prior research has leveraged such approaches, what we call beyond-real techniques, to make interactions in VR more practical, efficient, ergonomic, and accessible. We present a survey categorizing prior movement-based VR interaction literature as reality-based, illusory, or beyond-real interactions. We survey relevant conferences (CHI, IEEE VR, VRST, UIST, and DIS) while focusing on selection, manipulation, locomotion, and navigation in VR. For beyond-real interactions, we describe the transformations that have been used by prior works to create novel remappings. We discuss open research questions through the lens of the human sensorimotor control system and highlight challenges that need to be addressed for effective utilization of beyond-real interactions in future VR applications, including plausibility, control, long-term adaptation, and individual differences.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {358},
numpages = {17},
keywords = {sensorimotor control, framework, virtual reality, interaction design},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517691,
author = {Zinck, Graeme and Vogel, Daniel},
title = {Evaluating Singing for Computer Input Using Pitch, Interval, and Melody},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517691},
doi = {10.1145/3491102.3517691},
abstract = {In voice-based interfaces, non-verbal features represent a simple and underutilized design space for hands-free, language-agnostic interactions. We evaluate the performance of three fundamental types of voice-based musical interactions: pitch, interval, and melody. These interactions involve singing or humming a sequence of one or more notes. A 21-person study evaluates the feasibility and enjoyability of these interactions. The top performing participants were able to perform all interactions reasonably quickly (&lt;5s) with average error rates between 1.3% and 8.6% after training. Others improved with training but still had error rates as high as 46% for pitch and melody interactions. The majority of participants found all tasks enjoyable. Using these results, we propose design considerations for using singing interactions as well as potential use cases for both standard computers and augmented reality glasses.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {213},
numpages = {15},
keywords = {music, non-verbal vocal interactions},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517684,
author = {Haas, Gabriel and Rietzler, Michael and Jones, Matt and Rukzio, Enrico},
title = {Keep It Short: A Comparison of Voice Assistants’ Response Behavior},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517684},
doi = {10.1145/3491102.3517684},
abstract = {Voice assistants (VAs) are present in homes, smartphones, and cars. They allow users to perform tasks without graphical or tactile user interfaces, as they are designed for natural language interaction. However, we found that currently, VAs are emulating human behavior by responding in complete sentences, limiting the design options, and preventing VAs from meeting their full potential as a utilitarian tool. We implemented a VA that handles requests in three response styles: two differing short keyword-based response styles and a full-sentence baseline. In a user study, 72 participants interacted with our VA by issuing eight requests. Results show that the short responses were perceived similarly useful and likable while being perceived as more efficient, especially for commands, and sometimes better to comprehend than the baseline. To achieve widespread adoption, we argue that VAs should be customizable and adapt to users instead of always responding in full sentences.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {321},
numpages = {12},
keywords = {voice user interface, virtual assistant, voice assistant},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517648,
author = {Cao, Yu-Rong and Li, Xiao-Han and Pan, Jia-Yu and Lin, Wen-Chieh},
title = {VisGuide: User-Oriented Recommendations for Data Event Extraction},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517648},
doi = {10.1145/3491102.3517648},
abstract = {Data exploration systems have become popular tools with which data analysts and others can explore raw data and organize their observations. However, users of such systems who are unfamiliar with their datasets face several challenges when trying to extract data events of interest to them. Those challenges include progressively discovering informative charts, organizing them into a logical order to depict a meaningful fact, and arranging one or more facts to illustrate a data event. To alleviate them, we propose VisGuide—a data exploration system that generates personalized recommendations to aid users’ discovery of data events in breadth and depth by incrementally learning their data exploration preferences and recommending meaningful charts tailored to them. As well as user preferences, VisGuide’s recommendations simultaneously consider sequence organization and chart presentation. We conducted two user studies to evaluate 1) the usability of VisGuide and 2) user satisfaction with its recommendation system. The results of those studies indicate that VisGuide can effectively help users create coherent and user-oriented visualization trees that represent meaningful data events.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {412},
numpages = {13},
keywords = {Visualization Sequencing, Visualization Trees, Visualization Recommendation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517647,
author = {Kuang, Emily and Jin, Xiaofu and Fan, Mingming},
title = {“Merging Results Is No Easy Task”: An International Survey Study of Collaborative Data Analysis Practices Among UX Practitioners},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517647},
doi = {10.1145/3491102.3517647},
abstract = {Analysis is a key part of usability testing where UX practitioners seek to identify usability problems and generate redesign suggestions. Although previous research reported how analysis was conducted, the findings were typically focused on individual analysis or based on a small number of professionals in specific geographic regions. We conducted an online international survey of 279 UX practitioners on their practices and challenges while collaborating during data analysis. We found that UX practitioners were often under time pressure to conduct analysis and adopted three modes of collaboration: independently analyze different portions of the data and then collaborate, collaboratively analyze the session with little or no independent analysis, and independently analyze the same set of data and then collaborate. Moreover, most encountered challenges related to lack of resources, disagreements with colleagues regarding usability problems, and difficulty merging analysis from multiple practitioners. We discuss design implications to better support collaborative data analysis.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {318},
numpages = {16},
keywords = {User experience, Collaboration, Usability testing, Survey, Data analysis, UX},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517646,
author = {Shahid, Farhana and Kamath, Srujana and Sidotam, Annie and Jiang, Vivian and Batino, Alexa and Vashistha, Aditya},
title = {”It Matches My Worldview”: Examining Perceptions and Attitudes Around Fake Videos},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517646},
doi = {10.1145/3491102.3517646},
abstract = {We present a qualitative study with 36 diverse social media users in India to critically examine how low-resource communities engage with fake videos, including cheapfakes and AI-generated deepfakes. We find that most users are unaware of digitally manipulated fake videos and perceive videos to be fake only when they present inaccurate information. Few users who know about doctored videos expect them to be of poor quality and know nothing about sophisticated deepfakes. Moreover, most users lack the skills and willingness to spot fake videos and some were oblivious to the risks and harms of fake videos. Even when users know a video to be fake, they prefer to take no action and sometimes willingly share fake videos that favor their worldview. Drawing on our findings, we discuss design recommendations for social media platforms to curb the spread of fake videos.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {255},
numpages = {15},
keywords = {India, HCI4D, Misinformation, ICTD, Fake videos, Global South},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

