@inproceedings{10.1145/3411764.3445586,
author = {Antoine, Axel and Malacria, Sylvain and Marquardt, Nicolai and Casiez, G\'{e}ry},
title = {Interaction Illustration Taxonomy: Classification of Styles and Techniques for Visually Representing Interaction Scenarios},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445586},
doi = {10.1145/3411764.3445586},
abstract = {Static illustrations are ubiquitous means to represent interaction scenarios. Across papers and reports, these visuals demonstrate people’s use of devices, explain systems, or show design spaces. Creating such figures is challenging, and very little is known about the overarching strategies for visually representing interaction scenarios. To mitigate this task, we contribute a unified taxonomy of design elements that compose such figures. In particular, we provide a detailed classification of Structural and Interaction strategies, such as composition, visual techniques, dynamics, representation of users, and many others – all in context of the type of scenarios. This taxonomy can inform researchers’ choices when creating new figures, by providing a concise synthesis of visual strategies, and revealing approaches they were not aware of before. Furthermore, to support the community for creating further taxonomies, we also provide three open-source software facilitating the coding process and visual exploration of the coding scheme.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {188},
numpages = {22},
keywords = {interactive scenarios, taxonomy, figures, interaction illustrations},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445580,
author = {Syiem, Brandon Victor and Kelly, Ryan M. and Goncalves, Jorge and Velloso, Eduardo and Dingler, Tilman},
title = {Impact of Task on Attentional Tunneling in Handheld Augmented Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445580},
doi = {10.1145/3411764.3445580},
abstract = {Attentional tunneling describes a phenomenon in Augmented Reality (AR) where users excessively focus on virtual content while neglecting their physical surroundings. This leads to the concern that users could neglect hazardous situations when using AR applications. However, studies have often confounded the role of the virtual content with the role of the associated task in inducing attentional tunneling. In this paper, we disentangle the impact of the associated task and of the virtual content on the attentional tunneling effect by measuring reaction times to events in two user studies. We found that presenting virtual content did not significantly increase user reaction times to events, but adding a task to the content did. This work contributes towards our understanding of the attentional tunneling effect on handheld AR devices, and highlights the need to consider both task and context when evaluating AR application usage.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {193},
numpages = {14},
keywords = {Augmented Reality, Mobile Devices, Attentional Tunneling},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445554,
author = {Wang, Shang and Walker, Erin},
title = {Providing Adaptive Feedback in Concept Mapping to Improve Reading Comprehension},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445554},
doi = {10.1145/3411764.3445554},
abstract = {Previous research has demonstrated the benefits of applying comparative strategies while learning from informational texts, where students identify key concepts and then attempt to establish relationships between those concepts. Concept mapping is one activity that can prompt students to use comparative strategies, but not all students benefit from this activity without support. This work presents an intelligent tutoring system for concept mapping that facilitates the development of comparative strategies through diagnostic feedback that responds to the quality of students’ concept mapping process and map correctness. The novelty of the system lies in the combination of outcome-based feedback methods typical in concept mapping with adaptive process-based evaluation. In a lab study with 46 college students, we evaluate the effect of this combined adaptive support compared to solely process-based support and no support. Results suggested that the combined feedback approach showed promise at improving students’ use of comparative strategies and learning outcomes.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {677},
numpages = {11},
keywords = {comparative strategies, intelligent learning environments, concept mapping, reading comprehension},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445553,
author = {Mudliar, Preeti},
title = {Biographies of Biometric Devices: The POS Machine at Work in India's PDS},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445553},
doi = {10.1145/3411764.3445553},
abstract = {The centrality of the biometric point of sale (POS) machine in the administration of food security in Indian's public distribution system (PDS) invites scrutiny for its primacy as a non-negotiable artifact in the monthly PDS process. In this paper, I critically examine how the POS machine emerges as a site for varying imaginaries of a technologically-mediated welfare system for the three primary stakeholders of the PDS, consisting of the beneficiaries, dealers, and state administrators. Drawing on ethnographic fieldwork, the paper traces the histories of interaction and portraitures that the three stakeholders bring to their description and interpretation of the POS machine. It shows that an active POS machine provokes the stakeholders in the PDS to view it as an artifact that invites engagement on practical, moral, and knowledge dimensions. The varying ‘biographies’ that stakeholders narrate of the POS machine, collectively reveal the design, disposition, and functioning of a social justice infrastructure that rests on the compulsions of biometric technologies to improve inclusion and deter corruption in welfare delivery.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {596},
numpages = {15},
keywords = {Infrastructure, Aadhaar, Biometrics, Food security},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445552,
author = {Wang, Zeyu and Nguyen, Cuong and Asente, Paul and Dorsey, Julie},
title = {DistanciAR: Authoring Site-Specific Augmented Reality Experiences for Remote Environments},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445552},
doi = {10.1145/3411764.3445552},
abstract = {Most augmented reality (AR) authoring tools only support the author’s current environment, but designers often need to create site-specific experiences for a different environment. We propose DistanciAR, a novel tablet-based workflow for remote AR authoring. Our baseline solution involves three steps. A remote environment is captured by a camera with LiDAR; then, the author creates an AR experience from a different location using AR interactions; finally, a remote viewer consumes the AR content on site. A formative study revealed understanding and navigating the remote space as key challenges with this solution. We improved the authoring interface by adding two novel modes: Dollhouse, which renders a bird’s-eye view, and Peek, which creates photorealistic composite images using captured images. A second study compared this improved system with the baseline, and participants reported that the new modes made it easier to understand and navigate the remote scene.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {411},
numpages = {12},
keywords = {3D scanning, remote authoring, spatial design, augmented reality},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445550,
author = {Shen, Chenxinran and Lu, Zhicong and Faas, Travis and Wigdor, Daniel},
title = {The Labor of Fun: Understanding the Social Relationships between Gamers and Paid Gaming Teammates in China},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445550},
doi = {10.1145/3411764.3445550},
abstract = {Online video games support the development of social relationships through gameplay, however, gamers often cannot cultivate and maintain relationships based on social factors such as personality when using in-game matchmaking services. To address this, teammate matching sites external to games have emerged and enable gamers to offer to play games with others in exchange for payment. The affordances of these services are different from other existing gamer social sites, e.g., live streaming. Interviews were conducted with 16 dedicated users on Bixin, one of China’s largest paid teammate matching sites, to examine user motivations, practices, and perceptions. The interviews found that gamers selected paid teammates on Bixin using different criteria compared to in-game matchmaking services and emphasized the importance of real-life characteristics such as voice. To maintain connections, paid teammates often also extended communication to external communication services such as WeChat. Although most gamers expected to communicate with paid teammates as if they were friends, very few reported building real friendships with their matched counterparts.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {140},
numpages = {15},
keywords = {gaming, social media, social relationships, online community, social networking, gamers},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445549,
author = {Wang, Yu-Wei and Lin, Yu-Hsin and Ku, Pin-Sung and Miyatake, Y\={o}ko and Mao, Yi-Hsuan and Chen, Po Yu and Tseng, Chun-Miao and Chen, Mike Y.},
title = {JetController: High-Speed Ungrounded 3-DoF Force Feedback Controllers Using Air Propulsion Jets},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445549},
doi = {10.1145/3411764.3445549},
abstract = {JetController is a novel haptic technology capable of supporting high-speed and persistent 3-DoF ungrounded force feedback. It uses high-speed pneumatic solenoid valves to modulate compressed air to achieve 20-50Hz of full impulses at 4.0-1.0N, and combines multiple air propulsion jets to generate 3-DoF force feedback. Compared to propeller-based approaches, JetController supports 10-30 times faster impulse frequency, and its handheld device is significantly lighter and more compact. JetController supports a wide range of haptic events in games and VR experiences, from firing automatic weapons in games like Halo (15Hz) to slicing fruits in Fruit Ninja (up to 45Hz). To evaluate JetController, we integrated our prototype with two popular VR games, Half-life: Alyx and Beat Saber, to support a variety of 3D interactions. Study results showed that JetController significantly improved realism, enjoyment, and overall experience compared to commercial vibrating controllers, and was preferred by most participants.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {124},
numpages = {12},
keywords = {ungrounded force feedback., air propulsion, High-speed haptic feedback},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445534,
author = {Clarke, Loraine and Hornecker, Eva and Ruthven, Ian},
title = {Fighting Fires and Powering Steam Locomotives: Distribution of Control and Its Role in Social Interaction at Tangible Interactive Museum Exhibits},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445534},
doi = {10.1145/3411764.3445534},
abstract = {We present a video-analysis study of museum visitors’ interactions at two tangible interactive exhibits in a transport museum. Our focus is on groups’ social and shared interactions, in particular how exhibit setup and structure influence collaboration patterns. Behaviors at the exhibits included individuals focusing beyond their personal activity towards companions’ interaction, adults participating via physical interaction, and visitors taking opportunities to interact when companions moved between sections of the exhibit or stepped back from interaction. We demonstrate how exhibits’ physical configuration and interactive control engendered behavioral patterns. Systematic analysis reveals how different configurations (concerning physical-spatial hardware and interactive software) distribute control differently amongst visitors. We present four mechanisms for how control can be distributed at an interactive installation: functional, temporal, physical and indirect verbal. In summary, our work explores how mechanisms that distribute control influence patterns of shared interaction with the exhibits and social interaction between museum visitor companions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {344},
numpages = {17},
keywords = {Collaboration, Cultural Heritage, Museums, Public Displays, Qualitative Methods, Social Interaction, Tangible, Video Analysis},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445522,
author = {Levy, Ariel and Agrawal, Monica and Satyanarayan, Arvind and Sontag, David},
title = {Assessing the Impact of Automated Suggestions on Decision Making: Domain Experts Mediate Model Errors but Take Less Initiative},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445522},
doi = {10.1145/3411764.3445522},
abstract = {Automated decision support can accelerate tedious tasks as users can focus their attention where it is needed most. However, a key concern is whether users overly trust or cede agency to automation. In this paper, we investigate the effects of introducing automation to annotating clinical texts&nbsp;—&nbsp;a multi-step, error-prone task of identifying clinical concepts (e.g., procedures) in medical notes, and mapping them to labels in a large ontology. We consider two forms of decision aid: recommending which labels to map concepts to, and pre-populating annotation suggestions. Through laboratory studies, we find that 18 clinicians generally build intuition of when to rely on automation and when to exercise their own judgement. However, when presented with fully pre-populated suggestions, these expert users exhibit less agency: accepting improper mentions, and taking less initiative in creating additional annotations. Our findings inform how systems and algorithms should be designed to mitigate the observed issues.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {72},
numpages = {13},
keywords = {clinical annotation, agency, ontology, text tagging, human-AI teams, mental model},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445521,
author = {Gotfrid, Taylor and Mack, Kelly and Lum, Kathryn J and Yang, Evelyn and Hodgins, Jessica and Hudson, Scott E and Mankoff, Jennifer},
title = {Stitching Together the Experiences of Disabled Knitters},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445521},
doi = {10.1145/3411764.3445521},
abstract = {Knitting is a popular craft that can be used to create customized fabric objects such as household items, clothing and toys. Additionally, many knitters find knitting to be a relaxing and calming exercise. Little is known about how disabled knitters use and benefit from knitting, and what accessibility solutions and challenges they create and encounter. We conducted interviews with 16 experienced, disabled knitters and analyzed 20 threads from six forums that discussed accessible knitting to identify how and why disabled knitters knit, and what accessibility concerns remain. We additionally conducted an iterative design case study developing knitting tools for a knitter who found existing solutions insufficient. Our innovations improved the range of stitches she could produce. We conclude by arguing for the importance of improving tools for both pattern generation and modification as well as adaptations or modifications to existing tools such as looms to make it easier to track progress},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {488},
numpages = {14},
keywords = {knitting, Accessibility, craft},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445506,
author = {Wo\'{z}niak, Pawe\l{} W. and Zbytniewska, Monika and Kiss, Francisco and Niess, Jasmin},
title = {Making Sense of Complex Running Metrics Using a Modified Running Shoe},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445506},
doi = {10.1145/3411764.3445506},
abstract = {Running is a widely popular physical activity that offers many health benefits. As runners progress with their training, understanding one’s own body becomes a key concern in achieving wellbeing through running. While extensive bodily sensing opportunities exist for runners, understanding complex sensor data is a challenge. In this paper, we investigate how data from shoe-worn sensors can be visualised to empower runners to improve their technique. We designed GraFeet—an augmented running shoe that visualises kinesiological data about the runner’s feet and gait. We compared our prototype with a standard sensor dashboard in a user study where users ran with the sensor and analysed the generated data after the run. GraFeet was perceived as more usable; producing more insights and less confusion in the users. Based on our inquiry, we contribute findings about using data from body-worn sensors to support physically active individuals.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {50},
numpages = {11},
keywords = {Runscribe, running, HCI for sports, body sensing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445499,
author = {Bala, Paulo and Oakley, Ian and Nisi, Valentina and Nunes, Nuno Jardim},
title = {Dynamic Field of View Restriction in 360° Video: Aligning Optical Flow and Visual SLAM to Mitigate VIMS},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445499},
doi = {10.1145/3411764.3445499},
abstract = {Head-Mounted Display based Virtual Reality is proliferating. However, Visually Induced Motion Sickness (VIMS), which prevents many from using VR without discomfort, bars widespread adoption. Prior work has shown that limiting the Field of View (FoV) can reduce VIMS at a cost of also reducing presence. Systems that dynamically adjust a user’s FoV may be able to balance these concerns. To explore this idea, we present a technique for standard 360° video that shrinks FoVs only during VIMS inducing scenes. It uses Visual Simultaneous Localization and Mapping and peripheral optical flow to compute camera movements and reduces FoV during rapid motion or optical flow. A user study (N=23) comparing 360° video with unrestricted-FoVs (90°), reduced fixed-FoVs (40°) and dynamic-FoVs (40°-90°) revealed that dynamic-FoVs mitigate VIMS while maintaining presence. We close by discussing the user experience of dynamic-FoVs and recommendations for how they can help make VR comfortable and immersive for all.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {525},
numpages = {18},
keywords = {Simultaneous Localization and Mapping, Cinematic Virtual Reality, Visually Induced Motion Sickness, Field of View Restriction;, Optical Flow},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445490,
author = {Bu, Yaohua and Ma, Tianyi and Li, Weijun and Zhou, Hang and Jia, Jia and Chen, Shengqi and Xu, Kaiyuan and Shi, Dachuan and Wu, Haozhe and Yang, Zhihan and Li, Kun and Wu, Zhiyong and Shi, Yuanchun and Lu, Xiaobo and Liu, Ziwei},
title = {PTeacher: A Computer-Aided Personalized Pronunciation Training System with Exaggerated Audio-Visual Corrective Feedback},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445490},
doi = {10.1145/3411764.3445490},
abstract = {Second language (L2) English learners often find it difficult to improve their pronunciations due to the lack of expressive and personalized corrective feedback. In this paper, we present Pronunciation Teacher&nbsp;(PTeacher), a Computer-Aided Pronunciation Training (CAPT) system that provides personalized exaggerated audio-visual corrective feedback for mispronunciations. Though the effectiveness of exaggerated feedback has been demonstrated, it is still unclear how to define the appropriate degrees of exaggeration when interacting with individual learners. To fill in this gap, we interview 100 L2 English learners and 22 professional native teachers to understand their needs and experiences. Three critical metrics are proposed for both learners and teachers to identify the best exaggeration levels in both audio and visual modalities. Additionally, we incorporate the personalized dynamic feedback mechanism given the English proficiency of learners. Based on the obtained insights, a comprehensive interactive pronunciation training course is designed to help L2 learners rectify mispronunciations in a more perceptible, understandable, and discriminative manner. Extensive user studies demonstrate that our system significantly promotes the learners’ learning efficiency.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {676},
numpages = {14},
keywords = {Computer-Aided Pronunciation Training System, Audio-Visual Corrective Feedback, Language Learning, Exaggerated feedback},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445485,
author = {Seberger, John S. and Patil, Sameer},
title = {Us and Them (and It): Social Orientation, Privacy Concerns, and Expected Use of Pandemic-Tracking Apps in the United States},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445485},
doi = {10.1145/3411764.3445485},
abstract = {The deployment of technologies to track and mitigate the spread COVID-19 has surfaced tensions between individual autonomy and the collective good. These tensions reflect a conflict between two central concerns: (i)&nbsp;effectively controlling the spread of the pandemic and (ii)&nbsp;respecting individual rights, values, and freedoms. We explored these tensions in an online experiment (n = 389) designed to identify the influence of social orientation and communicative framing on perceptions and expected use of pandemic-tracking apps. We found that social orientation is a statistically significant predictor of app perception and expected use, with collectivist social orientation associated with higher levels and individualist social orientation with lower levels for both aspects. We found interactions between social orientation and communicative framing, as well as a connection between privacy concerns and expected duration of app use. Our findings hold important implications for the design, deployment, and adoption of technology for the public good. Shaping the post-pandemic social contract requires considering the long-term sociocultural impact of these technological solutions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {65},
numpages = {19},
keywords = {mobile apps, pandemic, COVID-19, social framing, MUIPC, smartphone apps, individualism, privacy, surveillance, social contract, contact tracing, IND-COL, social orientation, collectivism},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445483,
author = {Jokinen, Jussi and Acharya, Aditya and Uzair, Mohammad and Jiang, Xinhui and Oulasvirta, Antti},
title = {Touchscreen Typing As Optimal Supervisory Control},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445483},
doi = {10.1145/3411764.3445483},
abstract = {Traditionally, touchscreen typing has been studied in terms of motor performance. However, recent research has exposed a decisive role of visual attention being shared between the keyboard and the text area. Strategies for this are known to adapt to the task, design, and user. In this paper, we propose a unifying account of touchscreen typing, regarding it as optimal supervisory control. Under this theory, rules for controlling visuo-motor resources are learned via exploration in pursuit of maximal typing performance. The paper outlines the control problem and explains how visual and motor limitations affect it. We then present a model, implemented via reinforcement learning, that simulates co-ordination of eye and finger movements. Comparison with human data affirms that the model creates realistic finger- and eye-movement patterns and shows human-like adaptation. We demonstrate the model’s utility for interface development in evaluating touchscreen keyboard designs.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {720},
numpages = {14},
keywords = {touchscreen typing, computational modelling, rational adaptation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445481,
author = {Benjamin, Jesse Josua and Berger, Arne and Merrill, Nick and Pierce, James},
title = {Machine Learning Uncertainty as a Design Material: A Post-Phenomenological Inquiry},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445481},
doi = {10.1145/3411764.3445481},
abstract = {Design research is important for understanding and interrogating how emerging technologies shape human experience. However, design research with Machine Learning (ML) is relatively underdeveloped. Crucially, designers have not found a grasp on ML uncertainty as a design opportunity rather than an obstacle. The technical literature points to data and model uncertainties as two main properties of ML. Through post-phenomenology, we position uncertainty as one defining material attribute of ML processes which mediate human experience. To understand ML uncertainty as a design material, we investigate four design research case studies involving ML. We derive three provocative concepts: thingly uncertainty: ML-driven artefacts have uncertain, variable relations to their environments; pattern leakage: ML uncertainty can lead to patterns shaping the world they are meant to represent; and futures creep: ML technologies texture human relations to time with uncertainty. Finally, we outline design research trajectories and sketch a post-phenomenological approach to human-ML relations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {171},
numpages = {14},
keywords = {thingly uncertainty, design research, horizonal relations, machine learning, post-phenomenology},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445477,
author = {Chiang, Chia-En and Chen, Yu-Chun and Lin, Fang-Yu and Feng, Felicia and Wu, Hao-An and Lee, Hao-Ping and Yang, Chang-Hsuan and Chang, Yung-Ju},
title = {“I Got Some Free Time”: Investigating Task-Execution and Task-Effort Metrics in Mobile Crowdsourcing Tasks},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445477},
doi = {10.1145/3411764.3445477},
abstract = {Using a mixed-methods approach over six weeks, we studied 30 smartphone users’ task choices, task execution and effort devoted to two commercial mobile crowdsourcing platforms in the wild. We focused on the influence of activity contexts, characterized by breakpoint situations and activity attributes. In line with their stated preferences, the participants were more likely to proactively perform mobile crowdsourcing tasks during transitions between activities than during an ongoing activity and during long breaks, respectively. Their task choices were influenced by various activity attributes, and more impacted by their current and preceding activities than their upcoming ones. Two of our three target outcomes, task execution and task choice, were also influenced by individuals’ stress and energy levels. Our qualitative data provide further insights into participants’ decisions about which crowdsourcing tasks to perform and when; and our results’ implications for the design of future mobile crowdsourcing task-prompting mechanisms are also discussed.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {648},
numpages = {14},
keywords = {mixed-effect logistic regression, notification, ESM, qualitative analysis, interruption, Mobile crowdsourcing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445438,
author = {Vella, Kellie and Ploderer, Bernd and Brereton, Margot},
title = {Human-Nature Relations in Urban Gardens: Explorations with Camera Traps},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445438},
doi = {10.1145/3411764.3445438},
abstract = {As cities grow, their people become increasingly distanced from nature except within private and public green spaces. Sensing technologies provide a means to harness curiosity about the animals living in these spaces, and possibly also connect interest to care. Yet little is known as to how people may use these technologies, or the implications for human-nature relations. To learn more, we gave commercial camera traps to ten adult participants to understand how they explored their gardens, what they wanted to learn, and what they did with this knowledge. We discovered trade-offs between control and care; the usefulness of different media and mystery; the temporalities of engaging in natural sensing practice; and a prevalence of sharing media within households. We discuss design for convivial cohabitation with the creatures in our garden. This research contributes to better human-nature relations through citizen sensing, as well as HCI for urban biodiversity conservation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {566},
numpages = {13},
keywords = {Human Computer Interaction, Care, Gardening, Urban Biodiversity, Citizen Sensing, More-than-Human, Cameras},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445422,
author = {Strasnick, Evan and Agrawala, Maneesh and Follmer, Sean},
title = {Coupling Simulation and Hardware for Interactive Circuit Debugging},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445422},
doi = {10.1145/3411764.3445422},
abstract = {Simulation offers many advantages when designing analog circuits. Designers can explore alternatives quickly, without added cost or risk of hardware faults. However, it is challenging to use simulation as an aid during interactive debugging of physical circuits, due to difficulties in comparing simulated analyses with hardware measurements. Designers must continually configure simulations to match the state of the physical circuit (e.g. capturing sensor inputs), and must manually rework the hardware to replicate changes or analyses performed in simulation. We propose techniques leveraging instrumentation and programmable test hardware to create a tight coupling between a physical circuit and its simulated model. Bridging these representations helps designers to compare simulated and measured behaviors, and to quickly perform analytical techniques on hardware (e.g. parameter-response analysis) that are typically cumbersome outside of simulation. We implement these techniques in a prototype and show how it aids in efficiently debugging a variety of analog circuits.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {667},
numpages = {15},
keywords = {PCB, analysis, testing, debugging, circuit, simulation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445411,
author = {Frommel, Julian and Phillips, Cody and Mandryk, Regan L.},
title = {Gathering Self-Report Data in Games Through NPC Dialogues: Effects on Data Quality, Data Quantity, Player Experience, and Information Intimacy},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445411},
doi = {10.1145/3411764.3445411},
abstract = {Self-report assessment is important for research and game development, e.g., to gather data during play. Games can use dialogues with non-player characters (NPCs) to gather self-report data; however, players might respond differently to dialogues than questionnaires. Without guidance on how in-game assessment affects player perceptions and experiences, designers and researchers are in danger of making decisions that harm data quantity and quality, and perceptions of privacy. We conducted a user study to understand self-report collection from NPC dialogues and traditional in-game overlay questionnaires. Data quality and player experience measures autonomy, curiosity, immersion, and mastery did not differ significantly, although NPC dialogues enhanced meaning. NPC dialogues supported an increase in data quantity through voluntary 5-point scales but not via open responses; however, they also increased the perceived intimacy of shared information despite comparable objective intimacy. NPC dialogues are useful to gather quantitative self-report data. They enable a meaningful play experience but could facilitate negative effects related to privacy.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {118},
numpages = {12},
keywords = {surveys, non-player character, NPC, GUR, questionnaires, games user research, self-reports, intimacy, player experience},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445409,
author = {Cambre, Julia and Williams, Alex C and Razi, Afsaneh and Bicking, Ian and Wallin, Abraham and Tsai, Janice and Kulkarni, Chinmay and Kaye, Jofish},
title = {Firefox Voice: An Open and Extensible Voice Assistant Built Upon the Web},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445409},
doi = {10.1145/3411764.3445409},
abstract = {Voice assistants are fundamentally changing the way we access information. However, voice assistants still leverage little about the web beyond simple search results. We introduce Firefox Voice, a novel voice assistant built on the open web ecosystem with an aim to expand access to information available via voice. Firefox Voice is a browser extension that enables users to use their voice to perform actions such as setting timers, navigating the web, and reading a webpage’s content aloud. Through an iterative development process and use by over 12,000 active users, we find that users see voice as a way to accomplish certain browsing tasks efficiently, but struggle with discovering functionality and frequently discontinue use. We conclude by describing how Firefox Voice enables the development of novel, open web-powered voice-driven experiences.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {250},
numpages = {18},
keywords = {voice assistant, open source, conversational user interface, browser extension, CUI},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
doi = {10.1145/3411764.3445404},
abstract = {Tangibles can enrich interaction with digital surfaces. Among others, they support eyes-free control or increase awareness of other users’ actions. Tangibles have been studied in combination with horizontal surfaces such as tabletops, but not with vertical screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be placed on such surfaces without falling. We present WallTokens, easy-to-fabricate tangibles to interact with a vertical surface. A WallToken is a passive token whose footprint is recognized on a tactile surface. It is equipped with a push-handle that controls a suction cup. This makes it easy for users to switch between sliding the token or attaching it to the wall. We describe how to build such tokens and how to recognize them on a tactile surface. We report on a study showing the benefits of WallTokens for manipulating virtual objects over multi-touch gestures. This project is a step towards enabling tangible interaction in a wall display context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Tangible Interaction, Wall-sized display, Tokens, Fabrication},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445403,
author = {Brul\'{e}, Emeline and Bailly, Gilles},
title = {”Beyond 3D Printers”: Understanding Long-Term Digital Fabrication Practices for the Education of Visually Impaired or Blind Youth},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445403},
doi = {10.1145/3411764.3445403},
abstract = {Disability professionals could use digital fabrication tools to provide customised assistive technologies or accessible media beneficial to the education of Blind or visually impaired youth. However, there is little documentation of long-term practices with these tools by professionals in this field, limiting our ability to support their work. We report on such practices in a French organisation, providing disability educational services and using digital fabrication since 2013, for six years. We trace how professionals defined how digital fabrication could and should be used through a range of projects, based on pedagogical uses and the constraints in creation, production and maintenance. We outline new research perspectives going beyond 3D printers and its promises of automation to embrace hybrid approaches currently supported by laser cutters, the learning and documentation process, and the production of accessible tactile media at a regional or national scale.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {44},
numpages = {15},
keywords = {Social Design, Maker Space, Activity Theory, Workplace, Do-It-Yourself, 3D Printing, Tactile, Inclusive Innovation, Making, Disability, School, Fablab},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445400,
author = {Srinivasan, Arjun and Nyapathy, Nikhila and Lee, Bongshin and Drucker, Steven M. and Stasko, John},
title = {Collecting and Characterizing Natural Language Utterances for Specifying Data Visualizations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445400},
doi = {10.1145/3411764.3445400},
abstract = {Natural language interfaces (NLIs) for data visualization are becoming increasingly popular both in academic research and in commercial software. Yet, there is a lack of empirical understanding of how people specify visualizations through natural language. We conducted an online study (N = 102), showing participants a series of visualizations and asking them to provide utterances they would pose to generate the displayed charts. From the responses, we curated a dataset of 893 utterances and characterized the utterances according to (1) their phrasing (e.g., commands, queries, questions) and (2) the information they contained (e.g., chart types, data aggregations). To help guide future research and development, we contribute this utterance dataset and discuss its applications toward the creation and benchmarking of NLIs for visualization.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {464},
numpages = {10},
keywords = {data visualization, natural language corpus, natural language interfaces, natural language processing, visualization specification},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445397,
author = {Niu, Shuo and Bartolome, Ava and Mai, Cat and Ha, Nguyen Binh},
title = {#StayHome #WithMe: How Do YouTubers Help with COVID-19 Loneliness?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445397},
doi = {10.1145/3411764.3445397},
abstract = {Loneliness threatens public mental wellbeing during COVID-19. In response, YouTube creators participated in the #StayHome #WithMe movement (SHWM) and made myriad videos for people experiencing loneliness or boredom at home. User-shared videos generate parasocial attachment and virtual connectedness. However, there is limited knowledge of how creators contributed videos during disasters to provide social provisions as disaster-relief. Grounded on Weiss’s loneliness theory, this work analyzed 1488 SHWM videos to examine video sharing as a pathway to social provisions. Findings suggested that skill and knowledge sharing, entertaining arts, homelife activities, live chatting, and gameplay were the most popular video styles. YouTubers utilized parasocial relationships to form a space for staying away from the disaster. SHWM YouTubers provided friend-like, mentor-like, and family-like provisions through videos in different styles. Family-like provisions led to the highest overall viewer engagement. Based on the findings, design implications for supporting viewers’ mental wellbeing in disasters are discussed.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {338},
numpages = {15},
keywords = {video sharing, social provisions, loneliness, disaster, YouTube, parasocial},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445383,
author = {Offenwanger, Anna and Milligan, Alan John and Chang, Minsuk and Bullard, Julia and Yoon, Dongwook},
title = {Diagnosing Bias in the Gender Representation of HCI Research Participants: How It Happens and Where We Are},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445383},
doi = {10.1145/3411764.3445383},
abstract = {In human-computer interaction (HCI) studies, bias in the gender representation of participants can jeopardize the generalizability of findings, perpetuate bias in data driven practices, and make new technologies dangerous for underrepresented groups. Key to progress towards inclusive and equitable gender practices is diagnosing the current status of bias and identifying where it comes from. In this mixed-methods study, we interviewed 13 HCI researchers to identify the potential bias factors, defined a systematic data collection procedure for meta-analysis of participant gender data, and created a participant gender dataset from 1,147 CHI papers. Our analysis provided empirical evidence for the underrepresentation of women, the invisibility of non-binary participants, deteriorating representation of women in MTurk studies, and characteristics of research topics prone to bias. Based on these findings, we make concrete suggestions for promoting inclusive community culture and equitable research practices in HCI.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {18},
keywords = {gender, user studies, participants, CHI, data schema, human-computer interaction, dataset, meta-analysis, gender bias, research, HCI, human subjects},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445381,
author = {Zhang, Yixuan and Sun, Yifan and Padilla, Lace and Barua, Sumit and Bertini, Enrico and Parker, Andrea G},
title = {Mapping the Landscape of COVID-19 Crisis Visualizations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445381},
doi = {10.1145/3411764.3445381},
abstract = {In response to COVID-19, a vast number of visualizations have been created to communicate information to the public. Information exposure in a public health crisis can impact people’s attitudes towards and responses to the crisis and risks, and ultimately the trajectory of a pandemic. As such, there is a need for work that documents, organizes, and investigates what COVID-19 visualizations have been presented to the public. We address this gap through an analysis of 668 COVID-19 visualizations. We present our findings through a conceptual framework derived from our analysis, that examines who, (uses) what data, (to communicate) what messages, in what form, under what circumstances in the context of COVID-19 crisis visualizations. We provide a set of factors to be considered within each component of the framework. We conclude with directions for future crisis visualization research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {23},
keywords = {crisis informatics, Visualization, COVID-19},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445369,
author = {Young, Eric M. and Kuchenbecker, Katherine J.},
title = {Ungrounded Vari-Dimensional Tactile Fingertip Feedback for Virtual Object Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445369},
doi = {10.1145/3411764.3445369},
abstract = {Compared to grounded force feedback, providing tactile feedback via a wearable device can free the user and broaden the potential applications of simulated physical interactions. However, neither the limitations nor the full potential of tactile-only feedback have been precisely examined. Here we investigate how the dimensionality of cutaneous fingertip feedback affects user movements and virtual object recognition. We combine a recently invented 6-DOF fingertip device with motion tracking, a head-mounted display, and novel contact-rendering algorithms to enable a user to tactilely explore immersive virtual environments. We evaluate rudimentary 1-DOF, moderate 3-DOF, and complex 6-DOF tactile feedback during shape discrimination and mass discrimination, also comparing to interactions with real objects. Results from 20 naive study participants show that higher-dimensional tactile feedback may indeed allow completion of a wider range of virtual tasks, but that feedback dimensionality surprisingly does not greatly affect the exploratory techniques employed by the user.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {217},
numpages = {14},
keywords = {six-degree-of-freedom, tactile feedback, wearable, fingertip, haptic exploration},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445367,
author = {Hayashi, Eiji and Lien, Jaime and Gillian, Nicholas and Giusti, Leonardo and Weber, Dave and Yamanaka, Jin and Bedal, Lauren and Poupyrev, Ivan},
title = {RadarNet: Efficient Gesture Recognition Technique Utilizing a Miniature Radar Sensor},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445367},
doi = {10.1145/3411764.3445367},
abstract = {Gestures are a promising candidate as an input modality for ambient computing where conventional input modalities such as touchscreens are not available. Existing works have focused on gesture recognition using image sensors. However, their cost, high battery consumption, and privacy concerns made cameras challenging as an always-on solution. This paper introduces an efficient gesture recognition technique using a miniaturized 60 GHz radar sensor. The technique recognizes four directional swipes and an omni-swipe using a radar chip (6.5 \texttimes{} 5.0 mm) integrated into a mobile phone. We developed a convolutional neural network model efficient enough for battery powered and computationally constrained processors. Its model size and inference time is less than 1/5000 compared to an existing gesture recognition technique using radar. Our evaluations with large scale datasets consisting of 558,000 gesture samples and 3,920,000 negative samples demonstrated our algorithm’s efficiency, robustness, and readiness to be deployed outside of research laboratories.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {5},
numpages = {14},
keywords = {mobile, radar sensing, gesture recognition, deep learning},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445362,
author = {Kelly, Ryan M. and Cheng, Yueyang and McKay, Dana and Wadley, Greg and Buchanan, George},
title = {“It’s About Missing Much More Than the People”: How Students Use Digital Technologies to Alleviate Homesickness},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445362},
doi = {10.1145/3411764.3445362},
abstract = {Homesickness, which refers to feelings of distress caused by separation from home, is prevalent among university-aged students. Chronic homesickness can exacerbate mood problems, erode academic performance and lead to dropout from school. The present research examines how students use digital technologies to resolve the experience of missing home. Qualitative interviews and diaries with 50 students at major Australian universities revealed that technologies play a significant role in alleviating homesickness. Specifically, students use technologies to acquire social contact, find help and support, build co-presence to recreate their home, connect with culture, experience distant places, and regulate emotions. However, the use of technology sometimes led to increased emotional labour, frequent exposure to homesickness triggers, and heightened perceptions of distance. We conclude by discussing possible design implications for new technologies that allow students to alleviate homesickness by experiencing their home from afar.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {226},
numpages = {17},
keywords = {Migrants, Homesickness, Students;, Home},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445355,
author = {Mahadevan, Karthik and Sousa, Mauricio and Tang, Anthony and Grossman, Tovi},
title = {“Grip-That-There”: An Investigation of Explicit and Implicit Task Allocation Techniques for Human-Robot Collaboration},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445355},
doi = {10.1145/3411764.3445355},
abstract = {In ad-hoc human-robot collaboration (HRC), humans and robots work on a task without pre-planning the robot's actions prior to execution; instead, task allocation occurs in real-time. However, prior research has largely focused on task allocations that are pre-planned - there has not been a comprehensive exploration or evaluation of techniques where task allocation is adjusted in real-time. Inspired by HCI research on territoriality and proxemics, we propose a design space of novel task allocation techniques including both explicit techniques, where the user maintains agency, and implicit techniques, where the efficiency of automation can be leveraged. The techniques were implemented and evaluated using a tabletop HRC simulation in VR. A 16-participant study, which presented variations of a collaborative block stacking task, showed that implicit techniques enable efficient task completion and task parallelization, and should be augmented with explicit mechanisms to provide users with fine-grained control.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {215},
numpages = {14},
keywords = {Human-robot task allocation, human-robot collaboration},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445343,
author = {Yu, Difeng and Lu, Xueshi and Shi, Rongkai and Liang, Hai-Ning and Dingler, Tilman and Velloso, Eduardo and Goncalves, Jorge},
title = {Gaze-Supported 3D Object Manipulation in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445343},
doi = {10.1145/3411764.3445343},
abstract = {This paper investigates integration, coordination, and transition strategies of gaze and hand input for 3D object manipulation in VR. Specifically, this work aims to understand whether incorporating gaze input can benefit VR object manipulation tasks, and how it should be combined with hand input for improved usability and efficiency. We designed four gaze-supported techniques that leverage different combination strategies for object manipulation and evaluated them in two user studies. Overall, we show that gaze did not offer significant performance benefits for transforming objects in the primary working space, where all objects were located in front of the user and within the arm-reach distance, but can be useful for a larger environment with distant targets. We further offer insights regarding combination strategies of gaze and hand input, and derive implications that can help guide the design of future VR systems that incorporate gaze input for 3D object manipulation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {734},
numpages = {13},
keywords = {gaze input, multimodal interface, 3D object manipulation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445334,
author = {Obiorah, Mmachi God'sglory and Hammerman, James K. L. and Rother, Becky and Granger, Will and West, Haley Margaret and Horn, Michael and Trouille, Laura},
title = {U!Scientist: Designing for People-Powered Research in Museums},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445334},
doi = {10.1145/3411764.3445334},
abstract = {Scientists have long sought to engage public audiences in research through citizen science projects such as biological surveys or distributed data collection. Recent online platforms have expanded the scope of what people-powered research can mean. Science museums are unique cultural institutions that translate scientific discovery for public audiences, while conducting research of their own. This makes museums compelling sites for engaging audiences directly in scientific research, but there are associated challenges as well. This project engages public audiences in contributing to real research as part of their visit to a museum. We present the design and evaluation of U!Scientist, an interactive multi-person tabletop exhibit based on the online Zooniverse project, Galaxy Zoo. We installed U!Scientist in a planetarium and collected video, computer logs, naturalistic observations, and surveys with visitors. Our findings demonstrate the potential of exhibits to engage new audiences in collaborative scientific discussions as part of people-powered research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {675},
numpages = {14},
keywords = {museums, Citizen science, interactive tabletop displays},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445332,
author = {Charmaraman, Linda and Grevet Delcourt, Catherine},
title = {Prototyping for Social Wellbeing with Early Social Media Users: Belonging, Experimentation, and Self-Care},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445332},
doi = {10.1145/3411764.3445332},
abstract = {Many 10-14 year olds are at the early stages of using social media, habits they develop on popular platforms can have lasting effects on their socio-emotional wellbeing. We led a remote innovation workshop with 23 middle schoolers on digital wellbeing, identity exploration, and computational concepts related to social computing. This workshop was a unique opportunity to reflect on emergent habits, discuss them with peers, and imagine oneself as an ICT innovator. Resulting themes related to participants’ social wellbeing online included a) sense of belonging to communities of interest, friends, and family, b) self-care and social support strategies involving managing risks, control, and empathy, and c) experimentation while building self-confidence and bravely exploring audience reactions. Participants iteratively designed and tested a sandbox social network website, resulting in Social Sketch. Reflecting on our study, we describe the process for conceptualizing Social Sketch, and challenges in social media innovation with teenagers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {704},
numpages = {15},
keywords = {wellness, ICT, prototyping, cooperative inquiry, wellbeing, adolescence, social media, teenagers},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445321,
author = {Li, Franklin Mingzhe and Chen, Di Laura and Fan, Mingming and Truong, Khai N.},
title = {“I Choose Assistive Devices That Save My Face”: A Study on Perceptions of Accessibility and Assistive Technology Use Conducted in China},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445321},
doi = {10.1145/3411764.3445321},
abstract = {Despite the potential benefits of assistive technologies (ATs) for people with various disabilities, only around 7% of Chinese with disabilities have had an opportunity to use ATs. Even for those who have used ATs, the abandonment rate was high. Although China has the world’s largest population with disabilities, prior research exploring how ATs are used and perceived, and why ATs are abandoned have been conducted primarily in North America and Europe. In this paper, we present an interview study conducted in China with 26 people with various disabilities to understand their practices, challenges, perceptions, and misperceptions of using ATs. From the study, we learned about factors that influence AT adoption practices (e.g., misuse of accessible infrastructure, issues with replicating existing commercial ATs), challenges using ATs in social interactions (e.g., Chinese stigma), and misperceptions about ATs (e.g., ATs should overcome inaccessible social infrastructures). Informed by the findings, we derive a set of design considerations to bridge the existing gaps in AT design (e.g., manual vs. electronic ATs) and to improve ATs’ social acceptability in China.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {372},
numpages = {14},
keywords = {China, Qualitative study, Assistive technology, Misperceptions, People with disabilities, Interview, Accessibility},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445317,
author = {Christoforou, Evgenia and Barlas, Pinar and Otterbacher, Jahna},
title = {It’s About Time: A View of Crowdsourced Data Before and During the Pandemic},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445317},
doi = {10.1145/3411764.3445317},
abstract = {Data attained through crowdsourcing have an essential role in the development of computer vision algorithms. Crowdsourced data might include reporting biases, since crowdworkers usually describe what is “worth saying” in addition to images’ content. We explore how the unprecedented events of 2020, including the unrest surrounding racial discrimination, and the COVID-19 pandemic, might be reflected in responses to an open-ended annotation task on people images, originally executed in 2018 and replicated in 2020. Analyzing themes of Identity and Health conveyed in workers’ tags, we find evidence that supports the potential for temporal sensitivity in crowdsourced data. The 2020 data exhibit more race-marking of images depicting non-Whites, as well as an increase in tags describing Weight. We relate our findings to the emerging research on crowdworkers’ moods. Furthermore, we discuss the implications of (and suggestions for) designing tasks on proprietary platforms, having demonstrated the possibility for additional, unexpected variation in crowdsourced data due to significant events.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {14},
keywords = {data reproducibility, reporting bias, crowdsourcing, temporal sensitivity, image annotation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445304,
author = {Park, Hyanghee and Ahn, Daehwan and Hosanagar, Kartik and Lee, Joonhwan},
title = {Human-AI Interaction in Human Resource Management: Understanding Why Employees Resist Algorithmic Evaluation at Workplaces and How to Mitigate Burdens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445304},
doi = {10.1145/3411764.3445304},
abstract = {Recently, Artificial Intelligence (AI) has been used to enable efficient decision-making in managerial and organizational contexts, ranging from employment to dismissal. However, to avoid employees’ antipathy toward AI, it is important to understand what aspects of AI employees like and/or dislike. In this paper, we aim to identify how employees perceive current human resource (HR) teams and future algorithmic management. Specifically, we explored what factors negatively influence employees’ perceptions of AI making work performance evaluations. Through in-depth interviews with 21 workers, we found that 1) employees feel six types of burdens (i.e., emotional, mental, bias, manipulation, privacy, and social) toward AI's introduction to human resource management (HRM), and that 2) these burdens could be mitigated by incorporating transparency, interpretability, and human intervention to algorithmic decision-making. Based on our findings, we present design efforts to alleviate employees’ burdens. To leverage AI for HRM in fair and trustworthy ways, we call for the HCI community to design human-AI collaboration systems with various HR stakeholders.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {154},
numpages = {15},
keywords = {User burden, Algorithmic management, Trust, Adoption, Explainable AI (XAI), Human resource management (HRM), Algorithmic fairness, Interpretability, Artificial intelligence (AI), Algorithm aversion, Fair and responsible AI, Transparency, Human-AI collaboration},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445298,
author = {Hubenschmid, Sebastian and Zagermann, Johannes and Butscher, Simon and Reiterer, Harald},
title = {STREAM: Exploring the Combination of Spatially-Aware Tablets with Augmented Reality Head-Mounted Displays for Immersive Analytics},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445298},
doi = {10.1145/3411764.3445298},
abstract = {Recent research in the area of immersive analytics demonstrated the utility of head-mounted augmented reality devices for visual data analysis. However, it can be challenging to use the by default supported mid-air gestures to interact with visualizations in augmented reality (e.g. due to limited precision). Touch-based interaction (e.g. via mobile devices) can compensate for these drawbacks, but is limited to two-dimensional input. In this work we present STREAM: Spatially-aware Tablets combined with Augmented Reality Head-Mounted Displays for the multimodal interaction with 3D visualizations. We developed a novel eyes-free interaction concept for the seamless transition between the tablet and the augmented reality environment. A user study reveals that participants appreciated the novel interaction concept, indicating the potential for spatially-aware tablets in augmented reality. Based on our findings, we provide design insights to foster the application of spatially-aware touch devices in augmented reality and research implications indicating areas that need further investigation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {14},
keywords = {visualizations, multimodal interaction, mobile devices, immersive analytics, augmented reality},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445278,
author = {You, Chuang-Wen and Yuan, Chien Wen (Tina) and Bi, Nanyi and Hung, Min-Wei and Huang, Po-Chun and Wang, Hao-Chuan},
title = {Go Gig or Go Home: Enabling Social Sensing to Share Personal Data with Intimate Partner for the Health and Wellbeing of Long-Hour Workers},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445278},
doi = {10.1145/3411764.3445278},
abstract = {Maintaining an awareness of one’s well-being and making work-related decisions to achieve work-life balance is critical for flexible long-hour workers. In this study, we propose that social sensing could address bottlenecks in worker’s awareness, interpretation of the informatics, and subsequent behavioral change. We conducted a four-week technology probe study by recruiting flexible long-hour professional drivers (Taxi and Uber drivers) and their significant others to use a social sensing prototype which collects data from the drivers and shares it with their partners as well as incorporates partners’ observations. We interviewed them before and after the probe study and found that while technological sensing was able to increase drivers’ awareness of their well-being status and intention to modify behaviors. The “social sensing” design was able to further shape such awareness or intention into action, highlighting the potential of using the sociotechnical approach in promoting work-life balance among long-hour workers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {136},
numpages = {16},
keywords = {Social sensing, technological sensing, technology probe},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445269,
author = {Hutt, Stephen and Krasich, Kristina and R. Brockmole, James and K. D'Mello, Sidney},
title = {Breaking out of the Lab: Mitigating Mind Wandering with Gaze-Based Attention-Aware Technology in Classrooms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445269},
doi = {10.1145/3411764.3445269},
abstract = {We designed and tested an attention-aware learning technology (AALT) that detects and responds to mind wandering (MW), a shift in attention from task-related to task-unrelated thoughts, that is negatively associated with learning. We leveraged an existing gaze-based mind wandering detector that uses commercial off the shelf eye tracking to inform real-time interventions during learning with an Intelligent Tutoring System in real-world classrooms. The intervention strategies, co-designed with students and teachers, consisted of using student names, reiterating content, and asking questions, with the aim to reengage wandering minds and improve learning. After several rounds of iterative refinement, we tested our AALT in two classroom studies with 287 high-school students. We found that interventions successfully reoriented attention, and compared to two control conditions, reduced mind wandering, and improved retention (measured via a delayed assessment) for students with low prior-knowledge who occasionally (but not excessively) mind wandered. We discuss implications for developing gaze-based AALTs for real-world contexts.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {52},
numpages = {14},
keywords = {eye-gaze, cyberlearning, intelligent tutoring systems, mind wandering, attention-aware learning},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445259,
author = {Mim, Nusrat Jahan},
title = {Gospels of Modernity: Digital Cattle Markets, Urban Religiosity, and Secular Computing in the Global South},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445259},
doi = {10.1145/3411764.3445259},
abstract = {This paper joins the growing body of critical HCI work that studies the digitization of the Global South and reports the elements of ‘secularization’ in it. Based on a year-long ethnography on the contemporary transformations in religious practices in Dhaka, Bangladesh, this paper presents how the emerging “digital” cattle marketplaces subdue various forms of traditional manifestations of urban religiosity during Eid-ul-Adha, the second-largest Islamic festival in the city. This paper further depicts how such secularization contributes to diminishing rural-urban linkages, affecting electoral politics, and reducing the tolerance to religious celebrations in a city. Drawing from a rich body of work in critical urban studies, postcolonial computing, and sociology of religions, we explain how such oft-overlooked embedding of secularization in computing affects the religious fabrics in the urban regions of the Global South, and discuss its implication for HCI scholarship in diversity, inclusion, and development.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {91},
numpages = {17},
keywords = {Spatial Politics, Urban Design, Digital Marketplace, Modernity, Secular Computing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445253,
author = {Mhaidli, Abraham Hani and Schaub, Florian},
title = {Identifying Manipulative Advertising Techniques in XR Through Scenario Construction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445253},
doi = {10.1145/3411764.3445253},
abstract = {As Extended Reality (XR) devices and applications become more mainstream, so too will XR advertising&nbsp;—&nbsp;advertising that takes place in XR mediums. Due to the defining features of XR devices, such as the immersivity of the medium and the ability of XR devices to simulate reality, there are fears that these features could be exploited to create manipulative XR ads that trick consumers into buying products they do not need or might harm them. Using scenario construction, we investigate potential future incarnations of manipulative XR advertising and their harms. We identify five key mechanisms of manipulative XR advertising: misleading experience marketing; inducing artificial emotions in consumers; sensing and targeting people when they are vulnerable; emotional manipulation through hyperpersonalization; and distortion of reality. We discuss research challenges and questions in order to address and mitigate manipulative XR advertising risks.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {296},
numpages = {18},
keywords = {scenario construction, advertising, privacy, Extended reality, computer ethics., mixed reality, virtual reality, augmented reality},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445242,
author = {Schaadhardt, Anastasia and Hiniker, Alexis and Wobbrock, Jacob O.},
title = {Understanding Blind Screen-Reader Users’ Experiences of Digital Artboards},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445242},
doi = {10.1145/3411764.3445242},
abstract = {Two-dimensional canvases are the core components of many digital productivity and creativity tools, with “artboards” containing objects rather than pixels. Unfortunately, the contents of artboards remain largely inaccessible to blind users relying on screen-readers, but the precise problems are not well understood. This study sought to understand how blind screen-reader users interact with artboards. Specifically, we conducted contextual interviews, observations, and task-based usability studies with 15 blind participants to understand their experiences of artboards found in Microsoft PowerPoint, Apple Keynote, and Google Slides. Participants expressed that the inaccessibility of these artboards contributes to significant educational and professional barriers. We found that the key problems faced were: (1) high cognitive loads from a lack of feedback about artboard contents and object state; (2) difficulty determining relationships among artboard objects; and (3) constant uncertainty about whether object manipulations were successful. We offer design remedies that improve feedback for object state, relationships, and manipulations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {19},
keywords = {usability, blind and low-vision users., creativity applications, Computers and creativity, art and design programs, accessibility},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445227,
author = {Xia, Siyuan and Anzum, Nafisa and Salihoglu, Semih and Zhao, Jian},
title = {KTabulator: Interactive Ad Hoc Table Creation Using Knowledge Graphs},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445227},
doi = {10.1145/3411764.3445227},
abstract = {The need to find or construct tables arises routinely to accomplish many tasks in everyday life, as a table is a common format for organizing data. However, when relevant data is found on the web, it is often scattered across multiple tables on different web pages, requiring tedious manual searching and copy-pasting to collect data. We propose KTabulator, an interactive system to effectively extract, build, or extend ad hoc tables from large corpora, by leveraging their computerized structures in the form of knowledge graphs. We developed and evaluated KTabulator using Wikipedia and its knowledge graph DBpedia as our testbed. Starting from an entity or an existing table, KTabulator allows users to extend their tables by finding relevant entities, their properties, and other relevant tables, while providing meaningful suggestions and guidance. The results of a user study indicate the usefulness and efficiency of KTabulator in ad hoc table creation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {100},
numpages = {14},
keywords = {data cleaning, Data tables, user interface., database, data integration},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445221,
author = {Varanasi, Rama Adithya and Vashistha, Aditya and Dell, Nicola},
title = {Tag a Teacher: A Qualitative Analysis of WhatsApp-Based Teacher Networks in Low-Income Indian Schools},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445221},
doi = {10.1145/3411764.3445221},
abstract = {Although WhatsApp-based communication is playing an increasingly large role in the professional lives of teachers in low-income schools, the nature of the interactions that occur and how these interactions enable cooperative work are not well understood. We contribute a qualitative analysis of 26 existing WhatsApp groups (35,567 messages) that examines (1) the strategies used to encourage interaction within teacher-focused WhatsApp groups, and (2) how these interactions are sustained by teachers, management, and organizations over a period of time. We use teacher networks and activity awareness model to make sense of WhatsApp-based interactions and show how WhatsApp narrows the gap between management and teachers, leading to additional work and stress for teachers. WhatsApp was also used to circulate polarizing and malicious information, leading to a variety of interesting content moderation strategies. Our findings expand the scope of research on teacher networks to low-income contexts and will inform future interventions that enable cooperative work among teachers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {560},
numpages = {16},
keywords = {teacher development, ICTD, Education, cooperative work, HCI4D, teacher networks, whatsapp},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445206,
author = {Doyle, Philip R and Clark, Leigh and Cowan, Benjamin R.},
title = {What Do We See in Them? Identifying Dimensions of Partner Models for Speech Interfaces Using a Psycholexical Approach},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445206},
doi = {10.1145/3411764.3445206},
abstract = {Perceptions of system competence and communicative ability, termed partner models, play a significant role in speech interface interaction. Yet we do not know what the core dimensions of this concept are. Taking a psycholexical approach, our paper is the first to identify the key dimensions that define partner models in speech agent interaction. Through a repertory grid study (N=21), a review of key subjective questionnaires, an expert review of resulting word pairs and an online study of 356 users of speech interfaces, we identify three key dimensions that make up a users’ partner model: 1) perceptions towards partner competence and dependability; 2) assessment of human-likeness; and 3) a system’s perceived cognitive flexibility. We discuss the implications for partner modelling as a concept, emphasising the importance of salience and the dynamic nature of these perceptions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {244},
numpages = {14},
keywords = {human-machine dialogue, mental models, psychometrics, partner models, speech interfaces, psycholexical},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445198,
author = {Falk, Jeanette and Kannabiran, Gopinaath and Hansen, Nicolai Brodersen},
title = {What Do Hackathons Do? Understanding Participation in Hackathons Through Program Theory Analysis},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445198},
doi = {10.1145/3411764.3445198},
abstract = {Hackathons are increasingly embraced across diverse sectors as a way of democratizing the design of technology. Several attempts have been made to redefine the format and desired end goal of hackathons in recent years thereby warranting closer methodological scrutiny. In this paper, we apply program theory to analyze the processes and effects of 16 hackathon case studies through published research literature. Building upon existing research on hackathons, our work offers a critical perspective examining the methodological validity of hackathons and exemplifies how specific processes for organizing hackathons are modified for different purposes. Our main contribution is a program theory analysis of hackathon formats that provides an exploration and juxtaposition of 16 case studies in terms of causal relations between the input, process and the effects of hackathons. Our cataloguing of examples can serve as an inspirational planning resource for future organizers of hackathons.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {147},
numpages = {16},
keywords = {participatory design, program theory, research methods, hackathons},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445184,
author = {Velloso, Eduardo and Morimoto, Carlos H},
title = {A Probabilistic Interpretation of Motion Correlation Selection Techniques},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445184},
doi = {10.1145/3411764.3445184},
abstract = {Motion correlation interfaces are those that present targets moving in different patterns, which the user can select by matching their motion. In this paper, we re-formulate the task of target selection as a probabilistic inference problem. We demonstrate that previous interaction techniques can be modelled using a Bayesian approach and that how modelling the selection task as transmission of information can help us make explicit the assumptions behind similarity measures. We propose ways of incorporating uncertainty into the decision-making process and demonstrate how the concept of entropy can illuminate the measurement of the quality of a design. We apply these techniques in a case study and suggest guidelines for future work.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {285},
numpages = {13},
keywords = {gaze interaction, probabilistic input, computational interaction, motion correlation, gestures, pursuits},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445177,
author = {Chen, Xiuli and Acharya, Aditya and Oulasvirta, Antti and Howes, Andrew},
title = {An Adaptive Model of Gaze-Based Selection},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445177},
doi = {10.1145/3411764.3445177},
abstract = {Gaze-based selection has received significant academic attention over a number of years. While advances have been made, it is possible that further progress could be made if there were a deeper understanding of the adaptive nature of the mechanisms that guide eye movement and vision. Control of eye movement typically results in a sequence of movements (saccades) and fixations followed by a ‘dwell’ at a target and a selection. To shed light on how these sequences are planned, this paper presents a computational model of the control of eye movements in gaze-based selection. We formulate the model as an optimal sequential planning problem bounded by the limits of the human visual and motor systems and use reinforcement learning to approximate optimal solutions. The model accurately replicates earlier results on the effects of target size and distance and captures a number of other aspects of performance. The model can be used to predict number of fixations and duration required to make a gaze-based selection. The future development of the model is discussed.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {288},
numpages = {11},
keywords = {Reinforcement learning, computational rationality, adaptive model, gaze-based selection},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445168,
author = {Kirabo, Lynn and Carter, Elizabeth Jeanne and Barry, Devon and Steinfeld, Aaron},
title = {Priorities, Technology, &amp; Power: Co-Designing an Inclusive Transit Agenda in Kampala, Uganda},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445168},
doi = {10.1145/3411764.3445168},
abstract = {There is considerable effort within the HCI community to explore, document, and advocate for the lived experiences of persons with disabilities (PWDs). However, PWDs from the Global South, particularly Africa, are underrepresented in this scholarship. We contribute to closing this gap by investigating the unmet transit needs and characterization of technology within the disability community in Kampala, Uganda. We investigated transportation due to the increase in ride-share solutions created by widespread mobile computing and the resulting disruption of transportation worldwide. We hosted co-design sessions with disability advocates and adapted the stakeholder tokens method from the value-sensitive design framework to map the stakeholder ecosystem. Our key insight is the identification of a new group of non-traditional core stakeholders who highlight the values of inclusion, mobility, and safety within the ecosystem. Finally, we discuss how our findings engage with concepts of disability justice and perceptions of power.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {377},
numpages = {11},
keywords = {Value-Sensitive Design, Stakeholder Tokens Method, Uganda, People with Disabilities, Power Dynamics, Global South, Kampala, Accessibility},
location = {Yokohama, Japan},
series = {CHI '21}
}

