@inproceedings{10.1145/3411763.3443421,
author = {Schlosser, Paul},
title = {Head-Worn Displays for Emergency Medical Services},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3443421},
doi = {10.1145/3411763.3443421},
abstract = {In the prehospital environment, head-worn displays (HWDs) could support paramedics and emergency physicians during complex tasks and procedures. Previously, HWDs have been used in emergency medical service (EMS) contexts to support triage, telemedicine, patient monitoring, and patient localization. However, research on HWDs in EMS has three limitations: (1) HWD applications have not been developed based on field research of prehospital operations and training, (2) there are few guidelines that direct HWD deployment and application design, and (3) HWD applications seldom have been tested in randomized controlled trials. Therefore, it is unclear how HWDs affect EMS work and patient outcomes. During my PhD studies, I am investigating the potential of HWDs in EMS. I am addressing the limitations of previous research by conducting a literature review, a field study, design workshops, and a controlled evaluation study. The ultimate aims of this research are to benefit the work of EMS staff and to improve patient safety.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {67},
numpages = {5},
keywords = {Emergency medical services, Head-worn display, Augmented reality},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3441342,
author = {Ehsan, Upol and Wintersberger, Philipp and Liao, Q. Vera and Mara, Martina and Streit, Marc and Wachter, Sandra and Riener, Andreas and Riedl, Mark O.},
title = {Operationalizing Human-Centered Perspectives in Explainable AI},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3441342},
doi = {10.1145/3411763.3441342},
abstract = {The realm of Artificial Intelligence (AI)’s impact on our lives is far reaching – with AI systems proliferating high-stakes domains such as healthcare, finance, mobility, law, etc., these systems must be able to explain their decision to diverse end-users comprehensibly. Yet the discourse of Explainable AI (XAI) has been predominantly focused on algorithm-centered approaches, suffering from gaps in meeting user needs and exacerbating issues of algorithmic opacity. To address these issues, researchers have called for human-centered approaches to XAI. There is a need to chart the domain and shape the discourse of XAI with reflective discussions from diverse stakeholders. The goal of this workshop is to examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we put an emphasis on “operationalizing”, aiming to produce actionable frameworks, transferable evaluation methods, concrete design guidelines, and articulate a coordinated research agenda for XAI.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {94},
numpages = {6},
keywords = {Human-centered Computing, Critical Technical Practice, Explainable Artificial Intelligence, Artificial Intelligence, Interpretability, Trust in Automation, Interpretable Machine Learning, Algorithmic Fairness},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3457781,
author = {Andres, Josh},
title = {Designing Human–Computer Integration in an Exertion Context},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3457781},
doi = {10.1145/3411763.3457781},
abstract = {Human–computer interaction researchers continue to support the exerting user to promote the many benefits of being physically active. Recently, due to technological advances, systems emerged that can continuously sense, interpret and automatically act on information, opening the opportunity to design human-computer "integration", where the user and the system work in a partnership. However, today's knowledge gap is how to design human–computer integration experiences in an exertion context. In this talk, I present how I aimed to close this gap through the design of three eBike systems that "act on" different data types (motion, traffic light data, and&nbsp; EEG (electroencephalography)) to explore integrations with the exerting body. The investigation informed the creation of the "integrated exertion framework", which can guide interaction designers on how to, and in an inclusive manner, amplify a person's sensations of their abilities in an exertion context to create "superpower", "co-operative" and "symbiotic" human-computer partnerships.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {6},
numpages = {2},
keywords = {human-computer integration, exertion, human-computer interaction, whole body},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3457779,
author = {Dearden, Andy},
title = {SIGCHI Social Impact Award: Asking Better Questions},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3457779},
doi = {10.1145/3411763.3457779},
abstract = {I remember when I started my DPhil studies joking with friends that my research was improving the sum total of human happiness – by one. I was enjoying the work. It was as a post-doc, however, that I began to see how knowledge, or at the very least the pursuit of knowledge, is not neutral. The things that we choose to study, the problems that we choose to focus on, and the way we frame our questions, lead towards different benefits for different interests. If we want to make a better world, then perhaps we should focus on asking better questions.One question that was a turning point for me was posed by Steve Walker in 2002. In a world where e-commerce and e-government already had thriving, well-financed research communities, he convened a workshop asking “Can there be a Social Movement Informatics?” The topics ranged from designing with voluntary organizations and trade-unions, to investigating hate speech in Internet bulletin boards and chat rooms. Together with colleagues, we ran projects around “Design for Civil Society”, and “Technology and Social Action”, exploring how we as technologists, designers and researchers can connect and collaborate more effectively with groups promoting social change.Following on from that work, I won an opportunity to explore how participatory approaches in international social and economic development relate to understandings of participatory design in HCI. Working with the Sironj Crop Producers Company Ltd (a co-operative of small and marginal farmers in Madhya Pradesh, India) and Safal Solutions (a small software house focused on rural development, based in Telengana, India), this was my first attempt to apply participatory design methods in a context with very limited infrastructure and resources. How can we facilitate meaningful communications about priorities and possibilities across wide social, cultural, geographical, linguistic, experiential and economic divides? How does the way we arrange, organize and conduct projects aiming to advance ‘development’ affect the outputs, the outcomes and the impacts that are achieved? How can agency, creativity and control be shared in ways that move systems towards a more just world?I don't know all the answers to those questions, but I have learned that the inequalities of this world are far greater than I had originally imagined. I started with high hopes that expertise in participatory design, together with a commitment to participatory development would deliver radical results. I discovered that true participation and reciprocity is tougher than I thought. We cannot communicate effectively across such huge social divides without questioning, acknowledging and responding to our own positionality in the wider context. For example, we should ask how our own actions are contributing to harming others, such as the millions who will become, or are already, climate refugees? A few short-term “bungee research” visits will not lead us to real understanding. When key decision making remains in the usual centers of power, that simply reinforces the neo-colonial arrangements that underpin the marginalization that we say we want to change.To create a future for humanity as part of life on this planet, we must see changes in behavior close to centers of power – and that includes ourselves. We are already enmeshed in a system of unjust socio-economic relationships. “The problem” is not something that is “out there”, it is also “in here” and all around us. Are we asking the questions that really matter?},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {4},
numpages = {2},
keywords = {ICTDEthics, HCI4D, ICTD},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451851,
author = {Heng, Yew Ken},
title = {ReWIND: Psychoeducation Game Leveraging Cognitive Behavioral Therapy (CBT) to Enhance Emotion Control for Generalized Anxiety Disorder},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451851},
doi = {10.1145/3411763.3451851},
abstract = {ReWIND is a role-playing game (RPG) designed to enhance the emotion control of patients with generalized anxiety disorder (GAD) over the feeling of excessive worry and fear by integrating cognitive behavioral therapy (CBT) in a serious game. The goal of the game is to allow players to virtually encounter different anxiety-causing situations and provide constructive measures to deal with negative feelings following the ABC-model of CBT (antecedent, belief, consequence) along with disputation and new effect. The storyline's foundation focuses on four emotion regulation strategies common in GAD: catastrophizing, rumination, denial, and lack of refocus on planning. Each strategy consists of three scenarios that simulate real-life occurrences where GAD patients might find them hard to overcome. CBT elements are integrated with the diegetic components implemented in the game to provide psychoeducation in a fun way, which can be used to complement counseling.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {497},
numpages = {5},
keywords = {emotion control, generalized anxiety disorder (GAD), Role-playing game (RPG), cognitive behavioral therapy (CBT)},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451845,
author = {Alvington Silvester, Timothy},
title = {Playing with Drones: Towards Understanding the Design of Drone-Based Pervasive Play},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451845},
doi = {10.1145/3411763.3451845},
abstract = {Human-Drone Interaction is a fast-growing subset of the field of Human-Computer Interaction as drones enable novel and interesting interactions in 3D space as they can be regarded as pixels in physical space. We examine the intersection of drones and play and explore how drones can facilitate playful bodily experiences by pervading the physical space. We focus on “Paida” play to build explorative play experiences that pervade the player's physical environment. This work resulted in three play experiences built around simple interaction methods, in addition to observations from our design process, and three design strategies; drone-based play lends itself to collaborative play, such play benefits from simple designs, and designers benefit from designing for multiple players. From these design strategies, we set a starting point for designing novel, pervasive, and playful interactions whilst regarding drones as pixels in the physical space.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {5},
keywords = {drones, play, pervasive games, Human-drone interaction},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451825,
author = {Delgado Rodriguez, Sarah and Prange, Sarah and Mecke, Lukas and Alt, Florian},
title = {ActPad– A Smart Desk Platform to Enable User Interaction with IoT Devices},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451825},
doi = {10.1145/3411763.3451825},
abstract = {ActPad is a desk pad, capable of sensing capacitive touch input in desk setups. Our prototype can sense touches on both, its electrodes and on connected objects. ActPad’s interaction-space is customizable, allowing easy integration and extension of existing desk environments. In smart environments, users may interact with more than one device at the same time. This generates the need for new interaction mechanisms that bundle the control of multiple ubiquitous devices. We support this need through a platform that extends interaction with IoT devices. ActPad accounts for different ways of controlling IoT devices by enabling various modes of interaction – in particular simultaneous, sequential, implicit and explicit – and, hence, a rich input space. As a proof of concept, we illustrate several use cases, including, but not limited to, controlling the browser on a PC, turning lights on/off, switching songs, or preparing coffee.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {325},
numpages = {6},
keywords = {Capacitive Sensing, Smart Desk, IoT, Interaction Platform},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451816,
author = {Levordashka, Ana and Stanton Fraser, Dana\"{e} and D. Gilchrist, Iain and Hill, Paul and Chadwick, Eleanor},
title = {Sensing the Audience in Digital Streaming: Lessons from a Global Pandemic},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451816},
doi = {10.1145/3411763.3451816},
abstract = {Live performances are immersive shared experiences, traditionally taking place in designated, carefully designed physical spaces such as theatres or concert halls. As it is becoming increasingly common for audiences to experience this type of content remotely using digital technology, it is crucial to reflect on the design of digital experiences and the technology used to deliver them. This research is guided by the question: How can the design of streaming technologies support artists in creating immersive and engaging audience experiences? A series of audience studies, which took place as cultural organisations were forced to adapt and deliver their content remotely due to the COVID19 global pandemic, highlighted problems with existing streaming solutions and informed a set of design recommendations for audience experience and research.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {472},
numpages = {6},
keywords = {Design Guidelines, Immersive Technology, Audience Studies, Presence},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451797,
author = {Neidlinger, Kristin and Koenderink, Stephanie and Truong, Khiet P.},
title = {Give the Body a Voice: Co-Design with Profound Intellectual and Multiple Disabilities to Create Multisensory Wearables},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451797},
doi = {10.1145/3411763.3451797},
abstract = {This study explores non-verbal co-design techniques with multisensory wearables to give the body a voice. Sessions were led with professional caregivers, parents, and clients with PIMD (profound intellectual and multiple disabilities) to find fundamental building blocks for a common language based on tangible technologies. To provide an agent for communication we employed the tools of extimacy - translating biodata to visual, auditory, or tactile interactive displays. The caregivers expressed the need for action – reaction “Actie Reactie” to keep attention, which was an update from the Multisensory Environment (MSE) rooms previously used to calm. In the co-design sessions, we found the on-the-body wearables held the most focus. The final discovery from the study became the outline for creating a modular, highly personalized kit for a Multisensory Wearable (MSW) to inspire surprise and wonder.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {375},
numpages = {6},
keywords = {PIMD, multisensory, non-verbal, co-design, extimacy, biosensing, wearable},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451789,
author = {Olinsky, Samantha and Desai, Pooja M. and Turkay, Selen and Heitkemper, Elizabeth M and Mitchell, Elliot G and Mamykina, Lena and Hwang, Maria L.},
title = {Meals for Monsters: A Mobile Application for the Feasibility of Gaming and Social Mechanisms},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451789},
doi = {10.1145/3411763.3451789},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {9},
keywords = {social, meal photos., Avatars, gamification, macronutrients, nutritional engagement, community board, crowdsourcing},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451776,
author = {Masood, Mehreen and Khawaja, Mujtaba Ahmed and Sharif, Muhammad Shehryaar and Iqbal, Omer and Mehmood Butt, Momin and Shahid, Suleman},
title = {Meri Kahani: A Gamified Solution to Teach Computational Thinking to Female Teenagers in Low Resource Communities},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451776},
doi = {10.1145/3411763.3451776},
abstract = {This paper describes the design of a mobile based gaming application - Meri Kahani - created to teach computational thinking skills to school going teenagers in underdeveloped areas of Pakistan. We explore the use of gamification to teach computational thinking through level-based learning in a Pakistani context. This paper's final design demonstrates how gamified learning, rewarding techniques, and feminine themes can be used to attract female teenagers towards computational thinking. This paper also discusses the evaluation and usability testing results conducted on 16 school-going female teenagers. We hope that through this study, we have taken the first step towards nurturing an interest in young females for computational thinking and overcoming the gender gap that adversely affects female involvement in Computer Science in Pakistan.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {6},
keywords = {Gamification, Computational Thinking, Teenage Girls, Storytelling, Pakistan, Low-Socioeconomic},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451768,
author = {Last, Christina and Pramanik, Prithviraj and Saini, Nikita and Majety, Akash Smaran and Kim, Do-Hyung and Garc\'{\i}a-Herranz, Manuel and Majumdar, Subhabrata},
title = {Towards an Open Global Air Quality Monitoring Platform to Assess Children’s Exposure to Air Pollutants in the Light of COVID-19 Lockdowns},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451768},
doi = {10.1145/3411763.3451768},
abstract = {This ongoing work attempts to understand and address the requirements of UNICEF, a leading organization working in children’s welfare, where they aim to tackle the problem of air quality for children at a global level. We are motivated by the lack of a proper model to account for heavily fluctuating air quality levels across the world in the wake of the COVID-19 pandemic, leading to uncertainty among public health professionals on the exact levels of children’s exposure to air pollutants. We create an initial model as per the agency’s requirement to generate insights through a combination of virtual meetups and online presentations. Our research team comprised of UNICEF’s researchers and a group of volunteer data scientists. The presentations were delivered to a number of scientists and domain experts from UNICEF and community champions working with open data. We highlight their feedback and possible avenues to develop this research further.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {434},
numpages = {7},
keywords = {Air Quality Monitoring, Air Pollution, Global Model, COVID-19, PM2.5},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451764,
author = {Irlitti, Andrew and Hoang, Thuong and Vetere, Frank},
title = {Surrogate-Aloud: A Human Surrogate Method for Remote Usability Evaluation and Ideation in Virtual Reality},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451764},
doi = {10.1145/3411763.3451764},
abstract = {Virtual and augmented reality offer comparative performance in terms of remote usability testing to lab-based co-located settings. However, direct contact with a researcher is still required to provide setup, troubleshoot, and training. In this paper, we present Surrogate-Aloud as a remote ideation and usability method that establishes a surrogate relationship between participants and a facilitating researcher through video conferencing. The researcher wears a VR headset and shares their viewpoint through video conferencing to a remote participant, who applies think-aloud protocol to express movement and interaction commands to be executed by the researcher, alongside their thought process as they interact with virtual prototypes or scenarios. We conducted a preliminary study to evaluate the Surrogate-Aloud method for remote usability evaluation and ideation of a new instructional technique with volumetric recordings. Results show that Surrogate-Aloud leverages the surrogate’s technical expertise and enables sufficient capability to conduct truly remote usability evaluation and ideation.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {424},
numpages = {7},
keywords = {Remote Usability Testing, Think-Aloud, Virtual Reality Surrogate},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451747,
author = {Ipsita, Ananya and Li, Hao and Duan, Runlin and Cao, Yuanzhi and Chidambaram, Subramanian and Liu, Min and Ramani, Karthik},
title = {VRFromX: From Scanned Reality to Interactive Virtual Experience with Human-in-the-Loop},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451747},
doi = {10.1145/3411763.3451747},
abstract = {There is an increasing trend of Virtual-Reality (VR) applications found in education, entertainment, and industry. Many of them utilize real world tools, environments, and interactions as bases for creation. However, creating such applications is tedious, fragmented, and involves expertise in authoring VR using programming and 3D-modelling softwares. This hinders VR adoption by decoupling subject matter experts from the actual process of authoring while increasing cost and time. We present VRFromX, an in-situ Do-It-Yourself (DIY) platform for content creation in VR that allows users to create interactive virtual experiences. Using our system, users can select region(s) of interest (ROI) in scanned point cloud or sketch in mid-air using a brush tool to retrieve virtual models and then attach behavioral properties to them. We ran an exploratory study to evaluate usability of VRFromX and the results demonstrate feasibility of the framework as an authoring tool. Finally, we implemented three possible use-cases to showcase potential applications.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {289},
numpages = {7},
keywords = {Graphical user interface, Human-centered AI, Embodied interaction, Virtual Reality, Scene reconstruction, Behavioral modelling, Scene manipulation, Point cloud interaction},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451745,
author = {Kim, Wooseok and Lee, Sangsu},
title = {“I Can’t Talk Now”: Speaking with Voice Output Communication Aid Using Text-to-Speech Synthesis During Multiparty Video Conference},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451745},
doi = {10.1145/3411763.3451745},
abstract = {COVID-19 has resulted in the rapid popularization of video conferencing. A growing number of users have become obligated to find suitable places for video conferencing, but sometimes they inevitably participate in unsuitable conditions such as noisy or too silent public spaces. However, the video conference experience according to the environment users are in has not been sufficiently discussed. In particular, there is no conducted research on the occasions where video conferencing participants feel unable to speak with their voice due to spatial factors and how to address these situations. In this study, we propose a voice output communication aid (VOCA) for video conferencing which allows users to chat without making a sound. We made a technology probe and conducted a user test. Users who feel unable to speak orally could participate more actively with VOCA. Based on the results, we described the effects and potential of VOCA for video conferencing.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {288},
numpages = {6},
keywords = {Means of communication, Voice Output Communication Aid(VOCA), Video Conference},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451744,
author = {Ma, Yong and Drewes, Heiko and Butz, Andreas},
title = {Fake Moods: Can Users Trick an Emotion-Aware VoiceBot?},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451744},
doi = {10.1145/3411763.3451744},
abstract = {The ability to deal properly with emotion could be a critical feature of future VoiceBots. Humans might even choose to use fake emotions, e.g., sound angry to emphasize what they are saying or sound nice to get what they want. However, it is unclear whether current emotion detection methods detect such acted emotions properly, or rather the true emotion of the speaker. We asked a small number of participants (26) to mimic five basic emotions and used an open source emotion-in-voice detector to provide feedback on whether their acted emotion was recognized as intended. We found that it was difficult for participants to mimic all five emotions and that certain emotions were easier to mimic than others. However, it remains unclear whether this is due to the fact that emotion was only acted or due to the insufficiency of the detection software. As an intended side effect, we collected a small corpus of labeled data for acted emotion in speech, which we plan to extend and eventually use as training data for our own emotion detection. We present the study setup and discuss some insights on our results.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {269},
numpages = {4},
keywords = {Data Acquisition for Training Neural Networks, Emotion-Aware VoiceBot, Speech Emotion Detection},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451740,
author = {Lee, Chiwon and Joo, Hyunjong and Jun, Soojin},
title = {Social VR as the New Normal? Understanding User Interactions for the Business Arena},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451740},
doi = {10.1145/3411763.3451740},
abstract = {Due to the COVID-19 pandemic, online meetings have become the new normal amongst business professionals. The usage of video conferencing services such as Zoom has skyrocketed, and the usage of Social Virtual Reality (VR) services have also been taken under consideration to be the new normal as it enables users to have a spatial online presence; nonetheless, the usage of Social VR has been considerably lower compared to video conferencing services. The purpose of this study is to investigate the user interactions of business professionals regarding the web-based Social VR platform, Mozilla Hubs, and suggest alterations regarding the user experience in order to understand why the usage of Social VR is low amongst business professionals and to promote the usage of the platform that could resolve the issue having a lack of spatial presence in the online arena.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {420},
numpages = {5},
keywords = {Business Meetings, Mozilla Hubs, Online Meetings, Virtual Reality, Social VR},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451739,
author = {Beltran, Kevin and Rowland, Cody and Hashemi, Nicki and Nguyen, Anh and Harrison, Lane and Engle, Sophie and Yuksel, Beste F},
title = {Reducing Implicit Gender Bias Using a Virtual Workplace Environment},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451739},
doi = {10.1145/3411763.3451739},
abstract = {Implicit gender bias has costly and complex consequences for women in the workplace. We present an online desktop virtual environment that follows the story of a male or female self-avatar from the first-person perspective, who either experiences a positive or negative workplace scenario. Participants who experienced negative workplace experiences with a female self-avatar had significantly decreased levels of implicit gender bias compared to those who had a male self-avatar with evidence of perspective taking. Experiences of a positive workplace scenario showed no significant decreases in implicit gender bias regardless of self-avatar gender. We discuss the implications of these findings and make recommendations for virtual environment technologies and scenarios with respect to the reduction of implicit biases.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {277},
numpages = {7},
keywords = {Implicit Gender Bias, Implicit Association Test, Avatar, Virtual Environments, IAT, Gender.},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451738,
author = {Grieger, Florian and Klapperich, Holger and Hassenzahl, Marc},
title = {Trash It, Punch It, Burn It – Using Virtual Reality to Support Coping with Negative Thoughts},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451738},
doi = {10.1145/3411763.3451738},
abstract = {Negative thoughts are a widespread everyday experience. Failures to appropriately cope with negative thoughts are related to serious mental health issues, such as depression. Consequently, preventive technology-mediated everyday interventions to support coping with negative thoughts are of interest. One promising platform for mental health applications is personalized virtual reality (VR). We developed an explorative VR prototype based on personally relevant textual messages from email, messengers and alike, which trigger negative thoughts. The prototype presented these messages in VR and allowed to physically manipulate them, for example, by physically punching and trashing them. A qualitative empirical exploration (N=10) revealed a general positive shift in thoughts and emotions after using the prototype, mainly in form of increased relaxation and self-reflection. Based on this and further insights, we derive four themes for VR in mental health, touching upon the importance of personalization, immersion and focus, interaction design and embodiment, as well as, integration into everyday life.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {6},
keywords = {interaction design, negative thoughts, coping, virtual reality, mental health, reflection, design for wellbeing},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451728,
author = {Bhatia, Arpit and Lakra, Aneesha and Anand, Rakshita and Eden, Grace},
title = {An Analysis of Ludo Board Game Play on Smartphones},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451728},
doi = {10.1145/3411763.3451728},
abstract = {From sports to party games, almost every kind of game has been adapted into a digital video game format. While previous research has studied player motivations and experiences for certain categories of digital games, there has yet to be such a study on digital board games, especially in the modern context of smartphone apps. To address this, we conduct a case study of a popular board game, Ludo, to understand players’ opinions of its digital adaptation. For this, we study the functionality and user reviews of nine popular Ludo apps, to assess player opinions of how traditional gameplay has been re-imagined. Based upon our analysis, we conclude with recommendations for improving Ludo apps and other apps, based on random chance board games.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {396},
numpages = {6},
keywords = {Board Games, User Reviews, Mobile Apps},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451707,
author = {Shreepriya, Shreepriya and Legras, Christophe and Clinchant, St\'{e}phane and Willamowski, Jutta},
title = {Evaluating an Itinerary Recommendation Algorithm for Runners},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451707},
doi = {10.1145/3411763.3451707},
abstract = {Recommender systems for runners primarily rely on existing running traces in an area. In the absence of running traces, recommending running routes is challenging. This paper describes our approach to generating and proposing ”pleasant” running tours that consider the runner’s standard preferences and their distance and elevation constraints. Our algorithm is an approach to solve the cold start recommendation problem in unknown places by mining available map-data. We implemented a prototypical smartphone app that generates and recommends pleasant running routes to evaluate our algorithm’s effectiveness. An in-the-wild user study was conducted, with 11 participants across three cities. We tested the correlation between what is defined as ”pleasant path” by our algorithm and the user’s perception. The results of the user study show a positive correlation and support our algorithm. We also outline implications for the design of successful recommendation algorithms for runners.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {328},
numpages = {6},
keywords = {Running, Itinerary Recommendation, Sports, Route Generation},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451704,
author = {Clark, Juliet and Kelliher, Aisling},
title = {Understanding the Needs and Values of Rehabilitation Therapists in Designing and Implementing Telehealth Solutions},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451704},
doi = {10.1145/3411763.3451704},
abstract = {The strengthening of community care and the development of co-managed telehealth systems are vital components in addressing growing critical healthcare issues encountered worldwide. The global COVID pandemic highlights the challenges in providing appropriate co-managed home-based care in a systemic and financially viable way at scale. It is important to understand the individual, institutional, and socio-technical opportunities and barriers potentially encountered when attempting to implement telehealth systems as part of a broader social healthcare network. As part of our work designing telehealth systems for home based physical rehabilitation, we conducted a survey and interviews with occupational and physical therapists to better understand the everyday individual and institutional reality within which our systems might ultimately be embedded. We describe the integrated personal, economic, and regulatory issues involved and propose guidelines to consider for designers of telehealth systems for home-based contexts.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {247},
numpages = {6},
keywords = {telehealth, caregiver, rehabilitation, patient, therapist},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451702,
author = {Choi, Jinhan and Oh, Changhoon and Suh, Bongwon and Kim, Nam Wook},
title = {Toward a Unified Framework for Visualization Design Guidelines},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451702},
doi = {10.1145/3411763.3451702},
abstract = {Visualizations are now widely adopted across disciplines, providing effective means to understand and communicate data. However, people still frequently create misleading visualizations that distort the underlying data and ultimately misinform the audience. While design guidelines exist, they are currently scattered across different sources and devised by different people, often missing design trade-offs in different contexts and providing inconsistent and conflicting design knowledge to visualization practitioners. Our goal in this work is to investigate the ontology of visualization design guidelines and derive a unified framework for structuring the guidelines. We collected existing guidelines on the web and analyzed them using the grounded theory approach. We describe the current landscape of the available guidelines and propose a structured template for describing visualization design guidelines.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {240},
numpages = {7},
keywords = {visualization literacy, guidelines, visualization},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451701,
author = {Washington, Peter and Kline, Aaron and Mutlu, Onur Cezmi and Leblanc, Emilie and Hou, Cathy and Stockham, Nate and Paskov, Kelley and Chrisman, Brianna and Wall, Dennis},
title = {Activity Recognition with Moving Cameras and Few Training Examples: Applications for Detection of Autism-Related Headbanging},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451701},
doi = {10.1145/3411763.3451701},
abstract = {Activity recognition computer vision algorithms can be used to detect the presence of autism-related behaviors, including what are termed “restricted and repetitive behaviors”, or stimming, by diagnostic instruments. Examples of stimming include hand flapping, spinning, and head banging. One of the most significant bottlenecks for implementing such classifiers is the lack of sufficiently large training sets of human behavior specific to pediatric developmental delays. The data that do exist are usually recorded with a handheld camera which is itself shaky or even moving, posing a challenge for traditional feature representation approaches for activity detection which capture the camera's motion as a feature. To address these issues, we first document the advantages and limitations of current feature representation techniques for activity recognition when applied to head banging detection. We then propose a feature representation consisting exclusively of head pose keypoints. We create a computer vision classifier for detecting head banging in home videos using a time-distributed convolutional neural network (CNN) in which a single CNN extracts features from each frame in the input sequence, and these extracted features are fed as input to a long short-term memory (LSTM) network. On the binary task of predicting head banging and no head banging within videos from the Self Stimulatory Behaviour Dataset (SSBD), we reach a mean F1-score of 90.77% using 3-fold cross validation (with individual fold F1-scores of 83.3%, 89.0%, and 100.0%) when ensuring that no child who appeared in the train set was in the test set for all folds. This work documents a successful process for training a computer vision classifier which can detect a particular human motion pattern with few training examples and even when the camera recording the source clip is unstable. The process of engineering useful feature representations by visually inspecting the representations, as described here, can be a useful practice by designers and developers of interactive systems detecting human motion patterns for use in mobile and ubiquitous interactive systems.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {239},
numpages = {7},
keywords = {autism, motion detection, Activity recognition, machine learning, repetitive motions},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451698,
author = {Chen, Qinyue and Yan, Yuchun and Suk, Hyeon-Jeong},
title = {Bubble Coloring to Visualize the Speech Emotion},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451698},
doi = {10.1145/3411763.3451698},
abstract = {To explore the emotional effect of the chat bubble’s background color on voice messages, we carried out a user survey with Facebook Messenger, WeChat, and KakaoTalk, which use blue, green, and yellow, respectively, as the default color for chat bubbles. We provided the colors in orange, dark red, dark grey, and pale blue when the voice message seemed to be in an excited, angry, sad, or serene mood, respectively. With the exception of the serene, the emotion was intensified through the background color across the three messengers. Concerning willingness to use, the likelihood was reduced, particularly in negative emotions. Based on the empirical evidence, we discussed the potentials and concerns when the method is implemented in voice messaging.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {361},
numpages = {6},
keywords = {speech emotion recognition, color, voice message},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451696,
author = {Leong, Joanne and Pataranutaporn, Pat and Mao, Yaoli and Perteneder, Florian and Hoque, Ehsan and Baker, Janet M and Maes, Pattie},
title = {Exploring the Use of Real-Time Camera Filters on Embodiment and Creativity},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451696},
doi = {10.1145/3411763.3451696},
abstract = {Virtual representations of ourselves can influence the way we feel and behave. While this phenomenon has been explored heavily in the realms of virtual reality and gaming, little is known about the level of impact increasingly pervasive real-time camera filters can have on how people feel, think, and behave. The prevalence and popularity of these technologies have surged, coupled with greater usage of online communication tools. Motivated by a desire for self-improvement in an age of regular video-based online communication, we conducted a user study to investigate the potential for real-time camera filters to influence emotions, support embodiment illusions, and consequently impact cognitive performance by applying it to the domain of creative thinking.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {316},
numpages = {7},
keywords = {camera filters, embodiment, creativity, real-time, self-perception},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451664,
author = {Olafsson, Stefan and Parmar, Dhaval and Kimani, Everlyne and K. O'Leary, Teresa and Bickmore, Timothy},
title = {‘More like a Person than Reading Text in a Machine’: Characterizing User Choice of Embodied Agents vs. Conventional GUIs on Smartphones},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451664},
doi = {10.1145/3411763.3451664},
abstract = {Embodied conversational agents (ECAs) provide an interface modality on smartphones that may be particularly effective for tasks with significant social, affective, reflective, and narrative aspects, such as health education and behavior change counseling. However, the conversational medium is significantly slower than conventional graphical user interfaces (GUIs) for brief, time-sensitive tasks. We conducted a randomized experiment to determine user preferences in performing two kinds of health-related tasks—one affective and narrative in nature and one transactional—and gave participants a choice of a conventional GUI or a functionally equivalent ECA on a smartphone to complete the task. We found significant main effects of task type and user preference on user choice of modality, with participants choosing the conventional GUI more often for transactional and time-sensitive tasks.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {6},
keywords = {experiment, interface modality, mobile computing, virtual agent},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451652,
author = {Schneegass, Christina and Irmscher, Diana and Bemmann, Florian and Buschek, Daniel},
title = {LYLO – Exploring Disclosed Configurations for Inter-Personal Location Sharing},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451652},
doi = {10.1145/3411763.3451652},
abstract = {Continuous location sharing (CLS) can foster intimacy, for example, for couples in long-distance relationships. However, turning off CLS can then raise suspicions. To address this, we developed nuanced sharing settings in a focus group (N = 6) and implemented them to moderate CLS in an Android app. Crucially, the app also discloses each person’s current sharing settings to the partner. In a 16-day field study, four couples interacted with our app and the disclosed configurations, confirming the disclosure’s positive effect on transparency. However, features obfuscating the location were considered superfluous, as participants preferred sharing their location exactly or not at all. While participants overall appreciated having the configuration options, changes in their partners’ configurations raised questions about their motivations. Instead, participants would adjust the configuration for different intimacy levels (colleague vs. partner) rather than different activities when using CLS with the same person.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {320},
numpages = {6},
keywords = {disclosed configurations, transparency, continuous location sharing, data protection, privacy},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451641,
author = {Lu, Jie and Han, Yu and Xin, YunFei and Yue, Kang and Liu, Yue},
title = {Possibilities for Designing Enhancing Spatial Knowledge Acquirements Navigator: A User Study on the Role of Different Contributors in Impairing Human Spatial Memory During Navigation},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451641},
doi = {10.1145/3411763.3451641},
abstract = {Satellite mobile navigation systems have been criticized for impairing human spatial memory as an assistant in daily life. Nevertheless, few studies have directly investigated the specific role of different main contributors in such impairment in the same context. This study selected two of the main contributors leading to the impairment of human spatial memory and then made every possible effort to eliminate them from the navigation system: return user's route decision-making control, and subliminally return user's attention that has ever been distracted by the system to the environment. Two navigation modes were designed and compared in detail with the different spatial knowledge acquired by the efficient everyday navigation system. A within-subjects study in Virtual Reality (VR) urban environment was conducted and data on spatial knowledge was collected and analyzed. We concluded that the redirection of attention significantly benefits the acquisition of landmark as well as route knowledge, and the increase of route decisions further benefits survey knowledge as well as self-orientation. We also reflected on how these results might implicate future navigation systems design, and the results of analysis showed that it was possible to design a navigation system that does not impair or even enhance user's spatial memory while still retaining efficient navigation. Based on our findings, different future application-specific studies can better design navigation systems that focus on different spatial memories.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {295},
numpages = {6},
keywords = {Navigation, Virtual Reality, Mobile Device, Spatial Knowledge},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451637,
author = {Orii, Lisa and Tosca, Diana and Kun, Andrew L and Shaer, Orit},
title = {Perceptions on the Future of Automation in r/Truckers},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451637},
doi = {10.1145/3411763.3451637},
abstract = {New developments in automation have led to discussions about the impact that autonomous trucks will have on the trucking industry. However, there is a lack of literature on truck drivers’ perceptions of automation. To gain an understanding of the trucking community’s sentiments towards automation, we analyzed member discussions related to automation in the r/Truckers subreddit. Among the comments we analyzed, concerns about the feasibility of automation were popular and, in general, community members expressed negative perspectives on automation in trucking. This was corroborated by our findings that only 0.98% (9/915) comments had positive views on automation. Speculations on when automation of any degree will take place in the trucking industry varied, but the view that automation would eventually happen but not for a long time was the most common. To conclude, we highlight a need to support and empower truck drivers through the significant changes facing this industry.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {311},
numpages = {6},
keywords = {trucking, online communities, automation},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451616,
author = {Hammad, Noor and Harpstead, Erik and Hammer, Jessica},
title = {Towards Examining The Effects of Live Streaming an Educational Game},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451616},
doi = {10.1145/3411763.3451616},
abstract = {We propose a study on the effects of live streaming on an educational game’s learning outcomes. The COVID-19 pandemic has strengthened the call for interactive online learning experiences. There is a growing body of literature examining learning on platforms such as Twitch, and studies have shown that enhancing in-game performance is possible from viewing a stream. However, little work has explored whether learning from live streaming educational games, where in-game performance relates to educational outcomes outside of the game context, is possible. We share the details of our proposed study, in which an educational game called Angle Jungle will streamed to participants, and learning gains will be compared to three non-live streamed conditions. By executing this study, we can understand the benefits and shortcomings of current live streaming interfaces in supporting educational games, paving the way for the design of novel and interactive learning experiences built for live streaming platforms.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {235},
numpages = {6},
keywords = {educational games, live streaming, Twitch},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451604,
author = {Chen, Irene and Gibbs, Jennifer L. and Lin, Junchao},
title = {Understanding and Designing for Disaster Preparation on Social Media},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451604},
doi = {10.1145/3411763.3451604},
abstract = {The widespread adoption of social media brings both challenges and opportunities for the field of disaster management. However, there has been limited scholarly work on social media usage for disaster preparation. Our work explores how social media sites can be designed to help individuals and communities prepare for disasters, in particular with regard to crowdsourcing information, digital mobilization, and community resilience. We present preliminary findings from 4 online focus groups (N=31), which reveal two emergent themes that may prove useful for future research and design in HCI. We also propose four design recommendations for social media sites as tools for disaster preparation. These findings support the design and evaluation of social media sites to aid in community-based disaster preparedness.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {441},
numpages = {6},
keywords = {crisis and disaster management, Crisis informatics, focus group study, computer-mediated communication, user interface design, disaster preparation on social media},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451600,
author = {Ma, Celina and Wang, Haohong and Sun, Hao and van Huijgevoort, Elliot and Wang, Mea and He, Zhihai},
title = {Powering TV Experiences with Anytime Environmental Exploration},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451600},
doi = {10.1145/3411763.3451600},
abstract = {Our work proposes a novel interactive model for TV such that users can freely decide when and how much to interact with the story. At any time, users can enter the immersive 3D environment of each scene in the story by controlling an avatar. In this scene, users embrace a rich set of interactive possibilities, including in-depth exploration, conversations with characters, and gamified quests to guide the story. Users also have the option to watch their avatar explore the 3D environment automatically for a lean-back experience. User evaluation of our prototype confirmed the acceptance of this new model and enthusiasm for the interactive freedom and depth it provides. To the best of our knowledge, this is the world’s first lean-back-compatible TV model that offers a complete immersive experience driven by users, shedding light on a new direction for designing interactive videos appealing to a wide audience.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {363},
numpages = {6},
keywords = {gamification, environmental storytelling, interactive video, interactive narrative},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451594,
author = {Reinschluessel, Anke Verena and Muender, Thomas and D\"{o}ring, Tanja and Uslar, Verena Nicole and L\"{u}ck, Thomas and Weyhe, Dirk and Schenk, Andrea and Malaka, Rainer},
title = {A Study on the Size of Tangible Organ-Shaped Controllers for Exploring Medical Data in VR},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451594},
doi = {10.1145/3411763.3451594},
abstract = {Virtual reality (VR) is, by nature, excellent in showing spatial relationships, e.g. for viewing medical 3D data. In this work, we propose a VR system to view and manipulate medical 3D images of livers in combination with 3D printed liver models as controllers. We investigate whether users benefit from a controller in the shape of a liver and if the size matters by using three different sizes (50&nbsp;%, 75&nbsp;%, 100&nbsp;%). In a user study with 14 surgeons, we focused on presence, workload and qualitative feedback such as preference. While neither size differences nor the VIVE tracker as control resulted in significant differences, most surgeons preferred the 75&nbsp;% model. Qualitative results indicate that high similarity of physical and virtual objects regarding shape and a focus on good manageability of the physical object is more important than providing an exact replica in size.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {261},
numpages = {7},
keywords = {VR, Medical Imaging, Virtual Reality, Surgery, Spatial Interaction, Image Navigation, 3D Model, User Study, Interview, 3D printing},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451579,
author = {Lahlou, Saadi and Pea, Roy and Heitmayer, Maxi and G. Russell, Martha and Schimmelpfennig, Robin and Yamin, Paulius and Everri, Marina and Cordelois, Antoine and P. Dawes, Adelaide},
title = {Are We ‘Beyond Being There’ yet? Towards Better Interweaving Epistemic and Social Aspects of Virtual Reality Conferencing},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451579},
doi = {10.1145/3411763.3451579},
abstract = {Interactive virtual conferencing has become a necessity in adapting to travel reductions during the global pandemic. This paper reports experience with a recent 5-week VR conference with participants from academia and leading industry experts. Drawing on Activity Theory and Installation Theory, a structural grid for virtual conferencing activity analysis is described. We argue that for successful interactive virtual conferencing, the installation must facilitate both the development of knowledge and informal social interaction, the ‘epistemic’ and the ‘relational’. We focus on three specific aspects of the conference activity—onboarding, networking, and intersession transitions—to highlight key issues and illustrate the process of design thinking based on distributed architecture. We discuss lessons learned to inform this fast-growing field: provisions for meaningful social interactions remain underdeveloped in current conferencing systems.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {462},
numpages = {6},
keywords = {Activity Analysis, Installation for Virtual Conferencing (IVC)},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451564,
author = {Diaz, Yancarlos and Nishizawa, Gavin and Mansouri, Behrooz and Davila, Kenny and Zanibbi, Richard},
title = {The MathDeck Formula Editor: Interactive Formula Entry Combining LaTeX , Structure Editing, and Search},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451564},
doi = {10.1145/3411763.3451564},
abstract = {Writing formulas in LaTeX &nbsp;can be difficult, especially for complex formulas. MathDeck simplifies LaTeX formula entry by: 1) allowing rendered formulas to be edited directly alongside their associated LaTeX strings, 2) helping build formulas from smaller ones, and 3) providing searchable formula cards with associated names and descriptions. Cards are searchable by formula and title.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {192},
numpages = {5},
keywords = {Structure Editor, Mathematical Information Retrieval (MIR), LaTeX, Equation Editor},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451556,
author = {Kilian, Annika and Karolus, Jakob and Kosch, Thomas and Schmidt, Albrecht and Wo\'{z}niak, Pawe\l{} W.},
title = {EMPiano: Electromyographic Pitch Control on the Piano Keyboard},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451556},
doi = {10.1145/3411763.3451556},
abstract = {The piano keyboard offers a significant range and polyphony for well-trained pianists. Yet, apart from dynamics, the piano is incapable of translating expressive movements such as vibrato onto the played note. Adding sound effects requires additional modalities. A pitch wheel can be found on the side of most electric pianos. To add a vibrato or pitch bend, the pianist needs to actively operate the pitch wheel with their hand, which requires cognitive effort and may disrupt play. In this work, we present EMPiano, a system that allows pianists to incorporate a soft pitch vibrato into their play seamlessly. Vibrato can be triggered through muscle activity and is recognized via electromyography. This allows EMPiano to integrate into piano play. Our system offers new interaction opportunities with the piano to increase the player’s potential for expressive play. In this paper, we contribute the open-source implementation and the workflow behind EMPiano.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {196},
numpages = {4},
keywords = {seamless integration, Electromyography, expressive piano play, piano interaction.},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451540,
author = {Teng, Shan-Yuan and Li, Pengyu and Nith, Romain and Fonseca, Joshua and Lopes, Pedro},
title = {Demonstrating Touch&amp;Fold: A Foldable Haptic Actuator for Rendering Touch in Mixed Reality},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451540},
doi = {10.1145/3411763.3451540},
abstract = {We propose a nail-mounted foldable haptic device that provides tactile feedback to mixed reality (MR) environments by pressing against the user's fingerpad when a user touches a virtual object. What is novel in our device is that it quickly tucks away when the user interacts with real-world objects. Its design allows it to fold back on top of the user's nail when not in use, keeping the user's fingerpad free to, for instance, manipulate handheld tools and other objects while in MR. To achieve this, we engineered a wireless and self-contained haptic device, which measures 24\texttimes{}24\texttimes{}41&nbsp;mm and weighs 9.5&nbsp;g. Furthermore, our foldable end-effector also features a linear resonant actuator, allowing it to render not only touch contacts (i.e., pressure) but also textures (i.e., vibrations). We demonstrate how our device renders contacts with MR surfaces, buttons, low- and high-frequency textures.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {203},
numpages = {4},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451538,
author = {Luo, Danli and Yang, Humphrey and Khurana, Malika and Qian, Kuanren and Yao, Lining},
title = {Demonstrating Freeform Fabrication of Fluidic Edible Materials},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451538},
doi = {10.1145/3411763.3451538},
abstract = {From providing nutrition to being social platforms, food plays an essential role in our daily lives and cultures. In this work, we are interested in using food as an interaction medium and a context of personal fabrication with an expanded design space enabled by support bath-assisted printing. The bath scaffolds the embedded materials while preserving shapes during the printing processes and allows us to create freeform food with fluid-like materials. Coupled with different post-processing and cooking methods, this technique grants the versatility of food printing with fluidic materials. We will demo confectionery arts and dishes designed by our software tool.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {201},
numpages = {4},
keywords = {computational fabrication, edible interface, personal fabrication, 3D printing, Food printing},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451537,
author = {Abdullah, Muhammad and Taraz, Martin and Kommana, Yannis and Katakura, Shohei and Kovacs, Robert and Shigeyama, Jotaro and Roumen, Thijs and Baudisch, Patrick},
title = {Demonstrating FastForce: Real-Time Reinforcement of Laser-Cut Structures},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451537},
doi = {10.1145/3411763.3451537},
abstract = {We demonstrate fastForce, a software tool that detects structural flaws in laser cut 3D models and fixes them by introducing additional plates into the model, thereby making models up to 52x stronger. By focusing on a specific type of structural issue, i.e., poorly connected sub-structures in closed box structures, fastForce achieves real-time performance. This allows fastForce to fix structural issues continuously in the background, while users stay focused on editing their models and without ever becoming aware of any structural issues.In our study, six of seven participants inadvertently introduced severe structural flaws into the guitar stands they designed. Similarly, we found 286 of 402 relevant models in the kyub [1] model library to contain such flaws. We integrated fastForce into a 3D editor for lasercutting (kyub) and found that even with high plate counts fastForce achieves real-time performance.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {206},
numpages = {4},
keywords = {lasercutting, structural reinforcement, Personal fabrication, structural analysis},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451536,
author = {Marky, Karola and Wei\ss{}, Andreas and M\"{u}ller, Florian and Schmitz, Martin and M\"{u}hlh\"{a}user, Max and Kosch, Thomas},
title = {Let’s Frets! Mastering Guitar Playing with Capacitive Sensing and Visual Guidance},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451536},
doi = {10.1145/3411763.3451536},
abstract = {Mastering the guitar requires regular exercise to develop new skills and maintain existing abilities. We present Let’s Frets - a modular guitar support system that provides visual guidance through LEDs that are integrated into a capacitive fretboard to support the practice of chords, scales, melodies, and exercises. Additional feedback is provided through a 3D-printed fretboard that senses the finger positions through capacitive sensing. We envision Let’s Frets as an integrated guitar support system that raises the awareness of guitarists about their playing styles, their training progress, the composition of new pieces, and facilitating remote collaborations between teachers as well as guitar students. This interactivity demonstrates Let’s Frets with an augmented fretboard and supporting software that runs on a mobile device.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {169},
numpages = {4},
keywords = {musical instruments, support setup, capacitive sensing},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451522,
author = {Chopra, Bhavya and Verma, Khushali and Singhal, Sonali and Singla, Utsav},
title = {Reality Tales: Facilitating User-Character Interaction with Immersive Storytelling},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451522},
doi = {10.1145/3411763.3451522},
abstract = {Reality Tales is a platform to facilitate interaction with fictional story characters for readers (13-20 years). The platform leverages binaural audio and multi-voice narration for an immersive story experience. Several paradigms for interactive storytelling have emerged in recent years, involving sequence-based story generation with user inputs. However, the current work in this domain rarely applies to existing fictional stories, with defined characters and plots. Our work introduces voice-based conversational interaction with story characters as a novel dimension to digital interactive storytelling. Through a user-centered process and qualitative studies, we discover that providing users with the agency to directly converse with story characters about their lives makes the users invested in the storyline.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {489},
numpages = {7},
keywords = {user centered design, user-character interaction, binaural audio, interactive storytelling, multi-voice narration},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3450407,
author = {Lopes, Pedro and Chuang, Lewis L and Maes, Pattie},
title = {Physiological I/O},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450407},
doi = {10.1145/3411763.3450407},
abstract = {Interactive computing systems are able to receive, as inputs, activity generated by the user’s physiology (e.g., skin conductance, heart rate, brain potentials, and so forth). Besides health-related applications, this type of physiological sensing enables systems to infer users’ states (e.g., task engagement, anxiety, workload, and so forth). More recently, a number of techniques emerged that can also stimulate physiological activity (e.g., electrical muscle stimulation, galvanic vestibular stimulation, transcranial stimulation). These can serve as outputs of an interactive system to induce desired behavior in the user. Taken together, we envision systems that will close the loop between physiological input and output—interactive systems able to read and influence the user’s body. To realize this, we propose a Special Interest Group on Physiological I/O that will consolidate successful practices and identify research challenges to address as a community.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {161},
numpages = {4},
keywords = {wearables, muscle I/O, affective computing, physiological sensing, neural interfaces},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3450399,
author = {Ryskeldiev, Bektur and Ili\'{c}, Suzana and Ochiai, Yoichi and Elliott, Luba and Nikonole, Helena and Billinghurst, Mark},
title = {Creative Immersive AI:Emerging Challenges and Opportunities ForCreative Applications of AI in Immersive Media},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450399},
doi = {10.1145/3411763.3450399},
abstract = {Over the past several years artificial intelligence (AI) techniques have gained a considerable presence in immersive media. From assistance with real-time digital production to emerging novel forms of creative expression, applications of AI are becoming ubiquitous in the fields of human-computer interaction (HCI), computer graphics, and media art. As we are interested in how novel computational techniques are shaping the state of creativity in immersive and interactive technologies, we organize this special interest group (SIG) to stimulate a discussion among AI, HCI, immersive media, and art communities. The goal of this SIG includes outlining existing and emerging areas of cross-disciplinary collaborations, proposing a roadmap of future goals and challenges for creative immersive AI research, and establishing a diverse group of researchers and practitioners involved in creative applications of AI in immersive and interactive media.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {157},
numpages = {3},
keywords = {media art, computer graphics, human-computer interaction, immersive media, augmented reality, virtual reality, mixed reality, artificial intelligence, extended reality},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3450390,
author = {Reddy, Anuradha and Kocaballi, A. Baki and Nicenboim, Iohanna and S\o{}ndergaard, Marie Louise Juul and Lupetti, Maria Luce and Key, Cayla and Speed, Chris and Lockton, Dan and Giaccardi, Elisa and Gromm\'{e}, Francisca and Robbins, Holly and Primlani, Namrata and Yurman, Paulina and Sumartojo, Shanti and Phan, Thao and Bed\"{o}, Viktor and Strengers, Yolande},
title = {Making Everyday Things Talk: Speculative Conversations into the Future of Voice Interfaces at Home},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450390},
doi = {10.1145/3411763.3450390},
abstract = {What if things had a voice? What if we could talk directly to things instead of using a mediating voice interface such as an Alexa or a Google Assistant? In this paper, we share our insights from talking to a pair of boots, a tampon, a perfume bottle, and toilet paper among other everyday things to explore their conversational capabilities. We conducted Thing Interviews using a more-than-human design approach to discover a thing’s perspectives, worldviews and its relations to other humans and nonhumans. Based on our analysis of the speculative conversations, we identified some themes characterizing the emergent qualities of people’s relationships with everyday things. We believe the themes presented in the paper may inspire future research on designing everyday things with conversational capabilities at home.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {23},
numpages = {16},
keywords = {More-than-human Design, AI, Thing Interviews, Conversational Agents, Voice Interfaces, IoT},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3450388,
author = {Penzenstadler, Birgit and Norton, Juliet},
title = {Tapping In - How to Decide: Mind, Heart, or Gut?},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450388},
doi = {10.1145/3411763.3450388},
abstract = {Motivation: Immediate cognition without rationalization is called intuition - an empowering faculty. Many of us feel disconnected from our intuition, potentially causing us to struggle with confidently making decisions. Challenge: We set out to find out why that is and how to support aligned decision-making. Method: We interviewed fourteen experts on tuning into our intuition for decision-making, surveyed currently available decision-making support tools, and modeled a tool that extends current approaches with the expert insights. Results: Based on the experts’ insights, we modeled a decision trifecta including mind, heart, and gut along with a narrative of how to educate on their interplay and how to use that to take more aligned decisions. We critically question to what extent decision support technology is a beneficial way forward. Impact: The model opens up a space for discussion around holistic decision making from an individual’s perspective. It serves as a reflection tool for personal processes as well as the suitability and limits of supportive technology.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {10},
keywords = {decision-making, intuition, decision, decision support, analysis},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3450385,
author = {Halpin, Harry},
title = {The Philosophical and Technical Legacy of Bernard Stiegler},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450385},
doi = {10.1145/3411763.3450385},
abstract = {Although technical systems may not seem on the surface to be philosophical in nature, there is a historical influence in Human-Computer Interaction (HCI) of Heidegger via the work of Winograd and Dreyfus. However, the late philosopher Bernard Stiegler critiqued this positivist reading of Heidegger, noting how Heidegger himself ultimately did not understand the political stakes of technology. Rather than abandon technology, Bernard Stiegler argued that we must repurpose technology to create a new form of society in the wake of the digital disruption. We review his often difficult philosophical vocabulary, his political stance, and his nearly unknown role in motivating a number of innovative software projects at Institut de recherche et d’innovation du Centre Pompidou. It is precisely a fundamental philosophical reorientation that will allow researchers to create the new kinds of programs that can meet the challenge posed by our digital epoch.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {30},
numpages = {8},
keywords = {Digital studies, Human-Computer Interaction, Philosophy},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3450378,
author = {Pimentel, Daniel},
title = {The Peril and Potential of XR-Based Interactions with Wildlife},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450378},
doi = {10.1145/3411763.3450378},
abstract = {In “Being a Beast”, Charles Foster recounts living with, and as, wildlife (e.g., otters, foxes). These encounters, he contends, forge human-nature connections which have waned, negatively impacting biodiversity conservation. Yet, we need not live amidst beasts to bridge the human-nature gap. Cross-reality (XR) platforms (i.e., virtual and augmented reality) have the unique capacity to facilitate pseudo interactions with, and as, wildlife, connecting audiences to the plight of endangered species. However, XR-based wildlife interaction, I argue, is a double-edged sword whose implementation warrants as much attention in HCI as in environmental science. In this paper I highlight the promise of XR-based wildlife encounters, and discuss dilemmas facing developers tasked with fabricating mediated interactions with wildlife. I critique this approach by outlining how such experiences may negatively affect humans and the survivability of the very species seeking to benefit from them.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {15},
numpages = {9},
keywords = {Virtual reality, conservation, augmented reality, nature, biodiversity},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3450376,
author = {Kesewaa Dankwa, Nana},
title = {“All Names Are Pseudonyms”: A Critical Reflection on Pseudonymizing Names in HCI: “All Names Are Pseudonyms”},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450376},
doi = {10.1145/3411763.3450376},
abstract = {A person's name embodies identity. During user studies in Human Computer Interaction (HCI), persons are often renamed (pseudonymization) to hide their identity for privacy and ethical reasons. Pseudonymization occurs mostly as a “silent” affair of due diligence. Researchers barely give substantial information to the process nor reveal a reflexive position nor acknowledge the underlying elements of power and identity negotiation. As HCI advances in mitigating the design of biased technologies and breaking oppressive structures, I argue, in this paper, the need for the field to re-consider research requirements such as pseudonymization as possible to embody oppressive structures and erase identity. I present a review of papers from the 2020 CHI Conference on Human Factors in Computing Systems (CHI ‘20) that illustrate how silent the HCI approach is. My argument is built on Critical Race Theory, questioning the objectivity of such technical requirements. I use personal narratives to bolster this argument, ending with a call to the HCI community to acknowledge the power and privilege in renaming participants with three recommendations for consideration.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {34},
numpages = {6},
keywords = {Counter Story Telling, Negotiation, Critical Race Theory, Pseudonymization},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3450373,
author = {LC, RAY and Mizuno, Daijiro},
title = {Designing for Narrative Influence: Speculative Storytelling for Social Good in Times of Public Health and Climate Crises},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450373},
doi = {10.1145/3411763.3450373},
abstract = {Health and safety concerns have led to policies that put individuals under lockdown, but such restrictions lose effectiveness in the long-term due to inherent human needs of connection and physical action. People maintain prosocial behaviors long-term only if they make decisions themselves intrinsically as opposed to forced restrictions. To build systems for effecting positive social purpose in pandemic and environmental concerns, we apply speculative design to create story structures and interactions that promote behaviors for social good. We designed stories and interactions using both plot-based narrative frameworks and character-based machine-learning-generated dialogues for effecting cooperation. We then ran a series of workshops investigating how designers negotiate and collaborate to tell stories for social purpose using a "finish each other's stories" approach. This work illustrates the application of design fiction to promote sustainable behavioral patterns that value societal good.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {29},
numpages = {13},
keywords = {machine text, social influence, design fiction, intrinsic motivation, public good},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

