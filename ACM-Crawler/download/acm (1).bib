@inproceedings{10.1145/3313831.3376411,
author = {Zuckerman, Oren and Walker, Dina and Grishko, Andrey and Moran, Tal and Levy, Chen and Lisak, Barak and Wald, Iddo Yehoshua and Erel, Hadas},
title = {Companionship Is Not a Function: The Effect of a Novel Robotic Object on Healthy Older Adults' Feelings of "Being-Seen"},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376411},
doi = {10.1145/3313831.3376411},
abstract = {One of the challenges faced by healthy older adults is experiencing feelings of not "being-seen". Companion robots, commonly designed with zoomorphic or humanoid appearance show success among clinical older adults, but healthy older adults find them degrading. We present the design and implementation of a novel non-humanoid robot. The robot's primary function is a cognitive word game. Social interaction is conveyed as a secondary function, using non-verbal gestures, inspired by dancers' movement. In a lab study, 39 healthy older adults interacted with the prototype in 3 conditions: Companion-Function; Game-Function; and No-Function. Results show the non-verbal gestures were associated with feelings of "being-seen", and willingness to accept the robot into their home was influenced by its function, with game significantly higher than companion. We conclude that robot designers should further explore the potential of non-humanoid robots as a new class of companion robots, with a primary function that is not companionship.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {non-humanoid robot, acceptance, successful aging, older adults, tangible interaction, loneliness, social-interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376392,
author = {Ogbonnaya-Ogburu, Ihudiya Finda and Smith, Angela D.R. and To, Alexandra and Toyama, Kentaro},
title = {Critical Race Theory for HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376392},
doi = {10.1145/3313831.3376392},
abstract = {The human-computer interaction community has made some efforts toward racial diversity, but the outcomes remain meager. We introduce critical race theory and adapt it for HCI to lay a theoretical basis for race-conscious efforts, both in research and within our community. Building on the theory's original tenets, we argue that racism is pervasive in everyday socio-technical systems; that the HCI community is prone to "interest convergence", where concessions to inclusion require benefits to those in power; and that the neoliberal underpinnings of the technology industry itself propagate racism. Critical race theory uses storytelling as a means to upend deep-seated assumptions, and we relate several personal stories to highlight ongoing problems of race in HCI. The implications: all HCI research must be attuned to issues of race; participation of underrepresented minorities must be sought in all of our activities; and as a community, we cannot become comfortable while racial disparities exist.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {storytelling, race, theory, racism, critical race theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376372,
author = {Kontogiorgos, Dimosthenis and van Waveren, Sanne and Wallberg, Olle and Pereira, Andre and Leite, Iolanda and Gustafson, Joakim},
title = {Embodiment Effects in Interactions with Failing Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376372},
doi = {10.1145/3313831.3376372},
abstract = {The increasing use of robots in real-world applications will inevitably cause users to encounter more failures in interactions. While there is a longstanding effort in bringing human-likeness to robots, how robot embodiment affects users' perception of failures remains largely unexplored. In this paper, we extend prior work on robot failures by assessing the impact that embodiment and failure severity have on people's behaviours and their perception of robots. Our findings show that when using a smart-speaker embodiment, failures negatively affect users' intention to frequently interact with the device, however not when using a human-like robot embodiment. Additionally, users significantly rate the human-like robot higher in terms of perceived intelligence and social presence. Our results further suggest that in higher severity situations, human-likeness is distracting and detrimental to the interaction. Drawing on quantitative findings, we discuss benefits and drawbacks of embodiment in robot failures that occur in guided tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {social robots, common ground, smart-speakers, guided tasks, conversational failures, time pressure},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376361,
author = {Sas, Corina and Davies, Nigel and Clinch, Sarah and Shaw, Peter and Mikusz, Mateusz and Steeds, Madeleine and Nohrer, Lukas},
title = {Supporting Stimulation Needs in Dementia Care through Wall-Sized Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376361},
doi = {10.1145/3313831.3376361},
abstract = {Beside reminiscing, the increasing cognitive decline in dementia can also be addressed through sensory stimulation allowing the immediate, nonverbal engagement with the world through one's senses. Much HCI work has prioritized cognitive stimulation for reminiscing or personhood often on small screens, while less research has explored sensory stimulation like the one enabled by large displays. We describe a year-long deployment in a residential care home of a wall-sized display, and explored its domestication through 24 contextual interviews. Findings indicate strong engagement and attachment to the display which has inspired four psychosocial interventions using online generic content. We discuss the value of these findings for personhood through residents' exercise of choices, the tension between generic/personal content and its public/private use, the importance of participatory research approach to domestication, and the infrastructure-based prototype, illustrated by the DementiaWall and its generative quality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {memory technologies, wall-sized displays, reminiscing, psychosocial informal interventions, stimulation, dementia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376350,
author = {Pe\~{n}a-Araya, Vanessa and Bezerianos, Anastasia and Pietriga, Emmanuel},
title = {A Comparison of Geographical Propagation Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376350},
doi = {10.1145/3313831.3376350},
abstract = {Geographical propagation phenomena occur in multiple domains, such as in epidemiology and social media. Propagation dynamics are often complex, and visualizations play a key role in helping subject-matter experts understand and analyze them. However, there is little empirical data about the effectiveness of the various strategies used to visualize geographical propagation. To fill this gap, we conduct an experiment to evaluate the effectiveness of three strategies: an animated map, small-multiple maps, and a single map with glyphs. We compare them under five tasks that vary in one of the following dimensions: propagation scope, direction, speed, peaks, and spatial jumps. Our results show that small-multiple maps perform best overall, but that the effectiveness of each visualization varies depending on the task considered.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {propagation, animation, small-multiples, geo-temporal data},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376348,
author = {Romat, Hugo and Henry Riche, Nathalie and Hurter, Christophe and Drucker, Steven and Amini, Fereshteh and Hinckley, Ken},
title = {Dear Pictograph: Investigating the Role of Personalization and Immersion for Consuming and Enjoying Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376348},
doi = {10.1145/3313831.3376348},
abstract = {Much of the visualization literature focuses on assessment of visual representations with regard to their effectiveness for understanding data. In the present work, we instead focus on making data visualization experiences more enjoyable, to foster deeper engagement with data. We investigate two strategies to make visualization experiences more enjoyable and engaging: personalization, and immersion. We selected pictographs (composed of multiple data glyphs) as this representation affords creative freedom, allowing people to craft symbolic or whimsical shapes of personal significance to represent data. We present the results of a qualitative study with 12 participants crafting pictographs using a large pen-enabled device and while immersed within a VR environment. Our results indicate that personalization and immersion both have positive impact on making visualizations more enjoyable experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization, immersion, personalization, qualitative study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376333,
author = {Zhu, Mengjia and Memar, Amirhossein H. and Gupta, Aakar and Samad, Majed and Agarwal, Priyanshu and Visell, Yon and Keller, Sean J. and Colonnese, Nicholas},
title = {PneuSleeve: In-Fabric Multimodal Actuation and Sensing in a Soft, Compact, and Expressive Haptic Sleeve},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376333},
doi = {10.1145/3313831.3376333},
abstract = {Integration of soft haptic devices into garments can improve their usability and wearability for daily computing interactions. In this paper, we introduce PneuSleeve, a fabric-based, compact, and highly expressive forearm sleeve which can render a broad range of haptic stimuli including compression, skin stretch, and vibration. The haptic stimuli are generated by controlling pneumatic pressure inside embroidered stretchable tubes. The actuation configuration includes two compression actuators on the proximal and distal forearm, and four uniformly distributed linear actuators around and tangent to the forearm. Further, to ensure a suitable grip force, two soft mutual capacitance sensors are fabricated and integrated into the compression actuators, and a closed-loop force controller is implemented. We physically characterize the static and dynamic behavior of the actuators, as well as the performance of closed-loop control. We quantitatively evaluate the psychophysical characteristics of the six actuators in a set of user studies. Finally, we show the expressiveness of PneuSleeve by evaluating combined haptic stimuli using subjective assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {skin stretch, compression, wearables, pneumatic actuation, haptics, vibration, multimodal haptic display, closed-loop haptic rendering},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376320,
author = {Hettiachchi, Danula and Sarsenbayeva, Zhanna and Allison, Fraser and van Berkel, Niels and Dingler, Tilman and Marini, Gabriele and Kostakos, Vassilis and Goncalves, Jorge},
title = {"Hi! I Am the Crowd Tasker" Crowdsourcing through Digital Voice Assistants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376320},
doi = {10.1145/3313831.3376320},
abstract = {Inspired by the increasing prevalence of digital voice assistants, we demonstrate the feasibility of using voice interfaces to deploy and complete crowd tasks. We have developed Crowd Tasker, a novel system that delivers crowd tasks through a digital voice assistant. In a lab study, we validate our proof-of-concept and show that crowd task performance through a voice assistant is comparable to that of a web interface for voice-compatible and voice-based crowd tasks for native English speakers. We also report on a field study where participants used our system in their homes. We find that crowdsourcing through voice can provide greater flexibility to crowd workers by allowing them to work in brief sessions, enabling multi-tasking, and reducing the time and effort required to initiate tasks. We conclude by proposing a set of design guidelines for the creation of crowd tasks for voice and the development of future voice-based crowdsourcing systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {crowdsourcing, smart speakers, digital voice assistants, voice user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376318,
author = {Santhanam, Sashank and Karduni, Alireza and Shaikh, Samira},
title = {Studying the Effects of Cognitive Biases in Evaluation of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376318},
doi = {10.1145/3313831.3376318},
abstract = {Humans quite frequently interact with conversational agents. The rapid advancement in generative language modeling through neural networks has helped advance the creation of intelligent conversational agents. Researchers typically evaluate the output of their models through crowdsourced judgments, but there are no established best practices for conducting such studies. Moreover, it is unclear if cognitive biases in decision-making are affecting crowdsourced workers' judgments when they undertake these tasks. To investigate, we conducted a between-subjects study with 77 crowdsourced workers to understand the role of cognitive biases, specifically anchoring bias, when humans are asked to evaluate the output of conversational agents. Our results provide insight into how best to evaluate conversational agents. We find increased consistency in ratings across two experimental conditions may be a result of anchoring bias. We also determine that external factors such as time and prior experience in similar tasks have effects on inter-rater consistency.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conversational agents, experiment design, human evaluation, anchoring bias},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376312,
author = {Sauv\'{e}, Kim and Potts, Dominic and Alexander, Jason and Houben, Steven},
title = {A Change of Perspective: How User Orientation Influences the Perception of Physicalizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376312},
doi = {10.1145/3313831.3376312},
abstract = {As physicalizations encode data in their physical 3D form, the orientation in which the user is viewing the physicalization may impact the way the information is perceived. However, this relation between user orientation and perception of physical properties is not well understood or studied. To investigate this relation, we conducted an experimental study with 20 participants who viewed 6 exemplars of physicalizations from 4 different perspectives. Our findings show that perception is directly influenced by user orientation as it affects (i) the number and type of clusters, (ii) anomalies and (iii) extreme values identified within a physicalization. Our results highlight the complexity and variability of the relation between user orientation and perception of physicalizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data physicalization, user orientation, physical visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376308,
author = {Morreale, Fabio and Eriksson, Maria},
title = {"My Library Has Just Been Obliterated": Producing New Norms of Use Via Software Update},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376308},
doi = {10.1145/3313831.3376308},
abstract = {Software updates are commonly perceived as tools for fixing flaws and improving functionality. In this paper, we problematise this view by showing how software updates may also be used by vendors to create new norms of use that control user behaviour and reduce their agency. We explore the nature and aftermath of a controversial software update that was released by Spotify in June 2019. By analysing almost 3,500 reactions to this update, we show how it removed and modified several features in ways that severely affected users' capability to organise, navigate, and maintain their music libraries, while it pushed modes of listening that delegate song selection to Spotify. Elaborating upon our results, we discuss how updates may be used as political tools that privilege certain forms of behaviour while restricting others. We also portray updates as sites where ongoing struggles and negotiations regarding user agency and digital ownership take place.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {protocological power, spotify, normative affordances, music streaming, psychological ownership, critical computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376305,
author = {Aigner, Roland and Pointner, Andreas and Preindl, Thomas and Parzer, Patrick and Haller, Michael},
title = {Embroidered Resistive Pressure Sensors: A Novel Approach for Textile Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376305},
doi = {10.1145/3313831.3376305},
abstract = {We present a novel method for augmenting arbitrary fabrics with textile-based pressure sensors using an off-the-shelf embroidery machine. We apply resistive textiles and conductive yarns on top of a base fabric, to yield a flexible and versatile continuous sensing device, which is based on the widespread principle of force sensitive resistors. The patches can easily be attached to measurement and/or computing devices, e.g. for controlling accessories. In this paper, we investigate the impacts of related design and fabrication parameters, introduce five different pattern designs, and discuss their pros and cons. We present crucial insights and recommendations for design and manufacturing of embroidered pressure sensors. Our sensors show a very low activation threshold, as well as good dynamic range, signal-to-noise ratio, and part-to-part repeatability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart textiles, embroidered force sensitive resistance, space-filling patterns, embroidery, textile sensor},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376264,
author = {Seymour, William and Kraemer, Martin J. and Binns, Reuben and Van Kleek, Max},
title = {Informing the Design of Privacy-Empowering Tools for the Connected Home},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376264},
abstract = {Connected devices in the home represent a potentially grave new privacy threat due to their unfettered access to the most personal spaces in people's lives. Prior work has shown that despite concerns about such devices, people often lack sufficient awareness, understanding, or means of taking effective action. To explore the potential for new tools that support such needs directly we developed Aretha, a privacy assistant technology probe that combines a network disaggregator, personal tutor, and firewall, to empower end-users with both the knowledge and mechanisms to control disclosures from their homes. We deployed Aretha in three households over six weeks, with the aim of understanding how this combination of capabilities might enable users to gain awareness of data disclosures by their devices, form educated privacy preferences, and to block unwanted data flows. The probe, with its novel affordances-and its limitations-prompted users to co-adapt, finding new control mechanisms and suggesting new approaches to address the challenge of regaining privacy in the connected home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3313831.3376261,
author = {Liebling, Daniel J. and Lahav, Michal and Evans, Abigail and Donsbach, Aaron and Holbrook, Jess and Smus, Boris and Boran, Lindsey},
title = {Unmet Needs and Opportunities for Mobile Translation AI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376261},
doi = {10.1145/3313831.3376261},
abstract = {Translation apps and devices are often presented in the context of providing assistance while traveling abroad. However, the spectrum of needs for cross-language communication is much wider. To investigate these needs, we conducted three studies with populations spanning socioeconomic status and geographic regions: (1) United States-based travelers, (2) migrant workers in India, and (3) immigrant populations in the United States. We compare frequent travelers' perception and actual translation needs with those of the two migrant communities. The latter two, with low language proficiency, have the greatest translation needs to navigate their daily lives. However, current mobile translation apps do not meet these needs. Our findings provide new insights on the usage practices and limitations of mobile translation tools. Finally, we propose design implications to help apps better serve these unmet needs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {migrants, speech, machine translation, immigrants, mobile, emerging markets},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376255,
author = {Tabassum, Madiha and Kropczynski, Jess and Wisniewski, Pamela and Lipford, Heather Richter},
title = {Smart Home Beyond the Home: A Case for Community-Based Access Control},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376255},
doi = {10.1145/3313831.3376255},
abstract = {As smart devices are becoming commonplace in homes, we need to explore the needs of not just the residents of the home, but also of secondary stakeholders who may be granted access to these devices from outside of the home. We conducted a mixed methods study, which included a survey of 163 smart home device owners and a follow-up interview with 13 individuals who currently share their smart home devices with others outside of their home. Nearly half (47.8%) of our survey participants shared at least one smart home device with someone that did not live with them. Individuals sought greater safety and security by providing remote access to trusted family members or friends. By understanding users' perspectives about privacy and trust in relation to sharing smart home devices beyond the home, we build a case for community-based access control of smart home devices in the Internet of Things.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {smart home, access control, community},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376234,
author = {Park, Keunwoo and Kim, Daehwa and Heo, Seongkook and Lee, Geehyuk},
title = {MagTouch: Robust Finger Identification for a Smartwatch Using a Magnet Ring and a Built-in Magnetometer},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376234},
doi = {10.1145/3313831.3376234},
abstract = {Completing tasks on smartwatches often requires multiple gestures due to the small size of the touchscreens and the lack of sufficient number of touch controls that are easily accessible with a finger. We propose to increase the number of functions that can be triggered with the touch gesture by enabling a smartwatch to identify which finger is being used. We developed MagTouch, a method that uses a magnetometer embedded in an off-the-shelf smartwatch. It measures the magnetic field of a magnet fixed to a ring worn on the middle finger. By combining the measured magnetic field and the touch location on the screen, MagTouch recognizes which finger is being used. The tests demonstrated that MagTouch can differentiate among the three fingers used to make contacts at a success rate of 95.03%.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smartwatch, magnetic, touch, finger identification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376218,
author = {Wang, Wenting and Arya, Deeksha and Novielli, Nicole and Cheng, Jinghui and Guo, Jin L.C.},
title = {ArguLens: Anatomy of Community Opinions On Usability Issues Using Argumentation Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376218},
doi = {10.1145/3313831.3376218},
abstract = {In open-source software (OSS), the design of usability is often influenced by the discussions among community members on platforms such as issue tracking systems (ITSs). However, digesting the rich information embedded in issue discussions can be a major challenge due to the vast number and diversity of the comments. We propose and evaluate ArguLens, a conceptual framework and automated technique leveraging an argumentation model to support effective understanding and consolidation of community opinions in ITSs. Through content analysis, we anatomized highly discussed usability issues from a large, active OSS project, into their argumentation components and standpoints. We then experimented with supervised machine learning techniques for automated argument extraction. Finally, through a study with experienced ITS users, we show that the information provided by ArguLens supported the digestion of usability-related opinions and facilitated the review of lengthy issues. ArguLens provides the direction of designing valuable tools for high-level reasoning and effective discussion about usability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {open source software, online communities, issue discussion analysis, argumentation analysis, usability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376195,
author = {G\"{u}nther, Sebastian and M\"{u}ller, Florian and Sch\"{o}n, Dominik and Elmoghazy, Omar and M\"{u}hlh\"{a}user, Max and Schmitz, Martin},
title = {Therminator: Understanding the Interdependency of Visual and On-Body Thermal Feedback in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376195},
doi = {10.1145/3313831.3376195},
abstract = {Recent advances have made Virtual Reality (VR) more realistic than ever before. This improved realism is attributed to today's ability to increasingly appeal to human sensations, such as visual, auditory or tactile. While research also examines temperature sensation as an important aspect, the interdependency of visual and thermal perception in VR is still underexplored. In this paper, we propose Therminator, a thermal display concept that provides warm and cold on-body feedback in VR through heat conduction of flowing liquids with different temperatures. Further, we systematically evaluate the interdependency of different visual and thermal stimuli on the temperature perception of arm and abdomen with 25 participants. As part of the results, we found varying temperature perception depending on the stimuli, as well as increasing involvement of users during conditions with matching stimuli.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {thermal feedback, temperature, virtual reality, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376186,
author = {Trajkova, Milka and Alhakamy, A'aeshah and Cafaro, Francesco and Mallappa, Rashmi and Kankara, Sreekanth R.},
title = {Move Your Body: Engaging Museum Visitors with Human-Data Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376186},
doi = {10.1145/3313831.3376186},
abstract = {Museums have embraced embodied interaction: its novelty generates buzz and excitement among their patrons, and it has enormous educational potential. Human-Data Interaction (HDI) is a class of embodied interactions that enables people to explore large sets of data using interactive visualizations that users control with gestures and body movements. In museums, however, HDI installations have no utility if visitors do not engage with them. In this paper, we present a quasi-experimental study that investigates how different ways of representing the user ("mode type") next-to a data visualization alters the way in which people engage with a HDI system. We consider four mode types: avatar, skeleton, camera overlay, and control. Our findings indicate that the mode type impacts the number of visitors that interact with the installation, the gestures that people do, and the amount of time that visitors spend observing the data on display and interacting with the system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {informal learning, public displays, human-data interaction, museums, embodied interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376176,
author = {Dmitrenko, Dmitrijs and Maggioni, Emanuela and Brianza, Giada and Holthausen, Brittany E. and Walker, Bruce N. and Obrist, Marianna},
title = {CARoma Therapy: Pleasant Scents Promote Safer Driving, Better Mood, and Improved Well-Being in Angry Drivers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376176},
doi = {10.1145/3313831.3376176},
abstract = {Driving is a task that is often affected by emotions. The effect of emotions on driving has been extensively studied. Anger is an emotion that dominates in such investigations. Despite the knowledge on strong links between scents and emotions, few studies have explored the effect of olfactory stimulation in a context of driving. Such an outcome provides HCI practitioners very little knowledge on how to design for emotions using olfactory stimulation in the car. We carried out three studies to select scents of different valence and arousal levels (i.e. rose, peppermint, and civet) and anger eliciting stimuli (i.e. affective pictures and on-road events). We used this knowledge to conduct the fourth user study investigating how the selected scents change the emotional state, well-being, and driving behaviour of drivers in an induced angry state. Our findings enable better decisions on what scents to choose when designing interactions for angry drivers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {notification systems, smell, multimodal interfaces, perception, in-car user interfaces, odour stimulation, emotions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376175,
author = {Lee, Yi-Chieh and Yamashita, Naomi and Huang, Yun and Fu, Wai},
title = {"I Hear You, I Feel You": Encouraging Deep Self-Disclosure through a Chatbot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376175},
doi = {10.1145/3313831.3376175},
abstract = {Chatbots have great potential to serve as a low-cost, effective tool to support people's self-disclosure. Prior work has shown that reciprocity occurs in human-machine dialog; however, whether reciprocity can be leveraged to promote and sustain deep self-disclosure over time has not been systematically studied. In this work, we design, implement and evaluate a chatbot that has self-disclosure features when it performs small talk with people. We ran a study with 47 participants and divided them into three groups to use different chatting styles of the chatbot for three weeks. We found that chatbot self-disclosure had a reciprocal effect on promoting deeper participant self-disclosure that lasted over the study period, in which the other chat styles without self-disclosure features failed to deliver. Chatbot self-disclosure also had a positive effect on improving participants' perceived intimacy and enjoyment over the study period. Finally, we reflect on the design implications of chatbots where deep self-disclosure is needed over time.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {chatbot, conversation, self-disclosure, mental well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376174,
author = {Mitchell Finnigan, Samantha and Clear, Adrian K.},
title = {"No Powers, Man!": A Student Perspective on Designing University Smart Building Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376174},
doi = {10.1145/3313831.3376174},
abstract = {Smart buildings offer an opportunity for better performance and enhanced experience by contextualising services and interactions to the needs and practices of occupants. Yet, this vision is limited by established approaches to building management, delivered top-down through professional facilities management teams, opening up an interaction-gap between occupants and the spaces they inhabit. To address the challenge of how smart buildings might be more inclusively managed, we present the results of a qualitative study with student occupants of a smart building, with design workshops including building walks and speculative futuring. We develop new understandings of how student occupants conceptualise and evaluate spaces as they experience them, and of how building management practices might evolve with new sociotechnical systems that better leverage occupant agency. Our findings point to important directions for HCI research in this nascent area, including the need for HBI (Human-Building Interaction) design to challenge entrenched roles in building management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {speculative design, human-building interaction, hbi, sustainable hci, walking, sustainability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376169,
author = {Iivari, Netta and Kinnula, Marianne and Kuure, Leena and Keisanen, Tiina},
title = {"Arseing around Was Fun!"  Humor as a Resource in Design and Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376169},
doi = {10.1145/3313831.3376169},
abstract = {Humor is an inevitable part of human life. Most of us are capable of experiencing and appreciating humor. From this perspective, surprisingly little HCI research can be found scrutinizing the existence, role, and potential of humor in our design practice. The gap remains also related to children and teenagers; there is a lack of studies appreciating the emergence and existence of humor in the design process without intentionally evoking it. Thus, this study examines humor as a naturally occurring phenomenon in the design process. The study was conducted in collaboration with a class of teenagers and their teachers. The study identifies various forms and functions of humor in the design process and reveals its situated, emergent nature as a resource in interaction within design. The study proposes a practical tool for designers for anticipating and potentially facilitating the emergence, forms and usages of humor as an interactional resource in design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {making in education, teenager, children, nexus analysis, humor, design, interaction, discourse},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376157,
author = {Komatsu, Takanori and Yamada, Seiji},
title = {Exploring Auditory Information to Change Users' Perception of Time Passing as Shorter},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376157},
doi = {10.1145/3313831.3376157},
abstract = {Although the processing speed of computers has been drastically increasing year by year, users still have to wait for computers to complete tasks or to respond. To cope with this, several studies have proposed presenting certain visual information to users to change their perception of time passing as shorter, e.g., progress bars with animated ribbing or faster/slower virtual clocks. As speech interfaces such as smart speakers are becoming popular, a novel method is required to make users perceive the passing of time as shorter by presenting auditory stimuli. We thus prepared 20 pieces of auditory information as experimental stimuli; that is, 11 auditory stimuli that have the same 10.1-second duration but different numbers of 0.1-second sine-wave sounds and 9 other auditory stimuli that have the same 10.1-second duration and numbers of sounds but different interval patterns between the sounds. We conducted three experiments to figure out which kinds of auditory stimuli can change users' perception of time passing as shorter. We found that a 10.1-second auditory stimulus that has 0.1-second sine-wave sounds appearing 11 times with intervals between the sounds that narrow rapidly in a linear fashion was perceived as shortest at about 9.3 seconds, which was 7.6% shorter than the actual duration of the stimulus. We also found that different interval patterns of sounds in auditory information significantly affected users' perception of time passing as shorter, while different numbers of sounds did not.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {waiting time, filled-duration illusion, users' perception of time passing, auditory information, eyes-free interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376153,
author = {Clegg, Tamara and Greene, Daniel M. and Beard, Nate and Brunson, Jasmine},
title = {Data Everyday: Data Literacy Practices in a Division I College Sports Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376153},
doi = {10.1145/3313831.3376153},
abstract = {Data analysis is central to sports training. Today, cutting-edge digital technologies are deployed to measure and improve athletes' performance. But too often researchers focus on the technology collecting performance data at the expense of understanding athletes' experiences with data. This is particularly the case in the understudied context of collegiate athletics, where competition is fierce, tools for data analysis abound, and the institution actively manages athletes' lives. By investigating how student-athletes analyze their performance data and are analyzed in turn, we can better understand the individual and institutional factors that make data literacy practices in athletics meaningful and productive-or not. Our pilot interview study of student-athletes at one Division I university reveals a set of opportunities for student-athletes to engage with and learn from data analytics practices. These opportunities come with a set of contextual tensions that should inform the design of new technologies for collegiate sports settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci and sports, personal informatics, data literacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376146,
author = {Villanueva, Ana and Zhu, Zhengzhe and Liu, Ziyi and Peppler, Kylie and Redick, Thomas and Ramani, Karthik},
title = {Meta-AR-App: An Authoring Platform for Collaborative Augmented Reality in STEM Classrooms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376146},
doi = {10.1145/3313831.3376146},
abstract = {Augmented Reality (AR) has become a valuable tool for education and training processes. Meanwhile, cloud-based technologies can foster collaboration and other interaction modalities to enhance learning. We combine the cloud capabilities with AR technologies to present Meta-AR-App, an authoring platform for collaborative AR, which enables authoring between instructors and students. Additionally, we introduce a new application of an established collaboration process, the pull-based development model, to enable sharing and retrieving of AR learning content. We customize this model and create two modalities of interaction for the classroom: local (student to student) and global (instructor to class) pull. Based on observations from our user studies, we organize a four-category classroom model which implements our system: Work, Design, Collaboration, and Technology. Further, our system enables an iterative improvement workflow of the class content and enables synergistic collaboration that empowers students to be active agents in the learning process.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {version control, stem, git, authoring, classroom, pull-based model, electrical circuitry, collaboration, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376888,
author = {Wu, Qin and Yu, Chenmei and Chen, Yanjun and Yao, Jiayu and Wu, Xi and Peng, Xiaolan and Han, Teng},
title = {Squeeze the Ball: Designing an Interactive Playground towards Aiding Social Activities of Children with Low-Function Autism},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376888},
doi = {10.1145/3313831.3376888},
abstract = {Most intervention methods used for social skills training in children with autism are dedicated to high-functioning autism (HFA). However, extensive neurological and developmental disorders of low-functioning autism (LFA) have hampered their adoption. In this study, we observed and interviewed children with LFA, and their teachers, from a local educational institution, to better understand the children's social needs and barriers. Then, with the aim of aiding the children with their social activities, we illustrate the design process of SqueeBall, an interactive playground equipment. We evaluated the design with 18 children (16 with LFA and 2 with HFA) between 2.5 and 7 years of age. Results showed that these children had a pleasant game experience when the group bonded, and the equipment had a positive effect on aiding them in various ways. Finally, we discuss the challenges and opportunities of multimedia interaction techniques in aiding children with LFA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {social communication intervention, autism, disability, tangible interaction, low-function autism},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376884,
author = {Hou, Ming and Mahadevan, Karthik and Somanath, Sowmya and Sharlin, Ehud and Oehlberg, Lora},
title = {Autonomous Vehicle-Cyclist Interaction: Peril and Promise},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376884},
doi = {10.1145/3313831.3376884},
abstract = {Autonomous vehicles (AVs) will redefine interactions between road users. Presently, cyclists and drivers communicate through implicit cues (vehicle motion) and explicit but imprecise signals (hand gestures, horns). Future AVs could consistently communicate awareness and intent and other feedback to cyclists based on their sensor data. We present an exploration of AV-cyclist interaction, starting with preliminary design studies which informed the implementation of an immersive VR AV-cyclist simulator, and the design and evaluation of a number of AV-cyclist interfaces. Our findings suggest that AV-cyclist interfaces can improve rider confidence in lane merging scenarios. We contribute an AV-cyclist immersive simulator, insights on trade-offs of various aspects of AV-cyclist interaction design including modalities, location, and complexity, and positive results suggesting improved rider confidence due to AV-cyclist interaction. While we are encouraged by the potential positive impact AV-cyclist interfaces can have on cyclist culture, we also emphasize the risks over-reliance can pose to cyclists.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {autonomous vehicle cyclist interaction, interfaces for communicating intent and awareness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376882,
author = {Yeckehzaare, Iman and Barghi, Tirdad and Resnick, Paul},
title = {QMaps: Engaging Students in Voluntary Question Generation and Linking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376882},
doi = {10.1145/3313831.3376882},
abstract = {Generating multiple-choice questions is known to improve students' critical thinking and deep learning. Visualizing relationships between concepts enhances meaningful learning, students' ability to relate new concepts to previously learned concepts. We designed and deployed a collaborative learning process through which students generate multiple-choice questions and represent the prerequisite knowledge structure between questions as visual links in a shared map, using a variation of Concept Maps that we call "QMap." We conducted a four-month study with 19 undergraduate students. Students sustained voluntary contributions, creating 992 good questions, and drawing 1,255 meaningful links between the questions. Through analyzing self-reports, observations, and usage data, we report on the technical and social design features that led students to sustain their motivation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {cscl, learnersourcing, question generation, intrinsic motivation, collaborative learning, concept mapping, learner-centered design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376862,
author = {Zhang, Yixuan and Suhaimi, Nurul and Azghandi, Rana and Joseph, Mary Amulya and Kim, Miso and Griffin, Jacqueline and Parker, Andrea G.},
title = {Understanding the Use of Crisis Informatics Technology among Older Adults},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376862},
doi = {10.1145/3313831.3376862},
abstract = {Mass emergencies increasingly pose significant threats to human life, with a disproportionate burden being incurred by older adults. Research has explored how mobile technology can mitigate the effects of mass emergencies. However, less work has examined how mobile technologies support older adults during emergencies, considering their unique needs. To address this research gap, we interviewed 16 older adults who had recent experience with an emergency evacuation to understand the perceived value of using mobile technology during emergencies. We found that there was a lack of awareness and engagement with existing crisis apps. Our findings characterize the ways in which our participants did and did not feel crisis informatics tools address human values, including basic needs and esteem needs. We contribute an understanding of how older adults used mobile technology during emergencies and their perspectives on how well such tools address human values.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {crisis informatics, emergencies, older adults, human values},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376854,
author = {Sundar, S. Shyam and Kim, Jinyoung and Rosson, Mary Beth and Molina, Maria D.},
title = {Online Privacy Heuristics That Predict Information Disclosure},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376854},
doi = {10.1145/3313831.3376854},
abstract = {Online users' attitudes toward privacy are context-dependent. Studies show that contextual cues are quite influential in motivating users to disclose personal information. Increasingly, these cues are embedded in the interface, but the mechanisms of their effects (e.g., unprofessional design contributing to more disclosure) are not fully understood. We posit that each cue triggers a specific "cognitive heuristic" that provides a rationale for decision-making. Using a national survey (N = 786) that elicited participants' disclosure intentions in common online scenarios, we identify 12 distinct heuristics relevant to privacy, and demonstrate that they are systematically associated with information disclosure. Data show that those with a higher accessibility to a given heuristic are more likely to disclose information. Design implications for protection of online privacy and security are discussed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online decision-making, information disclosure, information privacy, cognitive heuristics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376842,
author = {Goffin, Pascal and Blascheck, Tanja and Isenberg, Petra and Willett, Wesley},
title = {Interaction Techniques for Visual Exploration Using Embedded Word-Scale Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376842},
doi = {10.1145/3313831.3376842},
abstract = {We describe a design space of view manipulation interactions for small data-driven contextual visualizations (word-scale visualizations). These interaction techniques support an active reading experience and engage readers through exploration of embedded visualizations whose placement and content connect them to specific terms in a document. A reader could, for example, use our proposed interaction techniques to explore word-scale visualizations of stock market trends for companies listed in a market overview article. When readers wish to engage more deeply with the data, they can collect, arrange, compare, and navigate the document using the embedded word-scale visualizations, permitting more visualization-centric analyses. We support our design space with a concrete implementation, illustrate it with examples from three application domains, and report results from two experiments. The experiments show how view manipulation interactions helped readers examine embedded visualizations more quickly and with less scrolling and yielded qualitative feedback on usability and future opportunities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {word-scale visualization, interaction techniques, glyphs, text visualization, information visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376837,
author = {Cibrian, Franceli L. and Lakes, Kimberley D. and Tavakoulnia, Arya and Guzman, Kayla and Schuck, Sabrina and Hayes, Gillian R.},
title = {Supporting Self-Regulation of Children with ADHD Using Wearables: Tensions and Design Challenges},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376837},
doi = {10.1145/3313831.3376837},
abstract = {The design of wearable applications supporting children with Attention Deficit Hyperactivity Disorders (ADHD) requires a deep understanding not only of what is possible from a clinical standpoint but also how the children might understand and orient towards wearable technologies, such as a smartwatch. Through a series of participatory design workshops with children with ADHD and their caregivers, we identified tensions and challenges in designing wearable applications supporting the self-regulation of children with ADHD. In this paper, we describe the specific challenges of smartwatches for this population, the balance between self-regulation and co-regulation, and tensions when receiving notifications on a smartwatch in various contexts. These results indicate key considerations-from both the child and caregiver viewpoints-for designing technological interventions supporting children with ADHD.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wearable, adhd, smartwatch, design tensions, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376829,
author = {Syeda, Uzma Haque and Murali, Prasanth and Roe, Lisa and Berkey, Becca and Borkin, Michelle A.},
title = {Design Study "Lite" Methodology: Expediting Design Studies and Enabling the Synergy of Visualization Pedagogy and Social Good},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376829},
doi = {10.1145/3313831.3376829},
abstract = {Design studies are frequently used to conduct problem-driven visualization research by working with real-world domain experts. In visualization pedagogy, design studies are often introduced but rarely practiced due to their large time requirements. This limits students to a classroom curriculum, often involving projects that may not have implications beyond the classroom. Thus we present the Design Study "Lite" Methodology, a novel framework for implementing design studies with novice students in 14 weeks. We utilized the Design Study "Lite" Methodology in conjunction with Service-Learning to teach five Data Visualization courses and demonstrate that it benefits not only the students but also the community through service to non-profit partners. In this paper, we provide a detailed breakdown of the methodology and how Service-Learning can be incorporated with it. We also include an extensive reflection on the methodology and provide recommendations for future applications of the framework for teaching visualization courses and research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {service-learning, design studies, visualization, theory and methods, pedagogy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376818,
author = {Pine, Kathleen H. and Chen, Yunan},
title = {Right Information, Right Time, Right Place: Physical Alignment and Misalignment in Healthcare Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376818},
doi = {10.1145/3313831.3376818},
abstract = {Implementation of new health information systems such as Electronic Health Records (EHR) is expected to reap many benefits. However, the transition from one information system to another is often associated with inefficiency, ineffectiveness, and patient safety hazards. These negative consequences are difficult to predict and avoid before system transitions take place. The changed physical form of information remains an unexamined facet of healthcare system transitions. Using ethnographic methods in two clinical sites, we discovered a recurrent set of problems that emerged due to physical disconnections between information and practice predicated on implementation of new information systems. "Physical misalignments" are instances where workers cannot bring information sources to hand in the precise time and place in which they are needed. We identify three types of physical misalignments, then discuss how physical misalignments can be proactively identified and corrected before, during, and after implementation of new health information systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {electronic health records, ethnography, implementation, health information systems, unintended consequences},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376815,
author = {Putze, Felix and Ihrig, Tilman and Schultz, Tanja and Stuerzlinger, Wolfgang},
title = {Platform for Studying Self-Repairing Auto-Corrections in Mobile Text Entry Based on Brain Activity, Gaze, and Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376815},
doi = {10.1145/3313831.3376815},
abstract = {Auto-correction is a standard feature of mobile text entry. While the performance of state-of-the-art auto-correct methods is usually relatively high, any errors that occur are cumbersome to repair, interrupt the flow of text entry, and challenge the user's agency over the process. In this paper, we describe a system that aims to automatically identify and repair auto-correction errors. This system comprises a multi-modal classifier for detecting auto-correction errors from brain activity, eye gaze, and context information, as well as a strategy to repair such errors by replacing the erroneous correction or suggesting alternatives. We integrated both parts in a generic Android component and thus present a research platform for studying self-repairing end-to-end systems. To demonstrate its feasibility, we performed a user study to evaluate the classification performance and usability of our approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {EEG, text entry, self-repair, eye gaze, auto-correction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376813,
author = {Wang, Ruotong and Harper, F. Maxwell and Zhu, Haiyi},
title = {Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376813},
doi = {10.1145/3313831.3376813},
abstract = {Algorithmic decision-making systems are increasingly used throughout the public and private sectors to make important decisions or assist humans in making these decisions with real social consequences. While there has been substantial research in recent years to build fair decision-making algorithms, there has been less research seeking to understand the factors that affect people's perceptions of fairness in these systems, which we argue is also important for their broader acceptance. In this research, we conduct an online experiment to better understand perceptions of fairness, focusing on three sets of factors: algorithm outcomes, algorithm development and deployment procedures, and individual differences. We find that people rate the algorithm as more fair when the algorithm predicts in their favor, even surpassing the negative effects of describing algorithms that are very biased against particular demographic groups. We find that this effect is moderated by several variables, including participants' education level, gender, and several aspects of the development procedure. Our findings suggest that systems that evaluate algorithmic fairness through users' feedback must consider the possibility of "outcome favorability" bias.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {perceived fairness, algorithm development, algorithmic decision-making, algorithmoutcome},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376806,
author = {Brooks, Jas and Nagels, Steven and Lopes, Pedro},
title = {Trigeminal-Based Temperature Illusions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376806},
doi = {10.1145/3313831.3376806},
abstract = {We explore a temperature illusion that uses low-powered electronics and enables the miniaturization of simple warm and cool sensations. Our illusion relies on the properties of certain scents, such as the coolness of mint or hotness of peppers. These odors trigger not only the olfactory bulb, but also the nose's trigeminal nerve, which has receptors that respond to both temperature and chemicals. To exploit this, we engineered a wearable device based on micropumps and an atomizer that emits up to three custom-made "thermal" scents directly to the user's nose. Breathing in these scents causes the user to feel warmer or cooler. We demonstrate how our device renders warmth and cooling sensations in virtual experiences. In our first study, we evaluated six candidate "thermal" scents. We found two hot-cold pairs, with one pair being less identifiable by odor. In our second study, pParticipants rated VR experiences with our device trigeminal stimulants as significantly warmer or cooler than the baseline conditions. Lastly, we believe this offers an alternative to existing thermal feedback devices, which unfortunately rely on power-hungry heat-lamps or Peltier-elements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {trigeminal, smell, thermal, haptics, vr, illusion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376803,
author = {Lange, Daniel and Stratmann, Tim Claudius and Gruenefeld, Uwe and Boll, Susanne},
title = {HiveFive: Immersion Preserving Attention Guidance in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376803},
doi = {10.1145/3313831.3376803},
abstract = {Recent advances in Virtual Reality (VR) technology, such as larger fields of view, have made VR increasingly immersive. However, a larger field of view often results in a user focusing on certain directions and missing relevant content presented elsewhere on the screen. With HiveFive, we propose a technique that uses swarm motion to guide user attention in VR. The goal is to seamlessly integrate directional cues into the scene without losing immersiveness. We evaluate HiveFive in two studies. First, we compare biological motion (from a prerecorded swarm) with non-biological motion (from an algorithm), finding further evidence that humans can distinguish between these motion types and that, contrary to our hypothesis, non-biological swarm motion results in significantly faster response times. Second, we compare HiveFive to four other techniques and show that it not only results in fast response times but also has the smallest negative effect on immersion.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, user studies, particle swarms, immersion, attention guidance, eye-tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376797,
author = {Hastings, Emily M. and Alamri, Albatool and Kuznetsov, Andrew and Pisarczyk, Christine and Karahalios, Karrie and Marinov, Darko and Bailey, Brian P.},
title = {LIFT: Integrating Stakeholder Voices into Algorithmic Team Formation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376797},
doi = {10.1145/3313831.3376797},
abstract = {Team formation tools assume instructors should configure the criteria for creating teams, precluding students from participating in a process affecting their learning experience. We propose LIFT, a novel learner-centered workflow where students propose, vote for, and weigh the criteria used as inputs to the team formation algorithm. We conducted an experiment (N=289) comparing LIFT to the usual instructor-led process, and interviewed participants to evaluate their perceptions of LIFT and its outcomes. Learners proposed novel criteria not included in existing algorithmic tools, such as organizational style. They avoided criteria like gender and GPA that instructors frequently select, and preferred those promoting efficient collaboration. LIFT led to team outcomes comparable to those achieved by the instructor-led approach, and teams valued having control of the team formation process. We provide instructors and designers with a workflow and evidence supporting giving learners control of the algorithmic process used for grouping them into teams.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {team composition, crowdsourcing, algorithms, team formation, learnersourcing, learning, catme},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376787,
author = {Yeo, Dohyeon and Kim, Gwangbin and Kim, Seungjun},
title = {Toward Immersive Self-Driving Simulations: Reports from a User Study across Six Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376787},
doi = {10.1145/3313831.3376787},
abstract = {As self-driving car technology matures, autonomous vehicle research is moving toward building more human-centric interfaces and accountable experiences. Driving simulators avoid many ethical and regulatory concerns about self-driving cars and play a key role in testing new interfaces or autonomous driving scenarios. However, apart from validity studies for manual driving simulation, the capabilities of driving simulators in replicating the experience of self-driving cars have not been widely investigated. In this paper, we build six self-driving simulation platforms with varying levels of visual and motion fidelities ranging from a screen-based in-lab simulator to the mixed-reality on-road simulator we propose. We compare the sense of presence and simulator sickness for each simulator composition, as well as its visual and motion fidelities with a user study. Our novel mixed-reality automotive driving simulator, named MAXIM, showed highest fidelity and presence. Our findings suggest how visual and motion configurations affect experience in autonomous driving simulators.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {on-road simulation, driving simulator, immersive technology, mixed reality, autonomous driving, user studies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376786,
author = {La Delfa, Joseph and Baytas, Mehmet Aydin and Patibanda, Rakesh and Ngari, Hazel and Khot, Rohit Ashok and Mueller, Florian 'Floyd'},
title = {Drone Chi: Somaesthetic Human-Drone Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376786},
doi = {10.1145/3313831.3376786},
abstract = {Somaesthetics - motivated by improving life quality via appreciation for bodily and sensory experiences - is increasingly influencing HCI designs. Investigating the potential of drones as a material for somaesthetic HCI, we designed Drone Chi: a Tai Chi-inspired close-range human-drone interaction experience. The design process for Drone Chi has been informed by the soma design approach and the Somaesthetic Appreciation concept from HCI literature. The artifact expands somaesthetic HCI by exemplifying dynamic and intimate somaesthetic interactions with a robotic design material, and body movements in expansive 3D space. To characterize the Drone Chi experience, we conducted an empirical study with 32 participants. Analysis of participant accounts revealed 4 themes that articulate different aspects of the experience: Looping Mental States, Environment, Agency vs. Control, and Physical Narratives. From these accounts and our craft knowledge, we derive 5 design implications to guide the development of movement-based close-range drone interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {movement, somaesthetics, human-drone interaction, somaesthetic appreciation, drones, soma design, tai chi},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376782,
author = {Srinivasan, Arjun and Lee, Bongshin and Henry Riche, Nathalie and Drucker, Steven M. and Hinckley, Ken},
title = {InChorus: Designing Consistent Multimodal Interactions for Data Visualization on Tablet Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376782},
doi = {10.1145/3313831.3376782},
abstract = {While tablet devices are a promising platform for data visualization, supporting consistent interactions across different types of visualizations on tablets remains an open challenge. In this paper, we present multimodal interactions that function consistently across different visualizations, supporting common operations during visual data analysis. By considering standard interface elements (e.g., axes, marks) and grounding our design in a set of core concepts including operations, parameters, targets, and instruments, we systematically develop interactions applicable to different visualization types. To exemplify how the proposed interactions collectively facilitate data exploration, we employ them in a tablet-based system, InChorus that supports pen, touch, and speech input. Based on a study with 12 participants performing replication and factchecking tasks with InChorus, we discuss how participants adapted to using multimodal input and highlight considerations for future multimodal visualization systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {touch, speech, data visualization, multimodal interaction, tablet devices, pen},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376781,
author = {Winkler, Rainer and Hobert, Sebastian and Salovaara, Antti and S\"{o}llner, Matthias and Leimeister, Jan Marco},
title = {Sara, the Lecturer: Improving Learning in Online Education with a Scaffolding-Based Conversational Agent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376781},
doi = {10.1145/3313831.3376781},
abstract = {Enrollment in online courses has sharply increased in higher education. Although online education can be scaled to large audiences, the lack of interaction between educators and learners is difficult to replace and remains a primary challenge in the field. Conversational agents may alleviate this problem by engaging in natural interaction and by scaffolding learners' understanding similarly to educators. However, whether this approach can also be used to enrich online video lectures has largely remained unknown. We developed Sara, a conversational agent that appears during an online video lecture. She provides scaffolds by voice and text when needed and includes a voice-based input mode. An evaluation with 182 learners in a 2 x 2 lab experiment demonstrated that Sara, compared to more traditional conversational agents, significantly improved learning in a programming task. This study highlights the importance of including scaffolding and voice-based conversational agents in online videos to improve meaningful learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {online videos, experiment, interactivity, conversational agent, scaffolding, voice interaction, online education},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376780,
author = {P\"{a}\"{a}kk\"{o}nen, Juho and Nelimarkka, Matti and Haapoja, Jesse and Lampinen, Airi},
title = {Bureaucracy as a Lens for Analyzing and Designing Algorithmic Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376780},
doi = {10.1145/3313831.3376780},
abstract = {Scholarship on algorithms has drawn on the analogy between algorithmic systems and bureaucracies to diagnose shortcomings in algorithmic decision-making. We extend the analogy further by drawing on Michel Crozier's theory of bureaucratic organizations to analyze the relationship between algorithmic and human decision-making power. We present algorithms as analogous to impartial bureaucratic rules for controlling action, and argue that discretionary decision-making power in algorithmic systems accumulates at locations where uncertainty about the operation of algorithms persists. This key point of our essay connects with Alkhatib and Bernstein's theory of 'street-level algorithms', and highlights that the role of human discretion in algorithmic systems is to accommodate uncertain situations which inflexible algorithms cannot handle. We conclude by discussing how the analysis and design of algorithmic systems could seek to identify and cultivate important sources of uncertainty, to enable the human discretionary work that enhances systemic resilience in the face of algorithmic errors.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {bureaucracy, automated decision-making, algorithmic power, street-level bureaucracies, street-level algorithms, uncertainty, algorithmic systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376768,
author = {Tahaei, Mohammad and Vaniea, Kami and Saphra, Naomi},
title = {Understanding Privacy-Related Questions on Stack Overflow},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376768},
doi = {10.1145/3313831.3376768},
abstract = {We analyse Stack Overflow (SO) to understand challenges and confusions developers face while dealing with privacy-related topics. We apply topic modelling techniques to 1,733 privacy-related questions to identify topics and then qualitatively analyse a random sample of 315 privacy-related questions. Identified topics include privacy policies, privacy concerns, access control, and version changes. Results show that developers do ask SO for support on privacy-related issues. We also find that platforms such as Apple and Google are defining privacy requirements for developers by specifying what "sensitive" information is and what types of information developers need to communicate to users (e.g. privacy policies). We also examine the accepted answers in our sample and find that 28% of them link to official documentation and more than half are answered by SO users without references to any external resources.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {stack overflow, software developers, usable privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376760,
author = {Trajkova, Milka and Martin-Hammond, Aqueasha},
title = {"Alexa is a Toy": Exploring Older Adults' Reasons for Using, Limiting, and Abandoning Echo},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376760},
doi = {10.1145/3313831.3376760},
abstract = {Intelligent voice assistants (IVAs) have the potential to support older adults' independent living. However, despite a growing body of research focusing on IVA use, we know little about why older adults become IVA non-users. This paper examines the reasons older adults use, limit, and abandon IVAs (i.e., Amazon Echo) in their homes. We conducted eight focus groups, with 38 older adults residing in a Life Plan Community. Thirty-six participants owned an Echo for at least a year, and two were considering adoption. Over time, most participants became non-users due to their difficulty finding valuable uses, beliefs associated with ability and IVA use, or challenges with use in shared spaces. However, we also found that participants saw the potential for future IVA support. We contribute a better understanding of the reasons older adults do not engage with IVAs and how IVAs might better support aging and independent living in the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {older adults, smart environments, life plan community, voice assistants, focus group, technology non-use},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376743,
author = {Kim, Taewan and Ruensuk, Mintra and Hong, Hwajung},
title = {In Helping a Vulnerable Bot, You Help Yourself: Designing a Social Bot as a Care-Receiver to Promote Mental Health and Reduce Stigma},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376743},
doi = {10.1145/3313831.3376743},
abstract = {Helping others can have a positive effect on both the giver and the receiver. However, supporting someone with depression can be complicated and overwhelming. To address this, we proposed a Facebook-based social bot displaying depressive symptoms and disclosing vulnerable experiences that allows users to practice providing reactions online. We investigated how 55 college students interacted with the social bot for three weeks and how these support-giving experiences affected their mental health and stigma. By responding to the bot, the participants reframed their own negative experiences, reported reduced feelings of danger regarding an individual with depression and increased willingness to help the person, and presented favorable attitudes toward seeking treatment for depression. We discuss design opportunities for accessible social bots that could help users to keep practicing peer support interventions without fear of negative consequences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {health, mental health, college student, social bot, depression, stigma},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376740,
author = {Wang, April Yi and Wu, Zihan and Brooks, Christopher and Oney, Steve},
title = {Callisto: Capturing the "Why" by Connecting Conversations with Computational Narratives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376740},
doi = {10.1145/3313831.3376740},
abstract = {When teams of data scientists collaborate on computational notebooks, their discussions often contain valuable insight into their design decisions. These discussions not only explain analysis in the current notebook but also alternative paths, which are often poorly documented. However, these discussions are disconnected from the notebooks for which they could provide valuable context. We propose Callisto, an extension to computational notebooks that captures and stores contextual links between discussion messages and notebook elements with minimal effort from users. Callisto allows notebook readers to better understand the current notebook content and the overall problem-solving process that led to it, by making it possible to browse the discussions and code history relevant to any part of the notebook. This is particularly helpful for onboarding new notebook collaborators to avoid misinterpretations and duplicated work, as we found in a two-stage evaluation with 32 data science students.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {computational notebooks, literate programming, collaborative systems, datascience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376737,
author = {Wang, Yanan and Amores, Judith and Maes, Pattie},
title = {On-Face Olfactory Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376737},
doi = {10.1145/3313831.3376737},
abstract = {On-face wearables are currently limited to piercings, tattoos, or interactive makeup that aesthetically enhances the user, and have been minimally used for scent-delivery methods. However, on-face scent interfaces could provide an advantage for personal scent delivery in comparison with other modalities or body locations since they are closer to the nose. In this paper, we present the mechanical and industrial design details of a series of form factors for on-face olfactory wearables that are lightweight and can be adhered to the skin or attached to glasses or piercings. We assessed the usability of three prototypes by testing with 12 participants in a within-subject study design while they were interacting in pairs at a close personal distance. We compare two of these designs with an "off-face" olfactory necklace and evaluate their social acceptance, comfort as well as perceived odor intensity for both the wearer and observer.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {wearability, fashion, jewelry, olfaction, olfactory interfaces, wearable device, on-face interfaces, on-face wearables, scent display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

