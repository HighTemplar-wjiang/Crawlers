@inproceedings{10.1145/3411764.3445631,
author = {Ogata, Masa and Koyama, Yuki},
title = {A Computational Approach to Magnetic Force Feedback Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445631},
doi = {10.1145/3411764.3445631},
abstract = {We present a computational approach to haptic design embedded in everyday tangible interaction with digital fabrication. To generate haptic feedback, the use of permanent magnets as the mechanism potentially contributes to simpleness and robustness; however, it is difficult to manually design how magnets should be embedded in the objects. Our approach enables the inverse design of magnetic force feedback; that is, we computationally solve an inverse problem to obtain an optimal arrangement of permanent magnets that renders the user-specified haptic sensation. To solve the inverse problem in a practical manner, we also present techniques on magnetic simulation and optimization. We demonstrate applications to explore the design possibility of augmenting digital fabrication for everyday use.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {284},
numpages = {12},
keywords = {Digital fabrication, Inverse design, Optimization, Haptics, Magnetic force feedback},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445630,
author = {Batool, Amna and Toyama, Kentaro and Veinot, Tiffany and Fatima, Beenish and Naseem, Mustafa},
title = {Detecting Data Falsification by Front-Line Development Workers: A Case Study of Vaccination in Pakistan},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445630},
doi = {10.1145/3411764.3445630},
abstract = {Front-line workers in global development are often responsible for data collection and record-keeping about their own work. The authenticity of such data and the role of mid-level supervisors, however, remains understudied. We report on the case of immunization in Pakistan, where, through interviews with 30 mid-level vaccination managers in Punjab district, we find that data falsification by vaccinators is common, though not necessarily rampant. Because of an intricate protocol for record-keeping, supervisors can detect data falsification, and we find they have devised an array of methods, broadly classifiable into four types: triangulation, supplementary data collection, anomaly detection, and interrogation. We also find that the strategies that supervisors use to detect falsification seem linked to their style of management, with authoritarian supervisors preferring supplementary data collection and spot checks, while supportive supervisors use triangulation. Our findings lead to recommendations for designing technologies intended to monitor and manage front-line data.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {700},
numpages = {14},
keywords = {Technology, Data Falsification, Supervisors, Supportive Supervision, Front-line Workers, Healthcare, Mid-level Managers, Immunization, Developing Countries},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445624,
author = {Liang, Chen and Yu, Chun and Wei, Xiaoying and Xu, Xuhai and Hu, Yongquan and Wang, Yuntao and Shi, Yuanchun},
title = {Auth+Track: Enabling Authentication Free Interaction on Smartphone by Continuous User Tracking},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445624},
doi = {10.1145/3411764.3445624},
abstract = {We propose Auth+Track, a novel authentication model that aims to reduce redundant authentication in everyday smartphone usage. By sparse authentication and continuous tracking of the user’s status, Auth+Track eliminates the “gap” authentication between fragmented sessions and enables “Authentication Free when User is Around”. To instantiate the Auth+Track model, we present PanoTrack, a prototype that integrates body and near field hand information for user tracking. We install a fisheye camera on the top of the phone to achieve a panoramic vision that can capture both user’s body and on-screen hands. Based on the captured video stream, we develop an algorithm to extract 1) features for user tracking, including body keypoints and their temporal and spatial association, near field hand status, and 2) features for user identity assignment. The results of our user studies validate the feasibility of PanoTrack and demonstrate that Auth+Track not only improves the authentication efficiency but also enhances user experiences with better usability.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {2},
numpages = {16},
keywords = {continuous user tracking, authentication model},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445617,
author = {Uriu, Daisuke and Toshima, Kenta and Manabe, Minori and Yazaki, Takeru and Funatsu, Takeshi and Izumihara, Atsushi and Kashino, Zendai and Hiyama, Atsushi and Inami, Masahiko},
title = {Generating the Presence of Remote Mourners: A Case Study of Funeral Webcasting in Japan},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445617},
doi = {10.1145/3411764.3445617},
abstract = {Funerals are irreplaceable events, especially for bereaved family members and relatives. However, the COVID-19 pandemic has prevented many people worldwide from attending their loved ones’ funerals. The authors had the opportunity to assist one family faced with this predicament by webcasting and recording funeral rites held near Tokyo in June, 2020. Using our original 360-degree Telepresence system and smartphones running Zoom, we enabled the deceased’s elder siblings to remotely attend the funeral and did our utmost to make them feel present in the funeral hall. Despite the webcasting via Zoom contributing more to their remote attendances than our system, we discovered thoughtful findings which could be useful for designing remote funeral attendances. From the findings, we also discuss how HCI designers can contribute to this highly sensitive issue, weaving together knowledge from various domains including techno-spiritual practices, thanato-sensitive designs; and other religious and cultural aspects related to death rituals.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {629},
numpages = {14},
keywords = {Funeral, Thanato-sensitivity, Death Rituals, Telepresence and Telexistence, 360-degree camera, Techno-spiritual practices, Mourning and Memorialization},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445603,
author = {Wang, Yihong and Papangelis, Konstantinos and Saker, Michel and Lykourentzou, Ioanna and Khan, Vassilis-Javed and Chamberlain, Alan and Grudin, Jonathan},
title = {An Examination of the Work Practices of Crowdfarms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445603},
doi = {10.1145/3411764.3445603},
abstract = {Crowdsourcing is a new value creation business model. Annual revenue of the Chinese market alone is hundreds of millions of dollars, yet few studies have focused on the practices of the Chinese crowdsourcing workforce, and those that do mainly focus on solo crowdworkers. We have extended our study of solo crowdworker practices to include crowdfarms, a relatively new entry to the gig economy: small companies that carry out crowdwork as a key part of their business. We report here on interviews of people who work in 53 crowdfarms. We describe how crowdfarms procure jobs, carry out macrotasks and microtasks, manage their reputation, and employ different management practices to motivate crowdworkers and customers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {139},
numpages = {14},
keywords = {Work Practices, Crowdfarms, Crowdsourcing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445588,
author = {Jicol, Crescent and Wan, Chun Hin and Doling, Benjamin and Illingworth, Caitlin H and Yoon, Jinha and Headey, Charlotte and Lutteroth, Christof and Proulx, Michael J and Petrini, Karin and O'Neill, Eamonn},
title = {Effects of Emotion and Agency on Presence in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445588},
doi = {10.1145/3411764.3445588},
abstract = {Arguably one of the most important characteristics of virtual reality (VR) is its ability to induce higher feelings of presence. Still, research has remained inconclusive on how presence is affected by human factors such as emotion and agency. Here we adopt a novel design to investigate their effects by testing virtual environments inducing either happiness or fear, with or without user agency. Results from 121 participants showed that the dominant emotion induced by a virtual environment is positively correlated with presence. In addition, agency had a significant positive effect on presence and, furthermore, moderated the effect of emotion on presence. We show for the first time that the effects of emotion and agency on presence are not straightforward but they can be modelled by separating design factors from subjective measures. We discuss how these findings can explain seemingly conflicting results of related work and their implications for VR design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {529},
numpages = {13},
keywords = {virtual reality, emotion, agency., presence},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445583,
author = {Matulic, Fabrice and Ganeshan, Aditya and Fujiwara, Hiroshi and Vogel, Daniel},
title = {Phonetroller: Visual Representations of Fingers for Precise Touch Input with Mobile Phones in VR},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445583},
doi = {10.1145/3411764.3445583},
abstract = {Smartphone touch screens are potentially attractive for interaction in virtual reality (VR). However, the user cannot see the phone or their hands in a fully immersive VR setting, impeding their ability for precise touch input. We propose mounting a mirror above the phone screen such that the front-facing camera captures the thumbs on or near the screen. This enables the creation of semi-transparent overlays of thumb shadows and inference of fingertip hover points with deep learning, which help the user aim for targets on the phone. A study compares the effect of visual feedback on touch precision in a controlled task and qualitatively evaluates three example applications demonstrating the potential of the technique. The results show that the enabled style of feedback is effective for thumb-size targets, and that the VR experience can be enriched by using smartphones as VR controllers supporting precise touch input.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {129},
numpages = {13},
keywords = {VR, visual feedback, mobile phone, deep learning, touch input},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445582,
author = {Ahuja, Karan and Mayer, Sven and Goel, Mayank and Harrison, Chris},
title = {Pose-on-the-Go: Approximating User Pose with Smartphone Sensor Fusion and Inverse Kinematics},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445582},
doi = {10.1145/3411764.3445582},
abstract = {We present Pose-on-the-Go, a full-body pose estimation system that uses sensors already found in today’s smartphones. This stands in contrast to prior systems, which require worn or external sensors. We achieve this result via extensive sensor fusion, leveraging a phone’s front and rear cameras, the user-facing depth camera, touchscreen, and IMU. Even still, we are missing data about a user’s body (e.g., angle of the elbow joint), and so we use inverse kinematics to estimate and animate probable body poses. We provide a detailed evaluation of our system, benchmarking it against a professional-grade Vicon tracking system. We conclude with a series of demonstration applications that underscore the unique potential of our approach, which could be enabled on many modern smartphones with a simple software update.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {9},
numpages = {12},
keywords = {Smartphone, Body pose, Mobile, Motion capture, Motion tracking},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445579,
author = {Kim, Yelim and Reza, Mohi and McGrenere, Joanna and Yoon, Dongwook},
title = {Designers Characterize Naturalness in Voice User Interfaces: Their Goals, Practices, and Challenges},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445579},
doi = {10.1145/3411764.3445579},
abstract = {This work investigates the practices and challenges of voice user interface (VUI) designers. Existing VUI design guidelines recommend that designers strive for natural human-agent conversation. However, the literature leaves a critical gap regarding how designers pursue naturalness in VUIs and what their struggles are in doing so. Bridging this gap is necessary for identifying designers’ needs and supporting them. Our interviews with 20 VUI designers identified 12 ways that designers characterize and approach naturalness in VUIs. We categorized these characteristics into three groupings based on the types of conversational context that each characteristic contributes to: Social, Transactional, and Core. Our results contribute new findings on designers’ challenges, such as a design dilemma in augmenting task-oriented VUIs with social conversations, difficulties in writing for spoken language, lack of proper tool support for imbuing synthesized voice with expressivity, and implications for developing design tools and guidelines.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {242},
numpages = {13},
keywords = {designers, characterize, challenges, voice user interfaces (VUI), practices, naturalness},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445573,
author = {Chen, Yan and Lee, Sang Won and Oney, Steve},
title = {CoCapture: Effectively Communicating UI Behaviors on Existing Websites by Demonstrating and Remixing},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445573},
doi = {10.1145/3411764.3445573},
abstract = {User Interface (UI) mockups are commonly used as shared context during interface development collaboration. In practice, UI designers often use screenshots and sketches to create mockups of desired UI behaviors for communication. However, in the later stages of UI development, interfaces can be arbitrarily complex, making it labor-intensive to sketch, and static screenshots are limited in the types of interactive and dynamic behaviors they can express. We introduce CoCapture, a system that allows designers to easily create UI behavior mockups on existing web interfaces by demonstrating and remixing, and to accurately describe their requests to helpers by referencing the resulting mockups using hypertext. We showed that participants could more accurately describe UI behaviors with CoCapture than with existing sketch and communication tools and that the resulting descriptions were clear and easy to follow. Our approach can help teams develop UIs efficiently by bridging communication gaps with more accurate visual context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {416},
numpages = {14},
keywords = {UI design communication, Rapid UI prototyping},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445572,
author = {Peng, Yi-Hao and Jang, JiWoong and Bigham, Jeffrey P and Pavel, Amy},
title = {Say It All: Feedback for Improving Non-Visual Presentation Accessibility},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445572},
doi = {10.1145/3411764.3445572},
abstract = {Presenters commonly use slides as visual aids for informative talks. When presenters fail to verbally describe the content on their slides, blind and visually impaired audience members lose access to necessary content, making the presentation difficult to follow. Our analysis of 90 presentation videos revealed that 72% of 610 visual elements (e.g., images, text) were insufficiently described. To help presenters create accessible presentations, we introduce Presentation A11y, a system that provides real-time and post-presentation accessibility feedback. Our system analyzes visual elements on the slide and the transcript of the verbal presentation to provide element-level feedback on what visual content needs to be further described or even removed. Presenters using our system with their own slide-based presentations described more of the content on their slides, and identified &nbsp;3.26 times more accessibility problems to fix after the talk than when using a traditional slide-based presentation interface. Integrating accessibility feedback into content creation tools will improve the accessibility of informational content for all.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {12},
keywords = {Video, Audio description, Slides, Accessibility, Presentation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445564,
author = {Albaugh, Lea and McCann, James and Hudson, Scott E. and Yao, Lining},
title = {Engineering Multifunctional Spacer Fabrics Through Machine Knitting},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445564},
doi = {10.1145/3411764.3445564},
abstract = {Machine knitting is an increasingly accessible fabrication technology for producing custom soft goods. However, recent machine knitting research has focused on knit shaping, or on adapting hand-knitting patterns. We explore a capability unique to machine knitting: producing multilayer spacer fabrics. These fabrics consist of two face layers connected by a monofilament filler yarn which gives the structure stiffness and volume. We show how to vary knit patterning and yarn parameters in spacer fabrics to produce tactile materials with embedded functionality for forming soft actuated mechanisms and sensors with tunable density, stiffness, material bias, and bristle properties. These soft mechanisms can be rapidly produced on a computationally-controlled v-bed knitting machine and integrated directly into soft objects.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {498},
numpages = {12},
keywords = {Knitted Mechanisms., Soft Sensors, Machine Knitting, Textiles},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445546,
author = {Veras, Rafael and Singh, Gaganpreet and Farhadi-Niaki, Farzin and Udhani, Ritesh and Patekar, Parth Pradeep and Zhou, Wei and Irani, Pourang and Li, Wei},
title = {Elbow-Anchored Interaction: Designing Restful Mid-Air Input},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445546},
doi = {10.1145/3411764.3445546},
abstract = {We designed a mid-air input space for restful interactions on the couch. We observed people gesturing in various postures on a couch and found that posture affects the choice of arm motions when no constraints are imposed by a system. Study participants that sat with the arm rested were more likely to use the forearm and wrist, as opposed to the whole arm. We investigate how a spherical input space, where forearm angles are mapped to screen coordinates, can facilitate restful mid-air input in multiple postures. We present two controlled studies. In the first, we examine how a spherical space compares with a planar space in an elbow-anchored setup, with a shoulder-level input space as baseline. In the second, we examine the performance of a spherical input space in four common couch postures that set unique constraints to the arm. We observe that a spherical model that captures forearm movement facilitates comfortable input across different seated postures.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {737},
numpages = {15},
keywords = {Elbow-anchored Input, Mid-air Gesture Fatigue, Restful Input, Mid-air Gestures, Variable-posture Gestures, Comfort},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445545,
author = {Winters, R. Michael and Walker, Bruce N. and Leslie, Grace},
title = {Can You Hear My Heartbeat?: Hearing an Expressive Biosignal Elicits Empathy},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445545},
doi = {10.1145/3411764.3445545},
abstract = {Interfaces designed to elicit empathy provide an opportunity for HCI with important pro-social outcomes. Recent research has demonstrated that perceiving expressive biosignals can facilitate emotional understanding and connection with others, but this work has been largely limited to visual approaches. We propose that hearing these signals will also elicit empathy, and test this hypothesis with sounding heartbeats. In a lab-based within-subjects study, participants (N = 27) completed an emotion recognition task in different heartbeat conditions. We found that hearing heartbeats changed participants’ emotional perspective and increased their reported ability to “feel what the other was feeling.” From these results, we argue that auditory heartbeats are well-suited as an empathic intervention, and might be particularly useful for certain groups and use-contexts because of its musical and non-visual nature. This work establishes a baseline for empathic auditory interfaces, and offers a method to evaluate the effects of future designs.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {225},
numpages = {11},
keywords = {AAC, music, emotion, communication, rhythm, affect, heart rate, physiology, ASD, empathy, sound},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445535,
author = {Liu, Richen and Gao, Min and Ye, Shunlong and Zhang, Jiang},
title = {IGScript: An Interaction Grammar for Scientific Data Presentation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445535},
doi = {10.1145/3411764.3445535},
abstract = {Most of the existing scientific visualizations toward interpretive grammar aim to enhance customizability in either the computation stage or the rendering stage or both, while few approaches focus on the data presentation stage. Besides, most of these approaches leverage the existing components from the general-purpose programming languages (GPLs) instead of developing a standalone compiler, which pose a great challenge about learning curves for the domain experts who have limited knowledge about programming. In this paper, we propose IGScript, a novel script-based interaction grammar tool, to help build scientific data presentation animations for communication. We design a dual-space interface and a compiler which converts natural language-like grammar statements or scripts into a data story animation to make an interactive customization on script-driven data presentations, and then develop a code generator (decompiler) to translate the interactive data exploration animations back into script codes to achieve statement parameters. IGScript makes the presentation animations editable, e.g., it allows to cut, copy, paste, append, or even delete some animation clips. We demonstrate the usability, customizability, and flexibility of IGScript by a user study, four case studies conducted by using four types of commonly-used scientific data, and performance evaluations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {26},
numpages = {13},
keywords = {interaction grammar, data presentation, scientific visualization},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445519,
author = {Baughan, Amanda and Oliveira, Nigini and August, Tal and Yamashita, Naomi and Reinecke, Katharina},
title = {Do Cross-Cultural Differences in Visual Attention Patterns Affect Search Efficiency on Websites?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445519},
doi = {10.1145/3411764.3445519},
abstract = {Prior work in cross-cultural psychology and neuroscience has shown robust variations in visual attention patterns. People from East Asian societies, in which a holistic thinking style predominates, have been found to attend to contextual information in scenes more than Westerners, whose tendency to think analytically expresses itself in greater attention to foreground objects. This paper applies these findings to website design, using an online study to evaluate whether Japanese (N=65) remember more and are faster at finding contextual website information than US Americans (N=84). Our results do not support this hypothesis. Instead, Japanese overall took significantly longer to find information than US participants—a difference that was exacerbated by an increase in website complexity—suggesting that Japanese may holistically take in a website before engaging with detailed information. We discuss implications of these findings for website design and cross-cultural research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {362},
numpages = {12},
keywords = {website search efficiency, visual attention, culture},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445517,
author = {Utz, Christine and Becker, Steffen and Schnitzler, Theodor and Farke, Florian M. and Herbert, Franziska and Schaewitz, Leonie and Degeling, Martin and D\"{u}rmuth, Markus},
title = {Apps Against the Spread: Privacy Implications and User Acceptance of COVID-19-Related Smartphone Apps on Three Continents},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445517},
doi = {10.1145/3411764.3445517},
abstract = {The COVID-19 pandemic has fueled the development of smartphone applications to assist disease management. Many “corona apps” require widespread adoption to be effective, which has sparked public debates about the privacy, security, and societal implications of government-backed health applications. We conducted a representative online study in Germany (n = 1003), the US (n = 1003), and China (n = 1019) to investigate user acceptance of corona apps, using a vignette design based on the contextual integrity framework. We explored apps for contact tracing, symptom checks, quarantine enforcement, health certificates, and mere information. Our results provide insights into data processing practices that foster adoption and reveal significant differences between countries, with user acceptance being highest in China and lowest in the US. Chinese participants prefer the collection of personalized data, while German and US participants favor anonymity. Across countries, contact tracing is viewed more positively than quarantine enforcement, and technical malfunctions negatively impact user acceptance.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {22},
keywords = {privacy, digital contact tracing, COVID-19},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445502,
author = {Schmitz, Martin and M\"{u}ller, Florian and M\"{u}hlh\"{a}user, Max and Riemann, Jan and Le, Huy Viet Viet},
title = {Itsy-Bits: Fabrication and Recognition of 3D-Printed Tangibles with Small Footprints on Capacitive Touchscreens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445502},
doi = {10.1145/3411764.3445502},
abstract = {Tangibles on capacitive touchscreens are a promising approach to overcome the limited expressiveness of touch input. While research has suggested many approaches to detect tangibles, the corresponding tangibles are either costly or have a considerable minimal size. This makes them bulky and unattractive for many applications. At the same time, they obscure valuable display space for interaction. To address these shortcomings, we contribute Itsy-Bits: a fabrication pipeline for 3D printing and recognition of tangibles on capacitive touchscreens with a footprint as small as a fingertip. Each Itsy-Bit consists of an enclosing 3D object and a unique conductive 2D shape on its bottom. Using only raw data of commodity capacitive touchscreens, Itsy-Bits reliably identifies and locates a variety of shapes in different sizes and estimates their orientation. Through example applications and a technical evaluation, we demonstrate the feasibility and applicability of Itsy-Bits for tangibles with small footprints.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {419},
numpages = {12},
keywords = {Machine Learning, Tangibles, Touchscreen, 3D Printing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445492,
author = {Karaosmanoglu, Sukran and Rogers, Katja and Wolf, Dennis and Rukzio, Enrico and Steinicke, Frank and Nacke, Lennart E.},
title = {Feels like Team Spirit: Biometric and Strategic Interdependence in Asymmetric Multiplayer VR Games},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445492},
doi = {10.1145/3411764.3445492},
abstract = {Virtual reality (VR) multiplayer games increasingly use asymmetry (e.g., differences in a person’s capability or the user interface) and resulting interdependence between players to create engagement even when one player has no access to a head-mounted display (HMD). Previous work shows this enhances player experience (PX). Until now, it remains unclear whether and how an asymmetric game design with interdependences creates comparably enjoyable PX for both an HMD and a non-HMD player. In this work, we designed and implemented an asymmetric VR game (different in its user interface) with two types of interdependence: strategic (difference in game information/player capability) and biometric (difference in player’s biometric influence). Our mixed-methods user study (N=30) shows that asymmetries positively impact PX for both player roles, that interdependence strongly affects players’ perception of agency, and that biometric feedback—while subjective—is a valuable game mechanic.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {443},
numpages = {15},
keywords = {VR, interdependence, strategic, biometric, asymmetry, multiplayer, virtual reality},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445486,
author = {Elgarf, Maha and Calvo-Barajas, Natalia and Paiva, Ana and Castellano, Ginevra and Peters, Christopher},
title = {Reward Seeking or Loss Aversion? Impact of Regulatory Focus Theory on Emotional Induction in Children and Their Behavior Towards a Social Robot},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445486},
doi = {10.1145/3411764.3445486},
abstract = {According to psychology research, emotional induction has positive implications in many domains such as therapy and education. Our aim in this paper was to manipulate the Regulatory Focus Theory to assess its impact on the induction of regulatory focus related emotions in children in a pretend play scenario with a social robot. The Regulatory Focus Theory suggests that people follow one of two paradigms while attempting to achieve a goal; by seeking gains (promotion focus - associated with feelings of happiness) or by avoiding losses (prevention focus - associated with feelings of fear). We conducted a study with 69 school children in two different conditions (promotion vs. prevention). We succeeded in inducing happiness emotions in the promotion condition and found a resulting positive effect of the induction on children’s social engagement with the robot. We also discuss the important implications of these results in both educational and child robot interaction fields.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {587},
numpages = {11},
keywords = {human robot interaction, regulatory focus, emotional induction, social engagement, social robotics},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445480,
author = {Holl\"{a}nder, Kai and Colley, Mark and Rukzio, Enrico and Butz, Andreas},
title = {A Taxonomy of Vulnerable Road Users for HCI Based On A Systematic Literature Review},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445480},
doi = {10.1145/3411764.3445480},
abstract = {Recent automotive research often focuses on automated driving, including the interaction between automated vehicles (AVs) and so-called “vulnerable road users” (VRUs). While road safety statistics and traffic psychology at least define VRUs as pedestrians, cyclists, and motorcyclists, many publications on human-vehicle interaction use the term without even defining it. The actual target group remains unclear. Since each group already poses a broad spectrum of research challenges, a one-fits-all solution seems unrealistic and inappropriate, and a much clearer differentiation is required. To foster clarity and comprehensibility, we propose a literature-based taxonomy providing a structured separation of (vulnerable) road users, designed to particularly (but not exclusively) support research on the communication between VRUs and AVs. It consists of two conceptual hierarchies and will help practitioners and researchers by providing a uniform and comparable set of terms needed for the design, implementation, and description of HCI applications.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {158},
numpages = {13},
keywords = {eHMIs, external communication, taxonomy, vulnerable road users, Automated vehicles},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445475,
author = {Pourjafarian, Narjes and Koelle, Marion and Fruchard, Bruno and Mavali, Sahar and Klamka, Konstantin and Groeger, Daniel and Strohmeier, Paul and Steimle, J\"{u}rgen},
title = {BodyStylus: Freehand On-Body Design and Fabrication of Epidermal Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445475},
doi = {10.1145/3411764.3445475},
abstract = {In traditional body-art, designs are adjusted to the body as they are applied, enabling creative improvisation and exploration. Conventional design and fabrication methods of epidermal interfaces, however, separate these steps. With BodyStylus we present the first computer-assisted approach for on-body design and fabrication of epidermal interfaces. Inspired by traditional techniques, we propose a hand-held tool that augments freehand inking with digital support: projected in-situ guidance assists creating valid on-body circuits and aesthetic ornaments that align with the human bodyscape, while pro-active switching between inking and non-inking creates error preventing constraints. We contribute BodyStylus’s design rationale and interaction concept along with an interactive prototype that uses self-sintering conductive ink. Results of two focus group explorations showed that guidance was more appreciated by artists, while constraints appeared more useful to engineers, and that working on the body inspired critical reflection on the relationship between bodyscape, interaction, and designs.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {504},
numpages = {15},
keywords = {wearable computing, skin, On-body design, pen-based interaction, on-body fabrication, epidermal devices, craft},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445468,
author = {Zuckerman, Oren and Sadka, Ofir and Gissin, Ron and Erel, Hadas},
title = {TUI as Social Entity: A Study of Joint-Actuation and Turn-Taking-Actuation in Actuated-Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445468},
doi = {10.1145/3411764.3445468},
abstract = {We present an actuated-interface that is not only a tangible interface but also an autonomous object, designed as an independent entity that takes a similar role to the user’s role in an anagram word game. We highlight two leading interaction paradigms: Turn-taking-actuation and Joint-actuation, and evaluate both in a qualitative interaction study with the autonomous actuated-interface. Our findings reveal that all participants perceived the interaction as a social experience. The different interaction paradigms led to different interpretations: Turn-taking-actuation was interpreted as a competitive experience, while Joint-actuation was interpreted as a collaborative experience. The interaction paradigms also influenced the intensity of emotions and perception of control, with Joint-actuation leading to more intense emotions and higher sensitivity to control in the interaction. To conclude, our findings show that it is possible to design an actuated-interface that users perceive both as a tangible interface and as a social entity with its own intent.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {507},
numpages = {12},
keywords = {actuated-interface, TUI, social interaction, self-actuation, autonomous behavior},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445459,
author = {Zeng, Eric and Kohno, Tadayoshi and Roesner, Franziska},
title = {What Makes a “Bad” Ad? User Perceptions of Problematic Online Advertising},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445459},
doi = {10.1145/3411764.3445459},
abstract = {Online display advertising on websites is widely disliked by users, with many turning to ad blockers to avoid “bad” ads. Recent evidence suggests that today’s ads contain potentially problematic content, in addition to well-studied concerns about the privacy and intrusiveness of ads. However, we lack knowledge of which types of ad content users consider problematic and detrimental to their browsing experience. Our work bridges this gap: first, we create a taxonomy of 15 positive and negative user reactions to online advertising from a survey of 60 participants. Second, we characterize classes of online ad content that users dislike or find problematic, using a dataset of 500 ads crawled from popular websites, labeled by 1000 participants using our taxonomy. Among our findings, we report that users consider a substantial amount of ads on the web today to be clickbait, untrustworthy, or distasteful, including ads for software downloads, listicles, and health &amp; supplements.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {361},
numpages = {24},
keywords = {dark patterns, deceptive advertising, online advertising},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445456,
author = {Feick, Martin and Kleer, Niko and Zenner, Andr\'{e} and Tang, Anthony and Kr\"{u}ger, Antonio},
title = {Visuo-Haptic Illusions for Linear Translation and Stretching Using Physical Proxies in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445456},
doi = {10.1145/3411764.3445456},
abstract = {Providing haptic feedback when manipulating virtual objects is an essential part of immersive virtual reality experiences; however, it is challenging to replicate all of an object's properties and characteristics. We propose the use of visuo-haptic illusions alongside physical proxies to enhance the scope of proxy-based interactions with virtual objects. In this work, we focus on two manipulation techniques, linear translation and stretching across different distances, and investigate how much discrepancy between the physical proxy and the virtual object may be introduced without participants noticing. In a study with 24 participants, we found that manipulation technique and travel distance significantly affect the detection thresholds, and that visuo-haptic illusions impact performance and accuracy. We show that this technique can be used to enable functional proxy objects that act as stand-ins for multiple virtual objects, illustrating the technique through a showcase VR-DJ application.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {220},
numpages = {13},
keywords = {Virtual Reality, Tangible Interfaces, Proxy Objects, Haptics, Visuo-haptic Illusions},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445447,
author = {Wong, Richmond Y. and Nguyen, Tonya},
title = {Timelines: A World-Building Activity for Values Advocacy},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445447},
doi = {10.1145/3411764.3445447},
abstract = {This paper presents Timelines, a design activity to assist values advocates: people who help others recognize values and ethical concerns as relevant to technical practice. Rather than integrate seamlessly into existing design processes, Timelines aims to create a space for critical reflection and contestation among expert participants (such as technology researchers, practitioners, or students) and a values advocate facilitator to surface the importance and relevance of values and ethical concerns. The activity’s design is motivated by theoretical perspectives from design fiction, scenario planning, and value sensitive design. The activity helps participants surface discussion of broad societal-level changes related to a technology by creating stories from news headlines, and recognize a diversity of experiences situated in the everyday by creating social media posts from different viewpoints. We reflect on how decisions on the activity’s design and facilitation enables it to assist in values advocacy practices.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {616},
numpages = {15},
keywords = {ethics, values in design, values work, design fiction, values advocacy},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445445,
author = {Yang, Xi and Aurisicchio, Marco},
title = {Designing Conversational Agents: A Self-Determination Theory Approach},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445445},
doi = {10.1145/3411764.3445445},
abstract = {Bringing positive experiences to users is one of the key goals when designing conversational agents (CAs). Yet we still lack an understanding of users’ underlying needs to achieve positive experiences and how to support them in design. This research first applies Self-Determination Theory in an interview study to explore how users’ needs of competence, autonomy and relatedness could be supported or undermined in CA experiences. Ten guidelines are then derived from the interview findings. The key findings demonstrate that: competence is affected by users’ knowledge of the CA capabilities and effectiveness of the conversation; autonomy is influenced by flexibility of the conversation, personalisation of the experiences, and control over user data; regarding relatedness, users still have concerns over integrating social features into CAs. The guidelines recommend how to inform users about the system capabilities, design effective and socially appropriate conversations, and support increased system intelligence, customisation, and data transparency.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {16},
keywords = {Conversational User Experience, Conversational Agents, Relatedness, Autonomy, Competence},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445440,
author = {Lee, Kyung-Ryong and Kim, Beom and Kim, Junyoung and Hong, Hwajung and Park, Young-Woo},
title = {ADIO: An Interactive Artifact Physically Representing the Intangible Digital Audiobook Listening Experience in Everyday Living Spaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445440},
doi = {10.1145/3411764.3445440},
abstract = {Although audiobooks are increasingly being used, people tend to perceive audiobook experiences as 'not real reading' due to its intangibility and ephemerality. In this paper, we developed ADIO, a device augmenting audiobook experience through representing personal listening state in the form of an interactive physical bookshelf. ADIO displays a user's listening progress through a pendant's changing length and the user's digital audiobook archive titles. The result of our four-week in-field study with six participants revealed that ADIO provided proof of the user's listening-to, which brought a sense of reading and gave a trigger for recalling the listened-to audiobook content. Additionally, audiobooks' improved visibility reminded participants to listen to them, and ADIO's physical interaction allowed participants to form personal patterns for listening to audiobooks. Our findings proposed new methods for augmenting the audiobook listening experience at three stages and further implications for designing physical curation on users’ digital archives.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {164},
numpages = {12},
keywords = {Audiobook, Physical interaction, Data physicalization, Digital possession},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445437,
author = {Yoo, Jung Eun and Seo, Kwanggyoon and Park, Sanghun and Kim, Jaedong and Lee, Dawon and Noh, Junyong},
title = {Virtual Camera Layout Generation Using a Reference Video},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445437},
doi = {10.1145/3411764.3445437},
abstract = {We propose a method that generates a virtual camera layout of a 3D animation scene by following the cinematic intention of a reference video. From a reference video, cinematic features such as the start frame, end frame, framing, camera movement, and the visual features of the subjects are extracted automatically. The extracted information is used to generate the virtual camera layout, which resembles the camera layout of the reference video. Our method handles stylized as well as human characters with body proportions different from those of humans. We demonstrate the effectiveness of our approach with various reference videos and 3D animation scenes. The user evaluation results show that the generated layouts are comparable to layouts created by the artist, allowing us to assert that our method can provide effective assistance to both novice and professional users when positioning a virtual camera.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {580},
numpages = {11},
keywords = {Content Analysis, Cinematography, Virtual Camera},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445427,
author = {Yu, Junnan and DeVore, Andrea and Roque, Ricarose},
title = {Parental Mediation for Young Children’s Use of Educational Media: A Case Study with Computational Toys and Kits},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445427},
doi = {10.1145/3411764.3445427},
abstract = {Parental mediation literature is mostly situated in the contexts of television, Internet use, video games, and mobile devices, while there is less understanding of how parents mediate their children’s engagement with educational-focused media. We examine parental involvement in young children’s use of a creation-oriented educational media, i.e., coding kits, from a mediation perspective through an interview study. We frame parents’ mediation practices along three dimensions: (1) creative mediation, where parents mediate to support children’s creating and learning with media; (2) preparative mediation, where parents explore and prepare media for children’s engagement; and (3) administrative mediation, where parents administer and regulate their children’s media use. Compared to the restrictive, active, and co-using mediation theory, our proposed framework highlights various supportive practices parents take to help their children learn and create with media. We further connect our findings to Joint Media Engagement and reflect on implications for parent involvement in children’s creation-oriented media design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {475},
numpages = {12},
keywords = {Young Children, Parental Mediation Theory, Educational Media, Parents},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445423,
author = {Gordon, Mitchell L. and Zhou, Kaitlyn and Patel, Kayur and Hashimoto, Tatsunori and Bernstein, Michael S.},
title = {The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445423},
doi = {10.1145/3411764.3445423},
abstract = {Machine learning classifiers for human-facing tasks such as comment toxicity and misinformation often score highly on metrics such as ROC AUC but are received poorly in practice. Why this gap? Today, metrics such as ROC AUC, precision, and recall are used to measure technical performance; however, human-computer interaction observes that evaluation of human-facing systems should account for people’s reactions to the system. In this paper, we introduce a transformation that more closely aligns machine learning classification metrics with the values and methods of user-facing performance measures. The disagreement deconvolution takes in any multi-annotator (e.g., crowdsourced) dataset, disentangles stable opinions from noise by estimating intra-annotator consistency, and compares each test set prediction to the individual stable opinions from each annotator. Applying the disagreement deconvolution to existing social computing datasets, we find that current metrics dramatically overstate the performance of many human-facing machine learning tasks: for example, performance on a comment toxicity task is corrected from .95 to .73 ROC AUC.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {388},
numpages = {14},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445417,
author = {Randhawa, Shan M and Ahmad, Tallal and Chen, Jay and Raza, Agha Ali},
title = {Karamad: A Voice-Based Crowdsourcing Platform for Underserved Populations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445417},
doi = {10.1145/3411764.3445417},
abstract = {Crowdsourcing enables the completion of large-scale and hard-to-automate tasks, while allowing people to earn money. However, 3.6 billion people – a workforce comprising 46.4% of the world population – who could benefit most from this source of income lack the access and literacy to use computers, smartphones, and the internet. In this paper we present Karamad, a voice-based crowdsourcing platform that allows workers in low-resource regions to complete crowd work using low-end phones and receive payments as mobile airtime balance. We explore the usefulness, scalability, and sustainability of Karamad in Pakistan through a 6-month deployment. Without any advertising, training, or airtime subsidies, Karamad organically engaged 725 workers who completed 3,939 tasks (involving 43,006 components) including translations, dataset generation, and surveys on demographics, accessibility, disability, health, employment, and literacy. Collectively, the workers produced a valuable service market for potential customers and included female, unemployed, non-literate, and blind users.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {569},
numpages = {15},
keywords = {Pakistan, voice, IVR, HCI4D, telephone, underserved, mobile phone, telephonic surveys, speech, income, ICT4D, low-literate, crowd work, Interactive Voice Response, crowdsourcing, cellphone.},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445416,
author = {Bragg, Danielle and Caselli, Naomi and Gallagher, John W. and Goldberg, Miriam and Oka, Courtney J. and Thies, William},
title = {ASL Sea Battle: Gamifying Sign Language Data Collection},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445416},
doi = {10.1145/3411764.3445416},
abstract = {The development of accurate machine learning models for sign languages like American Sign Language (ASL) has the potential to break down communication barriers for deaf signers. However, to date, no such models have been robust enough for real-world use. The primary barrier to enabling real-world applications is the lack of appropriate training data. Existing training sets suffer from several shortcomings: small size, limited signer diversity, lack of real-world settings, and missing or inaccurate labels. In this work, we present ASL Sea Battle, a sign language game designed to collect datasets that overcome these barriers, while also providing fun and education to users. We conduct a user study to explore the data quality that the game collects, and the user experience of playing the game. Our results suggest that ASL Sea Battle can reliably collect and label real-world sign language videos, and provides fun and education at the expense of data throughput.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {271},
numpages = {13},
keywords = {machine learning, sign language, data, game, ASL, crowdsourcing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445414,
author = {Ploderer, Bernd and Lawrence Taylor, Jennyfer and Mu\~{n}oz, Diego and Bircanin, Filip and Brereton, Margot},
title = {Diagramming Working Field Theories for Design in the HCI Classroom},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445414},
doi = {10.1145/3411764.3445414},
abstract = {HCI has historically provided little support for moving from fieldwork insights or theories to design outcomes. Having witnessed many students struggle and then justify their designs with a form of marketing hype, we developed a supporting approach of “field theories”. A field theory is a working theory about salient interactions in a particular domain and sensitizing concepts in order to frame design investigations.&nbsp;It is presented visually in a field theory diagram to support succinct communication and critique. Studying use of design prototypes that have been informed by a field theory helps to reflect upon and refine the theory.&nbsp;In this paper we present examples from our HCI classes and reflections based on interviews with students. We discuss how field theories offer an orientation in the spirit of a ‘bricoleur’ who harnesses elements of theory and practice to produce deeper understandings and more fitting outcomes for the task at hand.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {57},
numpages = {14},
keywords = {sensitizing concept, visual thinking, HCI education, design research, fieldwork},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445406,
author = {Pierce, James},
title = {In Tension with Progression: Grasping the Frictional Tendencies of Speculative, Critical, and Other Alternative Designs},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445406},
doi = {10.1145/3411764.3445406},
abstract = {Speculative design, critical design, and other alternative designs have emerged as popular approaches and burgeoning traditions within HCI and design research. While examples of this work abound, comparatively little theory exists for grasping alternative designs, and for explicating their relation to other types of design and to design in general. In response this paper develops the key concepts of progressional design, frictional design, and design as prefiguration. The progressional conceptualization of design holds that designs have a primary purpose, and that purpose is to ultimately converge toward and ideally arrive at production. The frictional conceptualization of design radically relaxes teleological assumptions and productional expectations. Frictional designs prefigure possibilities that are compellingly resistant to further progression and final production. Prefiguration grounds both progression and friction in the idea that designs are partial, provisional, and potentially preliminary actualizations of possible futures. To illustrate frictional design, this paper outlines a framework of 5 frictional tendencies: diverging, opposing, accelerating, counterfactualizing, and analogizing. These tendencies represent ways in which frictional designs are directionally in tension with the arrow-like vector of progressional design. Several additional concepts are discussed in conclusion to further explicate more nuanced relational potentials between friction and progression: transproductional uses, teleological ambiguity, and relational multiplicity.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {617},
numpages = {19},
keywords = {Design Theory, Design Fiction, Speculative Design, Critical Design, Design},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445401,
author = {Dickinson, Patrick and Jones, Arthur and Christian, Wayne and Westerside, Andrew and Mulloy, Francis and Gerling, Kathrin and Hicks, Kieran and Wilson, Liam and Parke, Adrian},
title = {Experiencing Simulated Confrontations in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445401},
doi = {10.1145/3411764.3445401},
abstract = {The use of virtual reality (VR) to simulate confrontational human behaviour has significant potential for use in training, where the recreation of uncomfortable feelings may help users to prepare for challenging real-life situations. In this paper we present a user study (n=68) in which participants experienced simulated confrontational behaviour performed by a virtual character either in immersive VR, or on a 2D display. Participants reported a higher elevation in anxiety in VR, which correlated positively with a perceived sense of physical space. Character believability was influenced negatively by visual elements of the simulation, and positively by behavioural elements, which complements findings from previous work. We recommend the use of VR for simulations of confrontational behaviour, where a realistic emotional response is part of the intended experience. We also discuss incorporation of domain knowledge of human behaviours, and carefully crafted motion-captured sequences, to increase users’ sense of believability.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {255},
numpages = {10},
keywords = {confrontational behaviour, Virtual reality, virtual character},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445394,
author = {Saha, Koustuv and Liu, Yozen and Vincent, Nicholas and Chowdhury, Farhan Asif and Neves, Leonardo and Shah, Neil and Bos, Maarten W.},
title = {AdverTiming Matters: Examining User Ad Consumption for Effective Ad Allocations on Social Media},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445394},
doi = {10.1145/3411764.3445394},
abstract = {Showing ads delivers revenue for online content distributors, but ad exposure can compromise user experience and cause user fatigue and frustration. Correctly balancing ads with other content is imperative. Currently, ad allocation relies primarily on demographics and inferred user interests, which are treated as static features and can be privacy-intrusive. This paper uses person-centric and momentary context features to understand optimal ad-timing. In a quasi-experimental study on a three-month longitudinal dataset of 100K Snapchat users, we find ad timing influences ad effectiveness. We draw insights on the relationship between ad effectiveness and momentary behaviors such as duration, interactivity, and interaction diversity. We simulate ad reallocation, finding that our study-driven insights lead to greater value for the platform. This work advances our understanding of ad consumption and bears implications for designing responsible ad allocation systems, improving both user and platform outcomes. We discuss privacy-preserving components and ethical implications of our work.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {581},
numpages = {18},
keywords = {social media, ads, Snapchat, momentary behaviors, causal-inference},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445386,
author = {Koushki, Masoud Mehrabi and Obada-Obieh, Borke and Huh, Jun Ho and Beznosov, Konstantin},
title = {On Smartphone Users’ Difficulty with Understanding Implicit Authentication},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445386},
doi = {10.1145/3411764.3445386},
abstract = {Implicit authentication (IA) has recently become a popular approach for providing physical security on smartphones. It relies on behavioral traits (e.g., gait patterns) for user identification, instead of biometric data or knowledge of a PIN. However, it is not yet known whether users can understand the semantics of this technology well enough to use it properly. We bridge this knowledge gap by evaluating how Android’s Smart Lock (SL), which is the first widely deployed IA solution on smartphones, is understood by its users. We conducted a qualitative user study (N=26) and an online survey (N=331). The results suggest that users often have difficulty understanding SL semantics, leaving them unable to judge when their phone would be (un)locked. We found that various aspects of SL, such as its capabilities and its authentication factors, are confusing for the users. We also found that depth of smartphone adoption is a significant antecedent of SL comprehension.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {690},
numpages = {14},
keywords = {Mental Models, Smart Lock, Smartphone Unlocking, Active Authentication, Implicit Authentication},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445385,
author = {Jacobs, Maia and He, Jeffrey and F. Pradier, Melanie and Lam, Barbara and Ahn, Andrew C. and McCoy, Thomas H. and Perlis, Roy H. and Doshi-Velez, Finale and Gajos, Krzysztof Z.},
title = {Designing AI for Trust and Collaboration in Time-Constrained Medical Decisions: A Sociotechnical Lens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445385},
doi = {10.1145/3411764.3445385},
abstract = {Major depressive disorder is a debilitating disease affecting 264 million people worldwide. While many antidepressant medications are available, few clinical guidelines support choosing among them. Decision support tools (DSTs) embodying machine learning models may help improve the treatment selection process, but often fail in clinical practice due to poor system integration. We use an iterative, co-design process to investigate clinicians’ perceptions of using DSTs in antidepressant treatment decisions. We identify ways in which DSTs need to engage with the healthcare sociotechnical system, including clinical processes, patient preferences, resource constraints, and domain knowledge. Our results suggest that clinical DSTs should be designed as multi-user systems that support patient-provider collaboration and offer on-demand explanations that address discrepancies between predictions and current standards of care. Through this work, we demonstrate how current trends in explainable AI may be inappropriate for clinical environments and consider paths towards designing these tools for real-world medical systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {14},
keywords = {healthcare, major depressive disorder, decision support tools},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445363,
author = {A. Sparrow, Lucy and Gibbs, Martin and Arnold, Michael},
title = {The Ethics of Multiplayer Game Design and Community Management: Industry Perspectives and Challenges},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445363},
doi = {10.1145/3411764.3445363},
abstract = {Game industry professionals are frequently implementing new methods of addressing ethical issues related to in-game toxicity and disruptive player behaviours associated with online multiplayer games. However, academic work on these behaviours tends to focus on the perspectives of players rather than the industry. To fully understand the ethics of multiplayer games and promote ethical design, we must examine the challenges facing those designing multiplayer games through an ethical lens. To this end, this paper presents a reflexive thematic analysis of 21 in-depth interviews with games industry professionals on their ethical views and experiences in game design and community management. We identify a number of tensions involved in making ethics-related design decisions for divided player communities alongside current game design practices that are concerned with functionality, revenue and entertainment. We then put forward a set of design considerations for integrating ethics into multiplayer game design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {325},
numpages = {13},
keywords = {Game Design, Ethics, Community Management, Toxicity, Multiplayer Games},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445341,
author = {Corbett, Eric and Le Dantec, Christopher},
title = {Designing Civic Technology with Trust},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445341},
doi = {10.1145/3411764.3445341},
abstract = {As the role technology plays in relationships between people and their governments grows, developing a better understanding of how trust can inform designing civic technology with trust is urgent work for human computer-interaction researchers. This paper reports our efforts to design with trust through a two-year design-ethnography with the City of Atlanta Mayor's Office of Immigrant Affairs. We developed a sociotechnical system—Code Enforcer—to help this office guide immigrant residents through successfully engaging the city's code enforcement process. To inform the design process, we adapted our framework of trust-as-distance. While the framework was instrumental for integrating issues of trust throughout our design process, it also introduced tensions between how and by whom trust was enacted and interpreted. By reflecting on these tensions, we tease out the political and moral elements of designing with trust vital for HCI to navigate moving forward.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {173},
numpages = {17},
keywords = {Civic Technology, Digital Civics, Smart Cities, Trust, Democracy},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445340,
author = {Tu, Huawei and Huang, Jin and Liang, Hai-Ning and Skarbez, Richard and Tian, Feng and Duh, Henry Been-Lirn},
title = {Distractor Effects on Crossing-Based Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445340},
doi = {10.1145/3411764.3445340},
abstract = {Task-irrelevant distractors affect visuo-motor control for target acquisition and studying such effects has already received much attention in human-computer interaction. However, there has been little research into distractor effects on crossing-based interaction. We thus conducted an empirical study on pen-based interfaces to investigate six crossing tasks with distractor interference in comparison to two tasks without it. The six distractor-related tasks differed in movement precision constraint (directional/amplitude), target size, target distance, distractor location and target-distractor spacing. We also developed and experimentally validated six quantitative models for the six tasks. Our results show that crossing targets with distractors had longer average times and similar accuracy than that without distractors. The effects of distractors varied depending on distractor location, target-distractor spacing and movement precision constraint. When spacing is smaller than 11.27 mm, crossing tasks with distractor interference can be regarded as pointing tasks or a combination of pointing and crossing tasks, which could be better fitted with our proposed models than Fitts’ law. According to these results, we provide practical implications to crossing-based user interface design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {192},
numpages = {13},
keywords = {distractor effects, models., Crossing, pointing, Fitts’ law},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445339,
author = {Arakawa, Riku and Yakura, Hiromu},
title = {Mindless Attractor: A False-Positive Resistant Intervention for Drawing Attention Using Auditory Perturbation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445339},
doi = {10.1145/3411764.3445339},
abstract = {Explicitly alerting users is not always an optimal intervention, especially when they are not motivated to obey. For example, in video-based learning, learners who are distracted from the video would not follow an alert asking them to pay attention. Inspired by the concept of Mindless Computing, we propose a novel intervention approach, Mindless Attractor, that leverages the nature of human speech communication to help learners refocus their attention without relying on their motivation. Specifically, it perturbs the voice in the video to direct their attention without consuming their conscious awareness. Our experiments not only confirmed the validity of the proposed approach but also emphasized its advantages in combination with a machine learning-based sensing module. Namely, it would not frustrate users even though the intervention is activated by false-positive detection of their attentive state. Our intervention approach can be a reliable way to induce behavioral change in human–AI symbiosis.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {99},
numpages = {15},
keywords = {Video-based learning, Human attention, Computational intervention, Mindless computing, Machine learning-based sensing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445328,
author = {\c{C}er\c{c}i, Sena and E. Cecchinato, Marta and Vines, John},
title = {How Design Researchers Interpret Probes: Understanding the Critical Intentions of a Designerly Approach to Research},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445328},
doi = {10.1145/3411764.3445328},
abstract = {Since entering the HCI lexicon in the 1990s, Probes have been interpreted and used in divergent ways as a designerly approach to research. While originally positioned as a critique of dominant user-research methods, literature on Probes rarely reflects on such critical dimensions nor explicitly articulates the intents of using Probes as research artifacts. We conducted interviews with 12 design researchers who have worked with Probes within diverse Research through Design projects, exploring direct accounts of how and why Probes are used in practice. Our interviews brought to the fore the critical concerns behind Probe practices in relation to the language of Probing, relationships with participants, and motivations to challenge normative practices. While the pluralistic interpretations of Probes offered by our participants brings challenges, we discuss how making visible the critical motivations of our research opens up new ways of practicing and disseminating Probes.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {624},
numpages = {15},
keywords = {Probes, design methods, Cultural Probes, Research through Design},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445327,
author = {Min Htike, Hein and H. Margrain, Tom and Lai, Yu-Kun and Eslambolchilar, Parisa},
title = {Augmented Reality Glasses as an Orientation and Mobility Aid for People with Low Vision: A Feasibility Study of Experiences and Requirements},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445327},
doi = {10.1145/3411764.3445327},
abstract = {People with low vision experience reduced mobility that affects their physical and mental wellbeing. With augmented reality (AR) glasses, there are new opportunities to provide visual and auditory information that can improve mobility for this vulnerable group. Current research into AR-based mobility aids has focused mainly on the technical aspects, and less emphasis has been placed on understanding the usability and suitability of these aids in people with various levels of visual impairment. In this paper, we present the results of qualitative interviews with 18 participants using HoloLens v1 and eight prototype augmentations to understand how these enhancements are perceived by people with low vision and how these aids should be adjusted to suit their needs. Our results suggested that participants with moderate vision loss could potentially perceive the most benefit from glasses and underlined the importance of extensive customizability to accommodate the needs of a highly varied low vision population.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {729},
numpages = {15},
keywords = {augmented reality, mobility aids, low vision, vision enhancement},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445319,
author = {Di Luca, Massimiliano and Seifi, Hasti and Egan, Simon and Gonzalez-Franco, Mar},
title = {Locomotion Vault: The Extra Mile in Analyzing VR Locomotion Techniques},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445319},
doi = {10.1145/3411764.3445319},
abstract = {Numerous techniques have been proposed for locomotion in virtual reality (VR). Several taxonomies consider a large number of attributes (e.g., hardware, accessibility) to characterize these techniques. However, finding the appropriate locomotion technique (LT) and identifying gaps for future designs in the high-dimensional space of attributes can be quite challenging. To aid analysis and innovation, we devised Locomotion Vault (https://locomotionvault.github.io/), a database and visualization of over 100 LTs from academia and industry. We propose similarity between LTs as a metric to aid navigation and visualization. We show that similarity based on attribute values correlates with expert similarity assessments (a method that does not scale). Our analysis also highlights an inherent trade-off between simulation sickness and accessibility across LTs. As such, Locomotion Vault shows to be a tool that unifies information on LTs and enables their standardization and large-scale comparison to help understand the space of possibilities in VR locomotion.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {128},
numpages = {10},
keywords = {locomotion method, visualization, VR, navigation, traveling, locomotion technique, movement, database},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445296,
author = {Ross, Andrew and Chen, Nina and Hang, Elisa Zhao and Glassman, Elena L. and Doshi-Velez, Finale},
title = {Evaluating the Interpretability of Generative Models by Interactive Reconstruction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445296},
doi = {10.1145/3411764.3445296},
abstract = {For machine learning models to be most useful in numerous sociotechnical systems, many have argued that they must be human-interpretable. However, despite increasing interest in interpretability, there remains no firm consensus on how to measure it. This is especially true in representation learning, where interpretability research has focused on “disentanglement” measures only applicable to synthetic datasets and not grounded in human factors. We introduce a task to quantify the human-interpretability of generative model representations, where users interactively modify representations to reconstruct target instances. On synthetic datasets, we find performance on this task much more reliably differentiates entangled and disentangled models than baseline approaches. On a real dataset, we find it differentiates between representation learning methods widely believed but never shown to produce more or less interpretable models. In both cases, we ran small-scale think-aloud studies and large-scale experiments on Amazon Mechanical Turk to confirm that our qualitative and quantitative results agreed.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {80},
numpages = {15},
keywords = {interpretability, representation learning, evaluation methods},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445290,
author = {Morrison, Cecily and Cutrell, Edward and Grayson, Martin and Thieme, Anja and Taylor, Alex and Roumen, Geert and Longden, Camilla and Tschiatschek, Sebastian and Faia Marques, Rita and Sellen, Abigail},
title = {Social Sensemaking with AI: Designing an Open-Ended AI Experience with a Blind Child},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445290},
doi = {10.1145/3411764.3445290},
abstract = {AI technologies are often used to aid people in performing discrete tasks with well-defined goals (e.g., recognising faces in images). Emerging technologies that provide continuous, real-time information enable more open-ended AI experiences. In partnership with a blind child, we explore the challenges and opportunities of designing human-AI interaction for a system intended to support social sensemaking. Adopting a research-through-design perspective, we reflect upon working with the uncertain capabilities of AI systems in the design of this experience. We contribute: (i) a concrete example of an open-ended AI system that enabled a blind child to extend his own capabilities; (ii) an illustration of the delta between imagined and actual use, highlighting how capabilities derive from the human-AI interaction and not the AI system alone; and (iii) a discussion of design choices to craft an ongoing human-AI interaction that addresses the challenge of uncertain outputs of AI systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {396},
numpages = {14},
keywords = {visual impairment, human-AI collaboration, children, Human-centred AI, human-AI interaction, accessibility, design, intelligent systems, disability, blindness},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445263,
author = {Leal, Debora de Castro and Strohmayer, Angelika and Kr\"{u}ger, Max},
title = {On Activism and Academia: Reflecting Together and Sharing Experiences Among Critical Friends},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445263},
doi = {10.1145/3411764.3445263},
abstract = {In recent years HCI and CSCW work has increasingly begun to address complex social problems and issues of social justice worldwide. Such activist-leaning work is not without problems. Through the experiences and reflections of an activist becoming academic and an academic becoming an activist, we outline these difficulties such as (1) the risk of perpetuating violence, oppression and exploitation when working with marginalised communities, (2) the reception of activist-academic work within our academic communities, and (3) problems of social justice that exist within our academic communities. Building on our own experiences, practices and existing literature from a variety of disciplines we advocate for the possibility of an activist-academic practice, outline possible ways forward and formulate questions we need to answer for HCI to contribute to a more just world.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {18},
keywords = {academic practice, activism, reflexivity, social justice},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445247,
author = {Tang, Kymeng and Gerling, Kathrin and Geurts, Luc and Spiel, Katta},
title = {Understanding the Role of Technology to Support Breastfeeding},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445247},
doi = {10.1145/3411764.3445247},
abstract = {Breastfeeding brings benefits for newborns and parents, but can be a challenging process. In this paper, we leverage a mixed-methods approach that builds on the Integrated Behavioural Model (IBM) to explore parents’ perspectives toward breastfeeding along with their lived experiences, and examine the role of technology in this setting. Results of twelve semi-structured interviews and 175 online survey responses suggest generally positive attitudes toward breastfeeding and good theoretical knowledge. This is combined with a complex lived experience of breastfeeding where main challenges are situated in practical, emotional, and environmental/societal aspects, which are currently not sufficiently recognised by technology that seeks to support breastfeeding. Building upon our findings, we present points for reflection for the design of technology to support breastfeeding, focusing on the importance of drawing from the lived experience of parents, and ensuring that technology not only casts breastfeeding as an individual but also as a collective effort.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {211},
numpages = {13},
keywords = {Breastfeeding, Integrated Behavioral Model},
location = {Yokohama, Japan},
series = {CHI '21}
}

