@inproceedings{10.1145/3313831.3376844,
author = {Karyda, Maria and Ry\"{o}ppy, Merja and Buur, Jacob and Lucero, Andr\'{e}s},
title = {Imagining Data-Objects for Reflective Self-Tracking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376844},
doi = {10.1145/3313831.3376844},
abstract = {While self-tracking data is typically captured real-time in a lived experience, the data is often stored in a manner detached from the context where it belongs. Research has shown that there is a potential to enhance people's lived experiences with data-objects (artifacts representing contextually relevant data), for individual and collective reflections through a physical portrayal of data. This paper expands that research by studying how to design contextually relevant data-objects based on people's needs. We conducted a participatory research project with five households using object theater as a core method to encourage participants to speculate upon combinations of meaningful objects and personal data archives. In this paper, we detail three aspects that seem relevant for designing data-objects: social sharing, contextual ambiguity and interaction with the body. We show how an experience-centric view on data-objects can contribute with the contextual, social and bodily interplay between people, data and objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {experience, data-objects, personal objects, object theater},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376838,
author = {Han, Changyo and Takahashi, Ryo and Yahagi, Yuchi and Naemura, Takeshi},
title = {PneuModule: Using Inflatable Pin Arrays for Reconfigurable Physical Controls on Pressure-Sensitive Touch Surfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376838},
doi = {10.1145/3313831.3376838},
abstract = {We present PneuModule, a tangible interface platform that enables users to reconfigure physical controls on pressure-sensitive touch surfaces using pneumatically-actuated inflatable pin arrays. PneuModule consists of a main module and extension modules. The main module is tracked on the touch surface and forwards continuous inputs from attached multiple extension modules to the touch surface. Extension modules have distinct mechanisms for user input, which pneumatically actuates the inflatable pins at the bottom of the main module through internal air pipes. The main module accepts multi-dimensional inputs since each pin is individually inflated by the corresponding air chamber. Also, since the extension modules are swappable and identifiable owing to the marker design, users can quickly customize the interface layout. We contribute to design details of inflatable pins and diverse pneumatic input control design examples for PneuModule. We also showcase the feasibility of PneuModule through a series of evaluations and interactive prototypes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tangible user interfaces, pneumatic actuation, pressure-sensitive touch surfaces, reconfigurable physical controls},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376835,
author = {Chen, Yan and Pandey, Maulishree and Song, Jean Y. and Lasecki, Walter S. and Oney, Steve},
title = {Improving Crowd-Supported GUI Testing with Structural Guidance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376835},
doi = {10.1145/3313831.3376835},
abstract = {Crowd testing is an emerging practice in Graphical User Interface (GUI) testing, where developers recruit a large number of crowd testers to test GUI features. It is often easier and faster than a dedicated quality assurance team, and its output is more realistic than that of automated testing. However, crowds of testers working in parallel tend to focus on a small set of commonly-used User Interface (UI) navigation paths, which can lead to low test coverage and redundant effort. In this paper, we introduce two techniques to increase crowd testers' coverage: interactive event-flow graphs and GUI-level guidance. The interactive event-flow graphs track and aggregate every tester's interactions into a single directed graph that visualizes the cases that have already been explored. Crowd testers can interact with the graphs to find new navigation paths and increase the coverage of the created tests. We also use the graphs to augment the GUI (GUI-level guidance) to help testers avoid only exploring common paths. Our evaluation with 30 crowd testers on 11 different test pages shows that the techniques can help testers avoid redundant effort while also increasing untrained testers' coverage by 55%. These techniques can help us develop more robust software that works in more mission-critical settings not only by performing more thorough testing with the same effort that has been put in before but also by integrating them into different parts of the development pipeline to make more reliable software in the early development stage.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {GUI testing, crowdsourcing, software testing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376833,
author = {Stowell, Elizabeth and O'Leary, Teresa K. and Kimani, Everlyne and Paasche-Orlow, Michael K. and Bickmore, Timothy and Parker, Andrea G.},
title = {Investigating Opportunities for Crowdsourcing in Church-Based Health Interventions: A Participatory Design Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376833},
doi = {10.1145/3313831.3376833},
abstract = {Churches play a major role in providing social support to address health inequities within Black communities, in part by connecting members to key organizations and services. While public health has a history of disseminating interventions in faith communities, little work has explored the use of crowdsourcing to tailor interventions to the unique culture of each church community. Following Community Based Participatory Research principles, we partnered with two predominantly Black churches, and report on a series of three participatory design sessions with nine participants. We developed a novel storyboarding method to explore how crowdsourcing could promote health in these faith-based communities. Our findings characterize existing supports within the church community, and how church social structures impact member access to these supports. We further identify motivations to engage with a church-situated health application, and how these motivations translate to crowdsourcing tasks. Finally, we discuss considerations for public health crowdsourcing tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {african-american, crowdsourcing, faith-based communities, participatory design, health promotion, mhealth},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376799,
author = {Newman, Anelise and McNamara, Barry and Fosco, Camilo and Zhang, Yun Bin and Sukhum, Pat and Tancik, Matthew and Kim, Nam Wook and Bylinskii, Zoya},
title = {TurkEyes: A Web-Based Toolbox for Crowdsourcing Attention Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376799},
doi = {10.1145/3313831.3376799},
abstract = {Eye movements provide insight into what parts of an image a viewer finds most salient, interesting, or relevant to the task at hand. Unfortunately, eye tracking data, a commonly-used proxy for attention, is cumbersome to collect. Here we explore an alternative: a comprehensive web-based toolbox for crowdsourcing visual attention. We draw from four main classes of attention-capturing methodologies in the literature. ZoomMaps is a novel zoom-based interface that captures viewing on a mobile phone. CodeCharts is a self-reporting methodology that records points of interest at precise viewing durations. ImportAnnots is an "annotation" tool for selecting important image regions, and cursor-based BubbleView lets viewers click to deblur a small area. We compare these methodologies using a common analysis framework in order to develop appropriate use cases for each interface. This toolbox and our analyses provide a blueprint for how to gather attention data at scale without an eye tracker.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {attention, crowdsourcing, eye tracking, interaction techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376794,
author = {Shin, Joon Gi and Kim, Doheon and So, Chaehan and Saakes, Daniel},
title = {Body Follows Eye: Unobtrusive Posture Manipulation Through a Dynamic Content Position in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376794},
doi = {10.1145/3313831.3376794},
abstract = {While virtual objects are likely to be a part of future interfaces, we lack knowledge of how the dynamic position of virtual objects influences users' posture. In this study, we investigated users' posture change following the unobtrusive and swift motions of a content window in virtual reality (VR). In two perception studies, we estimated the perception threshold on undetectable slow motions and displacement during an eye blink. In a formative study, we compared users' performance, posture change as well as subjective responses on unobtrusive, swift, and no motions. Based on the result, we designed concept applications and explored potential design space of moving virtual content for unobtrusive posture change. With our study, we discuss the interfaces that control users and the initial design guidelines of unobtrusive posture manipulation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {unobtrusive interaction, virtual reality, posture change},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376785,
author = {Kim, Soomin and Eun, Jinsu and Oh, Changhoon and Suh, Bongwon and Lee, Joonhwan},
title = {Bot in the Bunch: Facilitating Group Chat Discussion by Improving Efficiency and Participation with a Chatbot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376785},
doi = {10.1145/3313831.3376785},
abstract = {Although group chat discussions are prevalent in daily life, they have a number of limitations. When discussing in a group chat, reaching a consensus often takes time, members contribute unevenly to the discussion, and messages are unorganized. Hence, we aimed to explore the feasibility of a facilitator chatbot agent to improve group chat discussions. We conducted a needfinding survey to identify key features for a facilitator chatbot. We then implemented GroupfeedBot, a chatbot agent that could facilitate group discussions by managing the discussion time, encouraging members to participate evenly, and organizing members' opinions. To evaluate GroupfeedBot, we performed preliminary user studies that varied for diverse tasks and different group sizes. We found that the group with GroupfeedBot appeared to exhibit more diversity in opinions even though there were no differences in output quality and message quantity. On the other hand, GroupfeedBot promoted members' even participation and effective communication for the medium-sized group.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {group chat, discussion, conversational agent, consensus, online communication, chatbot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376773,
author = {Eschler, Jordan and Burgess, Eleanor R. and Reddy, Madhu and Mohr, David C.},
title = {Emergent Self-Regulation Practices in Technology and Social Media Use of Individuals Living with Depression},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376773},
doi = {10.1145/3313831.3376773},
abstract = {Much human-computer interaction work related to depression focuses on the population level (e.g., studying social media hashtags related to depression) or evaluates prototypes for digital interventions to manage depression. However, little is known about how people living with depression perceive and manage technology use, such as time spent on social media per day. For this study, we interviewed 30 individuals living with depression to explore their technology and social media use. We find that these individuals demonstrated emergent practices related to self-regulation, such as learning to monitor and adjust technology use to improve their emotional, cognitive, and behavioral health. Our findings add a human-centered viewpoint to the relationship between living with depression and technology and social media use. We present design implications of these findings for better empowering individuals with depression to encourage their natural inclinations to self-regulate technology and social media use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {self-regulation, qualitative, depression, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376771,
author = {Zhu, Suwen and Kim, Yoonsang and Zheng, Jingjie and Luo, Jennifer Yi and Qin, Ryan and Wang, Liuping and Fan, Xiangmin and Tian, Feng and Bi, Xiaojun},
title = {Using Bayes' Theorem for Command Input: Principle, Models, and Applications},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376771},
doi = {10.1145/3313831.3376771},
abstract = {Entering commands on touchscreens can be noisy, but existing interfaces commonly adopt deterministic principles for deciding targets and often result in errors. Building on prior research of using Bayes' theorem to handle uncertainty in input, this paper formalized Bayes' theorem as a generic guiding principle for deciding targets in command input (referred to as "BayesianCommand"), developed three models for estimating prior and likelihood probabilities, and carried out experiments to demonstrate the effectiveness of this formalization. More specifically, we applied BayesianCommand to improve the input accuracy of (1) point-and-click and (2) word-gesture command input. Our evaluation showed that applying BayesianCommand reduced errors compared to using deterministic principles (by over 26.9% for point-and-click and by 39.9% for word-gesture command input) or applying the principle partially (by over 28.0% and 24.5%).},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {bayes' theorem, touchscreen, word-gesture shortcuts, command input, point-and-click},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376770,
author = {Salminen, Joni and Jung, Soon-Gyo and Chowdhury, Shammur and Seng\"{u}n, Sercan and Jansen, Bernard J.},
title = {Personas and Analytics: A Comparative User Study of Efficiency and Effectiveness for a User Identification Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376770},
doi = {10.1145/3313831.3376770},
abstract = {Personas are a well-known technique in human computer interaction. However, there is a lack of rigorous empirical research evaluating personas relative to other methods. In this 34-participant experiment, we compare a persona system and an analytics system, both using identical user data, for efficiency and effectiveness for a user identification task. Results show that personas afford faster task completion than the analytics system, as well as outperforming analytics with significantly higher user identification accuracy. Qualitative analysis of think-aloud transcripts shows that personas have other benefits regarding learnability and consistency. However, the analytics system affords insights and capabilities that personas cannot due to inherent design differences. Findings support the use of personas to learn about users, empirically confirming some of the stated benefits in the literature, while also highlighting the limitations of personas that may necessitate the use of accompanying methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personas, mixed methods, analytics systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376746,
author = {Bae, Suyun Sandra and Kwon, Oh-Hyun and Chandrasegaran, Senthil and Ma, Kwan-Liu},
title = {Spinneret: Aiding Creative Ideation through Non-Obvious Concept Associations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376746},
doi = {10.1145/3313831.3376746},
abstract = {Mind mapping is a popular way to explore a design space in creative thinking exercises, allowing users to form associations between concepts. Yet, most existing digital tools for mind mapping focus on authoring and organization, with little support for addressing the challenges of mind mapping such as stagnation and design fixation. We present Spinneret, a functional approach to aid mind mapping by providing suggestions based on a knowledge graph. Spinneret uses biased random walks to explore the knowledge graph in the neighborhood of an existing concept node in the mind map, and provides "suggestions" for the user to add to the mind map. A comparative study with a baseline mind-mapping tool reveals that participants created more diverse and distinct concepts with Spinneret, and reported that the suggestions inspired them to think of ideas they would otherwise not have explored.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {suggestion, knowledge graph, mind mapping, creativity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376736,
author = {Okuya, Yujiro and Gladin, Olivier and Ladev\`{e}ze, Nicolas and Fleury, C\'{e}dric and Bourdot, Patrick},
title = {Investigating Collaborative Exploration of Design Alternatives on a Wall-Sized Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376736},
doi = {10.1145/3313831.3376736},
abstract = {Industrial design review is an iterative process which mainly relies on two steps involving many stakeholders: design discussion and CAD data adjustment. We investigate how a wall-sized display could be used to merge these two steps by allowing multidisciplinary collaborators to simultaneously generate and explore design alternatives. We designed ShapeCompare based on the feedback from a usability study. It enables multiple users to compute and distribute CAD data with touch interaction. To assess the benefit of the wall-sized display in such context, we ran a controlled experiment which aims to compare ShapeCompare with a visualization technique suitable for standard screens. The results show that pairs of participants performed a constraint solving task faster and used more deictic instructions with ShapeCompare. From these findings, we draw generic recommendations for collaborative exploration of alternatives.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {wall-sized display, collaboration, computer-aided design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376728,
author = {Gleason, Cole and Pavel, Amy and McCamey, Emma and Low, Christina and Carrington, Patrick and Kitani, Kris M. and Bigham, Jeffrey P.},
title = {Twitter A11y: A Browser Extension to Make Twitter Images Accessible},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376728},
doi = {10.1145/3313831.3376728},
abstract = {Social media platforms are integral to public and private discourse, but are becoming less accessible to people with vision impairments due to an increase in user-posted images. Some platforms (i.e. Twitter) let users add image descriptions (alternative text), but only 0.1% of images include these. To address this accessibility barrier, we created Twitter A11y, a browser extension to add alternative text on Twitter using six methods. For example, screenshots of text are common, so we detect textual images, and create alternative text using optical character recognition. Twitter A11y also leverages services to automatically generate alternative text or reuse them from across the web. We compare the coverage and quality of Twitter A11y's six alt-text strategies by evaluating the timelines of 50 self-identified blind Twitter users. We find that Twitter A11y increases alt-text coverage from 7.6% to 78.5%, before crowdsourcing descriptions for the remaining images. We estimate that 57.5% of returned descriptions are high-quality. We then report on the experiences of 10 participants with visual impairments using the tool during a week-long deployment. Twitter A11y increases access to social media platforms for people with visual impairments by providing high-quality automatic descriptions for user-posted images.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social media, twitter, accessibility, screen reader},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376727,
author = {Long, Duri and Magerko, Brian},
title = {What is AI Literacy? Competencies and Design Considerations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376727},
doi = {10.1145/3313831.3376727},
abstract = {Artificial intelligence (AI) is becoming increasingly integrated in user-facing technology, but public understanding of these technologies is often limited. There is a need for additional HCI research investigating a) what competencies users need in order to effectively interact with and critically evaluate AI and b) how to design learner-centered AI technologies that foster increased user understanding of AI. This paper takes a step towards realizing both of these goals by providing a concrete definition of AI literacy based on existing research. We synthesize a variety of interdisciplinary literature into a set of core competencies of AI literacy and suggest several design considerations to support AI developers and educators in creating learner-centered AI. These competencies and design considerations are organized in a conceptual framework thematically derived from the literature. This paper's contributions can be used to start a conversation about and guide future research on AI literacy within the HCI community.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {machine learning, AI education, AI for K-12, artificial intelligence, AI literacy, computing education},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376726,
author = {Wang, Xingbo and Zeng, Haipeng and Wang, Yong and Wu, Aoyu and Sun, Zhida and Ma, Xiaojuan and Qu, Huamin},
title = {VoiceCoach: Interactive Evidence-Based Training for Voice Modulation Skills in Public Speaking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376726},
doi = {10.1145/3313831.3376726},
abstract = {The modulation of voice properties, such as pitch, volume, and speed, is crucial for delivering a successful public speech. However, it is challenging to master different voice modulation skills. Though many guidelines are available, they are often not practical enough to be applied in different public speaking situations, especially for novice speakers. We present VoiceCoach, an interactive evidence-based approach to facilitate the effective training of voice modulation skills. Specifically, we have analyzed the voice modulation skills from 2623 high-quality speeches (i.e., TED Talks) and use them as the benchmark dataset. Given a voice input, VoiceCoach automatically recommends good voice modulation examples from the dataset based on the similarity of both sentence structures and voice modulation skills. Immediate and quantitative visual feedback is provided to guide further improvement. The expert interviews and the user study provide support for the effectiveness and usability of VoiceCoach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice modulation, public speaking, evidence-based training, data visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376720,
author = {B\"{u}ttner, Sebastian and Prilla, Michael and R\"{o}cker, Carsten},
title = {Augmented Reality Training for Industrial Assembly Work - Are Projection-Based AR Assistive Systems an Appropriate Tool for Assembly Training?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376720},
doi = {10.1145/3313831.3376720},
abstract = {Augmented Reality (AR) systems are on their way to industrial application, e.g. projection-based AR is used to enhance assembly work. Previous studies showed advantages of the systems in permanent-use scenarios, such as faster assembly times. In this paper, we investigate whether such systems are suitable for training purposes. Within an experiment, we observed the training with a projection-based AR system over multiple sessions and compared it with a personal training and a paper manual training. Our study shows that projection-based AR systems offer only small benefits in the training scenario. While a systematic mislearning of content is prevented through immediate feedback, our results show that the AR training does not reach the personal training in terms of speed and recall precision after 24 hours. Furthermore, we show that once an assembly task is properly trained, there are no differences in the long-term recall precision, regardless of the training method.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {empirical study, assistive system, industrial augmented reality, experiment, training, projection-based augmented reality, assembly},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376717,
author = {Dillahunt, Tawanna R. and Hsiao, Joey Chiao-Yin},
title = {Positive Feedback and Self-Reflection: Features to Support Self-Efficacy among Underrepresented Job Seekers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376717},
doi = {10.1145/3313831.3376717},
abstract = {Technologies play a key role in finding employment in today's job market. However, the majority of those who are unemployed, e.g., individuals who have limited education or who are racial and ethnic minorities, are not well supported by existing digital employment tools. Therefore, we conducted an 8-month randomized field experiment to evaluate two tools-Review-Me and Interview4-designed to address these job seekers' key employment needs. We used the Theory of Planned Behavior to examine the tools' effects on three factors influencing job seekers' job search intention: job search self-efficacy, subjective norms, and job search attitudes. Our interview data suggested that the tools positively affected all factors, but our survey results were mixed. Interview results suggest that these trends were caused by positive feedback and self-reflection. We contribute ways to integrate these two features into future tools for, and techniques to increase study retention among, underrepresented job seekers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {employment, theory of planned behavior, underrepresented job seekers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376712,
author = {Arimatsu, Kazuyuki and Mori, Hideki},
title = {Evaluation of Machine Learning Techniques for Hand Pose Estimation on Handheld Device with Proximity Sensor},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376712},
doi = {10.1145/3313831.3376712},
abstract = {Tracking finger movement for natural interaction using hand is commonly studied. For vision-based implementations of finger tracking in virtual reality (VR) application, finger movement is occluded by a handheld device which is necessary for auxiliary input, thus tracking finger movement using cameras is still challenging. Finger tracking controllers using capacitive proximity sensors on the surface are starting to appear. However, research on estimating articulated hand pose from curved capacitance sensing electrodes is still immature. Therefore, we built a prototype with 62 electrodes and recorded training datasets using an optical tracking system. We have introduced 2.5D representation to apply convolutional neural network methods on a capacitive image of the curved surface, and two types of network architectures based on recent achievements in the computer vision field were evaluated with our dataset. We also implemented real-time interactive applications using the prototype and demonstrated the possibility of intuitive interaction using fingers in VR applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human computer interactiton, hand pose estimation, capacitive image, finger tracking controller, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376710,
author = {Laschke, Matthias and Braun, Christoph and Neuhaus, Robin and Hassenzahl, Marc},
title = {Meaningful Technology at Work - A Reflective Design Case of Improving Radiologists' Wellbeing Through Medical Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376710},
doi = {10.1145/3313831.3376710},
abstract = {In radiology, medical technology providers (MTP) focus mainly on technology-related issues, such as image quality or efficiency of reporting. Broader notions of radiology as "meaningful work" are largely seen as out of scope for an MTP. The present paper challenges this. In a real-world case with a large MTP, we showed that medical technology could be designed more holistically to explicitly improve radiologists' wellbeing. We first gathered work practices experienced as especially conducive to wellbeing. From there, we distilled ideal practices to increase wellbeing and turned them into two software applications. The MTP's initial skepticism dissolved, while radiologists unanimously emphasized wellbeing and demonstrated how they work towards improving it. Based on our insights, the applications resonated well among the radiologists involved, the healthcare provider, and other customers of the MTP. We close with a critical reflection of the challenges and opportunities of designing wellbeing-driven technology in the work domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {job design, technology at work, practice-based, wellbeing-driven design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376705,
author = {Maekawa, Azumi and Matsubara, Seito and Wakisaka, Sohei and Uriu, Daisuke and Hiyama, Atsushi and Inami, Masahiko},
title = {Dynamic Motor Skill Synthesis with Human-Machine Mutual Actuation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376705},
doi = {10.1145/3313831.3376705},
abstract = {This paper presents an approach for coupling robotic capability with human ability in dynamic motor skills, called "Human-Machine Mutual Actuation (HMMA)." We focus specifically on throwing motions and propose a method to control the release timing computationally. A system we developed achieves our concept, HMMA, by a robotic handheld device that acts as a release controller. We conducted user studies to validate the feasibility of the concept and clarify related technical issues to be tackled. We recognized that the system successfully performs on throwing according to the target while it exploits human ability. These empirical experiments suggest that robotic capability can be embedded into the users' motions without losing their senses of control. Throughout the user study, we also revealed several issues to be tackled in further research contributing to HMMA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {robotic device, motor skill, human augmentation, human-machine mutual actuation, motion sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376701,
author = {Cheema, Noshaba and Frey-Law, Laura A. and Naderi, Kourosh and Lehtinen, Jaakko and Slusallek, Philipp and H\"{a}m\"{a}l\"{a}inen, Perttu},
title = {Predicting Mid-Air Interaction Movements and Fatigue Using Deep Reinforcement Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376701},
doi = {10.1145/3313831.3376701},
abstract = {A common problem of mid-air interaction is excessive arm fatigue, known as the "Gorilla arm" effect. To predict and prevent such problems at a low cost, we investigate user testing of mid-air interaction without real users, utilizing biomechanically simulated AI agents trained using deep Reinforcement Learning (RL). We implement this in a pointing task and four experimental conditions, demonstrating that the simulated fatigue data matches human fatigue data. We also compare two effort models: 1) instantaneous joint torques commonly used in computer animation and robotics, and 2) the recent Three Compartment Controller (3CC-) model from biomechanical literature. 3CC- yields movements that are both more efficient and relaxed, whereas with instantaneous joint torques, the RL agent can easily generate movements that are quickly tiring or only reach the targets slowly and inaccurately. Our work demonstrates that deep RL combined with the 3CC- provides a viable tool for predicting both interaction movements and user experiencein silico, without users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user modeling, biomechanical simulation, computational interaction, reinforcement learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376699,
author = {Ding, Xianghua and Gui, Xinning and Ma, Xiaojuan and Ding, Zhaofei and Chen, Yunan},
title = {Getting the Healthcare We Want: The Use of Online "Ask the Doctor" Platforms in Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376699},
doi = {10.1145/3313831.3376699},
abstract = {Online Ask the Doctor (AtD) services allow access to health professionals anytime anywhere beyond existing patient-provider relationships. Recently, many free-market AtD platforms have emerged and been adopted by a large scale of users. However, it is still unclear how people make use of these AtD platforms in practice. In this paper, we present an interview study with 12 patients/caregivers who had experience using AtD in China, highlighting patient agency in seeking more reliable and cost-effective healthcare beyond clinic settings. Specifically, we illustrate how they make strategic choices online on AtD platforms, and how they strategically integrate online and offline services together for healthcare. This paper contributes an empirical study of the use of large-scale AtD platforms in practice, demonstrates patient agency for healthcare beyond clinic settings, and recommends design implications for online healthcare services.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online healthcare services, ask the doctor services, patient agency, healthcare navigation, AtD, healthcare engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376690,
author = {Ahmad, Wajeeha and Liccardi, Ilaria},
title = {Addressing Anonymous Abuses: Measuring the Effects of Technical Mechanisms on Reported User Behaviors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376690},
doi = {10.1145/3313831.3376690},
abstract = {Anonymous networks intended to enhance privacy and evade censorship are also being exploited for abusive activities. Technical schemes have been proposed to selectively revoke the anonymity of abusive users, or simply limit them from anonymously accessing online service providers. We designed an empirical survey study to assess the effects of deploying these schemes on 75 users of the Tor anonymous network. We evaluated proposed schemes based on examples of the intended or abusive use cases they may address, their technical implementation and the types of entities responsible for enforcing them. Our results show that revocable anonymity schemes would particularly deter the intended uses of anonymous networks. We found a lower reported decrease in usage for schemes addressing spam than those directly compromising free expression. However, participants were concerned that all technical mechanisms for addressing anonymous abuses could be exploited beyond their intended goals (51.7%) to harm users (43.8%). Participants were distrustful of the enforcing entities involved (43.8%) and concerned about being unable to verify (49.3%) how particular mechanisms were applied.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {empirical study, abuse, trust, tor, anonymous networks},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376689,
author = {Claisse, Caroline and Petrelli, Daniela and Ciolfi, Luigina and Dulake, Nick and Marshall, Mark T. and Durrant, Abigail C.},
title = {Crafting Critical Heritage Discourses into Interactive Exhibition Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376689},
doi = {10.1145/3313831.3376689},
abstract = {This paper argues how a more reflective design practice that embraces critical discourses can transform interactive exhibition design and therefore the museum visiting experience. Four framing arguments underpin our exhibition design making: the value of materiality, visiting as an aesthetic experience, challenging the authorized voice, and heritage as a process. These arguments were embodied through design, art and craft practice into one interactive exhibition at a house museum. We draw from our design process discussing the implications that adopting an approach informed by critical heritage debates has on exhibition design and suggest three sensitizing concepts (polyvocal narratives, dialogical interaction, interweaving time and space) bridging the practice of interactive exhibition design and critical heritage theory.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {exhibition design, craft practice, reflective practice, tangible interaction, critical heritage},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376673,
author = {Fu, Xinyi and Zhu, Yaxin and Xiao, Zhijing and Xu, Yingqing and Ma, Xiaojuan},
title = {RestoreVR: Generating Embodied Knowledge and Situated Experience of Dunhuang Mural Conservation via Interactive Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376673},
doi = {10.1145/3313831.3376673},
abstract = {In Dunhuang Mogao Grottoes, unique Buddhist murals of ancient China are preserved. Unfortunately, the exquisite murals are suffering from degradation. Experts have been trying to enhance public's awareness of mural protection, but there's no efficacious means to attract interest and popularize knowledge yet. In this paper, we propose RestoreVR, an interactive virtual reality (VR) system engaging users to experience Dunhuang mural restoration in a digital tour in the cave. Based on an online survey with the public and in-depth interviews with five Dunhuang experts, we derive a set of design requirements for generating embodied knowledge and situated experience in VR to bridge the gap between highly specialized experts and general audiences. Accordingly, we design RestoreVR and conduct a between-subjects user study to compare our system with traditional methods. The results suggest that RestoreVR significantly improves user experience and awareness of CH protection over existing methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {implementation, mural conservation, dunhuang, interactive virtual reality, survey, cultural heritage},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376666,
author = {Masaki, Hiroaki and Shibata, Kengo and Hoshino, Shui and Ishihama, Takahiro and Saito, Nagayuki and Yatani, Koji},
title = {Exploring Nudge Designs to Help Adolescent SNS Users Avoid Privacy and Safety Threats},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376666},
doi = {10.1145/3313831.3376666},
abstract = {A nudge is a method to influence individual choices without taking away freedom of choice. We are interested in whether nudges can help adolescents avoid privacy and safety threats on social network services (SNS). We conducted an online survey to compare how 11 different nudge designs influence decisions on 9 scenarios featuring various privacy and safety threats. We collected 29,608 responses from adolescent SNS users (self-claimed high school and university students), and found that nudges can help to educe potentially risk choices. Participants were more likely to avoid potentially risky choices when presented with negative frames (e.g., "90% of users would not share a photo without permission'') than affirmative ones (e.g., "10% of users would''). Social nudges displaying statistics on how likely other people would make potentially risky decisions can have a negative effect in comparison to a nudge with only general privacy and safety suggestions. We conclude by providing design considerations for privacy/safety nudges targeting adolescent SNS users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {social nudges, online privacy and safety, large-scale survey, adolescent sns users},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376660,
author = {Cila, Nazli and Ferri, Gabriele and de Waal, Martijn and Gloerich, Inte and Karpinski, Tara},
title = {The Blockchain and the Commons: Dilemmas in the Design of Local Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376660},
doi = {10.1145/3313831.3376660},
abstract = {This paper addresses the design dilemmas that arise when distributed ledger technologies (DLT) are to be applied in the governance of artificial material commons. DLTs, such as blockchain, are often presented as enabling technologies for self-governing communities, provided by their consensus mechanisms, transparent administration, and incentives for collaboration and cooperation. Yet, these affordances may also undermine public values such as privacy and displace human agency in governance procedures. In this paper, the conflicts regarding the governance of communities which collectively manage and produce a commons are discussed through the case of a fictional energy community. Three mechanisms are identified in this process: tracking use of and contributions to the commons; managing resources, and negotiating the underlying rule sets and user rights. Our effort is aimed at contributing to the HCI community by introducing a framework of three mechanisms and six design dilemmas that can aid in balancing conflicting values in the design of local platforms for commons-based resource management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {platformization, energy community, blockchain, design dilemmas, commons, governance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376636,
author = {Sabie, Dina and Sabie, Samar and Ahmed, Syed Ishtiaque},
title = {Memory through Design: Supporting Cultural Identity for Immigrants through a Paper-Based Home Drafting Tool},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376636},
doi = {10.1145/3313831.3376636},
abstract = {Current research in HCI with immigrants predominantly focuses on their practical needs and little attention is given to their cultural identities. As such, we aim to understand how newcomers reflect their cultural values within domestic settings. We explore this by provoking memories immigrants associate with physical spaces inside their homes. Hence, we built "Our Home Sketcher": a paper-based home drafting tool that allows novice users to design their homes by sketching and implicitly expressing their space, light, and privacy preferences. The collected drawings are then fed into a computer algorithm that produces 3D models of the sketched houses. This process of design acts as an artifact-driven storytelling for heritage sharing and rapport building within migrant communities. We engage 13 Middle Eastern newcomers in Canada with the tool and use Halbwachs' [44] theory of collective memory to frame how home sketching provokes former experiences. Our findings show a strong longing for reclaiming the past, narrating space-related oral history, and designing beyond current limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {culture, hci, house design, ictd, immigrants, memory, 2d sketching},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376634,
author = {Kow, Yong Ming and Nardi, Bonnie and Cheng, Wai Kuen},
title = {Be Water: Technologies in the Leaderless Anti-ELAB Movement in Hong Kong},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376634},
doi = {10.1145/3313831.3376634},
abstract = {We examine a leaderless social movement characterized by participants' autonomy and the absence of leaders and organizations. We conducted a participant observation study of the Anti-ELAB movement in Hong Kong. Focusing on the organization of a protest march, we collected thousands of lines of discourse in the LIHKG Forum and the Telegram instant messaging system. Our grounded theory analysis revealed hundreds of groups acting within a symbiotic network. Participants promoted an ethos of empowering individual participants and groups to act autonomously. At the same time, participants' extensive use of hyperlinks and polls orchestrated a coherent social movement. We discuss how this novel formation can mediate successful leaderless movements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ethnography, hong kong, leaderless social movement, anti-elab},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376627,
author = {Hodge, James and Foley, Sarah and Brankaert, Rens and Kenning, Gail and Lazar, Amanda and Boger, Jennifer and Morrissey, Kellie},
title = {Relational, Flexible, Everyday: Learning from Ethics in Dementia Research},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376627},
doi = {10.1145/3313831.3376627},
abstract = {Engaging in participatory research in HCI raises numerous ethical complexities such as consent, researcher relationships, and participant compensation. Doing HCI work in the area of dementia amplifies these issues, and researchers in this area are modelling ethical stances to ensure researcher-participant relationships focus on meaningful engagement and care. This paper presents an insight into the kinds of ethical foci required when doing design research with people living with dementia and their carers. We interviewed 22 HCI researchers with experience working in dementia care contexts. Our qualitative analysis outlines subsequent lessons-learned, such as recognition of the participants, self-care, research impact, and subjectivity in ethical review boards. Furthermore, we found the complexity of navigating both "everyday" and more formal, institutional ethics in dementia research has implications beyond the context of working with people with dementia and outline key considerations for ethical practices in socially orientated HCI research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {ethics, care, emotion, relational, lived experience, dementia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376626,
author = {von Willich, Julius and Schmitz, Martin and M\"{u}ller, Florian and Schmitt, Daniel and M\"{u}hlh\"{a}user, Max},
title = {Podoportation: Foot-Based Locomotion in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376626},
doi = {10.1145/3313831.3376626},
abstract = {Virtual Reality (VR) allows for infinitely large environments. However, the physical traversable space is always limited by real-world boundaries. This discrepancy between physical and virtual dimensions renders traditional locomotion methods used in real world unfeasible. To alleviate these limitations, research proposed various artificial locomotion concepts such as teleportation, treadmills, and redirected walking. However, these concepts occupy the user's hands, require complex hardware or large physical spaces. In this paper, we contribute nine VR locomotion concepts for foot-based locomotion, relying on the 3D position of the user's feet and the pressure applied to the sole as input modalities. We evaluate our concepts and compare them to state-of-the-art point &amp; teleport technique in a controlled experiment with 20 participants. The results confirm the viability of our approaches for foot-based and engaging locomotion. Further, based on the findings, we contribute a wireless hardware prototype implementation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {foot-based input, virtual reality, locomotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376624,
author = {Smith-Renner, Alison and Fan, Ron and Birchfield, Melissa and Wu, Tongshuang and Boyd-Graber, Jordan and Weld, Daniel S. and Findlater, Leah},
title = {No Explainability without Accountability: An Empirical Study of Explanations and Feedback in Interactive ML},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376624},
doi = {10.1145/3313831.3376624},
abstract = {Automatically generated explanations of how machine learning (ML) models reason can help users understand and accept them. However, explanations can have unintended consequences: promoting over-reliance or undermining trust. This paper investigates how explanations shape users' perceptions of ML models with or without the ability to provide feedback to them: (1) does revealing model flaws increase users' desire to "fix" them; (2) does providing explanations cause users to believe - wrongly - that models are introspective, and will thus improve over time. Through two controlled experiments - varying model quality - we show how the combination of explanations and user feedback impacted perceptions, such as frustration and expectations of model improvement. Explanations without opportunity for feedback were frustrating with a lower quality model, while interactions between explanation and feedback for the higher quality model suggest that detailed feedback should not be requested without explanation. Users expected model correction, regardless of whether they provided feedback or received explanations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive machine learning, explainable machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376620,
author = {Waern, Annika and Rajkowska, Paulina and Johansson, Karin B. and Bac, Jon and Spence, Jocelyn and L\o{}vlie, Anders Sundnes},
title = {Sensitizing Scenarios: Sensitizing Designer Teams to Theory},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376620},
doi = {10.1145/3313831.3376620},
abstract = {Concepts and theories that emerge within the social sciences tend to be nuanced, dealing with complex social phenomena. While their relevance to design could be high, it is difficult to make sense of them in design projects, especially when participants have a variety of backgrounds. We report on our experiences using role-play scenarios as a way to sensitize heterogeneous designer teams to complex theoretical concepts related to museology as social and cultural phenomena. We discuss design requirements on such scenarios, and the importance of connecting their execution closely to the context of the design and the current stage of the design process.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {role-play, sensitizing concepts, social science theory, sensitizing designers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376617,
author = {Zhu, Junyi and Blumberg, Lotta-Gili and Zhu, Yunyi and Nisser, Martin and Carlson, Ethan Levi and Wen, Xin and Shum, Kevin and Quaye, Jessica Ayeley and Mueller, Stefanie},
title = {CurveBoards: Integrating Breadboards into Physical Objects to Prototype Function in the Context of Form},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376617},
doi = {10.1145/3313831.3376617},
abstract = {CurveBoards are breadboards integrated into physical objects. In contrast to traditional breadboards, CurveBoards better preserve the object's look and feel while maintaining high circuit fluidity, which enables designers to exchange and reposition components during design iteration. Since CurveBoards are fully functional, i.e., the screens are displaying content and the buttons take user input, designers can test interactive scenarios and log interaction data on the physical prototype while still being able to make changes to the component layout and circuit design as needed. We present an interactive editor that enables users to convert 3D models into CurveBoards and discuss our fabrication technique for making CurveBoard prototypes. We also provide a technical evaluation of CurveBoard's conductivity and durability and summarize informal user feedback.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personal fabrication, electronic prototyping, breadboards},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376613,
author = {Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim},
title = {Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376613},
doi = {10.1145/3313831.3376613},
abstract = {We present Embodied Axes, a controller which supports selection operations for 3D imagery and data visualisations in Augmented Reality. The device is an embodied representation of a 3D data space -- each of its three orthogonal arms corresponds to a data axis or domain specific frame of reference. Each axis is composed of a pair of tangible, actuated range sliders for precise data selection, and rotary encoding knobs for additional parameter tuning or menu navigation. The motor actuated sliders support alignment to positions of significant values within the data, or coordination with other input: e.g., mid-air gestures in the data space, touch gestures on the surface below the data, or another Embodied Axes device supporting multi-user scenarios. We conducted expert enquiries in medical imaging which provided formative feedback on domain tasks and refinements to the design. Additionally, a controlled user study was performed and found that the Embodied Axes was overall more accurate than conventional tracked controllers for selection tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {augmented reality, tangible interaction, device, 3d visualisation, actuation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376612,
author = {Lu, Zhicong and Jiang, Yue and Lu, Cheng and Naaman, Mor and Wigdor, Daniel},
title = {The Government's Dividend: Complex Perceptions of Social Media Misinformation in China},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376612},
doi = {10.1145/3313831.3376612},
abstract = {The social media environment in China has become the dominant source of information and news over the past decade. This news environment has naturally suffered from challenges related to mis- and dis-information, encumbered by an increasingly complex landscape of factors and players including social media services, fact-checkers, censorship policies, and astroturfing. Interviews with 44 Chinese WeChat users were conducted to understand how individuals perceive misinformation and how it impacts their news consumption practices. Overall, this work exposes the diverse attitudes and coping strategies that Chinese users employ in complex social media environments. Due to the complex nature of censorship in China and participants' lack of understanding of censor-ship, they expressed varied opinions about its influence on the credibility of online information sources. Further, although most participants claimed that their opinions would not be easily swayed by astroturfers, many admitted that they could not effectively distinguish astroturfers from ordinary Internet users. Participants' inability to make sense of comments found online lead many participants to hold pro-censorship attitudes: the Government's Dividend.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {astroturfing, misinformation, trust, social media, fake news},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376604,
author = {Lilija, Klemen and Pohl, Henning and Hornb\ae{}k, Kasper},
title = {Who Put That There? Temporal Navigation of Spatial Recordings by Direct Manipulation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376604},
doi = {10.1145/3313831.3376604},
abstract = {Spatial recordings allow viewers to move within them and freely choose their viewpoint. However, such recordings make it easy to miss events and difficult to follow moving objects when skipping through the recording. To alleviate these problems we present the Who Put That There system that allows users to navigate through time by directly manipulating objects in the scene. By selecting an object, the user can navigate to moments where the object changed. Users can also view trajectories of objects that changed location and directly manipulate them to navigate. We evaluated the system with a set of sensemaking questions in a think-aloud study. Participants understood the system and found it useful for finding events of interest, while being present and engaged in the recording.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {navigation techniques, temporal navigation, virtual reality, spatial recordings},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376599,
author = {Semertzidis, Nathan and Scary, Michaela and Andres, Josh and Dwivedi, Brahmi and Kulwe, Yutika Chandrashekhar and Zambetta, Fabio and Mueller, Florian Floyd},
title = {Neo-Noumena: Augmenting Emotion Communication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376599},
doi = {10.1145/3313831.3376599},
abstract = {The subjective experience of emotion is notoriously difficult to interpersonally communicate. We believe that technology can challenge this notion through the design of neuroresponsive systems for interpersonal communication. We explore this through "Neo-Noumena", a communicative neuroresponsive system that uses brain-computer interfacing and artificial intelligence to read one's emotional states and dynamically represent them to others in mixed reality through two head-mounted displays. In our study five participant pairs were given Neo-Noumena for three days, using the system freely. Measures of emotional competence demonstrated a statistically significant increase in participants' ability to interpersonally regulate emotions. Furthermore, participant interviews revealed themes regarding Spatiotemporal Actualization, Objective Representation, and Preternatural Transmission. We also suggest design strategies for future augmented emotion communication systems. We intend that work gives guidance towards a future in which our ability to interpersonally communicate emotion is augmented beyond traditional experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mixed reality, emotion communication, machine learning, brain-computer interfacing, eeg, emotion recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376592,
author = {Chen, Yuan and Katsuragawa, Keiko and Lank, Edward},
title = {Understanding Viewport- and World-Based Pointing with Everyday Smart Devices in Immersive Augmented Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376592},
doi = {10.1145/3313831.3376592},
abstract = {Personal smart devices have demonstrated a variety of efficient techniques for pointing and selecting on physical displays. However, when migrating these input techniques to augmented reality, it is both unclear what the relative performance of different techniques will be given the immersive nature of the environment, and it is unclear how viewport-based versus world-based pointing methods will impact performance. To better understand the impact of device and viewing perspectives on pointing in augmented reality, we present the results of two controlled experiments comparing pointing conditions that leverage various smartphone- and smartwatch-based external display pointing techniques and examine viewport-based versus world-based target acquisition paradigms. Our results demonstrate that viewport-based techniques offer faster selection and that both smartwatch- and smartphone-based pointing techniques represent high-performance options for performing distant target acquisition tasks in augmented reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {3D pointing, virtual reality, augmented reality, input devices, mobile devices},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376567,
author = {Anjani, Laurensia and Mok, Terrance and Tang, Anthony and Oehlberg, Lora and Goh, Wooi Boon},
title = {Why Do People Watch Others Eat Food? An Empirical Study on the Motivations and Practices of Mukbang Viewers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376567},
doi = {10.1145/3313831.3376567},
abstract = {We present a mixed-methods study of viewers on their practices and motivations around watching mukbang — video streams of people eating large quantities of food. Viewers' experiences provide insight on future technologies for multisensorial video streams and technology-supported commensality (eating with others). We surveyed 104 viewers and interviewed 15 of them about their attitudes and reflections on their mukbang viewing habits, their physiological aspects of watching someone eat, and their perceived social relationship with mukbangers. Based on our findings, we propose design implications for remote commensality, and for synchronized multisensorial video streaming content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mukbang, video streams},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376561,
author = {Wang, Jinping and Yang, Hyun and Shao, Ruosi and Abdullah, Saeed and Sundar, S. Shyam},
title = {Alexa as Coach: Leveraging Smart Speakers to Build Social Agents That Reduce Public Speaking Anxiety},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376561},
doi = {10.1145/3313831.3376561},
abstract = {Public speaking anxiety is one of the most common social phobias. We explore the feasibility of using a conversational agent to reduce this anxiety. We developed a public-speaking tutor on the Amazon Alexa platform that enables users to engage in cognitive reconstruction exercises. We also investigated how the sociability of the agent might affect its performance as a tutor. A user study of 53 college students with fear of public speaking showed that the interaction with the agent served to assuage pre-speech state anxiety. Agent sociability improved the sense of interpersonal closeness, which was associated with lower pre-speech anxiety. Moreover, sociability of the agent increased participants' satisfaction and their willingness to continue engagement. Our findings, thus, have implications not only for addressing public speaking anxiety in a scalable way but also for the design of future conversational agents using smart speaker platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {public speaking anxiety, experiment, sociability, conversational agent},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376550,
author = {Bai, Huidong and Sasikumar, Prasanth and Yang, Jing and Billinghurst, Mark},
title = {A User Study on Mixed Reality Remote Collaboration with Eye Gaze and Hand Gesture Sharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376550},
doi = {10.1145/3313831.3376550},
abstract = {Supporting natural communication cues is critical for people to work together remotely and face-to-face. In this paper we present a Mixed Reality (MR) remote collaboration system that enables a local worker to share a live 3D panorama of his/her surroundings with a remote expert. The remote expert can also share task instructions back to the local worker using visual cues in addition to verbal communication. We conducted a user study to investigate how sharing augmented gaze and gesture cues from the remote expert to the local worker could affect the overall collaboration performance and user experience. We found that by combing gaze and gesture cues, our remote collaboration system could provide a significantly stronger sense of co-presence for both the local and remote users than using the gaze cue alone. The combined cues were also rated significantly higher than the gaze in terms of ease of conveying spatial actions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mixed reality, eye gaze, augmented reality, virtual reality, 3d panorama, scene reconstruction, remote collaboration, hand gesture},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376538,
author = {Raissi, Reyhaneh and Dimara, Evanthia and Berry, Jacquelyn H. and Gray, Wayne D. and Bailly, Gilles},
title = {Retroactive Transfer Phenomena in Alternating User Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376538},
doi = {10.1145/3313831.3376538},
abstract = {We investigated retroactive transfer when users alternate between different interfaces. Retroactive transfer is the influence of a newly learned interface on users' performance with a previously learned interface. In an interview study, participants described their experiences when alternating between different interfaces, e.g. different operating systems, devices or techniques. Negative retroactive transfer related to text entry was the most frequently reported incident. We then reported a laboratory experiment that investigated the impact of similarity between two abstract keyboard layouts, and the number of alternations between them, on retroactive interference. Results indicated that even small changes in the interference interface produced a significant performance drop for the entire previously learned interface. The amplitude of this performance drop decreases with the number of alternations. We suggest that retroactive transfer should receive more attention in HCI, as the ubiquitous nature of interactions across applications and systems requires users to increasingly alternate between similar interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {skill transfer, retroactive interference, keyboard layout},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376519,
author = {Leake, Mackenzie and Shin, Hijung Valentina and Kim, Joy O. and Agrawala, Maneesh},
title = {Generating Audio-Visual Slideshows from Text Articles Using Word Concreteness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376519},
doi = {10.1145/3313831.3376519},
abstract = {We present a system that automatically transforms text articles into audio-visual slideshows by leveraging the notion of word concreteness, which measures how strongly a word or phrase is related to some perceptible concept. In a formative study we learn that people not only prefer such audio-visual slideshows but find that the content is easier to understand compared to text articles or text articles augmented with images. We use word concreteness to select search terms and find images relevant to the text. Then, based on the distribution of concrete words and the grammatical structure of an article, we time-align selected images with audio narration obtained through text-to-speech to produce audio-visual slideshows. In a user evaluation we find that our concreteness-based algorithm selects images that are highly relevant to the text. The quality of our slideshows is comparable to slideshows produced manually using standard video editing tools, and people strongly prefer our slideshows to those generated using a simple keyword-search based approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {word concreteness, text-to-video, audio-visual slideshows},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376510,
author = {Stawarz, Katarzyna and Preist, Chris and Tallon, Deborah and Thomas, Laura and Turner, Katrina and Wiles, Nicola and Kessler, David and Shafran, Roz and Coyle, David},
title = {Integrating the Digital and the Traditional to Deliver Therapy for Depression: Lessons from a Pragmatic Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376510},
doi = {10.1145/3313831.3376510},
abstract = {Traditional approaches to psychotherapy emphasise face-to-face contact between patients and therapists. In contrast, current computerised approaches tend to minimise this contact. This can limit the range of mental health difficulties for which computerised approaches are effective. Here, we explore an alternative approach that integrates face-to-face contact, electronic contact, online collaboration, and support for between-session activities. Our discussion is grounded in the design of a platform to deliver psychotherapy for depression. We report findings of an 11-month pragmatic study in which 17 patients received treatment for depression via the platform. Results show how design decisions had a significant impact on the dynamics of therapeutic sessions and the establishment of patient-therapist relationships. For example, the use of instant messaging for synchronous, in-session contact slowed communication, but also provided a valuable space for reflection and helped to maintain session focus. We discuss the impact of flexibility and the potential of integrated approaches to both enhance and reduce patient engagement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {cbt, mental health, integrated approach, cognitive behavioural therapy, depression, blended therapy, patient-therapist communication, health technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376498,
author = {Li, Yifang and Vishwamitra, Nishant and Hu, Hongxin and Caine, Kelly},
title = {Towards A Taxonomy of Content Sensitivity and Sharing Preferences for Photos},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376498},
doi = {10.1145/3313831.3376498},
abstract = {Determining which photos are sensitive is difficult. Although emerging computer vision systems can label content items, previous attempts to distinguish private or sensitive content fall short. There is no human-centered taxonomy that describes what content is sensitive or how sharing preferences for content differs across recipients. To fill this gap, we introduce a new sensitive content elicitation method which surmounts limitations of previous approaches, and, using this new method, collected sensitive content from 116 participants. We also recorded participants' sharing preferences with 20 recipient groups. Next, we conducted a card sort to surface user-defined categories of sensitive content. Using data from these studies, we generated a taxonomy that identifies 28 categories of sensitive content. We also establish how sharing preferences for content differs across groups of recipients. This taxonomy can serve as a framework for understanding photo privacy, which can, in turn, inform new photo privacy protection mechanisms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {security, privacy, photo privacy, sensitive content},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376497,
author = {Walker, Ashley Marie and DeVito, Michael A.},
title = {"'More Gay' Fits in Better": Intracommunity Power Dynamics and Harms in Online LGBTQ+ Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376497},
doi = {10.1145/3313831.3376497},
abstract = {Online spaces play crucial roles in the lives of most LGBTQ+ people, but can also replicate and exacerbate existing intracommunity tensions and power dynamics, potentially harming subgroups within this marginalized community. Using qualitative probes and interviews, we engaged a diverse group of 25 bi+ (attracted to more than one gender) people to explore these dynamics. We identify two types of intracommunity conflict that bi+ users face (validity and normative conflicts), and a resulting set of what we call latent harms, or coping strategies for dealing with conflict that have delayed negative psychological effects for bi+ users. Using intersectionality as a sensitizing concept to understand shifting power dynamics embedded in sociotechnical contexts, we discuss challenges for future design work including the need to account for intracommunity dynamics within marginalized groups and the utility of disentangling conflict from harm.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {social media, online communities, intersectionality, power dynamics, conflict, harm, bisexuality, pansexuality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376486,
author = {Heshmat, Yasamin and Neustaedter, Carman and McCaffrey, Kyle and Odom, William and Wakkary, Ron and Yang, Zikun},
title = {FamilyStories: Asynchronous Audio Storytelling for Family Members Across Time Zones},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376486},
doi = {10.1145/3313831.3376486},
abstract = {Family members who are separated across time zones can easily miss out on feeling connected. We designed and studied the usage of an asynchronous storytelling system, called FamilyStories, to explore the use of audio-based sharing. FamilyStories allows family members to share activities and experiences over distance in different time zones using three different devices that contain different contextual features. To evaluate the design, we conducted a five-week long field study with two family member pairs. Our results show the value of slow, flexible, and non-suggestive interfaces for asynchronous audio communication. We also found ephemerality helped in the sharing of 'instant' feelings, while large time zone differences could be 'synchronized' with time delayed messages. We raise these as design opportunities for asynchronous audio storytelling systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {audio, family communication, asynchronous communication, slow technology, domestic},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376479,
author = {Mayer, Sven and Laput, Gierad and Harrison, Chris},
title = {Enhancing Mobile Voice Assistants with WorldGaze},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376479},
doi = {10.1145/3313831.3376479},
abstract = {Contemporary voice assistants require that objects of inter-est be specified in spoken commands. Of course, users are often looking directly at the object or place of interest ? fine-grained, contextual information that is currently unused. We present WorldGaze, a software-only method for smartphones that provides the real-world gaze location of a user that voice agents can utilize for rapid, natural, and precise interactions. We achieve this by simultaneously opening the front and rear cameras of a smartphone. The front-facing camera is used to track the head in 3D, including estimating its direction vector. As the geometry of the front and back cameras are fixed and known, we can raycast the head vector into the 3D world scene as captured by the rear-facing camera. This allows the user to intuitively define an object or region of interest using their head gaze. We started our investigations with a qualitative exploration of competing methods, before developing a functional, real-time implementation. We conclude with an evaluation that shows WorldGaze can be quick and accurate, opening new multimodal gaze+voice interactions for mobile voice agents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {worldgaze, mobile interaction, interaction techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376463,
author = {Spagnolli, Anna and Mora, Diletta and Fanchin, Matteo and Orso, Valeria and Gamberini, Luciano},
title = {Automation and Creativity: A Case Study of DJs' and VJs' Ambivalent Positions on Automated Visual Software},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376463},
doi = {10.1145/3313831.3376463},
abstract = {Computerized solutions in the domain of creativity and expressive performance increasingly provide art and artists with exciting new opportunities. However, the combination of automation and creativity also raises controversies and resistance in some user groups. This paper considers the case of software-generated visuals in live music performance and tries to make sense of the ambivalent response given by its intended users (i.e., DJs and VJs). We carried out seven face-to-face interviews, an online survey (N = 102) and 25 interviews at a distance to unravel DJs' and VJs' positions on automated visual software. Four core controversies were eventually identified, gravitating around the implications of using such software on DJs' and VJs' identities as artists and on their competitive advantage in their activity sector. The conclusions reconnect these findings with the larger issue of understanding the users' responses to automation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {creativity, visual software, live music performance, ambivalence, acceptance, automation, argumentation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

