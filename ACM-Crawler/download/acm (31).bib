@inproceedings{10.1145/3334480.3382878,
author = {Wang, Qiaosi and Jing, Shan and Camacho, Ida and Joyner, David and Goel, Ashok},
title = {Jill Watson SA: Design and Evaluation of a Virtual Agent to Build Communities Among Online Learners},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382878},
doi = {10.1145/3334480.3382878},
abstract = {Despite being accessible and affordable, online education presents numerous challenges for online learners due to the absence of face-to-face interactions. Lack of community-belongingness, in particular, negatively impacts online learners' learning outcomes and learning experience. To help online learners build communities and foster connections with their peers, we designed and deployed Jill Watson SA (stands for Social Agent). Jill Watson SA is a virtual agent who can match students with shared identity, defined by similarities in location, timezone, hobby, class schedule, etc., on the Piazza class discussion forum. We implemented Jill Watson SA in two online classes and conducted three short surveys with online students to evaluate Jill Watson SA.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {community-building, online learning, virtual agent},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382866,
author = {Wicaksono, Irmandy and Kodama, Elena and Dementyev, Artem and Paradiso, Joseph A.},
title = {SensorNets: Towards Reconfigurable Multifunctional Fine-Grained Soft and Stretchable Electronic Skins},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382866},
doi = {10.1145/3334480.3382866},
abstract = {SensorNets is a bioinspired electronic skin integrated with multimodal sensor networks for interactive media applications, from wearables, self-aware objects, to intelligent environments. It is developed by connecting miniaturized flexible printed circuit boards as two-dimensional sensor arrays with stretchable interconnects. The system is embedded in between soft deformable layers, such as textiles or rubbers. The result is a soft sensate surface that can be distributed and conformally wrap and adapt to curved structures. Each node contains a microprocessor together with a collection of nine sensors and a light-emitting diode, providing multimodal data that can be used to detect various deformation, proxemic, tactile, and environmental changes. We show that the electronic skin can sense and respond to a variety of stimuli simultaneously, as well as open up a possibility for sensor-rich virtual and augmented reality-based visualization and interaction.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {flexible-stretchable electronics, sensor networks, spatiotemporal mapping, deformable interfaces, sensor visualization, smart materials},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382795,
author = {An, Pengcheng and Bakker, Saskia and Ordanovski, Sara and Paffen, Chris L.E. and Taconis, Ruurd and Eggen, Berry},
title = {Dandelion Diagram: Aggregating Positioning and Orientation Data in the Visualization of Classroom Proxemics},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382795},
doi = {10.1145/3334480.3382795},
abstract = {In the past two years, an emerging body of HCI work has been focused on classroom proxemics-how teachers divide time and attention over students in the different regions of the classroom. Tracking and visualizing this implicit yet relevant dimension of teaching can benefit both research and teacher professionalization. Prior work has proved the value of depicting teachers' whereabouts. Yet a major opportunity remains in the design of new, synthesized visualizations that help researchers and practitioners to gain more insights in the vast tracking data. We present Dandelion Diagram, a synthesized heatmap technique that combines both teachers' positioning and orientation (heading) data, and affords richer representations in addition to whereabouts-For example, teachers' attention pattern (which directions they were attending to), and their mobility pattern (i.e., trajectories in the classroom). Utilizing various classroom data from a field study, this paper illustrates the design and utility of Dandelion Diagram.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {classroom proxemics, visualization, teacher education, reflection, in-door positioning, multimodal analytics},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382785,
author = {Salminen, Joni and Vahlo, Jukka and Koponen, Aki and Jung, Soon-Gyo and Chowdhury, Shammur A. and Jansen, Bernard J.},
title = {Designing Prototype Player Personas from a Game Preference Survey},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382785},
doi = {10.1145/3334480.3382785},
abstract = {The competitiveness of the video game market has increased the need for understanding players. We generate player personas from survey data of 15,402 players' 195,158 stated game preferences from 130,495 game titles using the methodology of automatic persona generation. Our purpose is to demonstrate the potential of data-driven personas for segmenting players by their game preferences. The resulting prototype personas provide potential value for game marketing purposes, e.g., targeting gamers with social media advertising, although they can also be used for understanding demographic variation among various game preference patterns.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {video game, player personas, automatic persona generation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382784,
author = {Aloba, Aishat and Flores, Gianne and Langham, Jaida and McFadden, Zari and Bell, John and Dagar, Nikita and Esmaeili, Shaghayegh and Anthony, Lisa},
title = {Toward Exploratory Design with Stakeholders for Understanding Exergame Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382784},
doi = {10.1145/3334480.3382784},
abstract = {Prior work has explored improving the efficacy of exergames through participatory design with children. Children are not necessarily able to make informed decisions about their fitness, so their perspectives form only half the picture. Adults who are invested in the problem of children's fitness (e.g., PE teachers) are a valuable missing perspective. As a first step to understanding what we can learn from these stakeholders to aid the design of exergames, we conducted one in-depth interview with a PE teacher and several focus groups with children. Our findings showed that, although both children and the PE teacher like similar game elements, children viewed the elements through the lens of fun while the PE teacher viewed the elements through the lens of effectiveness. Our preliminary findings establish the importance of including such stakeholders in the formative design of exergames.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {children, design space, exergames, exertion games, pe, physical education teachers},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381829,
author = {Willis, Max and Hanna, Julian and Encinas, Enrique and Auger, James},
title = {Low Power Web: Legacy Design and the Path to Sustainable Net Futures},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381829},
doi = {10.1145/3334480.3381829},
abstract = {HCI is complicit in the climate crisis, as the systems and services that we design engender unsustainable energy use and waste. HCI has equal potential to find solutions for environmental challenges and script, by design, the behavioral changes needed for sustainable net futures. We explore this dichotomy through the lens of data transmission, examining the energy consumption and environmental impact of web communications. This work begins with a critical revisiting of legacy web design that mines the past for actionable ideas towards sustainable net futures. We query how we can reduce our own net energy consumption, and plot a path to design our low-power website. In addition we speculate on a redesign of the background systems, outlining the practical steps we have taken towards solar, wind, gravity and micro-hydro low-power web hosting solutions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {renewable energy, green HCI, sustainable design, web design, low-power web},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381822,
author = {Crovari, Pietro and Catania, Fabio and Garzotto, Franca},
title = {Crime Story as a Tool for Scientific and Technological Outreach},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381822},
doi = {10.1145/3334480.3381822},
abstract = {In a world where public engagement is increasingly important, where there is the urge of leaving the research laboratories to tell people what is being done, and where the effort from Academy is still limited, we propose Death on the Nile, a novel experience to get people in touch with innovative interactive technologies. In our exhibition, visitors are invited to solve a crime while they get in touch with the new frontiers of Human-Computer Interaction. Also, participants can experience the different stages of the research process through the metaphor of the investigation. An empirical study (N=969) shows that Death on the Nile is engaging and effective as a method through which to present HCI research. Finally, we conceptualize the experience into a framework that can be used with potentially any interactive technology.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {outreach, public engagement, experience design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381070,
author = {Rogers, Yvonne and Dourish, Paul and Olivier, Patrick and Brereton, Margot and Forlizzi, Jodi},
title = {The Dark Side of Interaction Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381070},
doi = {10.1145/3334480.3381070},
abstract = {This panel will provoke the audience into reflecting on the dark side of interaction design. It will ask what role the HCI community has played in the inception and rise of digital addiction, digital persuasion, data exploitation and dark patterns and what to do about this state of affairs. The panelists will present their views about what we have unleashed. They will examine how 'stickiness' came about and how we might give users control over their data that is sucked up in this process. Finally, they will be asked to consider the merits and prospects of an alternative agenda, that pushes for interaction design to be fairer, more ethically-grounded and more transparent, while at the same time addressing head-on the dark side of interaction design.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {interaction design, data exploitation, digital addiction, nudging, dark patterns, dark side},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381065,
author = {Mentis, Helena M. and Mandryk, Regan and Grossman, Tovi and Lampe, Cliff and Colnago, Jessica},
title = {CHI 2030: The Future is Wide Open},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381065},
doi = {10.1145/3334480.3381065},
abstract = {What is the future of the CHI conference? What will it look like in 2030? In this panel, we will present some data on the current state of the CHI conference - from paper submissions to attendance - and the initial findings on what our community has said is their 'ideal' CHI conference. We will then make wild predictions about the future of CHI and encourage audience discussion on the form that the conference and academic publishing could take in the future.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–3},
numpages = {3},
keywords = {future of conferences, global outreach, publications, affordable, sustainability, experience, accessibility},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381062,
author = {Wang, Xi and Bylinskii, Zoya and Castelhano, Monica and Hillis, James and Duchowski, Andrew T.},
title = {EMICS'20: Eye Movements as an Interface to Cognitive State},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381062},
doi = {10.1145/3334480.3381062},
abstract = {Eye movement recording has been extensively used in HCI and offers the possibility to understand how information is perceived and processed by users. Hardware developments provide the ubiquitous accessibility of eye recording, allowing eye movements to enter common usage as a control modality. Recent A.I. developments provide powerful computational means to make predictions about the user. However, the connection between eye movements and cognitive state has been largely under-exploited in HCI. Despite the rich literature in psychology, a deeper understanding of its usability in practice is still required. This EMICS SIG will provide an opportunity to discuss possible application scenarios and HCI interfaces to infer users' mental state from eye movements. It will bring together researchers across disciplines with the goal of expanding shared knowledge, discussing innovative research directions and methods, fostering future collaborations around the use of eye movements as an interface to cognitive state, and providing a solid foundation for an EMICS workshop at CHI 2021.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {eye movements, interaction modality, attention, interface, cognitive states},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381056,
author = {Vasilchenko, Anna and Li, Jie and Ryskeldiev, Bektur and Sarcar, Sayan and Ochiai, Yoichi and Kunze, Kai and Radu, Iulian},
title = {Collaborative Learning &amp; Co-Creation in XR},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381056},
doi = {10.1145/3334480.3381056},
abstract = {In this SIG, we aim at gathering researchers and practitioners to reflect on using XR technologies to support collaborative learning and co-creation, and to foster a joint force by connecting the Learning and Education community and the XR community at CHI. We witness a significant increase in CHI publications relating to these research areas: 292 titles about "collaborative learning" or "co-creation" since 2015 compared to 96 in 2010-2014; and 1180 titles about XR since 2015 compared to 288 in 2010-2014. This SIG will bring together researchers, educators, designers and practitioners to 1) stimulate a cross-disciplinary discussion on the opportunities of collaborative learning and co-creation in XR; 2) foresee the future directions, standards and obstacles to introduce XR to education; and 3) build a joint community connecting XR and education research at CHI.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {co-creation, cscl, augmented reality, virtual reality, mixed reality, collaborative learning, cscw, extended reality},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375174,
author = {McDonald, Nora and Badillo-Urquiola, Karla and Ames, Morgan G. and Dell, Nicola and Keneski, Elizabeth and Sleeper, Manya and Wisniewski, Pamela J.},
title = {Privacy and Power: Acknowledging the Importance of Privacy Research and Design for Vulnerable Populations},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375174},
doi = {10.1145/3334480.3375174},
abstract = {Privacy researchers and designers must take into consideration the unique needs and challenges of vulnerable populations. Normative and privileged lenses can impair conceptualizations of identities and privacy needs, as well as reinforce or exacerbate power structures and struggles-and how they are formalized within privacy research methods, theories, designs, and analytical tools. The aim of this one-day workshop is to facilitate discourse around alternative ways of thinking about privacy and power, as well as ways for researching and designing technologies that not only respect the privacy needs of vulnerable populations but attempt to empower them. We will work towards developing best practices to help academics and industry folks, technologists, researchers, policy makers, and designers do a better job of serving the privacy needs of vulnerable users of technology.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {vulnerable populations, intersectionality, privacy},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375160,
author = {Li, Jie and Vinayagamoorthy, Vinoba and Schwartz, Raz and IJsselsteijn, Wijnand and Shamma, David A. and Cesar, Pablo},
title = {Social VR: A New Medium for Remote Communication and Collaboration},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375160},
doi = {10.1145/3334480.3375160},
abstract = {There is a growing need for effective remote communication, which has many positive societal impacts, such as reducing environmental pollution and travel costs, supporting rich collaboration by remotely connecting talented people. Social Virtual Reality (VR) invites multiple users to join a collaborative virtual environment, which creates new opportunities for remote communication. The goal of social VR is not to completely replicate reality, but to facilitate and extend the existing communication channels of the physical world. Apart from the benefits provided by social VR, privacy concerns and ethical risks are raised when the boundary between the real and the virtual world is blurred. This workshop is intended to spur discussions regarding technology, evaluation protocols, application areas, research ethics and legal regulations for social VR as an emerging immersive remote communication tool.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {remote communication, VR ethics, social VR, VR evaluation metrics},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375152,
author = {Candello, Heloisa and Munteanu, Cosmin and Clark, Leigh and Sin, Jaisie and Torres, Mar\'{\i}a In\'{e}s and Porcheron, Martin and Myers, Chelsea M. and Cowan, Benjamin and Fischer, Joel and Schl\"{o}gl, Stephan and Murad, Christine and Reeves, Stuart},
title = {CUI@CHI: Mapping Grand Challenges for the Conversational User Interface Community},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375152},
doi = {10.1145/3334480.3375152},
abstract = {The aim of this workshop is twofold. First, it aims to grow critical mass in Conversational User Interfaces (CUI) research by mapping the grand challenges in designing and researching these interactions. Second, this workshop is intended to further build the CUI community with these challenges in mind, whilst also growing CUI research presence at CHI. In particular, the workshop will survey and map topics such as: interaction design for text and voice-based CUI; the interplay between engineering efforts such as in Natural language Processing (NLP) and the design of CUI; practical CUI applications (e.g. human-robot interaction, public spaces, hands-free and wearables); and social, contextual, and cultural aspects of CUI design (e.g. ethics, privacy, trust, information exploration, persuasion, well-being, or decision-making, marginalized users). By drawing from the diverse interdisciplinary expertise that defines CHI, we are proposing this workshop as a platform on which to build a community that is better equipped to tackle an emerging field that is rapidly-evolving, yet is under-studied --- especially as the commercial advances seem to outpace the scholarly research in this space.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {intelligent personal assistants, conversational user interface, speech interface, CUI, voice user interface},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375151,
author = {Mustafa, Maryam and Lazem, Shaimaa and Alabdulqader, Ebtisam and Toyama, Kentaro and Sultana, Sharifa and Ibtasam, Samia and Anderson, Richard and Ahmed, Syed Ishtiaque},
title = {IslamicHCI: Designing with and within Muslim Populations},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375151},
doi = {10.1145/3334480.3375151},
abstract = {In recent years there has been a growing body of work from the CHI communities that looks at designing for inclusivity and for the unique and specific constraints of diverse populations. This has included but is not limited to, work on designing within patriarchal contexts, designing around issues of gender and sexual orientation and designing around literacy. In tandem, local HCI initiatives such as ArabHCI [3] have emerged to address the misrepresentation of these populations in HCI research, highlighting the fact that Western originated design methods would require delicate adaptations to suit non-Western cultural contexts. With the same approach towards inclusivity and co-existence the aim of this workshop is to bring together HCI researchers and practitioners who engage in studies and interventions within Muslim majority communities around the world. The goal is to understand the Muslim identity and perceptions around it, the unique constraints and limitations within Muslim communities and to identify core issues and concerns within these populations. We will explore the following themes: refugees and islamophobia; Muslim feminism and Digital financial services.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {Muslims, Islam, design, HCI},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375143,
author = {Wallace, Jayne and Odom, Will and Montague, Kyle and Koulidou, Nantia and Sas, Corina and Morrissey, Kellie and Olivier, Patrick},
title = {HCI at End of Life &amp; Beyond},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375143},
doi = {10.1145/3334480.3375143},
abstract = {Death, whilst an inevitable part of being alive, factors more significantly in our lives than the event itself. The role that technology can play in how people live as they approach end of life as well as in bereavement is full of rich possibilities, but research here is also fraught with ethical and methodological dilemmas. Although there has been a turn to focus on the topic of death by some in HCI we need to go far further to embrace the contexts relating to it more meaningfully and broadly. Through this design focused workshop, we will bring experts and interested parties together to creatively explore opportunities and challenges for HCI at the end of life and beyond. Discussions and design activities will be supported by conceptual resources for design, lived experience accounts, design methods and ethical resources. The workshop will provide a time and place to bring together experts but will also provide an open and accepting environment for those for whom HCI at end of life and beyond is a new area of concern.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {bereavement, ethics, design, continuing bonds, death, dying, end of life},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375060,
author = {McNamara, Ann and Mehta, Ranjana},
title = {Additional Insights: Using Eye Tracking and Brain Sensing in Virtual Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375060},
doi = {10.1145/3334480.3375060},
abstract = {Virtual Reality has the potential to transform the way we work, rest and play. We are seeing use cases as diverse as education and pain management, with new applications being imagined every day. Virtual Reality technology comes with new challenges, and many obstacles need to be overcome to ensure good user experience. Recently many new Virtual Reality systems with integrated eye-tracking have become available. At the same time, many research labs are using Functional Near-Infrared Spectroscopy (fNIRS) to non-invasively measure brain activity and serve as a brain-computer interface. This course presents timely, relevant information on how Virtual Reality can leverage eye-tracking and brain activity data to optimize the user experience and to alleviate usability issues surrounding many challenges in immersive VEs. The integration of these sensors allows us to determine additional insights into human behavior, including where the viewer is focusing their attention, and monitor cognitive load. Advancing these approaches could make the Virtual Reality experience more comfortable, safe and effective for the user, and open a new world to facilitate new experimentation for Human Computer Interaction (and Brain Computer Interaction) researchers.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {eye tracking, fnirs, brain computer interface, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383093,
author = {Kresnye, K. Cassie and Shih, Patrick C.},
title = {Smart Habitat: A Wildlife Rehabilitation System},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383093},
doi = {10.1145/3334480.3383093},
abstract = {Wildlife rehabilitation centers are tasked with the difficult challenge of providing medical care to wildlife while limiting human contact to ensure a successful transition into the wild. Building off of interviews with volunteers and 6 months of participatory observation work, we present a smart habitat design for the rehabilitation of Virginian opossum joeys. Using maker technology, we crafted a prototype utilizing sensors, a microcontroller, and an android application. We then discuss the future direction for this project including improvements and a field deploy.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {volunteer management, wildlife, android, making, animal-computer interaction, opossum, arduino, rehabilitation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383090,
author = {Wang, Katherine and Zhang, Bingqing and Cho, Youngjun},
title = {Using Mobile Augmented Reality to Improve Attention in Adults with Autism Spectrum Disorder},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383090},
doi = {10.1145/3334480.3383090},
abstract = {Adults on the autism spectrum commonly experience impairments in attention management that hinder many other cognitive functions necessary to appreciate relationships between sensory stimuli. As autistic individuals generally identify as visual learners, the effective use of visual aids can be critical in developing life skills. In this brief paper, we propose a Mobile Augmented Reality for Attention (MARA) application which addresses a lack of supportive and simple cost- effective solutions for autistic adults to train attention management skills. We present the proposed design, configuration and implementation. Lastly, we discuss future directions for research.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {autism, assistive technology, augmented reality, attention, mobile applications},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383076,
author = {Prato, Gabriele and Sallemi, Federico and Cremonesi, Paolo and Scriminaci, Mario and Gudmundsson, Stefan and Palumbo, Silvio},
title = {Outfit Completion and Clothes Recommendation},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383076},
doi = {10.1145/3334480.3383076},
abstract = {Recommending fashion outfits requires learning a concept of style and fashionability that is typically human. There has been an increasing research effort into creating Machine Learning models able to learn such concepts, in order to distinguish between compatible and incompatible clothes and to select an item that would complete an outfit. However, most of the work done in literature tackles this problem from a pure Machine Learning point of view, disregarding real-case scenarios and the human interaction with systems able to generate outfits. This work tries to move the problem of generating outfits to the Recommender Systems domain by presenting as its main contribution a novel algorithm for a fashion-specific Recommender System that generates fashionable outfits, able to scale its inference time to be useful in real use case scenarios, and applies such algorithm on public and industrial datasets. In addition to this, this work shows preliminary results on how this algorithm can be employed in a real scenario and reports as preliminary results the evaluations provided by three professional stylists on the outfits generated by such algorithms.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {fashion, clothes recommendation, online evaluation, outfit completion},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383073,
author = {Agha, Zainab and Chatlani, Neeraj and Razi, Afsaneh and Wisniewski, Pamela},
title = {Towards Conducting Responsible Research with Teens and Parents Regarding Online Risks},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383073},
doi = {10.1145/3334480.3383073},
abstract = {We conducted an exploratory interview study with 10 undergraduate college students (ages 18-21) to get their feedback on how to best design a research study that asks teens (ages 13-17) to share portions of their Instagram data with their parents and discuss their online risk experiences. These young adults felt that teens should have as much control as possible when sharing their data, including the way that it was used in discussions with their parents. Our findings highlight the need to ensure researchers preserve the privacy and confidentiality of teens' social media data.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {online risk concerns, adolescent online safety, privacy, parent-teen reconciliation, design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383072,
author = {Weatherston, Jorin and Perin, Charles and Hore, Dennis and Wallace, Bruce and Storey, Margaret-Anne},
title = {An Unquantified Uncertainty Visualization Design Space During the Opioid Crisis},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383072},
doi = {10.1145/3334480.3383072},
abstract = {We propose a visualization design space for representing unquantified uncertainty in percent composition drug checking test results using pie and cake charts during the opioid crisis. The design space generates alternatives for use in a visual drug report design study that may improve decision-making concerning illicit drug use. Currently, communication of drug checking test results does not capture the uncertainty in drug checking tests, leading to poor and potentially harmful decisions. The design alternatives generated by the design space aim to empower people who use drugs with drug sample information and facilitate harm reduction efforts. Our visualizations may apply to other drug checking services and to scenarios where uncertainty visualization researchers wish to notify end users of the presence of unquantified uncertainty in safety-critical decision-making contexts like those found during the opioid crisis.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {drug-checking, decision-making, confidence, visualization, uncertainty},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383049,
author = {Kim, Minjoon and Kim, Yoojung and Lee, Joong-seek},
title = {Utilizing Response Time to Find In-between Ratings within Likes and Dislikes},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383049},
doi = {10.1145/3334480.3383049},
abstract = {Binary rating methods are known to allow easier and quicker ratings, yet they do not allow users to express how much they like/dislike an item. In this study, we argue that response times in ratings can be used to gauge the degree or strength of user ratings. We asked users to rate a set of movies while collecting individual response times, confidence levels, and reasons for user ratings. We investigate (1) the possibility of utilizing response time as a way to further distinguish likes and dislikes, and (2) the various factors that affect rating time. We find that response time can be used to distinguish between sure and unsure answers, as well as the mental process users take before rating an item. We believe that our study will be informative to better find user preferences and relations between explicit ratings and implicit data.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {user preference, response time, rating confidence, explicit ratings},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383046,
author = {Deja, Jordan Aiko and Dela Torre, Alexczar and Lee, Hans Joshua and Ciriaco, Jose Florencio and Eroles, Carlo Miguel},
title = {ViTune: A Visualizer Tool to Allow the Deaf and Hard of Hearing to See Music With Their Eyes},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383046},
doi = {10.1145/3334480.3383046},
abstract = {Visualizers are usually added into music players to augment the listening experiences of hearing users. However, for the case of most members of the Deaf and Hard of Hearing (DHH) community, they have partial deafness which may give them a "limited" listening experience as compared to their counterparts. In this paper, we present ViTune, a visualizer tool that enhances the musical experiences of the DHH through the use of an on-screen visualizer generating effects alongside music. We observed how members of the DHH community typically experienced music through an initial user study. We then iterated on developing a visualizer prototype where we did multiple usability tests involving at least 15 participants from the DHH community. We observed how they experienced music with the help of our prototype and noticed that certain music features and elements augmented these experiences. Visualization attributes, their matching qualitative descriptions and equivalent subjective attributes were identified with the help of music experts. Also, affects hypothesized to be induced and dissuaded were identified in improving these listening experiences.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {usability testing, visualizations, human-computer interaction, inclusive design, musical experience, sound and music computing, deaf and hard of hearing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383043,
author = {D\"{u}wel, Tim and Herbig, Nico and Kahl, Denise and Kr\"{u}ger, Antonio},
title = {Combining Embedded Computation and Image Tracking for Composing Tangible Augmented Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383043},
doi = {10.1145/3334480.3383043},
abstract = {This work proposes a combination of embedded computation and marker tracking to provide more robust augmentations for composed objects in Tangible Augmented Reality. By integrating conductive elements into the tangibles' sides, communication between embedded microprocessors is enabled, such that a connected composition can be computed without relying on any marker tracking information. Consequently, the virtual counterparts of the tangibles can be aligned, and this virtual composition can be attached to a single marker as a whole, increasing the tracking robustness towards occlusions and perspective distortions. A technical evaluation shows that this approach provides more robust augmentations if a tangible block in a composition is occluded by at least 50% or perspectively distorted by at least 40 to 50 degrees, depending on the block's size. Additionally, a test with users relying on the use case of a couch configuration tool shows promising results regarding usability and user experience.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {embedded computation, tangible augmented reality, augmented reality, configuration, assembling, tangible user interface, composition},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383041,
author = {Asha, Ashratuz Zavin and Smith, Christopher and Oehlberg, Lora and Somanath, Sowmya and Sharlin, Ehud},
title = {Views from the Wheelchair: Understanding Interaction between Autonomous Vehicle and Pedestrians with Reduced Mobility},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383041},
doi = {10.1145/3334480.3383041},
abstract = {We are interested in the ways pedestrians will interact with autonomous vehicle (AV) in a future AV transportation ecosystem, when nonverbal cues from the driver such as eye movements, hand gestures, etc. are no longer provided. In this work, we examine a subset of this challenge: interaction between pedestrian with reduced mobility (PRM) and AV. This study explores interface designs between AVs and people in a wheelchair to help them interact with AVs by conducting a preliminary design study. We have assessed the data collected from the study using qualitative analysis and presented different findings on AV-PRM interactions. Our findings reflect on the importance of visual interfaces, changes to the wheelchair and the creative use of the street infrastructure.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {pedestrian with reduced mobility, autonomous vehicle},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383038,
author = {Kim, Taenyun and Song, Hayeon},
title = {The Effect of Message Framing and Timing on the Acceptance of Artificial Intelligence's Suggestion},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383038},
doi = {10.1145/3334480.3383038},
abstract = {AI helps us make decisions in various domains such as healthcare, finance or entertainment (e.g. Netflix, IBM Watson and etc.). However, people's trust and acceptance of AI are highly susceptible to when and how the suggestion is presented. This study examined the role of the message framing and timing on acceptance when the performance of AI is stated. The study employed a 2 (message timing: before vs. after decision) x 3 (message framing: no information vs. negative framing vs. positive framing) between-subjects experiment where participants were told to solve the specific problem with AI in different conditions. The results showed that participants perceived the suggestion of AI more reasonable and accepted it more when the performance is not stated than any information is provided and they perceived the suggestion of AI more reasonable when the message is presented before the decision is made. The theoretical and practical implications are discussed.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {message timing, framing effect, artificial intelligence, acceptance},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382955,
author = {Li, Shuran and Hao, Yu and Yoon, Jungkyoon},
title = {PurPal: An Interactive Box That Up-Regulates Positive Emotions in Consumption Behaviors},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382955},
doi = {10.1145/3334480.3382955},
abstract = {Contrary to our anticipation, consumption experiences do not always please us; instead, they sometimes impede our well-being. People often regret using their resources unfavorably (i.e., buyers' remorse or impulse buying) or take the pleasure of having something for granted before long (i.e., hedonic adaptation). Given its effects on optimizing positive experiences, positive emotion regulation can be useful for mitigating these issues. The present paper introduces PurPal, a self-administered behavioral intervention technology that enables users to up-regulate their positive emotions in the context of consumption. PurPal provides adaptive questions associated with users' purchase intentions, which stimulate reflection on possible future positive experiences with purchased items. A user study is planned to validate the efficacy of PurPal in a lab setting. The longer-term goal of the current research is to develop behavioral intervention technologies that support users' emotion regulation processes, enhancing their subjective well-being.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {user experience, positive mental time traveling, positive emotion, behavioral intervention technologies, emotion regulation, consumption behavior},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382901,
author = {Skinner, Zoe and Brown, Stacey and Walsh, Greg},
title = {Children of Color's Perceptions of Fairness in AI: An Exploration of Equitable and Inclusive Co-Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382901},
doi = {10.1145/3334480.3382901},
abstract = {When it comes to algorithmic rights and protections for children, designers will need to face new paradigms to solve problems they are targeting. The field of Design typically deals with form and function and is executed in molecules or pixels. But algorithms have neither. More importantly, algorithms may be biased in their execution against those without privileged status such as people of color, children, and the non-affluent. In this paper, we review our work on exploring perceptions of fairness in AI through co-design sessions with children of color in non-affluent neighborhoods of Baltimore City. The design sessions aimed at designing an artificially intelligent librarian for their local branch. Our preliminary findings showcase three key themes of this group's perceptions of fairness in the context of an artificially intelligent authority figure.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {perceptions of fairness, AI, children, co-design, libraries, participatory design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381823,
author = {Akmal, Haider and Coulton, Paul},
title = {The Divination of Things by Things},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381823},
doi = {10.1145/3334480.3381823},
abstract = {As humans our view of the world is predominantly restricted to our own experience and are largely oblivious to the alternate perspective of reality experienced by the objects that cohabit our spaces even though such objects are often integral components of our lives. This paper considers the growing phenomenon whereby non-human objects such as cutlery and appliances are having what might be considered human-like experiences through integration of advanced computational programming. By examining the services provided by Madame Bitsy's Fantastic Future Forecasting and Fortune Telling Emporium for the Internet of Living Things, which is a fully autonomous online fortune telling service for Internet of Things enabled objects and services, we attempt to illuminate what it means to be a digitally connected object.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {internet of things, design fiction, hci, philosophical carpentry, forecasting, tarot},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381655,
author = {Walia, Angel and Goel, Prakhar and Kairon, Varnika and Jain, Mayank},
title = {HapTech: Exploring Haptics in Gaming for the Visually Impaired},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381655},
doi = {10.1145/3334480.3381655},
abstract = {Critical components of today's video games are their ability to provide life-like visuals. Using excellent graphics quality, they offer an immersive gaming experience to its users. However, graphics prove to be ineffective when we delve into developing games for the visually impaired. In our work, we explore how haptics and tactile interfaces can be harnessed to provide the visually impaired a better gaming experience. We have proposed the use of audio plus haptic data exchange between the user and the system. We have created a gaming console that is light, portable, easy to use and reprogrammable to provide the visually impaired a new source of entertainment. In this work, we present a proof of concept by conducting a preliminary evaluation of HapTech.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {visually impaired, audio-based, gaming, haptic, reprogrammable, tactile interfaces},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381436,
author = {Chalhoub, George},
title = {The UX of Things: Exploring UX Principles to Inform Security and Privacy Design in the Smart Home},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381436},
doi = {10.1145/3334480.3381436},
abstract = {Smart home devices have been successful in fulfilling functional requirements but have often failed at incorporating user-centric security and privacy. This research project addresses the problem of security and privacy in the smart home through the lens of User Experience (UX) Design. Using qualitative interviews with users and designers, we explore the relationship between UX design, security, and privacy in the smart home. This is followed by participatory design workshops with smart home stakeholders to gain an in-depth knowledge of UX design challenges of security and privacy. Our results are further broadened by the development of a conceptual framework for UX design of security and privacy in the smart home.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {design, smart home, privacy, internet of things, security, user experience},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375230,
author = {Grace, Lindsay},
title = {Pilot Case Study in Games as Polling Systems, Generating Knowledge about Fake News},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375230},
doi = {10.1145/3334480.3375230},
abstract = {This research reports on heuristics in the design and implementation of games as polling systems. Adapting previous research in human computation games, this paper examines the opportunity to collect player opinion through game mechanics. The goal is to make more engaging experiences and exploit poll-taker as player instinct response. This case study describes the design, development and data collected through three playable polls focused on news sources and media literacy. This is a pilot analysis, outlining the propensities and limitations of using games as polling systems and reporting on the findings from a limited release involving 287 play sessions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {playable polls, computer games, human computation games, engagement design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375067,
author = {Kumar, Neha and Cannanure, Vikram Kamath and Gamage, Dilrukshi and Prabhakar, Annu Sible and Sturm, Christian and Loaiza, Cuauht\'{e}moc Rivera and Sabie, Dina and Bhuiyan, Md. Moinuddin and Moreno Rocha, Mario A.},
title = {HCI Across Borders and Sustainable Development Goals},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375067},
doi = {10.1145/3334480.3375067},
abstract = {As HCI Across Borders aspires to celebrate its fifth year at CHI, and the CHI 2020 venue of Hawaii signifies a coming together of four continents, the goal of the 2020 symposium is to bring our focus to themes that unify and foster solidarity across borders. Thus we select the United Nations' Sustainable Development Goals as our object of study. Many communities within CHI focus on the constrained and ephemeral nature of resources, including the HCI for Development (HCI4D), Sustainable HCI (SHCI), and Crisis Informatics (CI) communities, among several others. We contend that it is time for these communities to come together in addressing issues of global relevance and impact, and for many more to care. Additionally, as the venue for CHI shifts to Asia in 2021, we aspire to prepare the conference and its participants to grapple with themes that might offer a different and novel perspective when engaged within the Global South.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {sustainable hci, sustainable development, hcixb, hci4d, crisis informatics},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383175,
author = {Kim, Bogyeong and Lee, Chaeeun and Huh, Jung and Lee, Woohun},
title = {Puppet Book: Digital Storybook with Back-of-Device Puppeteering Interface for Parent and Child},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383175},
doi = {10.1145/3334480.3383175},
abstract = {Puppet Book is a new concept of a digital storybook that is incorporated with puppetry. It enables parents to manipulate characters in real-time through a back-of-device interface while reading a storybook to their children. Puppet Book aims to provide enhanced expressiveness for parents and immersion for children. The Puppet Book interface was implemented carefully to minimize parents' task workload and maximize the expressiveness of puppeteering. A user study with 11 parent-child groups was conducted. Parents who easily adapted to the interface showed a higher motivation to tell the story, by identifying themselves with the characters. Children showed increased concentration and motivation for reading.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {back-of-device interaction, storytelling, digital storybook, children, digital puppetry},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383173,
author = {Masson, Damien and Malacria, Sylvain and Lank, Edward and Casiez, G\'{e}ry},
title = {Bringing Interactivity to Research Papers and Presentations with Chameleon},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383173},
doi = {10.1145/3334480.3383173},
abstract = {Chameleon is a software that combines computer vision feature-matching algorithms with an open database format to allow the incorporation of dynamic HTML5 interactive content over any type of document (e.g. PDF files, PowerPoint documents, etc.) without modifying existing applications or the source document. It thus allows the provision and viewing of an enhanced version of a research paper with embedded interactive demonstrations or videos. It can also be used to perform live demonstrations of interaction techniques while giving a presentation without having to switch tools.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {interactivity, augmented documents, feature matching},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383163,
author = {Semertzidis, Nathan and Scary, Michaela and Andres, Josh and Kulwe, Yutika and Dwivedi, Brahmi and Zambetta, Fabio and Mueller, Florian Floyd},
title = {Neo-Noumena},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383163},
doi = {10.1145/3334480.3383163},
abstract = {Communicating emotional experiences is something core to being human, yet also notoriously difficult. With this considered, we acknowledge previous work in bio-responsive and neurofeedback systems which facilitate the externalization of subjective experiences, which highlight potential for the appropriation of Neurofeedback for communication. We present a demonstration that explores this opportunity through "Neo-Noumena", a communicative neuro-responsive system that augments the interpersonal communication of emotion through brain-computer interfacing and artificial intelligence, which interprets the users affective state and dynamically to others in mixed reality through two head-mounted displays. The user will, with a partner, experience their affective state translated into an aural swarm of procedurally generated, emotionally informative fractals.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {mixed reality, machine learning, emotion communication, affective computing, brain-computer interfacing, EEG},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383143,
author = {Hung, Ching-Wen and Wu, Tzu-Chun and Tsai, Hsin-Ruey and Chen, Bing-Yu},
title = {Demonstration of ElastOscillation: A VR Controller Providing 3D Multilevel Feedback for Damped Oscillation},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383143},
doi = {10.1145/3334480.3383143},
abstract = {We propose ElastOscillation, mounted on a virtual reality(VR) controller to provide 3D multilevel force feedback for damped oscillation to enhance VR experiences. ElastOscillation consists of a proxy, six elastic bands and DC motors. It leverages the motors to control the bands' elasticity to restrain the movement of the proxy, which is connected with the bands. Therefore, when users shake the ElastOscillation device, the proxy shakes or moves in the corresponding movement ranges or levels. The users then perceive the force from oscillation in different levels. In addition, elastic force from the bands further reinforces the oscillation force feedback. In the demonstration, users can explore four VR applications that feel the sensation of pan-flipping, bartender-shaking, wine-swirling and fishing.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–3},
numpages = {3},
keywords = {elastic force, oscillation, haptic feedback, virtual reality, force feedback},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383102,
author = {Avellino, Ignacio},
title = {Hard Constraints: Why Telemanipulated Surgical Robots Affect Creative Tool Use},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383102},
doi = {10.1145/3334480.3383102},
abstract = {The operating room is fertile ground for creativity: problem solving is common, different surgical tasks impose particular constraints, and a wide range of tools are available. The introduction of telemanipulated robots in Minimally Invasive Surgery (MIS) has impacted the work of surgeons and their teams in terms of communication, use of perceptual senses, social structure, roles among other things. But do they also impact creativity? I present preliminary results of data re-analysis from an earlier field study focusing on creative tool use. Results suggest that current surgical robots limit creativity as they impose hard constraints: they remove haptic feedback, isolate the surgeon, and are built in rigid ways.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {teleoperation, surgical robots, creativity, appropiation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383017,
author = {Merino, Leonel and Sotomayor-G\'{o}mez, Boris and Yu, Xingyao and Salgado, Ronie and Bergel, Alexandre and Sedlmair, Michael and Weiskopf, Daniel},
title = {Toward Agile Situated Visualization: An Exploratory User Study},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383017},
doi = {10.1145/3334480.3383017},
abstract = {We introduce AVAR, a prototypical implementation of an agile situated visualization (SV) toolkit targeting liveness, integration, and expressiveness. We report on results of an exploratory study with AVAR and seven expert users. In it, participants wore a Microsoft HoloLens device and used a Bluetooth keyboard to program a visualization script for a given dataset. To support our analysis, we (i) video recorded sessions, (ii) tracked users' interactions, and (iii) collected data of participants' impressions. Our prototype confirms that agile SV is feasible. That is, liveness boosted participants' engagement when programming an SV, and so, the sessions were highly interactive and participants were willing to spend much time using our toolkit (i.e., median ≥ 1.5 hours). Participants used our integrated toolkit to deal with data transformations, visual mappings, and view transformations without leaving the immersive environment. Finally, participants benefited from our expressive toolkit and employed multiple of the available features when programming an SV.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {user study, augmented reality, situated visualization},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383001,
author = {Divekar, Rahul R. and Su, Hui and Kephart, Jeffrey O. and DeBayser, Maira Gratti and Guerra, Melina and Mou, Xiangyang and Peveler, Matthew and Chen, Lisha},
title = {HUMAINE: Human Multi-Agent Immersive Negotiation Competition},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383001},
doi = {10.1145/3334480.3383001},
abstract = {Competitions that directly pit software agents against one another have proven to be an effective and entertaining way to advance the state of the art in a multitude of AI domains. Less frequently, human-agent competitions have been held to gauge the relative competence of humans vs. agents, or agents vs. agents as measured indirectly by their performance against humans. We are developing a platform that supports a new type of AI competition that involves both agent-agent and human-agent interactions situated in an immersive environment. In this competition, human buyers haggle (in English) with two life-size AI agents that attempt to sell them various goods. We describe several research challenges that arise in this context, present the platform architecture and accompanying technologies, and report on early experiments with simple agents that establish feasibility and suggest that human participants enjoy the experience.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {dialogue systems, immersive environment, mixed reality, multimodal dialogue, multiparty dialogue, negotiation, agent competition},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382987,
author = {Fujita, Kazuyuki and Hayashi, Daigo and Hara, Kotaro and Takashima, Kazuki and Kitamura, Yoshifumi},
title = {Techniques to Visualize Occluded Graph Elements for 2.5D Map Editing},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382987},
doi = {10.1145/3334480.3382987},
abstract = {We propose an interface with two novel techniques to visualize occluded graph nodes and edges that help the user edit map data with a 2.5D geographical structure (e.g., multi-floor indoor maps). We first design a visualization technique -Repel Signification- that employs micro-animation to signify the graph elements that are overlapping with each other (and potentially erroneous). We also design a technique that enables the user to edit the occluded components with Expansion Interaction, which simultaneously visualizes both in-floor and across-floor occluded connections between the map elements. The combination of the two methods would enable the map editors (non-experts) to effectively find and fix erroneous data in 2.5D maps without changing the operation manner from the existing 2D map-editing interface.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {graph visualization, geovisualization},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382961,
author = {Allen, JoDee and Holzer, Adrian},
title = {Jingle Jigsaw - Playful Dance Scaffolding Through Motion Detection},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382961},
doi = {10.1145/3334480.3382961},
abstract = {Extended screen-time can have negative health effects in both children and adults. With the advent of motion de- tection sensors and other novel interaction methods, it is possible to envision digital games that move away from screen-centered design. However, such interaction is still underrepresented in both the mainstream and academia. To address this issue, this paper proposes a screenless dance game, called Jingle Jigsaw, that encourages players to physically explore the space around them by using spatial tracking and audio feedback. We conducted a preliminary usability evaluation that conveys the fact that such interaction is perceived as enjoyable by users and pointed to promising future work.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {digital-physical games, motion sensors, HCI, exer-games, dancing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382951,
author = {Choi, Yoonseo and Shin, Hyungyu and Monserrat, Toni-Jan Keith and Lee, Nyoungwoo and Park, Jeongeon and Kim, Juho},
title = {Supporting an Iterative Conversation Design Process},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382951},
doi = {10.1145/3334480.3382951},
abstract = {Conversation design is an essential step in building a chatbot. Much like visual user interface design, conversation design benefits from prototyping and user testing to allow for conversation exploration and improvement. However, it can be overwhelming to quickly iterate on the conversation design as the iterative process requires not only designing a conversation but also building and testing a working chatbot equipped with the conversation. We developed ProtoChat, a prototype system that supports an iterative conversation design by allowing designers to (1) prototype conversations, (2) test the conversations with the crowd, and (3) review and analyze the crowdsourced conversation data. Results of an exploratory study with four conversation designers show that the designers successfully iterated on their conversation design by reviewing how the crowd followed the conversation, which provided insights into concrete action items for improving their conversation design.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {iterative design, early-stage design support, crowdsourcing, conversation design, chatbot design process},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382949,
author = {Chen, Jiawei and Xu, Anbang and Liu, Zhe and Guo, Yufan and Liu, Xiaotong and Tong, Yingbei and Akkiraju, Rama and Carroll, John M.},
title = {A General Methodology to Quantify Biases in Natural Language Data},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382949},
doi = {10.1145/3334480.3382949},
abstract = {Biases in data, such as gender and racial stereotypes, are propagated through intelligent systems and amplified at end-user applications. Existing studies detect and quantify biases based on pre-defined attributes. However, in real practices, it is difficult to gather a comprehensive list of sensitive concepts for various categories of biases. We propose a general methodology to quantify dataset biases by measuring the difference of its data distribution with a reference dataset using Maximum Mean Discrepancy. For the case of natural language data, we show that lexicon-based features quantify explicit stereotypes, while deep learning-based features further capture implicit stereotypes represented by complex semantics. Our method provides a more flexible way to detect potential biases.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {quantify bias, natural language data},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382920,
author = {Knierim, Pascal and Kosch, Thomas and Groschopp, Johannes and Schmidt, Albrecht},
title = {Opportunities and Challenges of Text Input in Portable Virtual Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382920},
doi = {10.1145/3334480.3382920},
abstract = {Text input in virtual reality is not widespread outside of labs, although being increasingly researched. Current setups require powerful components that are expensive or not portable, hence preventing effective in-the-wild use. Latest technological advances enable portable mixed reality experiences on smartphones. In this work, we propose a portable low-fidelity solution for text input in mixed reality on a physical keyboard that employs accessible off-the-shelf components. Through a user study with 24 participants, we show that our prototype leads to a significantly higher text input performance compared to soft keyboards. However, it falls behind on copy editing compared to soft keyboards. Qualitative inquiries revealed that participants enjoyed the ample display space and perceived the accompanied privacy as beneficial. Finally, we conclude with challenges and future research that builds upon the presented findings.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {text entry, mixed reality, copy editing, portable virtual reality, physical keyboard, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382915,
author = {Lin, Li and Zhang, Jingyu and Zhang, Liang and Cao, Jianqin and Wang, Jifang and Luo, Xiaojun and Wang, Ya},
title = {Motive Structure Underlying the Use of Intelligent Connected Vehicles},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382915},
doi = {10.1145/3334480.3382915},
abstract = {Intelligent connected vehicles (ICVs) are the foundation to create an intelligent transport eco-system. While the population of ICV users is gradually increasing, the motives underlying use of ICVs remain unclear. Here, we developed a scale to measure motives for ICV use. Taken the results of explorative factor analysis and confirmatory factor analysis together, we suggested a four-factor model: symbolic, instrumental, affective-self, and affective-other motives. We found that ICV users with different characteristics in age, annual income and driving distance evaluated the importance of motives differently. ICV users who are richer and drive longer distances are more likely to show higher symbolic and affective-self motives. Also, users' symbolic motive grows with age. Finally, we found that symbolic and affective motives correlated highly with social norms and loyalty, while instrumental motives related to perceived control feelings toward operating the vehicle. These findings shed novel insights on how to design ICVs and make related policies.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {instrumental motive, affect-others, intelligent connected vehicles, motive structure, symbolic motive, user experience, affect-self},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382865,
author = {Colley, Mark and Walch, Marcel and Rukzio, Enrico},
title = {Unveiling the Lack of Scalability in Research on External Communication of Autonomous Vehicles},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382865},
doi = {10.1145/3334480.3382865},
abstract = {The traffic system is a complex network with numerous individuals (e.g., drivers, cyclists, and pedestrians) and vehicles involved. Road systems vary in various aspects such as the number of lanes, right of way, and configuration. With the emergence of autonomous vehicles, this system will change. Research has already addressed the missing communication possibilities when no human driver is needed. However, there is no common evaluation standard for the proposed external communication concept with respect to the complexity of the traffic system. We have therefore investigated the evaluation of these in Virtual Reality, in monitor-based, and in prototypical setups with special regard to scalability. We found that simulated traffic noise is a non-factor in current evaluations and that involving multiple people and multiple lanes with numerous vehicles is scarce.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {scalability, interface design, self-driving vehicles, autonomous vehicles, external communication},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382821,
author = {Yuksel, Beste F. and Kim, Soo Jung and Jin, Seung Jung and Lee, Joshua Junhee and Fazli, Pooyan and Mathur, Umang and Bisht, Vaishali and Yoon, Ilmi and Siu, Yue-Ting and Miele, Joshua A.},
title = {Increasing Video Accessibility for Visually Impaired Users with Human-in-the-Loop Machine Learning},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382821},
doi = {10.1145/3334480.3382821},
abstract = {Video accessibility is crucial for blind and visually impaired individuals for education, employment, and entertainment purposes. However, professional video descriptions are costly and time-consuming. Volunteer-created video descriptions could be a promising alternative, however, they can vary in quality and can be intimidating for novice describers. We developed a Human-in-the-Loop Machine Learning (HILML) approach to video description by automating video text generation and scene segmentation while allowing humans to edit the output. Our HILML system was significantly faster and easier to use for first-time video describers compared to a human-only control condition with no machine learning assistance. The quality of the video descriptions and understanding of the topic created by the HILML system compared to the human-only condition were rated as being significantly higher by blind and visually impaired users.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {video description, human-in-the-loop, machine learning, blind users, visually impaired users, video accessibility},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382806,
author = {Joharizadeh, Nima and Sarkar, Advait and Gordon, Andrew D. and Williams, Jack},
title = {Gridlets: Reusing Spreadsheet Grids},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382806},
doi = {10.1145/3334480.3382806},
abstract = {Spreadsheets allow end users to blend calculations with arbitrary layout and formatting. However, when it comes to reusing groups of formulae along with layout and formatting, spreadsheets provide only limited support. Most users rely on copy and paste, which is easy to learn and use, but maintaining several copies can be tedious and error-prone. We present the concept of Gridlets, an abstraction over calculation and presentation applicable in common use case scenarios. Using the Cognitive Dimensions of Notations framework, we compare Gridlets to copy/paste and sheet-defined functions. We find that Gridlets are consistent with the spreadsheet paradigm, enable users to take advantage of secondary notation, and make common edit operations less viscous and less error-prone.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {abstraction, end-user programming, spreadsheets},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

