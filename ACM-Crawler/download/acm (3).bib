@inproceedings{10.1145/3313831.3376375,
author = {Huffaker, Jordan S. and Kummerfeld, Jonathan K. and Lasecki, Walter S. and Ackerman, Mark S.},
title = {Crowdsourced Detection of Emotionally Manipulative Language},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376375},
doi = {10.1145/3313831.3376375},
abstract = {Detecting rhetoric that manipulates readers' emotions requires distinguishing intrinsically emotional content (IEC; e.g., a parent losing a child) from emotionally manipulative language (EML; e.g., using fear-inducing language to spread anti-vaccine propaganda). However, this remains an open classification challenge for both automatic and crowdsourcing approaches. Machine Learning approaches only work in narrow domains where labeled training data is available, and non-expert annotators tend to conflate IEC with EML. We introduce an approach, anchor comparison, that leverages workers' ability to identify and remove instances of EML in text to create a paraphrased "anchor text", which is then used as a comparison point to classify EML in the original content. We evaluate our approach with a dataset of news-style text snippets and show that precision and recall can be tuned for system builders' needs. Our contribution is a crowdsourcing approach that enables non-expert disentanglement of social references from content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {crowdsourcing, emotion, media manipulation, rhetoric},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376366,
author = {Nittala, Aditya Shekhar and Khan, Arshad and Kruttwig, Klaus and Kraus, Tobias and Steimle, J\"{u}rgen},
title = {PhysioSkin: Rapid Fabrication of Skin-Conformal Physiological Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376366},
doi = {10.1145/3313831.3376366},
abstract = {Advances in rapid prototyping platforms have made physiological sensing accessible to a wide audience. However, off-the-shelf electrodes commonly used for capturing biosignals are typically thick, non-conformal and do not support customization. We present PhysioSkin, a rapid, do-it-yourself prototyping method for fabricating custom multi-modal physiological sensors, using commercial materials and a commodity desktop inkjet printer. It realizes ultrathin skin-conformal patches (~1μm) and interactive textiles that capture sEMG, EDA and ECG signals. It further supports fabricating devices with custom levels of thickness and stretchability. We present detailed fabrication explorations on multiple substrate materials, functional inks and skin adhesive materials. Informed from the literature, we also provide design recommendations for each of the modalities. Evaluation results show that the sensor patches achieve a high signal-to-noise ratio. Example applications demonstrate the functionality and versatility of our approach for prototyping a next generation of physiological devices that intimately couple with the human body.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {e-textile, wearable devices, ink-jet printing, fabrication, rapid prototyping, physiological sensing, electronic skin},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376360,
author = {Schubhan, Marc and Altmeyer, Maximilian and Buchheit, Dominic and Lessel, Pascal},
title = {Investigating User-Created Gamification in an Image Tagging Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376360},
doi = {10.1145/3313831.3376360},
abstract = {Commonly, gamification is designed by developers and not by end-users. In this paper we investigate an approach where users take control of this process. Firstly, users were asked to describe their own gamification concepts which would motivate them to put more effort into an image tagging task. We selected this task as gamification has already been shown to be effective here in previous work. Based on these descriptions, an implementation was made for each concept and given to the creator. In a between-subjects study (n=71), our approach was compared to a no-gamification condition and two conditions with fixed gamification settings. We found that providing participants with an implementation of their own concept significantly increased the amount of generated tags compared to the other conditions. Although the quality of tags was lower, the number of usable tags remained significantly higher in comparison, suggesting the usefulness of this approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {motivation, user-driven game design, bottom-up, replication, customization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376346,
author = {Mohamed, Reham and Chametka, Paulina and Chiasson, Sonia},
title = {The Influence of Decaying the Representation of Older Social Media Content on Simulated Hiring Decisions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376346},
doi = {10.1145/3313831.3376346},
abstract = {Decaying representations gradually make social media content less visible to readers over time, which can help users disassociate from past online activities. We explore whether shrinking, one decaying representation, influences managers' assessments and simulated hiring decisions of job candidates, compared to seeing a full profile or an empty profile with no posts. Our 3 x 2 between-subjects crowdsourced survey (N = 360 US managers) shows that shrunk or empty profiles led to more positive decisions than profiles in their original full format. However, shrunk profiles also further contributed to more positive impressions of the candidates. Shrinking did not help the candidate of either gender more than the other and demographics of managers had limited impact on their assessment. Further, our managers regularly search job candidates' social media profiles in real life, suggesting that shrinking could support users' privacy. We finally present implications for individuals' privacy on social media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–19},
numpages = {19},
keywords = {online reputation management, decaying representations, online privacy, online social networks, hiring context},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376337,
author = {Logler, Nick and Pitt, Caroline and Gao, Xin and Hishikawa, Allison Marie and Yip, Jason and Friedman, Batya},
title = {"I Feel Like This is a Bad Thing": Investigating Disassembly in Action for Novices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376337},
doi = {10.1145/3313831.3376337},
abstract = {Materials are dynamic-they can be shaped and changed. Often however, our tools and technologies appear to fix materials in place. Disassembly is one practice that provides openings to explore and understand the dynamic nature of material. In this research, we investigate possibilities that emerge from disassembly. Specifically, we studied how novices disassembled a common digital artifact-desktop printers. We worked with 21 young people and family members across two evening workshops at a middle school. We report on the workshop interactions, categories of actions of disassembly, and four in-depth vignettes showcasing disassembly in action. In the discussion, we reflect on disassembly and permission, sustainability, the joy of disassembling, and design considerations in support of disassembly. Our contributions include: (1) extending existing theoretical framings about artifacts and materials; (2) an empirical study documenting the process by which novices disassemble; and (3) preliminary design and policy considerations that enable disassembly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {empowerment, materials, disassembly, making, novices, unmaking, play, design theory, design principles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376334,
author = {Ces\'{a}rio, Vanessa and Petrelli, Daniela and Nisi, Valentina},
title = {Teenage Visitor Experience: Classification of Behavioral Dynamics in Museums},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376334},
doi = {10.1145/3313831.3376334},
abstract = {Teenagers' engagement in museums is much talked about but little research has been done to understand their behavior and inform design. Findings from co-design sessions with teenagers suggested they value games and stories when thinking about enjoyable museum tours. Informed by these findings and working with a natural history museum, we designed: a story-based tour (Turning Point) and a game-based tour (Haunted Encounters), informed by similar content. The two strategies were evaluated with 78 teenagers (15-19 years old) visiting the museum as part of an educational school trip. We assessed teenagers' personality in class; qualitative and quantitative data on their engagement, experience, and usability of the apps were collected at the museum. The triangulation of quantitative and qualitative data show personality traits mapping into different behaviors. We offer implications for the design of museum apps targeted to teenagers, a group known as difficult to reach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-design, mobile experience, game, museums, storytelling, teenagers, visitor experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376331,
author = {Zarei, Niloofar and Chu, Sharon Lynn and Quek, Francis and Rao, Nanjie 'Jimmy' and Brown, Sarah Anne},
title = {Investigating the Effects of Self-Avatars and Story-Relevant Avatars on Children's Creative Storytelling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376331},
doi = {10.1145/3313831.3376331},
abstract = {Storytelling is a critical step in the cognitive development of children. Particularly, this requires children to mentally project into the story context and to identify with the thoughts of the characters in their stories. We propose to support free imagination in creative storytelling through an enactment-based approach that allows children to embody an avatar and perform as the story character. We designed our story creation interface with two modes of avatar: the story-relevant avatar and the self-avatar, to investigate the effects of avatar design on the quality of children's creative products. In our study with 20 child participants, the results indicate that self-avatars can create a stronger sense of identification and embodied presence, while story-relevant avatars can provide a scaffold for mental projection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {expressive writing, virtual reality, creativity, embodied interaction, storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376327,
author = {Lee, Chunggi and Kim, Sanghoon and Han, Dongyun and Yang, Hongjun and Park, Young-Woo and Kwon, Bum Chul and Ko, Sungahn},
title = {GUIComp: A GUI Design Assistant with Real-Time, Multi-Faceted Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376327},
doi = {10.1145/3313831.3376327},
abstract = {Users may face challenges while designing graphical user interfaces, due to a lack of relevant experience and guidance. This paper aims to investigate the issues users face during the design process, and how to resolve them. To this end, we conducted semi-structured interviews, based on which we built a GUI prototyping assistance tool called GUIComp. This tool can be connected to GUI design software as an extension, and it provides real-time, multi-faceted feedback on a user's current design. Additionally, we conducted two user studies, in which we asked participants to create mobile GUIs with or without GUIComp, and requested online workers to assess the created GUIs. The experimental results show that GUIComp facilitated iterative designs and the participants with GUIComp had better a user experience and produced more acceptable designs than those who did not use it.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gui design, design feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376322,
author = {Zhang, Xinlei and Miyaki, Takashi and Rekimoto, Jun},
title = {WithYou: Automated Adaptive Speech Tutoring With Context-Dependent Speech Recognition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376322},
doi = {10.1145/3313831.3376322},
abstract = {Learning to speak in foreign languages is hard. Speech shadowing has been rising as a proven way to practice speaking, which asks a learner to listen and repeat a native speech template as simultaneously as possible. However, shadowing can be hard to do because learners can frequently fail to follow the speech and unintentionally interrupt a practice session. Worse, as a technical way to evaluate shadowing performance in real-time has not been established, no automated solutions are available to help. In this paper, we propose a technical framework with context-dependent speech recognition to evaluate shadowing in real-time. We propose a shadowing tutor system called WithYou, which can automatically adjust the playback and the difficulty of a speech template when learners fail, so shadowing becomes smooth and tailored. Results from a user study show that WithYou provides greater speech improvements (14%) than the conventional method (2.7%) with a lower cognitive load.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {shadowing, speech recognition, computer assisted language learning (call), speaking, intelligent tutoring system, language learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376307,
author = {Clarke, Rachel Ivy and Schoonmaker, Sayward},
title = {The Critical Catalog: Library Information Systems, Tricksterism, and Social Justice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376307},
doi = {10.1145/3313831.3376307},
abstract = {In this paper, we describe the Critical Catalog, a grant-funded research through design project intended to investigate metadata elements, values, and organizational structures necessary to intentionally advocate for diversity and expose library users to resources from populations traditionally marginalized in literature and publishing. Drawing on principles from critical design, the prototype functions as a critical intervention intended to raise questions and stimulate debate, rather than a purely technical fix to deeply social concerns. A detailed reflective discussion of the design process reveals how existing infrastructural constraints shaped design decisions that led to increased advocacy and a stronger activist standpoint. We discuss the use of metadata as design material for social justice, the application of tricksterism in HCI, and how both practical limitations from professional contexts and imposed limitations based on identities and positions of power can lead to surprising places, meanings, and questions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tricksterism, whiteness, research through design, library catalogs, metadata},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376302,
author = {Dylan, Thomas and Wood, Gavin and Durrant, Abigail C. and Vines, John and Torres, Pablo E. and Ulrich, Philip I. N. and Cukurova, Mutlu and Carr, Amanda and \c{C}er\c{c}i, Sena and Lawson, Shaun},
title = {Designing IoT Resources to Support Outdoor Play for Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376302},
doi = {10.1145/3313831.3376302},
abstract = {We describe a Research-through-Design (RtD) project that explores the Internet of Things (IoT) as a resource for children's free play outdoors. Based on initial insights from a design ethnography, we developed four RtD prototypes for social play in different scenarios of use outdoors, including congregating on a street or in a park to play physical games with IoT. We observed these prototypes in use by children in their free play in two community settings, and report on the qualitative analysis of our fieldwork. Our findings highlight the designs' material qualities that encouraged social and physical play under certain conditions, suggesting social affordances that are central to the success of IoT designs for free play outdoors. We provide directions for future research that addresses the challenges faced when deploying IoT with children, contributing new considerations for interaction design with children in outdoor settings and free play contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {children, outdoor play, digital playing out, free play, pervasive play, internet of things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376288,
author = {Davis, Keith M. and Kangassalo, Lauri and Spap\'{e}, Michiel and Ruotsalo, Tuukka},
title = {Brainsourcing: Crowdsourcing Recognition Tasks via Collaborative Brain-Computer Interfacing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376288},
doi = {10.1145/3313831.3376288},
abstract = {This paper introduces brainsourcing: utilizing brain responses of a group of human contributors each performing a recognition task to determine classes of stimuli. We investigate to what extent it is possible to infer reliable class labels using data collected utilizing electroencephalography (EEG) from participants given a set of common stimuli. An experiment (N=30) measuring EEG responses to visual features of faces (gender, hair color, age, smile) revealed an improved F1 score of 0.94 for a crowd of twelve participants compared to an F1 score of 0.67 derived from individual participants and a random chance of 0.50. Our results demonstrate the methodological and pragmatic feasibility of brainsourcing in labeling tasks and opens avenues for more general applications using brain-computer interfacing in a crowdsourced setting.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {crowdsourcing, brainsourcing, brain-computer interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376282,
author = {Blank, Christopher and Zaman, Shaila and Wesley, Amanveer and Tsiamyrtzis, Panagiotis and Da Cunha Silva, Dennis R. and Gutierrez-Osuna, Ricardo and Mark, Gloria and Pavlidis, Ioannis},
title = {Emotional Footprints of Email Interruptions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376282},
doi = {10.1145/3313831.3376282},
abstract = {Working in an environment with constant interruptions is known to affect stress, but how do interruptions affect emotional expression? Emotional expression can have significant impact on interactions among coworkers. We analyzed the video of 26 participants who performed an essay task in a laboratory while receiving either continual email interruptions or receiving a single batch of email. Facial videos of the participants were run through a convolutional neural network to determine the emotional mix via decoding of facial expressions. Using a novel co-occurrence matrix analysis, we showed that with batched email, a neutral emotional state is dominant with sadness being a distant second, and with continual interruptions, this pattern is reversed, and sadness is mixed with fear. We discuss the implications of these results for how interruptions can impact employees' well-being and organizational climate.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {co-occurence matrix, facial expressions, emotions, email interruptions, convolutional neural network},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376281,
author = {Li, Quan and Lin, Huanbin and Wei, Xiguang and Huang, Yangkun and Fan, Lixin and Du, Jian and Ma, Xiaojuan and Chen, Tianjian},
title = {MaraVis: Representation and Coordinated Intervention of Medical Encounters in Urban Marathon},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376281},
doi = {10.1145/3313831.3376281},
abstract = {There is an increased use of Internet-of-Things and wearable sensing devices in the urban marathon to ensure effective response to unforeseen medical needs. However, the massive amount of real-time, heterogeneous movement and psychological data of runners impose great challenges on prompt medical incident analysis and intervention. Conventional approaches compile such data into one dashboard visualization to facilitate rapid data absorption but fail to support joint decision-making and operations in medical encounters. In this paper, we present MaraVis, a real-time urban marathon visualization and coordinated intervention system. It first visually summarizes real-time marathon data to facilitate the detection and exploration of possible anomalous events. Then, it calculates an optimal camera route with an arrangement of shots to guide offline effort to catch these events in time with a smooth view transition. We conduct a within-subjects study with two baseline systems to assess the efficacy of MaraVis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {marathon visualization, shot chaining, anomaly detection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376278,
author = {Chapko, Dorota and Frumiento, Pino and Edwards, Nalini and Emeh, Lizzie and Kennedy, Donald and McNicholas, David and Overton, Michaela and Snead, Mark and Steward, Robyn and Sutton, Jenny M. and Jeffreys, Evie and Long, Catherine and Croll-Knight, Jess and Connors, Ben and Castell-Ward, Sam and Coke, David and McPeake, Bethany and Renel, William and McGinley, Chris and Remington, Anna and Whittuck, Dora and Kieffer, John and Ewans, Sarah and Williams, Mark and Grierson, Mick},
title = {"We Have Been Magnified for Years - Now You Are under the Microscope!": Co-Researchers with Learning Disabilities Created an Online Survey to Challenge Public Understanding of Learning Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376278},
doi = {10.1145/3313831.3376278},
abstract = {Public attitudes towards learning disabilities (LDs) are generally reported as positive, inclusive and empathetic. However, these findings do not reflect the lived experiences of people with LDs. To shed light on this disparity, a team of co-researchers with LDs created the first online survey to challenge public understanding of LDs, asking questions in ways that are important to them and represent how they see themselves. Here, we describe and evaluate the process of creating an accessible survey platform and an online survey in a research team consisting of academic and non-academic professionals with and without LDs or autism. Through this inclusive research process, the co-designed survey met the expectations of the co-researchers and was well-received by the initial survey respondents. We reflect on the co-researchers' perspectives following the study completion, and consider the difficulties and advantages we encountered deploying such approaches and their potential implications on future survey data analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {video, attitudes, disability, design, survey, participatory/inclusive research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376277,
author = {An, Pengcheng and Holstein, Kenneth and d'Anjou, Bernice and Eggen, Berry and Bakker, Saskia},
title = {The TA Framework: Designing Real-Time Teaching Augmentation for K-12 Classrooms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376277},
doi = {10.1145/3313831.3376277},
abstract = {Recently, the HCI community has seen increased interest in the design of teaching augmentation (TA): tools that extend and complement teachers' pedagogical abilities during ongoing classroom activities. Examples of TA systems are emerging across multiple disciplines, taking various forms: e.g., ambient displays, wearables, or learning analytics dashboards. However, these diverse examples have not been analyzed together to derive more fundamental insights into the design of teaching augmentation. Addressing this opportunity, we broadly synthesize existing cases to propose the TA framework. Our framework specifies a rich design space in five dimensions, to support the design and analysis of teaching augmentation. We contextualize the framework using existing designs cases, to surface underlying design trade-offs: for example, balancing actionability of presented information with teachers' needs for professional autonomy, or balancing unobtrusiveness with informativeness in the design of TA systems. Applying the TA framework, we identify opportunities for future research and design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {classroom, orchestration, augmented intelligence, teacher, k-12, dashboards, ambient intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376272,
author = {Sheshadri, Smitha and Zhao, Shengdong and Chen, Yang and Fjeld, Morten},
title = {Learn with Haptics: Improving Vocabulary Recall with Free-Form Digital Annotation on Touchscreen Mobiles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376272},
doi = {10.1145/3313831.3376272},
abstract = {Mobile vocabulary learning interfaces typically present material only in auditory and visual channels, underutilizing the haptic modality. We explored haptic-integrated learning by adding free-form digital annotation to mobile vocabulary learning interfaces. Through a series of pilot studies, we identified three design factors: annotation mode, presentation sequence, and vibrotactile feedback, that influence recall in haptic-integrated vocabulary interfaces. These factors were then evaluated in a within-subject comparative study using a digital flashcard interface as baseline. Results using a 84-item vocabulary showed that the 'whole word' annotation mode is highly effective, yielding a 24.21% increase in immediate recall scores and a 30.36% increase in the 7-day delayed scores. Effects of presentation sequence and vibrotactile feedback were more transient; they affected the results of immediate tests, but not the delayed tests. We discuss the implications of these factors for designing future mobile learning applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {haptics for learning, mobile vocabulary learning, intersensory reinforced learning, multimodal learning, motoric engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376268,
author = {Turmo Vidal, Laia and Zhu, Hui and Riego-Delgado, Abraham},
title = {BodyLights: Open-Ended Augmented Feedback to Support Training Towards a Correct Exercise Execution},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376268},
doi = {10.1145/3313831.3376268},
abstract = {Technologies targeting a correct execution of physical training exercises typically use pre-determined models for what they consider correct, automatizing instruction and feedback. This falls short on catering to diverse trainees and exercises. We explore an alternative design approach, in which technology provides open-ended feedback for trainers and trainees to use during training. With a personal trainer we designed the augmentation of 18 strength training exercises with BodyLights: 3D printed wearable projecting lights that augment body movement and orientation. To study them, 15 trainees at different skill levels trained three times with our personal trainer and BodyLights. Our findings show that BodyLights catered to a wide range of trainees and exercises, and supported understanding, executing and correcting diverse technique parameters. We discuss design features and methodological aspects that allowed this; and what open-ended feedback offered in comparison to current technology approaches to support training towards a correct exercise execution.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {rtd, correct performance, activity design, augmented feedback, strength training, physical training, wearables},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376260,
author = {Alexandrovsky, Dmitry and Putze, Susanne and Bonfert, Michael and H\"{o}ffner, Sebastian and Michelmann, Pitt and Wenig, Dirk and Malaka, Rainer and Smeddinck, Jan David},
title = {Examining Design Choices of Questionnaires in VR User Studies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376260},
doi = {10.1145/3313831.3376260},
abstract = {Questionnaires are among the most common research tools in virtual reality (VR) user studies. Transitioning from virtuality to reality for giving self-reports on VR experiences can lead to systematic biases. VR allows to embed questionnaires into the virtual environment which may ease participation and avoid biases. To provide a cohesive picture of methods and design choices for questionnaires in VR (inVRQ), we discuss 15 inVRQ studies from the literature and present a survey with 67 VR experts from academia and industry. Based on the outcomes, we conducted two user studies in which we tested different presentation and interaction methods of inVRQs and evaluated the usability and practicality of our design. We observed comparable completion times between inVRQs and questionnaires outside VR (nonVRQs) with higher enjoyment but lower usability for inVRQs. These findings advocate the application of inVRQs and provide an overview of methods and considerations that lay the groundwork for inVRQ design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–21},
numpages = {21},
keywords = {vr, research methods, virtual reality, invrqs, user studies, in-vr questionnaires},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376254,
author = {Jardine, Jacinta and Earley, Caroline and Richards, Derek and Timulak, Ladislav and Palacios, Jorge E. and Duffy, Daniel and Tierney, Karen and Doherty, Gavin},
title = {The Experience of Guided Online Therapy: A Longitudinal, Qualitative Analysis of Client Feedback in a Naturalistic RCT},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376254},
doi = {10.1145/3313831.3376254},
abstract = {Internet-delivered Cognitive Behavioural Therapy (iCBT) is an effective treatment for depression and anxiety disorders. However longitudinal qualitative research into the client's subjective experience of this form of treatment ?in the wild' is relatively scarce. We present an analysis of secondary outcomes in a naturalistic RCT conducted within the UK's Improving Access to Psychological Therapies programme. We evaluated clients' expectations, experience, and context of usage of iCBT, across three timepoints. Results are discussed in terms of the creation of a therapeutic space online, the impact of hope, expectations and personal factors on the therapeutic experience, iCBT as "therapy on the go" and developing skills for life. While iCBT on the whole provides a positive, supportive and therapeutic experience for clients, the study identified managing expectations, polarized preferences, momentary help-seeking and long-term support as important aspects of the experience to consider in future design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {icbt, mental health, longitudinal study, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376250,
author = {Kim, Seoyoung and Thakur, Arti and Kim, Juho},
title = {Understanding Users' Perception Towards Automated Personality Detection with Group-Specific Behavioral Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376250},
doi = {10.1145/3313831.3376250},
abstract = {Thanks to advanced sensing and logging technology, automatic personality assessment (APA) with users' behavioral data in the workplace is on the rise. While previous work has focused on building APA systems with high accuracy, little research has attempted to understand users' perception towards APA systems. To fill this gap, we take a mixed-methods approach: we (1) designed a survey (n=89) to understand users'social workplace behavior both online and offline and their privacy concerns; (2) built a research probe that detects personality from online and offline data streams with up to 81.3% accuracy, and deployed it for three weeks in Korea (n=32); and (3) conducted post-interviews (n=9). We identify privacy issues in sharing data and system-induced change in natural behavior as important design factors for APA systems. Our findings suggest that designers should consider the complex relationship between users' perception and system accuracy for a more user-centered APA design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user perception, behavior change, co-located group, privacy, tracking, automatic personality assessment (apa)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376241,
author = {Heyer, Jeremy and Schmitt, Zachary and Dombrowski, Lynn and Yarosh, Svetlana},
title = {Opportunities for Enhancing Access and Efficacy of Peer Sponsorship in Substance Use Disorder Recovery},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376241},
doi = {10.1145/3313831.3376241},
abstract = {Substance use disorders (SUDs) are characterized by an inability to decrease a substance use (e.g., alcohol or opioids) despite negative repercussions. SUDs are clinically diagnosable, hazardous, and considered a public health issue. Sponsorship, a specialized type of peer mentorship, is vital in the recovery process and originates from 12-step fellowship programs such as Alcoholics Anonymous (AA) and Narcotics Anonymous (NA). To investigate sponsorship relationship practices and to identify design opportunities for digitally-mediated peer support, we conducted 27 in-depth interviews with members of AA and NA. We identified five key sponsorship relationship practices relevant for designing social computing tools to support sponsorship and recovery: 1) assessing dyadic compatibility, 2) managing sponsorship with or without technology, 3) establishing boundaries, 4) building a peer support network, and 5) managing anonymity. We identify social computing and digitally-mediated design opportunities and implications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {substance use disorders, peer health support, 12-step fellowships, recovery, addiction, technology for substance use},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376239,
author = {Silva, In\^{e}s Santos and Guerreiro, Jo\~{a}o and Rosa, Marlene and Campos, Joana and Pascoal, Augusto Gil and Pinto, Sofia and Nicolau, Hugo},
title = {Investigating the Opportunities for Technologies to Enhance QoL with Stroke Survivors and Their Families},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376239},
doi = {10.1145/3313831.3376239},
abstract = {There are over 80 million stroke survivors globally, making it the main cause of long-term disability worldwide. Not only do the challenges associated with stroke affect the quality of life (QoL) of survivors, but also of their families. To explore these challenges and define design opportunities for technologies to improve the QoL of both stakeholders, we conducted semi-structured interviews with 10 survivors and one of their family members. We uncovered three major interlinked themes: strategies to cope with technological barriers, the (in)adequacy of assistive technologies, and limitations of the rehabilitation process. Findings highlight multiple design opportunities, including the need for meaningful patient-centered tools and methods to improve rehabilitation effectiveness, emotion-aware computing for family emotional support, and re-thinking the nature of assistive technologies to consider the perception of transitory stroke-related disabilities. We thus argue for a new class of dual-purpose technologies that fit survivors' abilities while promoting the regain of function.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {quality of life, assistive technologies, stroke rehabilitation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376236,
author = {Olwal, Alex and Starner, Thad and Mainini, Gowa},
title = {E-Textile Microinteractions: Augmenting Twist with Flick, Slide and Grasp Gestures for Soft Electronics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376236},
doi = {10.1145/3313831.3376236},
abstract = {E-textile microinteractions advance cord-based interfaces by enabling the simultaneous use of precise continuous control and casual discrete gestures. We leverage the recently introduced I/O Braid sensing architecture to enable a series of user studies and experiments which help design suitable interactions and a real-time gesture recognition pipeline. Informed by a gesture elicitation study with 36 participants, we developed a user-dependent classifier for eight discrete gestures with 94% accuracy for 12 participants. In a formal evaluation we show that we can enable precise manipulation with the same architecture. Our quantitative targeting experiment suggests that twisting is faster than existing headphone button controls and is comparable in speed to a capacitive touch surface. Qualitative interview feedback indicates a preference for I/O Braid's interaction over that of in-line headphone controls. Our applications demonstrate how continuous and discrete gestures can be combined to form new, integrated e-textile microinteraction techniques for real-time continuous control, discrete actions and mode switching.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wearables, soft electronics, interactive fabric, e-textile, gestures, smart textile, microinteractions, electronic textile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376233,
author = {Zhu, Fengyuan and Grossman, Tovi},
title = {BISHARE: Exploring Bidirectional Interactions Between Smartphones and Head-Mounted Augmented Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376233},
doi = {10.1145/3313831.3376233},
abstract = {In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mixed-reality computing, augmented reality, smartphones, cross-device computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376203,
author = {Meschtscherjakov, Alexander and D\"{o}ttlinger, Christine and Kaiser, Tim and Tscheligi, Manfred},
title = {Chase Lights in the Peripheral View: How the Design of Moving Patterns on an LED Strip Influences the Perception of Speed in an Automotive Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376203},
doi = {10.1145/3313831.3376203},
abstract = {LEDs on a strip, when turned on and off in a specific order, result in the perception of apparent motion (i.e. beta movement). In the automotive domain such chase lights have been used to alter drivers' perception of driving speed by manipulating the pixel speed of LEDs. We argue that the perceived velocity of beta movement in the peripheral view is not only based on the actual pixel speed but can be influenced by other factors such as frequency, width and brightness of lit LED segments. We conducted a velocity matching experiment (N=25) by systematically varying these three properties, in order to determine their influence on a participant's perceived velocity in a vehicle mock-up. Results show that a higher frequency and stronger brightness increased perceived velocity, whereas segment width had no influence. We discuss how findings may be applied when designing systems that use beta movement to influence the perception of ambient light velocity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {peripheral vision, velocity perception, chase lights, moving patterns},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376199,
author = {Klamka, Konstantin and Horak, Tom and Dachselt, Raimund},
title = {Watch+Strap: Extending Smartwatches with Interactive StrapDisplays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376199},
doi = {10.1145/3313831.3376199},
abstract = {While smartwatches are widely adopted these days, their input and output space remains fairly limited by their screen size. We present StrapDisplays-interactive watchbands with embedded display and touch technologies-that enhance commodity watches and extend their input and output capabilities. After introducing the physical design space of these StrapDisplays, we explore how to combine a smartwatch and straps in a synergistic Watch+Strap system. Specifically, we propose multiple interface concepts that consider promising content distributions, interaction techniques, usage types, and display roles. For example, the straps can enrich watch apps, display visualizations, provide glanceable feedback, or help avoiding occlusion issues. Further, we provide a modular research platform incorporating three StrapDisplay prototypes and a flexible web-based software architecture, demonstrating the feasibility of our approach. Early brainstorming sessions with 15 participants informed our design process, while later interviews with six experts supported our concepts and provided valuable feedback for future developments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mde, mobile interaction, flexible displays, wearable device, interactive watchband, smartwatch, mobile visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376197,
author = {Ackermans, Sander and Dey, Debargha and Ruijten, Peter and Cuijpers, Raymond H. and Pfleging, Bastian},
title = {The Effects of Explicit Intention Communication, Conspicuous Sensors, and Pedestrian Attitude in Interactions with Automated Vehicles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376197},
doi = {10.1145/3313831.3376197},
abstract = {In this paper, we investigate the effect of an external human-machine interface (eHMI) and a conspicuous external vehicle appearance due to visible sensors on pedestrian interactions with automated vehicles (AVs). Recent research shows that AVs may need to explicitly communicate with the environment due to the absence of a driver. Furthermore, in interaction situations, an AV that looks different and conspicuous owing to an extensive sensor system may potentially lead to hesitation stemming from mistrust in automation. Thus, we evaluated in a virtual reality study how pedestrian attitude, the presence/absence of an eHMI, and a conspicuous sensor system affect their willingness to cross the road. Results recommend the use of an eHMI. A conspicuous appearance of automated-driving capability had no effect for the sample as a whole, although it led to more efficient crossing decisions for those with a more negative attitude towards AVs. Our findings contribute towards the effective design of future AV interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {automated vehicles, vulnerable road users, external appearance, ehmi, pedestrians, automated driving, vehicle-pedestrian interaction, visible sensors},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376171,
author = {Wilson, Cara and Sitbon, Laurianne and Ploderer, Bernd and Opie, Jeremy and Brereton, Margot},
title = {Self-Expression by Design: Co-Designing the ExpressiBall with Minimally-Verbal Children on the Autism Spectrum},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376171},
doi = {10.1145/3313831.3376171},
abstract = {Expressing one's thoughts and feelings is a fundamental human need - the basis for communication and social interaction. We ask, how do minimally-verbal children on the autism spectrum express themselves? How can we better recognise instances of self-expression? And how might technologies support and encourage self-expression? To address these questions, we undertook co-design research at an autism-specific primary school with 20 children over one school year. This paper contributes six Modalities of Self-Expression, through which children self-express and convey their design insights. Each modality of self-expression can occur across two different dimensions (socio-expressive and auto-expressive) and can be of a fundamental or an integrative nature. Further, we contribute the design trajectory of a tangible ball prototype, the ExpressiBall, which - through voice, sounds, lights, and motion sensors - explores how tangible technologies can support this range of expressive modalities. Finally, we discuss the concept of Self-Expression by Design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tangible, play, autism, multimodal, self-expression, non-verbal, minimally-verbal, modalities, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376164,
author = {Arshad, Muhammad Bilal and Sarwar, Muhammad Farhan and Zaidi, Meher Fatima and Shahid, Suleman},
title = {EAST: Early Autism Screening Tool for Preschoolers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376164},
doi = {10.1145/3313831.3376164},
abstract = {We describe the iterative co-design process and evaluation of an early autism screening tool (EAST). EAST is an intermediary interactive tablet based app that assists in the early-detection of Autism Spectrum Disorder (ASD) by screening preschoolers in Pakistan through play-based activities in a home, school or clinical setting. Medical professionals, parents of autistic children and teachers were surveyed through focus groups to understand the reasons that contribute to the increasing number of missed early detections, and late- or misdiagnoses. We also evaluate the acceptability, usability and validity of our tool. We tested EAST with both typically developed and autistic children on how they relate to people, imitation, motor skills, visual and intellectual response. They were scored via time taken, the number of wrong attempts, or incorrect answers and audiovisual feedback. This paper contributes towards a digital autism screening tool that delivers insights into the child's behaviour and enables collaboration among parents, teachers and medical professionals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {preschool children, autism screening, digital tool},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376163,
author = {Sarsenbayeva, Zhanna and Marini, Gabriele and van Berkel, Niels and Luo, Chu and Jiang, Weiwei and Yang, Kangning and Wadley, Greg and Dingler, Tilman and Kostakos, Vassilis and Goncalves, Jorge},
title = {Does Smartphone Use Drive Our Emotions or Vice Versa? A Causal Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376163},
doi = {10.1145/3313831.3376163},
abstract = {In this paper, we demonstrate the existence of a bidirectional causal relationship between smartphone application use and user emotions. In a two-week long in-the-wild study with 30 participants we captured 502,851 instances of smartphone application use in tandem with corresponding emotional data from facial expressions. Our analysis shows that while in most cases application use drives user emotions, multiple application categories exist for which the causal effect is in the opposite direction. Our findings shed light on the relationship between smartphone use and emotional states. We furthermore discuss the opportunities for research and practice that arise from our findings and their potential to support emotional well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mobile application use, smartphones, emotion detection, mobile interaction, emotions, emotional well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376154,
author = {Shin, Donghoon and Song, Jaeyoon and Song, Seokwoo and Park, Jisoo and Lee, Joonhwan and Jun, Soojin},
title = {TalkingBoogie: Collaborative Mobile AAC System for Non-Verbal Children with Developmental Disabilities and Their Caregivers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376154},
doi = {10.1145/3313831.3376154},
abstract = {Augmentative and alternative communication (AAC) technologies are widely used to help non-verbal children enable communication. For AAC-aided communication to be successful, caregivers should support children with consistent intervention strategies in various settings. As such, caregivers need to continuously observe and discuss children's AAC usage to create a shared understanding of these strategies. However, caregivers often find it challenging to effectively collaborate with one another due to a lack of family involvement and the unstructured process of collaboration. To address these issues, we present TalkingBoogie, which consists of two mobile apps: TalkingBoogie-AAC for caregiver-child communication, and TalkingBoogie-coach supporting caregiver collaboration. Working together, these applications provide contextualized layouts for symbol arrangement, scaffold the process of sharing and discussing observations, and induce caregivers' balanced participation. A two-week deployment study with four groups (N=11) found that TalkingBoogie helped increase mutual understanding of strategies and encourage balanced participation between caregivers with reduced cognitive loads.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {caregiver collaboration, aac, accessibility, assistive technology, developmental disability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376150,
author = {Warner, Mark and Kitkowska, Agnieszka and Gibbs, Jo and Maestre, Juan F. and Blandford, Ann},
title = {Evaluating 'Prefer Not to Say' Around Sensitive Disclosures},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376150},
doi = {10.1145/3313831.3376150},
abstract = {As people's offline and online lives become increasingly entwined, the sensitivity of personal information disclosed online is increasing. Disclosures often occur through structured disclosure fields (e.g., drop-down lists). Prior research suggests these fields may limit privacy, with non-disclosing users being presumed to be hiding undesirable information. We investigated this around HIV status disclosure in online dating apps used by men who have sex with men. Our online study asked participants (N=183) to rate profiles where HIV status was either disclosed or undisclosed. We tested three designs for displaying undisclosed fields. Visibility of undisclosed fields had a significant effect on the way profiles were rated, and other profile information (e.g., ethnicity) could affect inferences that develop around undisclosed information. Our research highlights complexities around designing for non-disclosure and questions the voluntary nature of these fields. Further work is outlined to ensure disclosure control is appropriately implemented around online sensitive information disclosures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy unraveling, privacy, online privacy, prefer not to say, non-disclosure, online dating, disclosure, structured disclosure fields},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376878,
author = {Liu, Wanyu and Gori, Julien and Rioul, Olivier and Beaudouin-Lafon, Michel and Guiard, Yves},
title = {How Relevant is Hick's Law for HCI?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376878},
doi = {10.1145/3313831.3376878},
abstract = {Hick's law is a key quantitative law in Psychology that relates reaction time to the logarithm of the number of stimulus-response alternatives in a task. Its application to HCI is controversial: Some believe that the law does not apply to HCI tasks, others regard it as the cornerstone of interface design. The law, however, is often misunderstood. We review the choice-reaction time literature and argue that: (1) Hick's law speaks against, not for, the popular principle that 'less is better'; (2) logarithmic growth of observed temporal data is not necessarily interpretable in terms of Hick's law; (3) the stimulus-response paradigm is rarely relevant to HCI tasks, where choice-reaction time can often be assumed to be constant; and (4) for user interface design, a detailed examination of the effects on choice-reaction time of psychological processes such as visual search and decision making is more fruitful than a mere reference to Hick's law.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {stimulus-response, logarithm, the hick-hyman law, hick's law, information, convexity, uncertainty, choice reaction time},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376863,
author = {Jung, Jingun and Lee, Sangyoon and Hong, Jiwoo and Youn, Eunhye and Lee, Geehyuk},
title = {Voice+Tactile: Augmenting In-Vehicle Voice User Interface with Tactile Touchpad Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376863},
doi = {10.1145/3313831.3376863},
abstract = {Promisingly, driving is adapting to a Voice User Interface (VUI) that lets drivers utilize diverse applications with little effort. However, the VUI has innate usability issues, such as a turn-taking problem, a short-term memory workload, inefficient controls, and difficulty correcting errors. To overcome these weaknesses, we explored supplementing the VUI with tactile interaction. As an early result, we present the Voice+Tactile interactions that augment the VUI via multi-touch inputs and high-resolution tactile outputs. We designed various Voice+Tactile interactions to support different VUI interaction stages and derived four Voice+Tactile interaction themes: Status Feedback, Input Adjustment, Output Control, and Finger Feedforward. A user study showed that the Voice+Tactile interactions improved the VUI efficiency and its user experiences without incurring significant additional distraction overhead on driving. We hope these early results open new research questions to improve in-vehicle VUI with a tactile channel.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice user interface, in-vehicle user interface, tactile feedback touchpad},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376857,
author = {Price, Thomas W. and Williams, Joseph Jay and Solyst, Jaemarie and Marwan, Samiha},
title = {Engaging Students with Instructor Solutions in Online Programming Homework},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376857},
doi = {10.1145/3313831.3376857},
abstract = {Students working on programming homework do not receive the same level of support as in the classroom, relying primarily on automated feedback from test cases. One low-effort way to provide more support is by prompting students to compare their solution to an instructor's solution, but it is unclear the best way to design such prompts to support learning. We designed and deployed a randomized controlled trial during online programming homework, where we provided students with an instructor's solution, and randomized whether they were prompted to compare their solution to the instructor's, to fill in the blanks for a written explanation of the instructor's solution, to do both, or neither. Our results suggest that these prompts can effectively engage students in reflecting on instructor solutions, although the results point to design trade-offs between the amount of effort that different prompts require from students and instructors, and their relative impact on learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {self-explanation, programming, comparison, computing education},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376850,
author = {Olgado, Benedict Salazar and Pei, Lucy and Crooks, Roderic},
title = {Determining the Extractive Casting Mold of Intimate Platforms through Document Theory},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376850},
doi = {10.1145/3313831.3376850},
abstract = {This paper introduces document theory as a mechanism to analyze intimate platforms as sociotechnical systems. The theory, developed in documentation studies and applied to HCI, focuses on the casting mold or how agents, through particular means and modes, produce documents that govern social relations. We studied the process of creating a profile by identifying and mapping out the fields asked among the ten most popular online dating apps in the US. By looking at dating profiles as documents and their creation as a process of documentation, we argue that the current casting mold of these intimate platforms is designed to extract profit via invisibilization of labor in digital networks leading to the emergence of a constrained rational market agent. Our study illustrates how document theory makes visible the assumptions of technological systems, calling on us to imagine alternatives beyond incremental design changes given broader structural realities of market and power.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {political economy, document theory, intimate platforms},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376848,
author = {Wacker, Philipp and Wagner, Adrian and Voelker, Simon and Borchers, Jan},
title = {Heatmaps, Shadows, Bubbles, Rays: Comparing Mid-Air Pen Position Visualizations in Handheld AR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376848},
doi = {10.1145/3313831.3376848},
abstract = {In Handheld Augmented Reality, users look at AR scenes through the smartphone held in their hand. In this setting, having a mid-air pointing device like a pen in the other hand greatly expands the interaction possibilities. For example, it lets users create 3D sketches and models while on the go. However, perceptual issues in Handheld AR make it difficult to judge the distance of a virtual object, making it hard to align a pen to it. To address this, we designed and compared different visualizations of the pen's position in its virtual environment, measuring pointing precision, task time, activation patterns, and subjective ratings of helpfulness, confidence, and comprehensibility of each visualization. While all visualizations resulted in only minor differences in precision and task time, subjective ratings of perceived helpfulness and confidence favor a 'heatmap' technique that colors the objects in the scene based on their distance to the pen.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {augmented reality, 3D pen, interaction, mid-air, depth cues, depth perception, modeling, smartphone},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376831,
author = {Mirza-Babaei, Pejman and Stahlke, Samantha and Wallner, G\"{u}nter and Nova, Atiya},
title = {A Postmortem on Playtesting: Exploring the Impact of Playtesting on the Critical Reception of Video Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376831},
doi = {10.1145/3313831.3376831},
abstract = {Game studios aim to develop titles that deliver a fun and engaging experience for players. Playtesting promises to help identify opportunities to improve player experience and assist developers in achieving their design intent. However, a lack of research on the added value of playtesting means that many studios are still uncertain about its commercial viability and impact on product success. This gap in understanding is further complicated by the vague definition of "success" afforded by sales figures and review scores. In this paper, we assess reported feature quality of three commercial titles by analyzing playtesting reports and game reviews. By comparing themes and design issues expressed in game reviews to the results of pre-release playtesting for each game, we aim to highlight the value of playtesting and propose a set of guidelines for selecting playtest methods based on the needs of a given game evaluation. Through the real-world case studies presented, this paper contributes to the growing domain of games user research and highlights the value of playtesting in game development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {playtesting, games user research, game reviews},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376827,
author = {Nguyen, Josef and Ruberg, Bonnie},
title = {Challenges of Designing Consent: Consent Mechanics in Video Games as Models for Interactive User Agency},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376827},
doi = {10.1145/3313831.3376827},
abstract = {This paper argues for a conceptual framework that treats user consent in interactive technologies as a design challenge necessitating careful, culturally-informed consideration. We draw on recent work in HCI as well as queer and feminist theory that understands consent as rooted in negotiating agency in order to frame our exploration of unique difficulties and potential solutions to meaningful opportunities for user consent in the design of computational technologies. Through a critical analysis of three video games that offer different models of consent-each of which communicates different values through its design-we introduce the concept of consent mechanics. Consent mechanics describe designed interactions that allow players to consent to or opt out of in-game experiences, often those related to sexuality or intimacy. Here, we approach video games as windows onto design considerations surrounding interactive technologies more broadly, suggesting crucial questions and tactics for how to design user agency ethically into computational systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ethics, video games, critical approaches, design, sexuality, consent, queerness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376819,
author = {Do, Seungwon and Lee, Byungjoo},
title = {Improving Reliability of Virtual Collision Responses: A Cue Integration Technique},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376819},
doi = {10.1145/3313831.3376819},
abstract = {In virtual reality (VR), a user's virtual avatar can interact with a virtual object by colliding with it. If collision responses do not occur in the direction that the user expects, the user experiences degradation of accuracy and precision in applications such as VR sports games. In determining the response of a virtual collision, existing physics engines have not considered the direction in which the user perceived and estimated the collision. Based on the cue integration theory, this study presents a statistical model explaining how users estimate the direction of a virtual collision from their body's orientation and velocity vectors. The accuracy and precision of virtual collisions can be improved by 8.77% and 30.29%, respectively, by setting the virtual collision response in the direction that users perceive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, cue integration theory, collision response},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376805,
author = {Dahl, Yngve and Svan\ae{}s, Dag},
title = {Facilitating Democracy: Concerns from Participatory Design with Asymmetric Stakeholder Relations in Health Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376805},
doi = {10.1145/3313831.3376805},
abstract = {This paper addresses how facilitation can implicate what, whose and how perspectives and values become embedded in the results from participatory design activities. Inspired by Donald Sch\"{o}n's reflection-on-action theory, an analysis of our facilitator performances in three design activities involving health care stakeholder groups with asymmetric relations has been performed. The analysis highlights the often subtle and unforeseen ways by which facilitator actions influence who "has a say". The results emphasize how continuous introspective analyses and reflections may improve the facilitator's attentiveness to actions that may inadvertently impede the disfavored party. In the long-term, neglect may threaten the integrity of participatory design as a democratic and empowering design approach. The shift towards a practice-perspective on facilitation goes beyond the efforts of the individual practitioner. The cultivation of the reflective facilitator, a concern of relevance for the Human?Computer Interaction and Participatory Design community as a whole, is considered.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {facilitation, participation, asymmetries, reflection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376792,
author = {Lindley, Joseph and Akmal, Haider Ali and Pilling, Franziska and Coulton, Paul},
title = {Researching AI Legibility through Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376792},
doi = {10.1145/3313831.3376792},
abstract = {Everyday interactions with computers are increasingly likely to involve elements of Artificial Intelligence (AI). Encompassing a broad spectrum of technologies and applications, AI poses many challenges for HCI and design. One such challenge is the need to make AI's role in a given system legible to the user in a meaningful way. In this paper we employ a Research through Design (RtD) approach to explore how this might be achieved. Building on contemporary concerns and a thorough exploration of related research, our RtD process reflects on designing imagery intended to help increase AI legibility for users. The paper makes three contributions. First, we thoroughly explore prior research in order to critically unpack the AI legibility problem space. Second, we respond with design proposals whose aim is to enhance the legibility, to users, of systems using AI. Third, we explore the role of design-led enquiry as a tool for critically exploring the intersection between HCI and AI research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {legibility, machine learning, human-data interaction, artificial intelligence, research through design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376784,
author = {Geeng, Christine and Yee, Savanna and Roesner, Franziska},
title = {Fake News on Facebook and Twitter: Investigating How People (Don't) Investigate},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376784},
doi = {10.1145/3313831.3376784},
abstract = {With misinformation proliferating online and more people getting news from social media, it is crucial to understand how people assess and interact with low-credibility posts. This study explores how users react to fake news posts on their Facebook or Twitter feeds, as if posted by someone they follow. We conducted semi-structured interviews with 25 participants who use social media regularly for news, temporarily caused fake news to appear in their feeds with a browser extension unbeknownst to them, and observed as they walked us through their feeds. We found various reasons why people do not investigate low-credibility posts, including taking trusted posters' content at face value, as well as not wanting to spend the extra time. We also document people's investigative methods for determining credibility using both platform affordances and their own ad-hoc strategies. Based on our findings, we present design recommendations for supporting users when investigating low-credibility posts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {verification, trust, twitter, social media, misinformation, disinformation, fake news, Facebook},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376779,
author = {Ku, Pin-Sung and Shao, Qijia and Wu, Te-Yen and Gong, Jun and Zhu, Ziyan and Zhou, Xia and Yang, Xing-Dong},
title = {ThreadSense: Locating Touch on an Extremely Thin Interactive Thread},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376779},
doi = {10.1145/3313831.3376779},
abstract = {We propose a new sensing technique for one-dimensional touch input workable on an interactive thread of less than 0.4 mm thick. Our technique locates up to two touches using impedance sensing with a spacing resolution unachievable by the existing methods. Our approach is also unique in that it locates a touch based on a mathematical model describing the change in thread impedance in relation to the touch locations. This allows the system to be easily calibrated by the user touching a known location(s) on the thread. The system can thus quickly adapt to various environmental settings and users. A system evaluation showed that our system could track the slide motion of a finger with an average error distance of 6.13 mm and 4.16 mm using one and five touches for calibration, respectively. The system could also distinguish between single touch and two concurrent touches with an accuracy of 99% and could track two concurrent touches with an average error distance of 8.55 mm. We demonstrate new interactions enabled by our sensing approach in several unique applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {fabric, impedance sensing, touch input, thread},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376778,
author = {Lee, DoYoung and Lee, SooHwan and Oakley, Ian},
title = {Nailz: Sensing Hand Input with Touch Sensitive Nails},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376778},
doi = {10.1145/3313831.3376778},
abstract = {Touches between the fingers of an unencumbered hand represent a ready-to-use, eyes-free and expressive input space suitable for interacting with wearable devices such as smart glasses or watches. While prior work has focused on touches to the inner surface of the hand, touches to the nails, a practical site for mounting sensing hardware, have been comparatively overlooked. We extend prior implementations of single touch sensing nails to a full set of five and explore their potential for wearable input. We present design ideas and an input space of 144 touches (taps, flicks and swipes) derived from an ideation workshop. We complement this with data from two studies characterizing the subjective comfort and objective characteristics (task time, accuracy) of each touch. We conclude by synthesizing this material into a set of 29 viable nail touches, assessing their performance in a final study and illustrating how they could be used by presenting, and qualitatively evaluating, two example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {touch sensing fingernail, eyes-free, wearable, finger input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376765,
author = {Li, Jingyi and Brandt, Joel and Mech, Radom\'{\i}r and Agrawala, Maneesh and Jacobs, Jennifer},
title = {Supporting Visual Artists in Programming through Direct Inspection and Control of Program Execution},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376765},
doi = {10.1145/3313831.3376765},
abstract = {Programming offers new opportunities for visual art creation, but understanding and manipulating the abstract representations that make programming powerful can pose challenges for artists who are accustomed to manual tools and concrete visual interaction. We hypothesize that we can reduce these barriers through programming environments that link state to visual artwork output. We created Demystified Dynamic Brushes (DDB), a tool that bidirectionally links code, numerical data, and artwork across the programming interface and the execution environment - i.e., the artist's in-progress artwork. DDB automatically records stylus input as artists draw, and stores a history of brush state and output in relation to the input. This structure enables artists to inspect current and past numerical input, state, and output and control program execution through the direct selection of visual geometric elements in the drawing canvas. An observational study suggests that artists engage in program inspection when they can visually access geometric state information on the drawing canvas in the process of manual drawing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {programming, visual art, creativity support tools},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376758,
author = {Jain, Dhruv and Mack, Kelly and Amrous, Akli and Wright, Matt and Goodman, Steven and Findlater, Leah and Froehlich, Jon E.},
title = {HomeSound: An Iterative Field Deployment of an In-Home Sound Awareness System for Deaf or Hard of Hearing Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376758},
doi = {10.1145/3313831.3376758},
abstract = {We introduce HomeSound, an in-home sound awareness system for Deaf and hard of hearing (DHH) users. Similar to the Echo Show or Nest Hub, HomeSound consists of a microphone and display, and uses multiple devices installed in each home. We iteratively developed two prototypes, both of which sense and visualize sound information in real-time. Prototype 1 provided a floorplan view of sound occurrences with waveform histories depicting loudness and pitch. A three-week deployment in four DHH homes showed an increase in participants' home- and self-awareness but also uncovered challenges due to lack of line of sight and sound classification. For Prototype 2, we added automatic sound classification and smartwatch support for wearable alerts. A second field deployment in four homes showed further increases in awareness but misclassifications and constant watch vibrations were not well received. We discuss findings related to awareness, privacy, and display placement and implications for future home sound awareness technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sound awareness, smart home, deaf and hard of hearing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376756,
author = {Ku, Pin-Sung and Gong, Jun and Wu, Te-Yen and Wei, Yixin and Tang, Yiwen and Ens, Barrett and Yang, Xing-Dong},
title = {Zippro: The Design and Implementation of An Interactive Zipper},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376756},
doi = {10.1145/3313831.3376756},
abstract = {Zippers are common in a wide variety of objects that we use daily. This work investigates how we can take advantage of such common daily activities to support seamless interaction with technology. We look beyond simple zipper-sliding interactions explored previously to determine how to weave foreground and background interactions into a vocabulary of natural usage patterns. We begin by conducting two user studies to understand how people typically interact with zippers. The findings identify several opportunities for zipper input and sensing, which inform the design of Zippro, a self-contained prototype zipper slider, which we evaluate with a standard jacket zipper. We conclude by demonstrating several applications that make use of the identified foreground and background input methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {zipper, wearable, smart things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376751,
author = {Gerber, Michael A. and Schroeter, Ronald and Xiaomeng, Li and Elhenawy, Mohammed},
title = {Self-Interruptions of Non-Driving Related Tasks in Automated Vehicles: Mobile vs Head-Up Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376751},
doi = {10.1145/3313831.3376751},
abstract = {Automated driving raises new human factors challenges. There is a paradox that allows drivers to perform non-driving related tasks (NDRTs), while benefiting from a driver who regularly attends to the driving task. Systems that aim to better manage a driver's attention, encouraging task switching and interleaving, may help address this paradox. However, a better understanding of how drivers self-interrupt while engaging in NDRTs is required to inform such systems. This paper presents a counterbalanced within-subject simulator study with N=42 participants experiencing automated driving in a familiar driving environment. Participants chose a TV show to watch on a HUD and mobile display during two 15min drives on the same route. Eye and head tracking data revealed more self-interruptions in the HUD condition, suggesting a higher likelihood of a higher situation awareness. Our results may benefit the design of future attention management systems by informing the visual and temporal integration of the driving and non-driving related task.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {non-driving related task, conditionally automated vehicles, self-interruption, human-automation interaction, task engagement, attention management},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

