@inproceedings{10.1145/3313831.3376226,
author = {Weitekamp, Daniel and Harpstead, Erik and Koedinger, Ken R.},
title = {An Interaction Design for Machine Teaching to Develop AI Tutors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376226},
doi = {10.1145/3313831.3376226},
abstract = {Intelligent tutoring systems (ITSs) have consistently been shown to improve the educational outcomes of students when used alone or combined with traditional instruction. However, building an ITS is a time-consuming process which requires specialized knowledge of existing tools. Extant authoring methods, including the Cognitive Tutor Authoring Tools' (CTAT) example-tracing method and SimStudent's Authoring by Tutoring, use programming-by-demonstration to allow authors to build ITSs more quickly than they could by hand programming with model-tracing. Yet these methods still suffer from long authoring times or difficulty creating complete models. In this study, we demonstrate that Simulated Learners built with the Apprentice Learner (AL) Framework can be combined with a novel interaction design that emphasizes model transparency, input flexibility, and problem solving control to enable authors to achieve greater model completeness in less time than existing authoring methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {programming-by-demonstration, {simulated learners, machine teaching, interaction design, intelligent tutoring systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376215,
author = {Watson, Colin and Kirkham, Reuben and Kharrufa, Ahmed},
title = {PIP Kit: An Exploratory Investigation into Using Lifelogging to Support Disability Benefit Claimants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376215},
doi = {10.1145/3313831.3376215},
abstract = {Disability assessment processes are complex and stressful, with claimants finding it challenging to prepare an effective account of their disabilities to support their claim. This project focuses on a disability benefit called Personal Independence Payment (PIP), which is received by millions of people with disabilities in the UK. We present a multi-stage exploratory investigation into how lifelogging could help address the challenges claimants have in accessing disability benefits. In the first study, benefit advisors participated in interviews and workshops to inform the design of PIP Kit, a highly customisable prototype elicitation diary to help disability claimants articulate their experiences. In the second study, PIP Kit was trialled by benefit claimants whilst making their actual PIP claims. We found that PIP Kit helped empower claimants in understanding the claim process and assisted in building arguments for their claims. We also have identified clear principles for supporting disability benefit claimants with technological interventions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {accessibility, social security, disability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376213,
author = {Yaqub, Waheeb and Kakhidze, Otari and Brockman, Morgan L. and Memon, Nasir and Patil, Sameer},
title = {Effects of Credibility Indicators on Social Media News Sharing Intent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376213},
doi = {10.1145/3313831.3376213},
abstract = {In recent years, social media services have been leveraged to spread fake news stories. Helping people spot fake stories by marking them with credibility indicators could dissuade them from sharing such stories, thus reducing their amplification. We carried out an online study (N = 1,512) to explore the impact of four types of credibility indicators on people's intent to share news headlines with their friends on social media. We confirmed that credibility indicators can indeed decrease the propensity to share fake news. However, the impact of the indicators varied, with fact checking services being the most effective. We further found notable differences in responses to the indicators based on demographic and personal characteristics and social media usage frequency. Our findings have important implications for curbing the spread of misinformation via social media platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {misinformation, news headlines, news sharing, disinformation, social media, facebook, fact-check indicators, fake news},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376206,
author = {Lockton, Dan and Lallemand, Carine},
title = {Meeting Designers Where They Are: Using Industry Events as a Research Venue for HCI and Design Methods Development},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376206},
doi = {10.1145/3313831.3376206},
abstract = {There is much work in the CHI community about the 'industry-academia divide', and how to bridge it. One key crossover between HCI/UX scientists and practitioners is the development and use of tools and methods-boundary objects between academia and practice. Among other forms of collaboration, there is an underdeveloped opportunity for academics to make use of industry events (conferences, meetups, design jams) as a research venue in the context of tool and method development. This paper describes three cases from work in academia-industry engagement over the last decade, in which workshops or experiments have been run at industry events as a way of trialling and developing tools directly with practitioners. We discuss advantages of this approach and extract key insights and practical implications, highlighting how the CHI community might use this method more widely, gathering relevant research outcomes while contributing to knowledge exchange between academia and practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {practitioners, industry events, method development, design tools, industry-academia engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376202,
author = {Dogan, Mustafa Doga and Faruqi, Faraz and Churchill, Andrew Day and Friedman, Kenneth and Cheng, Leon and Subramanian, Sriram and Mueller, Stefanie},
title = {G-ID: Identifying 3D Prints Using Slicing Parameters},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376202},
doi = {10.1145/3313831.3376202},
abstract = {We present G-ID, a method that utilizes the subtle patterns left by the 3D printing process to distinguish and identify objects that otherwise look similar to the human eye. The key idea is to mark different instances of a 3D model by varying slicing parameters that do not change the model geometry but can be detected as machine-readable differences in the print. As a result, G-ID does not add anything to the object but exploits the patterns appearing as a by-product of slicing, an essential step of the 3D printing pipeline.We introduce the G-ID slicing and labeling interface that varies the settings for each instance, and the G-ID mobile app, which uses image processing techniques to retrieve the parameters and their associated labels from a photo of the 3D printed object. Finally, we evaluate our method's accuracy under different lighting conditions, when objects were printed with different filaments and printers, and with pictures taken from various positions and angles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {3d printing, tags, making, personal fabrication, identification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376201,
author = {Zhou, Rui and DiSalvo, Betsy},
title = {User's Role in Platform Infrastructuralization: WeChat as an Exemplar},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376201},
doi = {10.1145/3313831.3376201},
abstract = {Recent years have witnessed the rise of platforms such as Facebook and Google. Gigantic in scope and becoming omnipresent, these platforms are acquiring qualities of infrastructure, which is large-scale connected systems that support people's activities invisibly. Recent scholarship has identified WeChat, the most popular mobile social platform in China, as infrastructure. WeChat follows a platform logic to expand, and by conforming to the Chinese government's techno-nationalist focus, it has gradually become an infrastructure in China. We contribute to the understanding of platform infrastructuralization by taking WeChat as a case, highlighting the user's role in this process. We find user contributes to WeChat's infrastructuralization through a three-level interaction process: to practice, to appropriate, and to create. By calling out the user's role in platform infra-structuralization, we discuss how the CHI community can contribute to a better understanding of this phenomenon.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user, infrastructure, wechat, china, social network, platform},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376198,
author = {Yeo, Hui-Shyong and Feng, Wenxin and Huang, Michael Xuelin},
title = {WATouCH: Enabling Direct Input on Non-Touchscreen Using Smartwatch's Photoplethysmogram and IMU Sensor Fusion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376198},
doi = {10.1145/3313831.3376198},
abstract = {Interacting with non-touchscreens such as TV or public displays can be difficult and inefficient. We propose WATouCH, a novel method that localizes a smartwatch on a display and allows direct input by turning the smartwatch into a tangible controller. This low-cost solution leverages sensor fusion of the built-in inertial measurement unit (IMU) and photoplethysmogram (PPG) sensor on a smartwatch that is used for heart rate monitoring. Specifically, WATouCH tracks the smartwatch movement using IMU data and corrects its location error caused by drift using the PPG responses to a dynamic visual pattern on the display. We conducted a user study on two tasks -- a point and click and line tracing task -- to evaluate the system usability and user performance. Evaluation results suggested that our sensor fusion mechanism effectively confined IMU-based localization error, achieved encouraging targeting and tracing precision, was well received by the participants, and thus opens up new opportunities for interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {direct input, public display, tangible input, smartwatch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376179,
author = {Lambton-Howard, Daniel and Olivier, Patrick and Vlachokyriakos, Vasilis and Celina, Hanna and Kharrufa, Ahmed},
title = {Unplatformed Design: A Model for Appropriating Social Media Technologies for Coordinated Participation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376179},
doi = {10.1145/3313831.3376179},
abstract = {Using existing social media technologies as a resource for design offers significant potential for sustainable and scalable ways of coordinating participation. We look at three exemplar projects in three distinct domains that have successfully coordinated participation through the configuration and augmentation of existing social media technologies: participatory future forecasting, participatory health research, and connectivist learning. In this paper we conceptualise social media technologies as material for design, that is, as the raw material with which coordinated participation is realized. From this we develop a model that proposes four material qualities of social media technologies, morphology, role, representation of activity and permeability, and point to how they can be productively employed in the design of coordination of participation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media, materiality, design of participation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376159,
author = {Gibson, Ryan Colin and Dunlop, Mark D. and Bouamrane, Matt-Mouley and Nayar, Revathy},
title = {Designing Clinical AAC Tablet Applications with Adults Who Have Mild Intellectual Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376159},
doi = {10.1145/3313831.3376159},
abstract = {Patients with mild intellectual disabilities (ID) face significant communication barriers within primary care services. This has a detrimental effect on the quality of treatment being provided, meaning the consultation process could benefit from augmentative and alternative communication (AAC) technologies. However, little research has been conducted in this area beyond that of paper-based aids. We address this by extracting design requirements for a clinical AAC tablet application from n=10 adults with mild ID. Our results show that such technologies can promote communication between general practitioners (GPs) and patients with mild ID by extracting symptoms in advance of the consultation via an accessible questionnaire. These symptoms act as a referent and assist in raising the awareness of conditions commonly overlooked by GPs. Furthermore, the application can support people with ID in identifying and accessing healthcare services. Finally, the participants identified 6 key factors that affect the clarity of medical images.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {intellectual disabilities, accessibility, mobile applications, augmentative and alternative communication, primary health care},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376148,
author = {Martinez-Maldonado, Roberto and Echeverria, Vanessa and Fernandez Nieto, Gloria and Buckingham Shum, Simon},
title = {From Data to Insights: A Layered Storytelling Approach for Multimodal Learning Analytics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376148},
doi = {10.1145/3313831.3376148},
abstract = {Significant progress to integrate and analyse multimodal data has been carried out in the last years. Yet, little research has tackled the challenge of visualising and supporting the sensemaking of multimodal data to inform teaching and learning. It is na\"{\i}ve to expect that simply by rendering multiple data streams visually, a teacher or learner will be able to make sense of them. This paper introduces an approach to unravel the complexity of multimodal data by organising it into meaningful layers that explain critical insights to teachers and students. The approach is illustrated through the design of two data storytelling prototypes in the context of nursing simulation. Two authentic studies with educators and students identified the potential of the approach to create learning analytics interfaces that communicate insights on team performance, as well as concerns in terms of accountability and automated insights discovery.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {data storytelling, teamwork, visualization, CSCW},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376139,
author = {Gupta, Aakar and Lin, Bo Rui and Ji, Siyi and Patel, Arjav and Vogel, Daniel},
title = {Replicate and Reuse: Tangible Interaction Design for Digitally-Augmented Physical Media Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376139},
doi = {10.1145/3313831.3376139},
abstract = {Technology has transformed our physical interactions into infinitely more scalable and flexible digital ones. We can peruse an infinite number of photos, news articles, and books. However, these digital experiences lack the physical experience of paging through an album, reading a newspaper, or meandering through a bookshelf. Overlaying physical objects with digital content using augmented reality is a promising avenue towards bridging this gap. In this paper, we investigate the interaction design for such digital-overlaid physical objects and their varying levels of tangibility. We first conduct a user evaluation of a physical photo album that uses tangible interactions to support physical and digital operations. We further prototype multiple objects including bookshelves and newspapers and probe users on their usage, capabilities, and interactions. We then conduct a qualitative investigation of three interaction designs with varying tangibility that use three different input modalities. Finally, we discuss the insights from our investigations and recommend design guidelines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {design, physical objects, augmented reality, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376138,
author = {Han, Teng and Wang, Sirui and Wang, Sijia and Fan, Xiangmin and Liu, Jie and Tian, Feng and Fan, Mingming},
title = {Mouill\'{e}: Exploring Wetness Illusion on Fingertips to Enhance Immersive Experience in VR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376138},
doi = {10.1145/3313831.3376138},
abstract = {Providing users with rich sensations is beneficial to enhance their immersion in Virtual Reality (VR) environments. Wetness is one such imperative sensation that affects users' sense of comfort and helps users adjust grip force when interacting with objects. Researchers have recently begun to explore ways to create wetness illusions, primarily on a user's face or body skin. In this work, we extended this line of research by creating wetness illusion on users' fingertips. We first conducted a user study to understand the effect of thermal and tactile feedback on users' perceived wetness sensation. Informed by the findings, we designed and evaluated a prototype---Mouill\'{e}---that provides various levels of wetness illusions on fingertips for both hard and soft items when users squeeze, lift, or scratch it. Study results indicated that users were able to feel wetness with different levels of temperature changes and they were able to distinguish three levels of wetness for simulated VR objects. We further presented applications that simulated an ice cube, an iced cola bottle, and a wet sponge, etc, to demonstrate its use in VR.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {user study, virtual reality, prototype, wetness illusion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376137,
author = {Jensen, Rikke Bjerg and Coles-Kemp, Lizzie and Wendt, Nicola and Lewis, Makayla},
title = {Digital Liminalities: Understanding Isolated Communities on the Edge},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376137},
doi = {10.1145/3313831.3376137},
abstract = {This paper brings together three distinct case studies to explore how social isolation and notions of liminality shape ontological security within communities on "the edge" of society. Each case study exemplifies the differing nature of liminality in everyday contexts and the extent to which increased digitalisation perturbs it in multiple ways. Taking an ethnographic approach, the research engaged with seafarers onboard container ships in European waters, communities in Greenland and welfare claimants in the North East of England. It posits that technological innovation must attend to the routinisation of everyday life through which people establish ontological security if such innovation is to be supportive. The paper thus moves beyond existing HCI scholarship by foregrounding the contextual and relational aspects of social isolation rather than the technological. It does so by advocating a ground-up design process that considers ontological security in relation to notions of liminality among communities on the edge.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ethnography, communities, isolation, design principles, liminality: ontological security},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376136,
author = {Tejada, Carlos E. and Ramakers, Raf and Boring, Sebastian and Ashbrook, Daniel},
title = {AirTouch: 3D-Printed Touch-Sensitive Objects Using Pneumatic Sensing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376136},
doi = {10.1145/3313831.3376136},
abstract = {3D printing technology can be used to rapidly prototype the look and feel of 3D objects. However, the objects produced are passive. There has been increasing interest in making these objects interactive, yet they often require assembling components or complex calibration. In this paper, we contribute AirTouch, a technique that enables designers to fabricate touch-sensitive objects with minimal assembly and calibration using pneumatic sensing. AirTouch-enabled objects are 3D printed as a single structure using a consumer-level 3D printer. AirTouch uses pre-trained machine learning models to identify interactions with fabricated objects, meaning that there is no calibration required once the object has completed printing. We evaluate our technique using fabricated objects with various geometries and touch sensitive locations, obtaining accuracies of at least 90% with 12 interactive locations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {3d printing, touch interactio, pneumatic sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376134,
author = {Kianzad, Soheil and Huang, Yuxiang and Xiao, Robert and MacLean, Karon E.},
title = {Phasking on Paper: Accessing a Continuum of PHysically Assisted SKetchING},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376134},
doi = {10.1145/3313831.3376134},
abstract = {When sketching, we must choose between paper (expressive ease, ruler and eraser) and computational assistance (parametric support, a digital record). PHysically Assisted SKetching provides both, with a pen that displays force constraints with which the sketcher interacts as they draw on paper. Phasking provides passive, "bound" constraints (like a ruler); or actively "brings" the sketcher along a commanded path (e.g., a curve), which they can violate for creative variation. The sketcher modulates constraint strength (control sharing) by bearing down on the pen-tip. Phasking requires untethered, graded force-feedback, achieved by modifying a ballpoint drive that generates force through rolling surface contact. To understand phasking's viability, we implemented its interaction concepts, related them to sketching tasks and measured device performance. We assessed the experience of 10 sketchers, who could understand, use and delight in phasking, and who valued its control-sharing and digital twinning for productivity, creative control and learning to draw.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {stylus interaction, sketching, computer aided drawing, force-feedback, shared control drawing, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376886,
author = {Tomlinson, Brianna J. and Walker, Bruce N. and Moore, Emily B.},
title = {Auditory Display in Interactive Science Simulations: Description and Sonification Support Interaction and Enhance Opportunities for Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376886},
doi = {10.1145/3313831.3376886},
abstract = {Science simulations are widely used in classrooms to support inquiry-based learning of complex science concepts. These tools typically rely on interactive visual displays to convey relationships. Auditory displays, including verbal description and sonification (non-speech audio), combined with alternative input capabilities, may provide an enhanced experience for learners, particularly learners with visual impairment. We completed semi-structured interviews and usability testing with eight adult learners with visual impairment for two audio-enhanced simulations. We analyzed trends and edge cases in participants' interaction patterns, interpretations, and preferences. Findings include common interaction patterns across simulation use, increased efficiency with second use, and the complementary role that description and sonification play in supporting learning opportunities. We discuss how these control and display layers work to encourage exploration and engagement with science simulations. We conclude with general and specific design takeaways to support the implementation of auditory displays for accessible simulations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual impairment, multimodal, learning, interactive simulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376875,
author = {Wu, Jason and Harrison, Chris and Bigham, Jeffrey P. and Laput, Gierad},
title = {Automated Class Discovery and One-Shot Interactions for Acoustic Activity Recognition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376875},
doi = {10.1145/3313831.3376875},
abstract = {Acoustic activity recognition has emerged as a foundational element for imbuing devices with context-driven capabilities, enabling richer, more assistive, and more accommodating computational experiences. Traditional approaches rely either on custom models trained in situ, or general models pre-trained on preexisting data, with each approach having accuracy and user burden implications. We present Listen Learner, a technique for activity recognition that gradually learns events specific to a deployed environment while minimizing user burden. Specifically, we built an end-to-end system for self-supervised learning of events labelled through one-shot interaction. We describe and quantify system performance 1) on preexisting audio datasets, 2) on real-world datasets we collected, and 3) through user studies which uncovered system behaviors suitable for this new type of interaction. Our results show that our system can accurately and automatically learn acoustic events across environments (e.g., 97% precision, 87% recall), while adhering to users' preferences for non-intrusive interactive behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {automatic class discovery, acoustic activity recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376872,
author = {Baceviciute, Sarune and Mottelson, Aske and Terkildsen, Thomas and Makransky, Guido},
title = {Investigating Representation of Text and Audio in Educational VR Using Learning Outcomes and EEG},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376872},
doi = {10.1145/3313831.3376872},
abstract = {This paper reports findings from a between-subjects experiment that investigates how different learning content representations in virtual environments (VE) affect the process and outcomes of learning. Seventy-eight participants were subjected to an immersive virtual reality (VR) application, where they received identical instructional information, rendered in three different formats: as text in an overlay interface, as text embedded semantically in a virtual book, or as audio. Learning outcome measures, self-reports, and an electroencephalogram (EEG) were used to compare conditions. Results show that reading was superior to listening for the learning outcomes of retention, self-efficacy, and extraneous attention. Reading text from a virtual book was reported to be less cognitively demanding, compared to reading from an overlay interface. EEG analyses show significantly lower theta and higher alpha activation in the audio condition. The findings provide important considerations for the design of educational VR environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cognitive load, educational technology, virtual reality, eeg, learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376870,
author = {Yuan, Arianna and Li, Yang},
title = {Modeling Human Visual Search Performance on Realistic Webpages Using Analytical and Deep Learning Methods},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376870},
doi = {10.1145/3313831.3376870},
abstract = {Modeling visual search not only offers an opportunity to predict the usability of an interface before actually testing it on real users but also advances scientific understanding about human behavior. In this work, we first conduct a set of analyses on a large-scale dataset of visual search tasks on realistic webpages. We then present a deep neural network that learns to predict the scannability of webpage content, i.e., how easy it is for a user to find a specific target. Our model leverages both heuristic-based features such as target size and unstructured features such as raw image pixels. This approach allows us to model complex interactions that might be involved in a realistic visual search task, which can not be achieved by traditional analytical models. We analyze the model behavior to offer our insights into how the salience map learned by the model aligns with human intuition.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {scannability, performance modeling, convolutional neural network, deep learning, webpage, visual attention},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376868,
author = {Voelker, Simon and Hueber, Sebastian and Corsten, Christian and Remy, Christian},
title = {HeadReach: Using Head Tracking to Increase Reachability on Mobile Touch Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376868},
doi = {10.1145/3313831.3376868},
abstract = {People often operate their smartphones with only one hand, using just their thumb for touch input. With today's larger smartphones, this leads to a reachability issue: Users can no longer comfortably touch everywhere on the screen without changing their grip. We investigate using the head tracking in modern smartphones to address this reachability issue. We developed three interaction techniques, pure head (PH), head + touch (HT), and head area + touch (HA), to select targets beyond the reach of one's thumb. In two user studies, we found that selecting targets using HT and HA had higher success rates than the default direct touch (DT) while standing (by about 9%) and walking (by about 12%), while being moderately slower. HT and HA were also faster than one of the best techniques, BezelCursor (BC) (by about 20% while standing and 6% while walking), while having the same success rate.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {walking, touch input, head tracking, force input, reachability, user study, gaze selection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376859,
author = {Altarriba Bertran, Ferran and M\'{a}rquez Segura, Elena and Isbister, Katherine},
title = {Technology for Situated and Emergent Play: A Bridging Concept and Design Agenda},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376859},
doi = {10.1145/3313831.3376859},
abstract = {Despite the capacity of play to spontaneously emerge in our daily life, the scope of application of play design in HCI is generally narrower, specifically targeting areas of pure leisure, or wholly utilitarian and productive play. Here we focus on the value of play design to respond to and support our natural gravitation towards emergent play that helps to meet our social and emotional needs. We present a bridging concept: Technology for Situated and Emergent Play, i.e. technology design that supports playful engagement that emerges interwoven with our everyday activities outside leisure, and that enriches these activities with socio-emotional value. Our intermediate-level contribution has value as a synthesis piece: it weaves together theories of play and play design and bridges them with concrete design examples. As a bridging concept, it contributes: i) theoretical grounding; ii) inspiring design exemplars that illustrate the theory and foreground its value; and iii) design articulations in the form of valuable experiential qualities and design features. Our work can help to focus design agendas for playful technology and inspire future designs in this space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {play, playfulness, hci, interaction design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376849,
author = {Baughan, Amanda and August, Tal and Yamashita, Naomi and Reinecke, Katharina},
title = {Keep It Simple: How Visual Complexity and Preferences Impact Search Efficiency on Websites},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376849},
doi = {10.1145/3313831.3376849},
abstract = {We conducted an online study with 165 participants in which we tested their search efficiency and information recall. We confirm that the visual complexity of a website has a significant negative effect on search efficiency and information recall. However, the search efficiency of those who preferred simple websites was more negatively affected by highly complex websites than those who preferred high visual complexity. Our results suggest that diverse visual preferences need to be accounted for when assessing search response time and information recall in HCI experiments, testing software, or A/B tests.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {usability, search efficiency, visual complexity, information recall, visual appeal, design, user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376847,
author = {Peng, Yi-Hao and Yu, Carolyn and Liu, Shi-Hong and Wang, Chung-Wei and Taele, Paul and Yu, Neng-Hao and Chen, Mike Y.},
title = {WalkingVibe: Reducing Virtual Reality Sickness and Improving Realism While Walking in VR Using Unobtrusive Head-Mounted Vibrotactile Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376847},
doi = {10.1145/3313831.3376847},
abstract = {Virtual Reality (VR) sickness is common with symptoms such as headaches, nausea, and disorientation, and is a major barrier to using VR. We propose WalkingVibe, which applies unobtrusive vibrotactile feedback for VR walking experiences, and also reduces VR sickness and discomfort while improving realism. Feedback is delivered through two small vibration motors behind the ears at a frequency that strikes a balance in inducing vestibular response while minimizing annoyance. We conducted a 240-person study to explore how visual, audio, and various tactile feedback designs affect the locomotion experience of users walking passively in VR while seated statically in reality. Results showed timing and location for tactile feedback have significant effects on VR sickness and realism. With WalkingVibe, 2-sided step-synchronized design significantly reduces VR sickness and discomfort while significantly improving realism. Furthermore, its unobtrusiveness and ease of integration make WalkingVibe a practical approach for improving VR experiences with new and existing VR headsets.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {realism, vibrotactile feedback, discomfort, vestibular system, virtual reality sickness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376846,
author = {Williams, Francis and Bock, Alexander and Doraiswamy, Harish and Donatelli, Cassandra and Hall, Kayla and Summers, Adam and Panozzo, Daniele and Silva, Cl\'{a}udio T.},
title = {Unwind: Interactive Fish Straightening},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376846},
doi = {10.1145/3313831.3376846},
abstract = {The ScanAllFish project is a large-scale effort to scan all the world's 33,100 known species of fishes. It has already generated thousands of volumetric CT scans of fish species which are available on open access platforms such as the Open Science Framework. To achieve a scanning rate required for a project of this magnitude, many specimens are grouped together into a single tube and scanned all at once. The resulting data contain many fish which are often bent and twisted to fit into the scanner. Our system, Unwind, is a novel interactive visualization and processing tool which extracts, unbends, and untwists volumetric images of fish with minimal user interaction. Our approach enables scientists to interactively unwarp these volumes to remove the undesired torque and bending using a piecewise-linear skeleton extracted by averaging isosurfaces of a harmonic function connecting the head and tail of each fish. The result is a volumetric dataset of a individual, straight fish in a canonical pose defined by the marine biologist expert user. We have developed Unwind in collaboration with a team of marine biologists: Our system has been deployed in their labs, and is presently being used for dataset construction, biomechanical analysis, and the generation of figures for scientific publication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive system, ct scan data, volumetric deformation, visualization toolkits, visual analytics, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376843,
author = {Shi, Weiyan and Wang, Xuewei and Oh, Yoo Jung and Zhang, Jingwen and Sahay, Saurav and Yu, Zhou},
title = {Effects of Persuasive Dialogues: Testing Bot Identities and Inquiry Strategies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376843},
doi = {10.1145/3313831.3376843},
abstract = {Intelligent conversational agents, or chatbots, can take on various identities and are increasingly engaging in more human-centered conversations with persuasive goals. However, little is known about how identities and inquiry strategies influence the conversation's effectiveness. We conducted an online study involving 790 participants to be persuaded by a chatbot for charity donation. We designed a two by four factorial experiment (two chatbot identities and four inquiry strategies) where participants were randomly assigned to different conditions. Findings showed that the perceived identity of the chatbot had significant effects on the persuasion outcome (i.e., donation) and interpersonal perceptions (i.e., competence, confidence, warmth, and sincerity). Further, we identified interaction effects among perceived identities and inquiry strategies. We discuss the findings for theoretical and practical implications for developing ethical and effective persuasive chatbots. Our published data, codes, and analyses serve as the first step towards building competent ethical persuasive chatbots.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {crowdsourced, behavior change, text/speech/language, empirical study that tells us about people},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376826,
author = {Hansen, Derek L. and Hughes, Amanda Lee and Cram, Sophie and Harker, Austin Bond and Ashton, Brinnley and Hirschi, Karli and Dorton, Ben and Bothwell, Nate and Stevens, Ashley},
title = {The DELAY Framework: Designing for Extended LAtencY},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376826},
doi = {10.1145/3313831.3376826},
abstract = {This paper introduces the Designing for Extended Latency (DELAY) Framework meant to inspire new systems that support social interaction in high-latency settings such as interplanetary communication, intermittent internet access, and time-zone incompatibilities. The framework includes six dimensions: Goal, Communication Genre, Sequencing, Cardinality, Mutability, and Responsiveness. We describe the iterative design process used to create the Framework, as well as three novel prototypes designed to increase social connectedness and social presence in high-latency situations: 1) the InSync app that allows partners to perform activities simultaneously even though they only see proof of their synchronicity later; 2) the After the Beep system that lets users leave IoT messages that are triggered by the recipients; and 3) the Surrogate platform where players play group battle games against "surrogate" artificial intelligence avatars that mimic unavailable individuals. Data from two design workshops validates the usefulness of the framework for generating new solutions to high-latency scenarios.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {delayed communication, delay framework, interpersonal communication, social presence, social connectedness, high-latency, interplanetary communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376817,
author = {Kaur, Harmanpreet and Williams, Alex C. and McDuff, Daniel and Czerwinski, Mary and Teevan, Jaime and Iqbal, Shamsi T.},
title = {Optimizing for Happiness and Productivity: Modeling Opportune Moments for Transitions and Breaks at Work},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376817},
doi = {10.1145/3313831.3376817},
abstract = {Information workers perform jobs that demand constant multitasking, leading to context switches, productivity loss, stress, and unhappiness. Systems that can mediate task transitions and breaks have the potential to keep people both productive and happy. We explore a crucial initial step for this goal: finding opportune moments to recommend transitions and breaks without disrupting people during focused states. Using affect, workstation activity, and task data from a three-week field study (N=25), we build models to predict whether a person should continue their task, transition to a new task, or take a break.&nbsp;The R-squared values of our models are as high as 0.7, with only 15% error cases. We ask users to evaluate the timing of recommendations provided by a recommender that relies on these models. Our study shows that users find our transition and break recommendations to be well-timed, rating them as 86% and 77% accurate, respectively. We conclude with a discussion of the implications for intelligent systems that seek to guide task transitions and manage interruptions at work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {affect, workplace, productivity, recommendations},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376816,
author = {Funk, Markus and Tobisch, Vanessa and Emfield, Adam},
title = {Non-Verbal Auditory Input for Controlling Binary, Discrete, and Continuous Input in Automotive User Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376816},
doi = {10.1145/3313831.3376816},
abstract = {Using auditory input while driving is becoming increasingly popular for making distraction-free inputs while driving. However, we argue that auditory input is more than just using speech. Thus, in this work, we explore using Non-Verbal Auditory Input (NVAI) for interacting with smart assistants while driving. Through an online study with 100 participants, we initially investigated users' input preferences for binary, discrete, and continuous data types. After identifying the top three modalities for NVAI, we subsequently conducted an in-person study with 16 participants. In our study, the participants tested these input modalities for three different input data types regarding their accuracy, driver-distraction, and social acceptability, while operating a driving simulator. The results reveal that, although clapping hands for making input was initially preferred in our online survey, it is snapping fingers for binary input and discrete input and humming for making continuous input that is the preferred NVAI modality while driving.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {automotive user interfaces, speech input, non-verbal auditory interaction, voice-user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376814,
author = {Kim, Lawrence H. and Drew, Daniel S. and Domova, Veronika and Follmer, Sean},
title = {User-Defined Swarm Robot Control},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376814},
doi = {10.1145/3313831.3376814},
abstract = {A swarm of robots can accomplish more than the sum of its parts, and swarm systems will soon see increased use in applications ranging from tangible interfaces to search and rescue teams. However, effective human control of robot swarms has been shown to be demonstrably more difficult than controlling a single robot, and swarm-specific interactions methodologies are relatively underexplored. As we envision even non-expert users will have more daily in-person encounters with different numbers of robots in the future, we present a user-defined set of control interactions for tabletop swarm robots derived from an elicitation study. We investigated the effects of number of robots and proximity on the user's interaction and found significant effects. For instance, participants varied between using 1-2 fingers, one hand, and both hands depending on the group size. We also provide general design guidelines such as preferred interaction modality, common strategies, and a high-agreement interaction set.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {elicitation study, swarm robot control, multi-robot control, swarm user interface, swarm robotics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376795,
author = {Avellino, Ignacio and Bailly, Gilles and Arico, Mario and Morel, Guillaume and Canlorbe, Geoffroy},
title = {Multimodal and Mixed Control of Robotic Endoscopes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376795},
doi = {10.1145/3313831.3376795},
abstract = {Bedside robotic endoscopes render surgeons autonomous from assistants, potentially improving surgical outcome and decreasing costs. Why then have they not been widely adopted? We take a step back and first characterize classic (non-robotic) endoscope use through observations, literature and a domain expert interview. We review the literature on bedside robotic endoscopes and find that existing controls, individually, do not have the power to support both intended and appropriated endoscope uses. We thus explore combining controls to support this diversity of uses. Through an iterative cycle, we design and implement a multimodal and mixed-initiative technique that combines two user controls and one system control. Our evaluations confirm that individual controls do not satisfy the diversity of endoscope uses, and also that our technique indeed does so. Our work highlights the relevance of HCI research in the medical domain through robotic systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {minimally invasive surgery, robotic endoscope manipulator, mixed-initiative interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376762,
author = {Gupta, Saumya and Tanenbaum, Theresa Jean and Muralikumar, Meena Devii and Marathe, Aparajita S.},
title = {Investigating Roleplaying and Identity Transformation in a Virtual Reality Narrative Experience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376762},
doi = {10.1145/3313831.3376762},
abstract = {In this paper we describe the design and evaluation of The Next Fairy Tale (TNFT) VR, a theatrical interactive storytelling system created in virtual reality and informed by performing arts theories. TNFT was designed to produce opportunities for interactors to experience role-taking and character identification using design principles drawn from actor training and theatrical performance. We report the results of a pilot qualitative study of interactors using TNFT to explore the elements of the design that supported or hindered roleplaying behavior. We identify four design patterns that supported roleplaying in the system: (1) using explicit roles to set player expectations, (2) embracing the "mask and the mirror" effect, (3) attending to visual and interactional details, and (4) easing the player gently into the roleplaying experience. These patterns speak to a broader need to support roleplay through explicit scaffolding of desired player behaviors in digital narrative experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {narrative, roleplaying, virtual reality, drama, interactive digital storytelling, interactive performance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376722,
author = {Ashtari, Narges and Bunt, Andrea and McGrenere, Joanna and Nebeling, Michael and Chilana, Parmit K.},
title = {Creating Augmented and Virtual Reality Applications: Current Practices, Challenges, and Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376722},
doi = {10.1145/3313831.3376722},
abstract = {Augmented Reality (AR) and Virtual Reality (VR) devices are becoming easier to access and use, but the barrier to entry for creating AR/VR applications remains high. Although the recent spike in HCI research on novel AR/VR tools is promising, we lack insights into how AR/VR creators use today's state-of-the-art authoring tools as well as the types of challenges that they face. We interviewed 21 AR/VR creators, which we grouped into hobbyists, domain experts, and professional designers. Despite having a variety of motivations and skillsets, they described similar challenges in designing and building AR/VR applications. We synthesize 8 key barriers that AR/VR creators face nowadays, starting from prototyping the initial experiences to dealing with "the many unknowns" during implementation, to facing difficulties in testing applications. Based on our analysis, we discuss the importance of considering end-user developers as a growing population of AR/VR creators, how we can build learning opportunities into AR/VR tools, and the need for building AR/VR toolchains that integrate debugging and testing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {AR/VR development, AR/VR authoring, augmented reality, end-user development, virtual reality, AR/VR design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376718,
author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
title = {A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376718},
doi = {10.1145/3313831.3376718},
abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {health, human-centered ai, deep learning, diabetes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376697,
author = {Wiley, Katelyn and Vedress, Sarah and Mandryk, Regan L.},
title = {How Points and Theme Affect Performance and Experience in a Gamified Cognitive Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376697},
abstract = {Cognitive tasks are increasingly being gamified in an attempt to leverage the motivational power of games; however, they are sensitive to manipulation and literature is divided on how adding game elements affects participant performance and experience. We applied two popular gamification approaches (points/feedback and theme/narrative) to a typical cognitive task (the dot probe) and measured performance and experience in two studies (N1=287, N2=321). Similar to prior work, we confirm in Study1 that points increase reaction time and error rate, and positive affect. We replicated these results in Study2, and expanded our analysis to investigate participant experience. Our findings suggest that theme creates expectations of an interesting game, which gamified tasks fail to deliver, whereas points maintain enjoyment better throughout the task itself. Important for the development of gamified cognitive tasks, our findings suggest that novel approaches to gameful assessment may be better than the status quo.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inproceedings{10.1145/3313831.3376696,
author = {Vezzoli, Yvonne and Kalantari, Sara and Kucirkova, Natalia and Vasalou, Asimina},
title = {Exploring the Design Space for Parent-Child Reading},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376696},
doi = {10.1145/3313831.3376696},
abstract = {Given the significant potential of shared book reading to promote children's learning, the design of e-books has focused on maximising this learning experience. However, recent studies have begun to show that shared reading is a broader opportunity for the family to spend quality time together. Our study aims to explore this perspective further, focusing on the types of parent-child interactions during shared reading and the ways in which shared reading may foster intimacy when parents and children read digital books. We used cultural probes and contextual interviews to capture the shared reading experiences of 7 parents and 6 children in their homes. We discuss the different nuances of the shared reading practices identified. We use these findings to suggest new design opportunities that support the complex practices of shared reading with technologies at home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {shared reading, cultural probes, parent-child reading, families, digital books},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376675,
author = {Kraus, Matthias and Angerbauer, Katrin and Buchm\"{u}ller, Juri and Schweitzer, Daniel and Keim, Daniel A. and Sedlmair, Michael and Fuchs, Johannes},
title = {Assessing 2D and 3D Heatmaps for Comparative Analysis: An Empirical Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376675},
doi = {10.1145/3313831.3376675},
abstract = {Heatmaps are a popular visualization technique that encode 2D density distributions using color or brightness. Experimental studies have shown though that both of these visual variables are inaccurate when reading and comparing numeric data values. A potential remedy might be to use 3D heatmaps by introducing height as a third dimension to encode the data. Encoding abstract data in 3D, however, poses many problems, too. To better understand this tradeoff, we conducted an empirical study (N=48) to evaluate the user performance of 2D and 3D heatmaps for comparative analysis tasks. We test our conditions on a conventional 2D screen, but also in a virtual reality environment to allow for real stereoscopic vision. Our main results show that 3D heatmaps are superior in terms of error rate when reading and comparing single data items. However, for overview tasks, the well-established 2D heatmap performs better.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, visual analytics, heatmaps},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376657,
author = {Wang, Xiyao and Besan\c{c}on, Lonni and Rousseau, David and Sereno, Mickael and Ammi, Mehdi and Isenberg, Tobias},
title = {Towards an Understanding of Augmented Reality Extensions for Existing 3D Data Analysis Tools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376657},
doi = {10.1145/3313831.3376657},
abstract = {We present an observational study with domain experts to understand how augmented reality (AR) extensions to traditional PC-based data analysis tools can help particle physicists to explore and understand 3D data. Our goal is to allow researchers to integrate stereoscopic AR-based visual representations and interaction techniques into their tools, and thus ultimately to increase the adoption of modern immersive analytics techniques in existing data analysis workflows. We use Microsoft's HoloLens as a lightweight and easily maintainable AR headset and replicate existing visualization and interaction capabilities on both the PC and the AR view. We treat the AR headset as a second yet stereoscopic screen, allowing researchers to study their data in a connected multi-view manner. Our results indicate that our collaborating physicists appreciate a hybrid data exploration setup with an interactive AR extension to improve their understanding of particle collision events.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {3D visualization, user interface, immersive analytics, hybrid visualization system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376652,
author = {Jetter, Hans-Christian and R\"{a}dle, Roman and Feuchtner, Tiare and Anthes, Christoph and Friedl, Judith and Klokmose, Clemens Nylandsted},
title = {"In VR, Everything is Possible!": Sketching and Simulating Spatially-Aware Interactive Spaces in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376652},
doi = {10.1145/3313831.3376652},
abstract = {We propose using virtual reality (VR) as a design tool for sketching and simulating spatially-aware interactive spaces. Using VR, designers can quickly experience their envisioned spaces and interactions by simulating technologies such as motion tracking, multiple networked devices, or unusual form factors such as spherical touchscreens or bezel-less display tiles. Design ideas can be rapidly iterated without restrictions by the number, size, or shape and availability of devices or sensors in the lab. To understand the potentials and challenges of designing in VR, we conducted a user study with 12 interaction designers. As their tool, they used a custom-built virtual design environment with finger tracking and physics simulations for natural interactions with virtual devices and objects. Our study identified the designers' experience of space in relation to their own bodies and playful design explorations as key opportunities. Key challenges were the complexities of building a usable yet versatile VR-based "World Editor".},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {prototyping, design tools, interaction design, simulation, spatial awareness, interactive spaces, sketching, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376650,
author = {Richardson, Dan and Kharrufa, Ahmed},
title = {We Are the Greatest Showmen: Configuring a Framework for Project-Based Mobile Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376650},
abstract = {Little research has explored how mobile-learning technologies could be used by students to produce interactive artefacts during project-based learning processes. Following a design-based approach, we report on engagements spanning classroom and outdoor learning with students (ages 6-13) and teachers from three different UK schools and a summer school of Travelling Showchildren. Working within the time constraints of each context, we deployed a variety of configurations of a project-based mobile learning (PBML) framework intended to support the production of student-designed mobile-learning activities. We contribute insights gained from these engagements, including how mobile technologies can harness students' existing desire for independence and how they can be configured to leverage the physical and social attributes of place and community as learning resources. We argue for further exploration of the potential roles for mobile technologies within project-based learning, and contribute our PBML framework with recommendations for its re-configuration in response to contextual constraints.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3313831.3376644,
author = {Park, So Yeon and Moore, Dylan James and Sirkin, David},
title = {What a Driver Wants: User Preferences in Semi-Autonomous Vehicle Decision-Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376644},
doi = {10.1145/3313831.3376644},
abstract = {Autonomous vehicle (AV) systems are developing at a rapid pace, not only in technological capabilities, but also in human-centered directions. Despite this development, we lack a nuanced understanding of driver preference in decision scenarios that semi-AVs will face, and of possible misalignment between semi-AV decisions and user preference. Using an online survey, we explore how participants would like semi-AVs to act and alert them of the vehicles' decisions in various scenarios. Participants reported varying levels of comfort with autonomy, desire to takeover control, and desire for AV informing. Individual differences, including level of experience with autonomy and situation awareness, affected perceptions of the vehicle. Our results highlight the importance of considering driver preference in AV decision-making, and we present an influence diagram that situates this factor among others. We also derive five design principles, including that a previous positive AV experience can lead to more harmful consequences for AVs when not aligned with driver preference.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {transition of control, notifications, online study, decision-making, autonomous vehicles, driver preferences},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376638,
author = {De-Arteaga, Maria and Fogliato, Riccardo and Chouldechova, Alexandra},
title = {A Case for Humans-in-the-Loop: Decisions in the Presence of Erroneous Algorithmic Scores},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376638},
doi = {10.1145/3313831.3376638},
abstract = {The increased use of algorithmic predictions in sensitive domains has been accompanied by both enthusiasm and concern. To understand the opportunities and risks of these technologies, it is key to study how experts alter their decisions when using such tools. In this paper, we study the adoption of an algorithmic tool used to assist child maltreatment hotline screening decisions. We focus on the question: Are humans capable of identifying cases in which the machine is wrong, and of overriding those recommendations? We first show that humans do alter their behavior when the tool is deployed. Then, we show that humans are less likely to adhere to the machine's recommendation when the score displayed is an incorrect estimate of risk, even when overriding the recommendation requires supervisory approval. These results highlight the risks of full automation and the importance of designing decision pipelines that provide humans with autonomy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {algorithm aversion, decision support, automation bias, human-in-the-loop, algorithm assisted decision making, child welfare},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376625,
author = {Rajcic, Nina and McCormack, Jon},
title = {Mirror Ritual: An Affective Interface for Emotional Self-Reflection},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376625},
doi = {10.1145/3313831.3376625},
abstract = {This paper introduces a new form of real-time affective interface that engages the user in a process of conceptualisation of their emotional state. Inspired by Barrett's Theory of Constructed Emotion, 'Mirror Ritual' aims to expand upon the user's accessible emotion concepts, and to ultimately provoke emotional reflection and regulation. The interface uses classified emotions – obtained through facial expression recognition -- as a basis for dynamically generating poetry. The perceived emotion is used to seed a poetry generation system based on OpenAI's GPT-2 model, fine-tuned on a specially curated corpus. We evaluate the device's ability to foster a personalised, meaningful experience for individual users over a sustained period. A qualitative analysis revealed that participants were able to affectively engage with the mirror, with each participant developing a unique interpretation of its poetry in the context of their own emotional landscape.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {affective interface, poetry, emotion, computational creativity, affective computing, generative networks, theory of constructed emotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376602,
author = {Miniukovich, Aliaksei and Marchese, Maurizio},
title = {Relationship Between Visual Complexity and Aesthetics of Webpages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376602},
doi = {10.1145/3313831.3376602},
abstract = {Substantial HCI research investigated the relationship between webpage complexity and aesthetics, but without a definitive conclusion. Some research showed an inverse linear correlation, some other showed an inverted u-shaped curve, while the rest showed no relationship at all. Such a lack of clarity complicates hypothesis formulation and result interpretation for future research, and lowers the reliability and generalizability of potential advice for Web design practice. We re-collected complexity and aesthetics ratings for five datasets previously used in webpage aesthetics and complexity research. The results were mixed, but suggested an inverse linear relationship with a weaker u-shaped sub-component. A subsequent visual inspection of revealed several confounding factors that may have led to the mixed results, including some webpages looking broken or archaic. The second data collection showed that accounting for these factors generally eliminates the u-shaped tendency of the complexity-aesthetics relationship, at least, for a relatively homogeneous sample of English-speaking participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual aesthetics, graphical user interfaces, web design, quantitative analyses, user study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376598,
author = {Troiano, Giovanni Maria and Wood, Matthew and Harteveld, Casper},
title = {"And This, Kids, Is How I Met Your Mother": Consumerist, Mundane, and Uncanny Futures with Sex Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376598},
doi = {10.1145/3313831.3376598},
abstract = {Sex Robots are no longer science fiction and may soon be-come widespread. While much discussion has developed in academia on their moral and social impact, sex robots have yet to be examined from a critical design perspective and are under-explored in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions around futures with sex robots and discuss those from a critical design perspective. Thirty five participants completed a story stem of a human encountering a sex robot or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships between humans and sex robots, stories that describe sex robots as highly-efficient sex workers that (out)perform humans in routinal sex activities, and narratives that explore sex robots as empathetic and sentient beings. Our participant-created stories both reinforce and challenge established norms of sex robots and raise questions that concern responsible design and ethics in HCI. Finally, we show opportunities and limitations of using multiple-perspective story stems in SCM},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {speculative design, sexual HCI, story completion method, ethics, human-robot interaction, research fiction, sex robots},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376594,
author = {Zhu, Haining and Moffa, Zachary J. and Gui, Xinning and Carroll, John M.},
title = {Prehabilitation: Care Challenges and Technological Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376594},
doi = {10.1145/3313831.3376594},
abstract = {Millions of surgeries are performed in the US annually, and numbers are trending upwards. Traditional rehabilitative interventions are struggling to meet current demands, and researchers have turned to pre-operative interventions, or prehabilitation, to improve patient functions. However, existing literature primarily discusses efficacy or the use of commercial sensing devices, and lacks a clear comprehension of healthcare professionals' (HPs') needs and perspectives. User-centered stakeholder understandings are crucial for a technology's adoption, but prehabilitation literature lacks such understandings. Therefore we conduct semi-structured interviews with 12 prehabilitation healthcare professionals (HPs) to offer descriptions of care challenges, tool usage, and perspectives regarding suitable and effective technologies. These data can assist designers in fostering prehabilitation processes via tailored prehabilitation tools which meet HPs' needs and expectations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {surgical care, user-centered design, nutritional health, prehabilitation, rehabilitation, physical health, psychological health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376576,
author = {Rakhmetulla, Gulnar and Arif, Ahmed Sabbir},
title = {Senorita: A Chorded Keyboard for Sighted, Low Vision, and Blind Mobile Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376576},
doi = {10.1145/3313831.3376576},
abstract = {Senorita is a novel two-thumb virtual chorded keyboard for mobile devices. It arranges the letters on eight keys in a single row by the bottom edge of the device based on letter frequencies and the anatomy of the thumbs. Unlike most chorded methods, it provides visual cues to perform the chording actions in sequence, instead of simultaneously, when the actions are unknown, facilitating "learning by doing". Its compact design leaves most of the screen available and its position near the edge accommodates eyes-free text entry. In a longitudinal study with a smartphone, Senorita yielded on average 14 wpm. In a short-term study with a tablet, it yielded on average 9.3 wpm. In the final longitudinal study, it yielded 3.7 wpm with blind users, surpassing their Qwerty performance. Low vision users yielded 5.8 wpm. Further, almost all users found Senorita effective, easy to learn, and wanted to keep use it.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile, chords, tablets, text input, accessibility, blind},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376562,
author = {Ogawa, Nami and Narumi, Takuji and Kuzuoka, Hideaki and Hirose, Michitaka},
title = {Do You Feel Like Passing Through Walls?: Effect of Self-Avatar Appearance on Facilitating Realistic Behavior in Virtual Environments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376562},
doi = {10.1145/3313831.3376562},
abstract = {Preventing users from walking through virtual boundaries (e.g., walls) is an important issue to be addressed in room-scale virtual environments (VEs), considering the safety and design limitations. Sensory feedback from wall collisions has been shown to be effective; however, it can disrupt the immersion. We assumed that a greater sense of presence would discourage users from walking through walls and conducted a two-factor between-subjects experiment (N = 92) that controls the anthropomorphism (realistic or abstract) and visibility (full-body or hand-only) of self-avatars. We analyzed the participants' behaviors and the moment they first penetrated the wall in game-like VEs that gradually instigated participants to penetrate the walls. The results showed that the realistic full-body self-avatar was the most effective for discouraging the participants from penetrating the walls. Furthermore, the participants with lower presence tended to walk through the walls sooner. This study can contribute to applications that require realistic user responses in VEs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {presence, self-avatar, body ownership},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376558,
author = {Tsenova, Violeta and Wood, Gavin and Dolfini, Andrea and Tindley, Annie and Kirk, David},
title = {Un-Authorised View: Leveraging Volunteer Expertise in Heritage},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376558},
doi = {10.1145/3313831.3376558},
abstract = {Volunteers are an underused but important resource in presenting plural heritages within large heritage organizations. We report on a qualitative study at a heritage site in the UK which combined explorations of volunteers' practice and digital design. The study comprised of observational fieldwork with co-creative activities across eight linked workshops, where we explored the site with volunteers, and how we might leverage existing working structures to make new design prototypes. Our collective account contributes new insights on working with volunteers and the opportunities that arise from acknowledging them as genius loci - recognising them as experts of their own experience and capturing and supporting their skills as storytellers. Working with the volunteering staff in a co-design process we created innovative designs including our Un-authorised View, which draws out the unique perspectives and the personal stories at heritage destinations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {cultural probes, critical heritage, plural heritages, vr design, digital storytelling, genius loci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376551,
author = {Cho, Eugene and Sundar, S. Shyam and Abdullah, Saeed and Motalebi, Nasim},
title = {Will Deleting History Make Alexa More Trustworthy? Effects of Privacy and Content Customization on User Experience of Smart Speakers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376551},
doi = {10.1145/3313831.3376551},
abstract = {"Always-on" smart speakers have raised privacy and security concerns, to address which vendors have introduced customizable privacy settings. But, does the act of customizing one's privacy preferences have any effects on user experience and trust? To address this question, we developed an app for Amazon Alexa and conducted a user study (N = 90). Our data show that the affordance to customize privacy settings enhances trust and usability for regular users, while it has adverse effects on power users. In addition, only enabling privacy-setting customization without allowing content customization negatively affects trust among users with higher privacy concerns. When they can customize both content and privacy settings, user trust is highest. That is, while privacy customization may cause reactance among power users, allowing privacy-concerned individuals to simultaneously customize content can help to alleviate the resultant negative effect on trust. These findings have implications for designing more privacy-sensitive and trustworthy smart speakers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy concern, power usage, voice assistant(s), security, customization, smart speaker(s)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376543,
author = {Hanton, Ollie and Wessely, Michael and Mueller, Stefanie and Fraser, Mike and Roudaut, Anne},
title = {ProtoSpray: Combining 3D Printing and Spraying to Create Interactive Displays with Arbitrary Shapes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376543},
doi = {10.1145/3313831.3376543},
abstract = {ProtoSpray is a fabrication method that combines 3D printing and spray coating, to create interactive displays of arbitrary shapes. Our approach makes novel use of 3D printed conductive channels to create base electrodes on 3D shapes. This is then combined with spraying active materials to produce illumination. We demonstrate the feasibility and benefits of this combined approach in 6 evaluations exploring different shaped topologies. We analyze factors such as spray orientations, surface topologies and printer resolutions, to discuss how spray nozzles can be integrated into traditional 3D printers. We present a series of ProtoSprayed objects demonstrating how our technique goes beyond existing fabrication techniques by allowing creation of displays on objects with curvatures as complex as a Mobius strip. Our work provides a platform to empower makers to use displays as a fabrication material.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {rapid prototyping, electroluminescence, fabrication, 3d printing, display, spraying},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

