@inproceedings{10.1145/3313831.3376536,
author = {Lehmann, Florian and Buschek, Daniel},
title = {Heartbeats in the Wild: A Field Study Exploring ECG Biometrics in Everyday Life},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376536},
doi = {10.1145/3313831.3376536},
abstract = {This paper reports on an in-depth study of electrocardiogram (ECG) biometrics in everyday life. We collected ECG data from 20 people over a week, using a non-medical chest tracker. We evaluated user identification accuracy in several scenarios and observed equal error rates of 9.15% to 21.91%, heavily depending on 1) the number of days used for training, and 2) the number of heartbeats used per identification decision. We conclude that ECG biometrics can work in the wild but are less robust than expected based on the literature, highlighting that previous lab studies obtained highly optimistic results with regard to real life deployments. We explain this with noise due to changing body postures and states as well as interrupted measures. We conclude with implications for future research and the design of ECG biometrics systems for real world deployments, including critical reflections on privacy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {field study, electrocardiogram, biometrics, ecg},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376534,
author = {Schr\"{o}der, Christoph and Al Zaidawi, Sahar Mahdie Klim and Prinzler, Martin H.U. and Maneth, Sebastian and Zachmann, Gabriel},
title = {Robustness of Eye Movement Biometrics Against Varying Stimuli and Varying Trajectory Length},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376534},
doi = {10.1145/3313831.3376534},
abstract = {Recent results suggest that biometric identification based on human's eye movement characteristics can be used for authentication. In this paper, we present three new methods and benchmark them against the state-of-the-art. The best of our new methods improves the state-of-the-art performance by 5.2 percentage points. Furthermore, we investigate some of the factors that affect the robustness of the recognition rate of different classifiers on gaze trajectories, such as the type of stimulus and the tracking trajectory length. We find that the state-of-the-art method only works well when using the same stimulus for testing that was used for training. By contrast, our novel method more than doubles the identification accuracy for these transfer cases. Furthermore, we find that with only 90 seconds of eye tracking data, 86.7% accuracy can be achieved.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {gaze detection, eye tracking, eye movement biometrics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376530,
author = {Roldan, Wendy and Gao, Xin and Hishikawa, Allison Marie and Ku, Tiffany and Li, Ziyue and Zhang, Echo and Froehlich, Jon E. and Yip, Jason},
title = {Opportunities and Challenges in Involving Users in Project-Based HCI Education},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376530},
doi = {10.1145/3313831.3376530},
abstract = {Users are fundamental to HCI. However, little is known about how HCI education introduces students to working with users, particularly those different from themselves. To better understand design students' engagement, reactions, and reflections with users, we investigate a case study of a graduate-level 10-week prototyping studio course that partnered with a children's co-design team. HCI students participated in two co-design sessions with children to design a STEM learning experience for youth. We conducted participant observations, interviews with 14 students, and analyzed final artifacts. Our findings demonstrate the communication challenges and strategies students experienced, how students observed issues of power dynamics, and students' perceived value in engaging with users. We contribute empirical evidence of how HCI students directly interact with target users, principles for reflective HCI pedagogy, and highlight the need for more intentional investigation into HCI educational practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {user-centered design, reflection, hci education},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376521,
author = {Kim, Sunyoung and Li, Muyang},
title = {Awareness, Understanding, and Action: A Conceptual Framework of User Experiences and Expectations about Indoor Air Quality Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376521},
doi = {10.1145/3313831.3376521},
abstract = {With the advent of new sensors and technologies, smart devices that monitor the level of indoor air quality (IAQ) are increasingly available to create a healthy home environment. However, little has been studied regarding design principles for effective IAQ visualizations to help better understand and improve IAQ. We analyzed Amazon reviews of IAQ monitors and their design components for IAQ visualizations. Based on our findings, we created a conceptual framework to explain the process of facilitating an effective IAQ visualization with a proposed set of design considerations in each stage. The process includes helping users easily understand what is happing to IAQ (awareness), what it means to them (understanding), and what to do with the information (action), which results in two outcomes, knowledge gain and emotional relief. We hope our framework can help practitioners and researchers in designing eco-feedback system and beyond to advance both research and practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {design principles, peripheral display, indoor air quality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376518,
author = {Bassen, Jonathan and Balaji, Bharathan and Schaarschmidt, Michael and Thille, Candace and Painter, Jay and Zimmaro, Dawn and Games, Alex and Fast, Ethan and Mitchell, John C.},
title = {Reinforcement Learning for the Adaptive Scheduling of Educational Activities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376518},
doi = {10.1145/3313831.3376518},
abstract = {Adaptive instruction for online education can increase learning gains and decrease the work required of learners, instructors, and course designers. Reinforcement Learning (RL) is a promising tool for developing instructional policies, as RL models can learn complex relationships between course activities, learner actions, and educational outcomes. This paper demonstrates the first RL model to schedule educational activities in real time for a large online course through active learning. Our model learns to assign a sequence of course activities while maximizing learning gains and minimizing the number of items assigned. Using a controlled experiment with over 1,000 learners, we investigate how this scheduling policy affects learning gains, dropout rates, and qualitative learner feedback. We show that our model produces better learning gains using fewer educational activities than a linear assignment condition, and produces similar learning gains to a self-directed condition using fewer educational activities and with lower dropout rates.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {reinforcement learning, adaptive learning, online education},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376515,
author = {Wong, Richmond Y. and Khovanskaya, Vera and Fox, Sarah E. and Merrill, Nick and Sengers, Phoebe},
title = {Infrastructural Speculations: Tactics for Designing and Interrogating Lifeworlds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376515},
doi = {10.1145/3313831.3376515},
abstract = {This paper introduces "infrastructural speculations," an orientation toward speculative design that considers the complex and long-lived relationships of technologies with broader systems, beyond moments of immediate invention and design. As modes of speculation are increasingly used to interrogate questions of broad societal concern, it is pertinent to develop an orientation that foregrounds the "lifeworld" of artifacts-the social, perceptual, and political environment in which they exist. While speculative designs often imply a lifeworld, infrastructural speculations place lifeworlds at the center of design concern, calling attention to the cultural, regulatory, environmental, and repair conditions that enable and surround particular future visions. By articulating connections and affinities between speculative design and infrastructure studies research, we contribute a set of design tactics for producing infrastructural speculations. These tactics help design researchers interrogate the complex and ongoing entanglements among technologies, institutions, practices, and systems of power when gauging the stakes of alternate lifeworlds.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {infrastructure, futures, design research, lifeworld, infrastructure studies, speculative design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376513,
author = {Davis, Josh Urban and Wu, Te-Yen and Shi, Bo and Lu, Hanyi and Panotopoulou, Athina and Whiting, Emily and Yang, Xing-Dong},
title = {TangibleCircuits: An Interactive 3D Printed Circuit Education Tool for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376513},
doi = {10.1145/3313831.3376513},
abstract = {We present a novel haptic and audio feedback device that allows blind and visually impaired (BVI) users to understand circuit diagrams. TangibleCircuits allows users to interact with a 3D printed tangible model of a circuit which provides audio tutorial directions while being touched. Our system comprises an automated parsing algorithm which extracts 3D printable models as well as an audio interfaces from a Fritzing diagram. To better understand the requirements of designing technology to assist BVI users in learning hardware computing, we conducted a series of formative inquiries into the accessibility limitations of current circuit tutorial technologies. In addition, we derived insights and design considerations gleaned from conducting a formal comparative user study to understand the effectiveness of TangibleCircuits as a tutorial system. We found that BVI users were better able to understand the geometric, spatial and structural circuit information using TangibleCircuits, as well as enjoyed learning with our tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tangible user interfaces, accessibility, universal design, circuit prototyping, education tools},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376493,
author = {Wirfs-Brock, Jordan and Mennicken, Sarah and Thom, Jennifer},
title = {Giving Voice to Silent Data: Designing with Personal Music Listening History},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376493},
doi = {10.1145/3313831.3376493},
abstract = {Music streaming services collect listener data to support personalization and discovery of their extensive catalogs. Yet this data is typically used in ways that are not immediately apparent to listeners. We conducted design workshops with ten Spotify listeners to imagine future voice assistant (VA) interactions leveraging logged music data. We provided participants with detailed personal music listening data, such as play-counts and temporal patterns, which grounded their design ideas in their current behaviors. In the interactions participants designed, VAs did not simply speak their data out loud; instead, participants envisioned how data could implicitly support introspection, behavior change, and exploration. We present reflections on how VAs could evolve from voice-activated remote controls to intelligent music coaches and how personal data can be leveraged as a design resource.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {voice assistants, co-design, music, personal informatics, participatory design, speculative design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376491,
author = {Muthukumarana, Sachith and Elvitigala, Don Samitha and Forero Cortes, Juan Pablo and Matthies, Denys J.C. and Nanayakkara, Suranga},
title = {Touch Me Gently: Recreating the Perception of Touch Using a Shape-Memory Alloy Matrix},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376491},
doi = {10.1145/3313831.3376491},
abstract = {We present a wearable forearm augmentation that enables the recreation of natural touch sensation by applying shear-forces onto the skin. In contrast to previous approaches, we arrange light-weight and stretchable 3x3cm plasters in a matrix onto the skin. Individual plasters were embedded with lines of shape-memory alloy (SMA) wires to generate shear-forces. Our design is informed by a series of studies investigating the perceptibility of different sizes, spacings, and attachments of plasters on the forearm. Our matrix arrangement enables the perception of touches, for instance, feeling ones wrist being grabbed or the arm being stroked. Users rated the recreated touch sensations as being fairly similar to a real touch (4.1/5). Even without a visual representation, users were able to correctly distinguish them with an overall accuracy of 94.75%. Finally, we explored two use cases showing how AR and VR could be empowered with experiencing recreated touch sensations on the forearm.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touch perception, pinching, recreation of touch, wearable, shape memory alloys, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376489,
author = {Henrikson, Rorik and Grossman, Tovi and Trowbridge, Sean and Wigdor, Daniel and Benko, Hrvoje},
title = {Head-Coupled Kinematic Template Matching: A Prediction Model for Ray Pointing in VR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376489},
abstract = {This paper presents a new technique to predict the ray pointer landing position for selection movements in virtual reality (VR) environments. The technique adapts and extends a prior 2D kinematic template matching method to VR environments where ray pointers are used for selection. It builds on the insight that the kinematics of a controller and Head-Mounted Display (HMD) can be used to predict the ray's final landing position and angle. An initial study provides evidence that the motion of the head is a key input channel for improving prediction models. A second study validates this technique across a continuous range of distances, angles, and target sizes. On average, the technique's predictions were within 7.3° of the true landing position when 50% of the way through the movement and within 3.4° when 90%. Furthermore, compared to a direct extension of Kinematic Template Matching, which only uses controller movement, this head-coupled approach increases prediction accuracy by a factor of 1.8x when 40% of the way through the movement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3313831.3376470,
author = {Fang, Cathy and Zhang, Yang and Dworman, Matthew and Harrison, Chris},
title = {Wireality: Enabling Complex Tangible Geometries in Virtual Reality with Worn Multi-String Haptics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376470},
doi = {10.1145/3313831.3376470},
abstract = {Today's virtual reality (VR) systems allow users to explore immersive new worlds and experiences through sight. Unfortunately, most VR systems lack haptic feedback, and even high-end consumer systems use only basic vibration motors. This clearly precludes realistic physical interactions with virtual objects. Larger obstacles, such as walls, railings, and furniture are not simulated at all. In response, we developed Wireality, a self-contained worn system that allows for individual joints on the hands to be accurately arrested in 3D space through the use of retractable wires that can be programmatically locked. This allows for convincing tangible interactions with complex geometries, such as wrapping fingers around a railing. Our approach is lightweight, low-cost, and low-power, criteria important for future, worn consumer uses. In our studies, we further show that our system is fast-acting, spatially-accurate, high-strength, comfortable, and immersive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {haptics, force feedback, virtual reality, string-driven, grasp, touch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376457,
author = {Abbott, Jacob and Patil, Sameer},
title = {How Mandatory Second Factor Affects the Authentication User Experience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376457},
doi = {10.1145/3313831.3376457},
abstract = {Recent years have seen growing organizational adoption of two-factor authentication as organizations seek to limit the damage caused by password breaches. However, research on the user experience of two-factor authentication in a real-world setting is relatively scant. To fill this gap, we conducted multiple waves of an online survey of users at a large public university during its multi-phase rollout of mandatory two-factor authentication for faculty, staff, and students. In addition, we examined multiple months of logs of all authentication events at the university. We found no significant changes in user experience and acceptance of two-factor authentication when it was mandatory for select systems that dealt with sensitive information. However, these factors degraded when users were forced to use two-factor authentication for logging into every single university resource. Our findings can serve as important guidance for the implementation of two-factor authentication in organizations in a way that can help achieve a balance between security and user experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user experience, ux, multi-factor authentication, security, two-factor authentication, login, 2fa, university it},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376455,
author = {Asai, Kentaro and Fukusato, Tsukasa and Igarashi, Takeo},
title = {Integrated Development Environment with Interactive Scatter Plot for Examining Statistical Modeling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376455},
abstract = {The development of a statistical modeling program requires example data to observe and verify the behavior of the program. Such example data are either taken from an existing dataset or synthesized using commands. Programmers may want to directly design an arbitrary dataset or modify it interactively, but it is difficult to do so in current development environments. We therefore propose combining a code editor with an interactive scatter plot editor to efficiently understand the behavior of statistical modeling algorithms. The user interactively creates and modifies the dataset on the scatter plot editor, while the system continuously executes the code in the editor, taking the data as input, and shows the result in the editor. This paper presents the design rationale behind the system and introduces several usage scenarios.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7}
}

@inproceedings{10.1145/3313831.3376452,
author = {Son, Kihoon and Chun, Hwiwon and Park, Sojin and Hyun, Kyung Hoon},
title = {C-Space: An Interactive Prototyping Platform for Collaborative Spatial Design Exploration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376452},
doi = {10.1145/3313831.3376452},
abstract = {C-Space is an interactive prototyping platform for collaborative spatial design exploration. Spatial design projects often begin with conceptualization that includes abstract diagramming, zoning, and massing to provide a foundation for making design decisions. Specifically, abstract diagrams guide designers to explore alternative designs without thinking prematurely about the details. However, complications arise when communicating ambiguous and incomplete designs to collaborators. To overcome this drawback, designers devote considerable amounts of time and resources into searching for design references and creating rough prototypes to explicate their design concepts better. Therefore, this study proposes C-Space, a novel design support system that integrates the abstract diagram with design reference retrieval and prototyping through a tangible user interface and augmented reality. Through a user study with 12 spatial designers, we verify that C-Space promotes rapid and robust spatial design exploration, inducing collaborative discussions and motivating users to interact with designs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design collaboration, design support system, spatial design, augmented reality, human-computer interaction, tangible user interface, prototyping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376440,
author = {Abu-Salma, Ruba and Livshits, Benjamin},
title = {Evaluating the End-User Experience of Private Browsing Mode},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376440},
abstract = {In this paper, we investigate why users of private browsing mode misunderstand the benefits and limitations of private browsing. We design and conduct a three-part study: (1) an analytic evaluation of the user interface of private mode in different browsers; (2) a qualitative user study to explore user mental models of private browsing; (3) a participatory design study to investigate why existing browser disclosures, the in-browser explanations of private mode, do not communicate the actual protection of private mode. We find the user interface of private mode in different browsers violated well-established design guidelines and heuristics. Further, most participants had incorrect mental models of private browsing, influencing their understanding and usage of private mode. We also find existing browser disclosures did not explain the primary security goal of private mode. Drawing from the results of our study, we extract a set of recommendations to improve the design of disclosures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3313831.3376433,
author = {Robinson, Raquel Breejon and Reid, Elizabeth and Fey, James Collin and Depping, Ansgar E. and Isbister, Katherine and Mandryk, Regan L.},
title = {Designing and Evaluating 'In the Same Boat', A Game of Embodied Synchronization for Enhancing Social Play},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376433},
doi = {10.1145/3313831.3376433},
abstract = {Social closeness is important for health and well-being, but is difficult to maintain over a distance. Games can help connect people by strengthening existing relationships or creating new ones through shared playful experiences. We present the design and evaluation of 'In the Same Boat' (ITSB), a two-player infinite runner designed to foster social closeness in distributed dyads. ITSB leverages the synchronization of both players' input to steer a canoe down a river and avoid obstacles. We created two versions: embodied controls, which use players' physiological signals (breath rate, facial expressions), and standard keyboard controls. Results from a study with 35 dyads indicate that ITSB fostered affiliation, and while embodied controls were less intuitive, people enjoyed them more. Further, photos of the dyads were rated as happier and closer in the embodied condition, indicating the potential of embodied controls to foster social closeness in synchronized play over a distance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {physiological data, emotion, body games, social games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376431,
author = {Shi, Lei and Zhao, Yuhang and Gonzalez Penuela, Ricardo and Kupferstein, Elizabeth and Azenkot, Shiri},
title = {Molder: An Accessible Design Tool for Tactile Maps},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376431},
doi = {10.1145/3313831.3376431},
abstract = {Tactile materials are powerful teaching aids for students with visual impairments (VIs). To design these materials, designers must use modeling applications, which have high learning curves and rely on visual feedback. Today, Orientation and Mobility (O&amp;M) specialists and teachers are often responsible for designing these materials. However, most of them do not have professional modeling skills, and many are visually impaired themselves. To address this issue, we designed Molder, an accessible design tool for interactive tactile maps, an important type of tactile materials that can help students learn O&amp;M skills. A designer uses Molder to design a map using tangible input techniques, and Molder provides auditory feedback and high-contrast visual feedback. We evaluated Molder with 12 participants (8 with VIs, 4 sighted). After a 30-minute training session, the participants were all able to use Molder to design maps with customized tactile and interactive information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tactile maps, visual impairments, design tool},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376427,
author = {Yang, Jackie (Junrui) and Banerjee, Gaurab and Gupta, Vishesh and Lam, Monica S. and Landay, James A.},
title = {Soundr: Head Position and Orientation Prediction Using a Microphone Array},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376427},
doi = {10.1145/3313831.3376427},
abstract = {Although state-of-the-art smart speakers can hear a user's speech, unlike a human assistant these devices cannot figure out users' verbal references based on their head location and orientation. Soundr presents a novel interaction technique that leverages the built-in microphone array found in most smart speakers to infer the user's spatial location and head orientation using only their voice. With that extra information, Soundr can figure out users references to objects, people, and locations based on the speakers' gaze, and also provide relative directions. To provide training data for our neural network, we collected 751 minutes of data (50x that of the best prior work) from human speakers leveraging a virtual reality headset to accurately provide head tracking ground truth. Our results achieve an average positional error of 0.31m and an orientation angle accuracy of 34.3° for each voice command. A user study to evaluate user preferences for controlling IoT appliances by talking at them found this new approach to be fast and easy to use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {internet of things, machine learning, acoustic source localization, smart speakers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376418,
author = {Jensen, Emily and Dale, Meghan and Donnelly, Patrick J. and Stone, Cathlyn and Kelly, Sean and Godley, Amanda and D'Mello, Sidney K.},
title = {Toward Automated Feedback on Teacher Discourse to Enhance Teacher Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376418},
doi = {10.1145/3313831.3376418},
abstract = {Like anyone, teachers need feedback to improve. Due to the high cost of human classroom observation, teachers receive infrequent feedback which is often more focused on evaluating performance than on improving practice. To address this critical barrier to teacher learning, we aim to provide teachers with detailed and actionable automated feedback. Towards this end, we developed an approach that enables teachers to easily record high-quality audio from their classes. Using this approach, teachers recorded 142 classroom sessions, of which 127 (89%) were usable. Next, we used speech recognition and machine learning to develop teacher-generalizable computer-scored estimates of key dimensions of teacher discourse. We found that automated models were moderately accurate when compared to human coders and that speech recognition errors did not influence performance. We conclude that authentic teacher discourse can be recorded and analyzed for automatic feedback. Our next step is to incorporate the automatic models into an interactive visualization tool that will provide teachers with objective feedback on the quality of their discourse.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {audio recording, automatic speech recognition, classroom discourse, natural language processing, dialogic instruction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376404,
author = {Stangl, Abigale and Morris, Meredith Ringel and Gurari, Danna},
title = {"Person, Shoes, Tree. Is the Person Naked?" What People with Vision Impairments Want in Image Descriptions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376404},
doi = {10.1145/3313831.3376404},
abstract = {Access to digital images is important to people who are blind or have low vision (BLV). Many contemporary image description efforts do not take into account this population's nuanced image description preferences. In this paper, we present a qualitative study that provides insight into 28 BLV people's experiences with descriptions of digital images from news websites, social networking sites/platforms, eCommerce websites, employment websites, online dating websites/platforms, productivity applications, and e-publications. Our findings reveal how image description preferences vary based on the source where digital images are encountered and the surrounding context. We provide recommendations for the development of next-generation image description technologies inspired by our empirical analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual impairment, image captions, alt text, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376391,
author = {Kotut, Lindah and Horning, Michael and Stelter, Timothy L. and McCrickard, D. Scott},
title = {Preparing for the Unexpected: Community Framework for Social Media Use and Social Support by Trail Thru-Hikers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376391},
doi = {10.1145/3313831.3376391},
abstract = {A months-long hike of the Appalachian Trail often involve long-term preparation and life-altering decisions. Would-be hikers leverage institutional knowledge from literature and online forums to physically and mentally prepare for such an arduous hike. Their use of social platforms provide useful insights on motivations for undertaking the thru-hike, how they deal with unexpected conditions on the trail and understand choices made in conditions of scarcity. By analyzing over 100,000 Reddit posts and comments in r/AppalachianTrail and applying a Sense of Community theory, we sought to understand hikers' identity as community members, how their emotional and practical needs are met, and how they evolve. We found that the role and language of thru-hikers change as they progress from pre-hike, on-hike, and post-hike stages, from a questioner early on, to an expert post-hike. We conclude with design recommendations to support offline communities online.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {thru-hike, information seeking, trail community, long-distance hiking, rural computing, appalachian trail},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376367,
author = {Yang, Yalong and Marriott, Kim and Butler, Matthew and Goncu, Cagatay and Holloway, Leona},
title = {Tactile Presentation of Network Data: Text, Matrix or Diagram?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376367},
doi = {10.1145/3313831.3376367},
abstract = {Visualisations are commonly used to understand social, biological and other kinds of networks. Currently we do not know how to effectively present network data to people who are blind or have low-vision (BLV). We ran a controlled study with 8 BLV participants comparing four tactile representations: organic node-link diagram, grid node-link diagram, adjacency matrix and braille list. We found that the node-link representations were preferred and more effective for path following and cluster identification while the matrix and list were better for adjacency tasks. This is broadly in line with findings for the corresponding visual representations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {blindness, accessibility, adjacency matrix, vision impairment, graphvisualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376364,
author = {Pschetz, Larissa and Dixon, Billy and Pothong, Kruakae and Bailey, Arlene and Glean, Allister and Soares, Luis Louren\c{c}o and Enright, Jessica A.},
title = {Designing Distributed Ledger Technologies for Social Change: The Case of CariCrop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376364},
doi = {10.1145/3313831.3376364},
abstract = {Distributed ledger technologies (DLTs) have been celebrated for promoting transparency, trust, and efficiency in several domains. However, recent research has also pointed out the potential of these technologies to increase power asymmetries and deepen social inequality. In this paper, we contribute to this discussion by reporting on a collective effort of academics, development partners, local authorities, businesses, and farming groups to look at the potential of DLTs, particularly Blockchains, to support socio-economic development in rural communities in the Caribbean. We present a series of design concepts resulting from this effort and reflect on a method to facilitate stakeholders' experience of possible implementations and enable them to voice concerns, preferences, and expectations. Results from workshops with different groups of stakeholders contribute insights into opportunities and limitations of these applications to enable social development and to level the playing field in agricultural exchanges in developing countries.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {agricultural development, farming, blockchain, distributed ledger technologies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376357,
author = {Ryding, Karin},
title = {The Silent Conversation: Designing for Introspection and Social Play in Art Museums},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376357},
doi = {10.1145/3313831.3376357},
abstract = {This paper presents an attempt to design for a combination of social play and introspection using a ludic approach within an art museum setting. The field trial is described of a mobile web app called 'Never let me go', a two-player system enabling visitors to an art museum to create impromptu experiences in-situ for a companion. The study reveals that players used the app for communicating with each other during the visit, often without speaking. This led to deeply personal and introspective moments, as well as, lots of teasing and playing. The implications of allowing for social, personal and playful experiences in an art museum are discussed, as well as, the advantages and challenges of designing for improvisation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {affective, personalisation, art, mobile, experience, play, introspective, museums, social, impromptu experience design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376351,
author = {Tancred, Nicoletta and Turkay, Selen and Vickery, Nicole and Wyeth, Peta and McCoombe, Anna},
title = {Understanding Women Modders Using the Serious Leisure Perspective},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376351},
doi = {10.1145/3313831.3376351},
abstract = {Modding, the act of custom creation in videogames, is a large enterprise comprising millions of people. Despite the large number of individuals creating mods, our understanding of who modders are and their motivation for modding is limited. This is especially true for minority groups, including women. In prior research with modding communities, women modders were consistently underrepresented. Using a mixed-method survey (N = 68) that incorporates the Serious Leisure Framework, this study begins to unravel women's participation in modding activities. We begin to identify who women modders are, examine what motivates them to mod, and investigate their modding practices. Results show that women modders value the creation of multiple mod types, including cosmetic, environmental and gameplay modification. They are primarily motivated by self-gratification and enjoyment. These findings create new insights into how women interact with gaming environments, as well as identifying those aspects of the experience that motivate women's engagement in modding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {women modding, game modifications, modding, video games, serious leisure, modders, custom content},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376343,
author = {Garzotto, Franca and Beccaluva, Eleonora and Gianotti, Mattia and Riccardi, Fabiano},
title = {Interactive Multisensory Environments for Primary School Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376343},
doi = {10.1145/3313831.3376343},
abstract = {Interactive Multi-Sensory Environments (iMSEs) are room-sized interactive installations equipped with digitally enriched physical materials and ambient embedded devices. These items can sense users' presence, gestures, movements, and manipulation, and react by providing gentle stimulation (e.g., light, sound, projections, blowing bubbles, tactile feel, aromas) to different senses. Most of prior research on iMSEs investigates their use for persons with disabilities (e.g., autism). Our work focuses on the use of iMSEs in primary education contexts and for mixed groups of young students, i.e., children with and without disability. The paper describes the latest version of an iMSE called Magic Room that has been installed in two local schools. We report two empirical studies devoted to understand how the Magic Room could be used in inclusive educational settings, and to explore its potential benefits.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interactive multisensory environment, embodied interaction, children with special needs, children, well-being, smart space, smart object, primary school},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376340,
author = {Mayer, Sven and Reinhardt, Jens and Schweigert, Robin and Jelke, Brighten and Schwind, Valentin and Wolf, Katrin and Henze, Niels},
title = {Improving Humans' Ability to Interpret Deictic Gestures in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376340},
doi = {10.1145/3313831.3376340},
abstract = {Collaborative Virtual Environments (CVEs) offer unique opportunities for human communication. Humans can interact with each other over a distance in any environment and visual embodiment they want. Although deictic gestures are especially important as they can guide other humans' attention, humans make systematic errors when using and interpreting them. Recent work suggests that the interpretation of vertical deictic gestures can be significantly improved by warping the pointing arm. In this paper, we extend previous work by showing that models enable to also improve the interpretation of deictic gestures at targets all around the user. Through a study with 28 participants in a CVE, we analyzed the errors users make when interpreting deictic gestures. We derived a model that rotates the arm of a pointing user's avatar to improve the observing users' accuracy. A second study with 24 participants shows that we can improve observers' accuracy by 22.9%. As our approach is not noticeable for users, it improves their accuracy without requiring them to learn a new interaction technique or distracting from the experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {correction model, virtual reality, ray tracing, deictic},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376336,
author = {Huang, Jin and Tian, Feng and Fan, Xiangmin and Tu, Huawei and Zhang, Hao and Peng, Xiaolan and Wang, Hongan},
title = {Modeling the Endpoint Uncertainty in Crossing-Based Moving Target Selection},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376336},
doi = {10.1145/3313831.3376336},
abstract = {Modeling the endpoint uncertainty of moving target selection with crossing is essential to understand factors such as speed-accuracy trade-off and interaction efficiency in crossing-based user interfaces with dynamic contents. However, there have been few studies looking into this research topic in the HCI field. This paper presents a Quaternary-Gaussian model to quantitatively measure the endpoint uncertainty in crossing-based moving target selection. To validate this model, we conducted an experiment with discrete crossing tasks on five factors, i.e., initial distance, size, speed, orientation, and moving direction. Results showed that our model fit the data of μ and σ accurately with adjusted R2 of 0.883 and 0.920. We also demonstrated the validity of our model in predicting error rates in crossing-based moving target selection. We concluded with a set of implications for future designs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {error rate, endpoint distribution, crossing-based selection, moving target selection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376317,
author = {Kumar, Chandan and Hedeshy, Ramin and MacKenzie, I. Scott and Staab, Steffen},
title = {TAGSwipe: Touch Assisted Gaze Swipe for Text Entry},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376317},
doi = {10.1145/3313831.3376317},
abstract = {The conventional dwell-based methods for text entry by gaze are typically slow and uncomfortable. A swipe-based method that maps gaze path into words offers an alternative. However, it requires the user to explicitly indicate the beginning and ending of a word, which is typically achieved by tedious gaze-only selection. This paper introduces TAGSwipe, a bi-modal method that combines the simplicity of touch with the speed of gaze for swiping through a word. The result is an efficient and comfortable dwell-free text entry method. In the lab study TAGSwipe achieved an average text entry rate of 15.46 wpm and significantly outperformed conventional swipe-based and dwell-based methods in efficacy and user satisfaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touch input, swipe, multimodal interaction, eye typing, eye tracking, word-level text entry, dwell-free typing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376313,
author = {Zhou, Qian and Sykes, Sarah and Fels, Sidney and Kin, Kenrick},
title = {Gripmarks: Using Hand Grips to Transform In-Hand Objects into Mixed Reality Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376313},
doi = {10.1145/3313831.3376313},
abstract = {We introduce Gripmarks, a system that enables users to opportunistically use objects they are already holding as input surfaces for mixed reality head-mounted displays (HMD). Leveraging handheld objects reduces the need for users to free up their hands or acquire a controller to interact with their HMD. Gripmarks associate a particular hand grip with the shape primitive of the physical object without the need of object recognition or instrumenting the object. From the grip pose and shape primitive we can infer the surface of the object. With an activation gesture, we can enable the object for use as input to the HMD. With five gripmarks we demonstrate a recognition rate of 94.2%; we show that our grip detection benefits from the physical constraints of holding an object. We explore two categories of input objects 1) tangible surfaces and 2) tangible tools and present two representative applications. We discuss the design and technical challenges for expanding the concept.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gripmarks, grip recognition, tangible objects, mixed reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376304,
author = {Chen, Yuxin and Li, Huiying and Teng, Shan-Yuan and Nagels, Steven and Li, Zhijing and Lopes, Pedro and Zhao, Ben Y. and Zheng, Haitao},
title = {Wearable Microphone Jamming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376304},
doi = {10.1145/3313831.3376304},
abstract = {We engineered a wearable microphone jammer that is capable of disabling microphones in its user's surroundings, including hidden microphones. Our device is based on a recent exploit that leverages the fact that when exposed to ultrasonic noise, commodity microphones will leak the noise into the audible range.Unfortunately, ultrasonic jammers are built from multiple transducers and therefore exhibit blind spots, i.e., locations in which transducers destructively interfere and where a microphone cannot be jammed. To solve this, our device exploits a synergy between ultrasonic jamming and the naturally occur- ring movements that users induce on their wearable devices (e.g., bracelets) as they gesture or walk. We demonstrate that these movements can blur jamming blind spots and increase jamming coverage. Moreover, current jammers are also directional, requiring users to point the jammer to a microphone; instead, our wearable bracelet is built in a ring-layout that al- lows it to jam in multiple directions. This is beneficial in that it allows our jammer to protect against microphones hidden out of sight.We evaluated our jammer in a series of experiments and found that: (1) it jams in all directions, e.g., our device jams over 87% of the words uttered around it in any direction, while existing devices jam only 30% when not pointed directly at the microphone; (2) it exhibits significantly less blind spots; and, (3) our device induced a feeling of privacy to participants of our user study. We believe our wearable provides stronger privacy in a world in which most devices are constantly eavesdropping on our conversations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ultrasound, jamming, wearable, microphone, privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376299,
author = {Pradhan, Alisha and Jelen, Ben and Siek, Katie A. and Chan, Joel and Lazar, Amanda},
title = {Understanding Older Adults' Participation in Design Workshops},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376299},
doi = {10.1145/3313831.3376299},
abstract = {Design workshops are a popular means of including older adults in technology development. However, there are open questions around how to best scaffold this participation, particularly in supporting older adults to associate their designs with themselves, rather than designing for an "other older adult." By conducting workshops focusing on envisioning the future of internet of things (IoT) technologies at home, we provide an understanding of how older individuals participate in group activities to conceptualize technology for themselves. We find that at different stages of the design process, individuals shift in who they envision the end user of the technology: at first, they think about common older adult needs, then turn to designing for themselves. Individuals' attitudes towards technology also impact group dynamics along with final design ideas. Our discussion contributes to an understanding of how to support older adults in designing for themselves, new perspectives on aging-in-place technologies, and recommendations for configuring design workshops with older individuals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {older adults, design workshops, co-design, iot, participatory design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376293,
author = {Fan, Jenny and Zhang, Amy X.},
title = {Digital Juries: A Civics-Oriented Approach to Platform Governance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376293},
doi = {10.1145/3313831.3376293},
abstract = {As concerns have grown regarding harmful content spread on social media, platform mechanisms for content moderation have become increasingly significant. However, many existing platform governance structures lack formal processes for democratic participation by users of the platform. Drawing inspiration from constitutional jury trials in many legal systems, this paper proposes digital juries as a civics-oriented approach for adjudicating content moderation cases. Building on existing theoretical models of jury decision-making, we outline a 5-stage model characterizing the space of design considerations in a digital jury process. We implement two examples of jury designs involving blind-voting and deliberation. From users who participate in our jury implementations, we gather informed judgments of the democratic legitimacy of a jury process for content moderation. We find that digital juries are perceived as more procedurally just than existing common platform moderation practices, but also find disagreement over whether jury decisions should be enforced or used as recommendations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {juries, governance, civics, online speech, content moderation, platforms, institutional design, democracy, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376292,
author = {Wang, Bo-Xiang and Wang, Yu-Wei and Chen, Yen-Kai and Tseng, Chun-Miao and Hsu, Min-Chien and Hsieh, Cheng An and Lee, Hsin-Ying and Chen, Mike Y.},
title = {Miniature Haptics: Experiencing Haptic Feedback through Hand-Based and Embodied Avatars},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376292},
doi = {10.1145/3313831.3376292},
abstract = {We present Miniature Haptics, a new approach to providing realistic haptic experiences by applying miniaturized haptic feedback to hand-based, embodied avatars. By shrinking haptics to a much smaller scale, Miniature Haptics enables the exploration of new haptic experiences that are not practical to create at the full, human-body scale. Using Finger Walking in Place (FWIP) as an example avatar embodiment and control method, we first explored the feasibility of Miniature Haptics then conducted a human factors study to understand how people map their full-body skeletal model to their hands. To understand the user experience of Miniature Haptic, we developed a miniature football haptic display, and results from our user study show that Miniature Haptics significantly improved the realism and enjoyment of the experience and is preferred by users (p &lt; 0.05). In addition, we present two miniature motion platforms supporting the haptic experiences of: 1) rapidly changing ground height for platform jumping games such as Super Mario Bros and 2) changing terrain slope. Overall, Miniature Haptics makes it possible to explore novel haptic experiences that have not been practical before.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {embodiment illusion, embodied avatar, haptics, finger walking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376287,
author = {Nouwens, Midas and Borowski, Marcel and Fog, Bjarke and Klokmose, Clemens Nylandsted},
title = {Between Scripts and Applications: Computational Media for the Frontier of Nanoscience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376287},
abstract = {The popularity of computational notebooks heralds a return of software as computational media rather than turn-key applications. We believe this software model has potential beyond supporting just the computationally literate. We studied a biomolecular nano-design lab that works on a current frontier of science - RNA origami - whose researchers depend on computational tools to do their work, yet are not trained as programmers. Using a participatory design process, we developed a computational labbook to concretise what computational media could look like, using the principles of computability, malleability, shareability, and distributability suggested by previous work. We used this prototype to co-reflect with the nanoscientists about how it could transform their practice. We report on the computational culture specific to this research area; the scientists' struggles managing their computational environments; and their subsequent disempowerment yet dependence. Lastly, we discuss the generative potential and limitations of the four design principles for the future of computational media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3313831.3376275,
author = {Dove, Graham and Fayard, Anne-Laure},
title = {Monsters, Metaphors, and Machine Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376275},
doi = {10.1145/3313831.3376275},
abstract = {Machine learning (ML) poses complex challenges for user experience (UX) designers. Typically unpredictable and opaque, it may produce unforeseen outcomes detrimental to particular groups or individuals, yet simultaneously promise amazing breakthroughs in areas as diverse as medical diagnosis and universal translation. This results in a polarized view of ML, which is often manifested through a technology-as-monster metaphor. In this paper, we acknowledge the power and potential of this metaphor by resurfacing historic complexities in human-monster relations. We (re)introduce these liminal and ambiguous creatures, and discuss their relation to ML. We offer a background to designers' use of metaphor, and show how the technology-as-monster metaphor can generatively probe and (re)frame the questions ML poses. We illustrate the effectiveness of this approach through a detailed discussion of an early-stage generative design workshop inquiring into ML approaches to supporting student mental health and well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {ux design, monster theory, generative metaphor, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376274,
author = {Wang, Ding and Kale, Santosh D. and O'Neill, Jacki},
title = {Please Call the Specialism: Using WeChat to Support Patient Care in China},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376274},
doi = {10.1145/3313831.3376274},
abstract = {We examine how WeChat has been adopted to support nurse-patient communication in an IVF clinic in China. In this setting, the biggest challenge to delivering high-quality patient-centred care is the large number of patients. Nurses typically spend less than five minutes with each patient during clinical visits. To compensate for such minimal in-person consultation, nurse-facilitated patient groups were created on WeChat, to extend medical care and facilitate peer support. Through an ethnographic study, we examined how these groups fit into the clinic's communication ecosystem, and the challenges they raise for nurse-facilitators who receive thousands of messages daily. We propose a set of design suggestions aiming to make the work of the nurse-facilitator easier and more effective. In highlighting the opportunities and challenges of using chat to extend care beyond the clinic, we contribute to a burgeoning discussion of how chat can support patient care in the Global South.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {chat apps, wechat, healthcare, peer support, ethnography, nurse-patient communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376271,
author = {Wang, Zezhong and Sundin, Lovisa and Murray-Rust, Dave and Bach, Benjamin},
title = {Cheat Sheets for Data Visualization Techniques},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376271},
doi = {10.1145/3313831.3376271},
abstract = {This paper introduces the concept of 'cheat sheets' for data visualization techniques, a set of concise graphical explanations and textual annotations inspired by infographics, data comics, and cheat sheets in other domains. Cheat sheets aim to address the increasing need for accessible material that supports a wide audience in understanding data visualization techniques, their use, their fallacies and so forth. We have carried out an iterative design process with practitioners, teachers and students of data science and visualization, resulting six types of cheat sheet (anatomy, construction, visual patterns, pitfalls, false-friends and well-known relatives) for six types of visualization, and formats for presentation. We assess these with a qualitative user study using 11 participants that demonstrates the readability and usefulness of our cheat sheets.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization literacy, cheat sheet},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376267,
author = {Tigwell, Garreth W. and Gorman, Benjamin M. and Menzies, Rachel},
title = {Emoji Accessibility for Visually Impaired People},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376267},
doi = {10.1145/3313831.3376267},
abstract = {Emoji are graphical symbols that appear in many aspects of our lives. Worldwide, around 36 million people are blind and 217 million have a moderate to severe visual impairment. This portion of the population may use and encounter emoji, yet it is unclear what accessibility challenges emoji introduce. We first conducted an online survey with 58 visually impaired participants to understand how they use and encounter emoji online, and the challenges they experience. We then conducted 11 interviews with screen reader users to understand more about the challenges reported in our survey findings. Our interview findings demonstrate that technology is both an enabler and a barrier, emoji descriptors can hinder communication, and therefore the use of emoji impacts social interaction. Using our findings from both studies, we propose best practice when using emoji and recommendations to improve the future accessibility of emoji for visually impaired people.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {cmc, emoji, accessibility, visual impairments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376265,
author = {Gerling, Kathrin and Dickinson, Patrick and Hicks, Kieran and Mason, Liam and Simeone, Adalberto L. and Spiel, Katta},
title = {Virtual Reality Games for People Using Wheelchairs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376265},
doi = {10.1145/3313831.3376265},
abstract = {Virtual Reality (VR) holds the promise of providing engaging embodied experiences, but little is known about how people with disabilities engage with it. We explore challenges and opportunities of VR gaming for wheelchair users. First, we present findings from a survey that received 25 responses and gives insights into wheelchair users' motives to (non-) engage with VR and their experiences. Drawing from this survey, we derive design implications which we tested through implementation and qualitative evaluation of three full-body VR game prototypes with 18 participants. Our results show that VR gaming engages wheelchair users, though nuanced consideration is required for the design of embodied immersive experiences for minority bodies, and we illustrate how designers can create meaningful, positive experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {games, virtual reality, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376258,
author = {Lin, Yuyu and Guo, Jiahao and Chen, Yang and Yao, Cheng and Ying, Fangtian},
title = {It Is Your Turn: Collaborative Ideation With a Co-Creative Robot through Sketch},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376258},
doi = {10.1145/3313831.3376258},
abstract = {Co-creative systems have been widely explored in the field of computational creativity. However, existing AI partners of these systems are mostly virtual agents. As sketching on paper with embodied robots could be more engaging for designers' early-stage ideation and collaborative practices, we envision the possibility of Cobbie, a mobile robot that ideates iteratively with designers by generating creative and diverse sketches. To evaluate the differences in co-creativity and user experience between the co-creative robots and virtual agents, we conducted a comparative experiment and analyzed the data collected from quantitative scales, observation, and semi-structured interview. The results reveal that Cobbie is more satisfying in motivating exploration, provoking unexpected ideas and engaging designers in the collaborative ideation process. Based on these findings, we discussed the prospects of co-creative robots for future developments of human-AI collaborative systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {co-creative system, early-stage design, creative robot, ideation, human-ai collaboration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376245,
author = {Jensen, Rikke Bjerg and Coles-Kemp, Lizzie and Talhouk, Reem},
title = {When the Civic Turn Turns Digital: Designing Safe and Secure Refugee Resettlement},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376245},
abstract = {Across Europe, refugees are required to engage with the "civic turn" -- a process of integrating refugees into the social and cultural aspects of the new land. Over a two-year period, we engaged 89 refugees settling in Sweden, to explore how accelerated and digitalised resettlement processes shape the civic turn. Framed within wider literature on transitioning and everyday insecurities, we show how this "digital turn" exacerbates existing barriers to resettlement experienced by refugees. By critically analysing these barriers, we reveal how the civic turn rests upon a series of everyday social and cultural practices and relations, which are largely ignored in digital service design. We show how this leads to a "vacuum" for our participants. We call on the HCI community to engage with this vacuum and understand resettlement as encompassing multiple digitally-mediated transitional phases of citizenry. We do so by focusing on the digitalisation processes shaping these transitions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3313831.3376228,
author = {Hsieh, Ching-Yu and Chiang, Yi-Shyuan and Chiu, Hung-Yu and Chang, Yung-Ju},
title = {Bridging the Virtual and Real Worlds: A Preliminary Study of Messaging Notifications in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376228},
doi = {10.1145/3313831.3376228},
abstract = {Virtual reality (VR) platforms provide their users with immersive virtual environments, but disconnect them from real-world events. The increasing length of VR sessions can therefore be expected to boost users' needs to obtain information about external occurrences such as message arrival. Yet, how and when to present these real-world notifications to users engaged in VR activities remains underexplored. We conducted an experiment to investigate individuals' receptivity during four VR activities (Loading, 360 Video, Treasure Hunt, Rhythm Game) to message notifications delivered using three types of displays (head-mounted, controller, and movable panel). While higher engagement generally led to higher perceptions that notifications were ill-timed and/or disruptive, the suitability of notification displays to VR activities was influenced by the time-sensitiveness of VR content, overlapping use of modalities for delivering alerts, the display locations, and a requirement that the display be moved for notifications to be seen. Specific design suggestions are also provided.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, interruptibility, eye-tracking, receptivity, notification systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376223,
author = {Pfau, Johannes and Smeddinck, Jan David and Bikas, Ioannis and Malaka, Rainer},
title = {Bot or Not? User Perceptions of Player Substitution with Deep Player Behavior Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376223},
doi = {10.1145/3313831.3376223},
abstract = {Many online games suffer when players drop off due to lost connections or quitting prematurely, which leads to match terminations or game-play imbalances. While rule-based outcome evaluations or substitutions with bots are frequently used to mitigate such disruptions, these techniques are often perceived as unsatisfactory. Deep learning methods have successfully been used in deep player behavior modelling (DPBM) to produce non-player characters or bots which show more complex behavior patterns than those modelled using traditional AI techniques. Motivated by these findings, we present an investigation of the player-perceived awareness, believability and representativeness, when substituting disconnected players with DPBM agents in an online-multiplayer action game. Both quantitative and qualitative outcomes indicate that DPBM agent substitutes perform similarly to human players and that players were unable to detect substitutions. Notably, players were in fact able to detect substitution with agents driven by more traditional heuristics.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {games user research, player substitution, games, player modeling, neural networks, game disruption prevention, deep learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376221,
author = {Peng, Xiaolan and Huang, Jin and Denisova, Alena and Chen, Hui and Tian, Feng and Wang, Hongan},
title = {A Palette of Deepened Emotions: Exploring Emotional Challenge in Virtual Reality Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376221},
doi = {10.1145/3313831.3376221},
abstract = {Recent work introduced the notion of 'emotional challenge' promising for understanding more unique and diverse player experiences (PX). Although emotional challenge has immediately attracted HCI researchers' attention, the concept has not been experimentally explored, especially in virtual reality (VR), one of the latest gaming environments. We conducted two experiments to investigate how emotional challenge affects PX when separately from or jointly with conventional challenge in VR and PC conditions. We found that relatively exclusive emotional challenge induced a wider range of different emotions in both conditions, while the adding of emotional challenge broadened emotional responses only in VR. In both experiments, VR significantly enhanced the measured PX of emotional responses, appreciation, immersion and presence. Our findings indicate that VR may be an ideal medium to present emotional challenge and also extend the understanding of emotional (and conventional) challenge in video games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emotion, virtual reality, player experience, emotional challenge, games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376219,
author = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
title = {Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376219},
doi = {10.1145/3313831.3376219},
abstract = {Machine learning (ML) models are now routinely deployed in domains ranging from criminal justice to healthcare. With this newfound ubiquity, ML has moved beyond academia and grown into an engineering discipline. To that end, interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study data scientists' use of two existing interpretability tools, the InterpretML implementation of GAMs and the SHAP Python package. We conduct a contextual inquiry (N=11) and a survey (N=197) of data scientists to observe how they use interpretability tools to uncover common issues that arise when building and evaluating ML models. Our results indicate that data scientists over-trust and misuse interpretability tools. Furthermore, few of our participants were able to accurately describe the visualizations output by these tools. We highlight qualitative themes for data scientists' mental models of interpretability tools. We conclude with implications for researchers and tool designers, and contextualize our findings in the social science literature.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interpretability, user-centric evaluation, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376212,
author = {Lee, Sangyoon and Lim, Youn-kyung and Lee, Geehyuk},
title = {MirrorPad: Mirror on Touchpad for Direct Pen Interaction in the Laptop Environment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376212},
doi = {10.1145/3313831.3376212},
abstract = {There are needs for pen interaction on a laptop, and the market sees many pen-enabled laptop products. Many of these laptops can be transformed into tablets, when pen interaction is needed. In a real situation, however, a workflow often requires both keyboard and pen interactions, and such a convertible feature may not be effective. In this study, we introduce MirrorPad, a novel interface device contained in a laptop for direct pen interaction. It is both a normal touchpad and a viewport for pen interaction with a mirrored region on the screen. We report findings and decisions obtained from the design iterations that we conducted with users to refine MirrorPad toward the final design. In the user study, MirrorPad showed the same performance as that of the laptop configuration during keyboard interaction and a performance similar to that of the tablet configuration during pen interaction. The user study results confirmed that MirrorPad effectively supports a workflow, which requires interspersed keyboard and pen interactions, thereby achieving its initial goal.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {laptop environment, direct pen interaction, touchpad with display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376211,
author = {Andrade, Ronny and Rogerson, Melissa J. and Waycott, Jenny and Baker, Steven and Vetere, Frank},
title = {Introducing the Gamer Information-Control Framework: Enabling Access to Digital Games for People with Visual Impairment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376211},
doi = {10.1145/3313831.3376211},
abstract = {In this paper, we present a foundation for understanding the elements that enable people with visual impairment to engage with digital games. This is defined by the gamer's relation- ships with information and with elements of control provided by the game, and is mediated through in-game metaphors and affordances when gamers interact as users or creators. This work complements previous research exploring the points of view of gamers with visual impairment by focusing on the games they play and prioritising the relationships between the key enablers of access to digital games. Using the framework to examine existing and missing components will enable de- signers to consider broader aspects of accessibility in game design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visual impairment, framework, audiogames, control, digital games, information},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376191,
author = {T\"{u}rkay, Selen and Formosa, Jessica and Adinolf, Sonam and Cuthbert, Robert and Altizer, Roger},
title = {See No Evil, Hear No Evil, Speak No Evil: How Collegiate Players Define, Experience and Cope with Toxicity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376191},
doi = {10.1145/3313831.3376191},
abstract = {Toxicity in online environments is a complex and a systemic issue. Collegiate esports communities seem to be particularly vulnerable to toxic behaviors. In esports games, negative behavior, such as harassment, can create barriers to players achieving high performance and can reduce enjoyment which may cause them to leave the game. The aim of this study is to investigate how players define, experience and deal with toxicity in esports games that they play. Our findings from an interview study and five monthly follow ups with 19 participants from a university esports club show that players define toxicity as behaviors disrupt their morale and team dynamics, and are inclined to normalize negative behaviors, rationalize it as part of the competitive game culture akin to traditional sports, and participate a form of gamer classism, believing that toxicity is more common in lower level play than in professional and collegiate esports. There are many coping mechanisms employed by collegiate esports players, including ignoring offenders, deescalating tense encounters, and using tools to mute offenders. Understanding the motivations behind collegiate esports players' engagement with toxicity may help the growing sport plot a positive trajectory towards healthy play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {player perceptions, toxicity, competitive games, esports, interview study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376182,
author = {Taber, Lee and Whittaker, Steve},
title = {"On Finsta, I Can Say 'Hail Satan'": Being Authentic but Disagreeable on Instagram},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376182},
doi = {10.1145/3313831.3376182},
abstract = {We use personality theory to compare self-presentation between multiple Instagram accounts, investigating authenticity and consistency. Many studies claim social media promote inauthentic self-presentation focused on socially desirable traits. At the same time, affordances suggest that self-presentation should be relatively consistent within one social medium. For 88 participants, we examine personality traits for 'real Instagram' ('Rinsta') versus 'fake Instagram' ('Finsta') accounts, comparing these with people's offline traits using mixed-methods. Counterintuitively, we find Finsta accounts often present socially undesirable traits. Furthermore, different accounts on the same social medium reveal quite different styles of self-presentation. Overall Finstas are more Extraverted, less Conscientious, and less Agreeable than Rinstas, although equally Neurotic as offline. Interviews indicate trait differences arise from differing audience perceptions. A large anonymous Rinsta audience promotes a carefully curated self. In contrast, a small but trusted Finsta audience can engender more authentic, but negative self-presentation. We discuss design and theory implications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {finsta, self-presentation, social media, traits, instagram, personality, rinsta, self-perception, affordances},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

