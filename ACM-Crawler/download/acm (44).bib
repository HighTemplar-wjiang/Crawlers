@inproceedings{10.1145/3411764.3445717,
author = {Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
title = {Does the Whole Exceed Its Parts? The Effect of AI Explanations on Complementary Team Performance},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445717},
doi = {10.1145/3411764.3445717},
abstract = {Many researchers motivate explainable AI with studies showing that human-AI team performance on decision-making tasks improves when the AI explains its recommendations. However, prior studies observed improvements from explanations only when the AI, alone, outperformed both the human and the best team. Can explanations help lead to complementary performance, where team accuracy is higher than either the human or the AI working solo? We conduct mixed-method user studies on three datasets, where an AI with accuracy comparable to humans helps participants solve a task (explaining itself in some conditions). While we observed complementary improvements from AI augmentation, they were not increased by explanations. Rather, explanations increased the chance that humans will accept the AI’s recommendation, regardless of its correctness. Our result poses new challenges for human-centered AI: Can we develop explanatory approaches that encourage appropriate trust in AI, and therefore help generate (or improve) complementary performance?},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {81},
numpages = {16},
keywords = {Explainable AI, Human-AI teams, Augmented intelligence},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445714,
author = {Zhang, Enhao and Banovic, Nikola},
title = {Method for Exploring Generative Adversarial Networks (GANs) via Automatically Generated Image Galleries},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445714},
doi = {10.1145/3411764.3445714},
abstract = {Generative Adversarial Networks (GANs) can automatically generate quality images from learned model parameters. However, it remains challenging to explore and objectively assess the quality of all possible images generated using a GAN. Currently, model creators evaluate their GANs via tedious visual examination of generated images sampled from narrow prior probability distributions on model parameters. Here, we introduce an interactive method to explore and sample quality images from GANs. Our first two user studies showed that participants can use the tool to explore a GAN and select quality images. Our third user study showed that images sampled from a posterior probability distribution using a Markov Chain Monte Carlo (MCMC) method on parameters of images collected in our first study resulted in on average higher quality and more diverse images than existing baselines. Our work enables principled qualitative GAN exploration and evaluation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {76},
numpages = {15},
keywords = {Interactive model exploration, qualitative model validation.},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445708,
author = {Aneja, Deepali and Hoegen, Rens and McDuff, Daniel and Czerwinski, Mary},
title = {Understanding Conversational and Expressive Style in a Multimodal Embodied Conversational Agent},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445708},
doi = {10.1145/3411764.3445708},
abstract = {Embodied conversational agents have changed the ways we can interact with machines. However, these systems often do not meet users’ expectations. A limitation is that the agents are monotonic in behavior and do not adapt to an interlocutor. We present SIVA (a Socially Intelligent Virtual Agent), an expressive, embodied conversational agent that can recognize human behavior during open-ended conversations and automatically align its responses to the conversational and expressive style of the other party. SIVA leverages multimodal inputs to produce rich and perceptually valid responses (lip syncing and facial expressions) during the conversation. We conducted a user study (N=30) in which participants rated SIVA as being more empathetic and believable than the control (agent without style matching). Based on almost 10 hours of interaction, participants who preferred interpersonal involvement evaluated SIVA as significantly more animate than the participants who valued consideration and independence.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {102},
numpages = {10},
keywords = {multi-modality, Embodied agents, social dialogue, facial expressive style, social behavior, emotional expressions, conversational style},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445701,
author = {MacArthur, Cayley and Grinberg, Arielle and Harley, Daniel and Hancock, Mark},
title = {You’re Making Me Sick: A Systematic Review of How Virtual Reality Research Considers Gender &amp; Cybersickness},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445701},
doi = {10.1145/3411764.3445701},
abstract = {While multiple studies suggest that female-identified participants are more likely to experience cybersickness in virtual reality (VR), our systematic review of 71 eligible VR publications (59 studies and 12 surveys) pertaining to gender and cybersickness reveals a number of confounding factors in study design (e.g., a variety of technical specifications, tasks, content), a lack of demographic data, and a bias in participant recruitment. Our review shows an ongoing need within VR research to more consistently include and report on women’s experiences in VR to better understand the gendered possibility of cybersickness. Based on the gaps identified in our systematic review, we contribute study design recommendations for future work, arguing that gender considerations are necessary at every stage of VR study design, even when the study is not ‘about’ gender.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {401},
numpages = {15},
keywords = {systematic review, simulator sickness, virtual reality, virtual environments, cybersickness, sex, gender},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445692,
author = {Nisser, Martin and Liao, Christina Chen and Chai, Yuchen and Adhikari, Aradhana and Hodges, Steve and Mueller, Stefanie},
title = {LaserFactory: A Laser Cutter-Based Electromechanical Assembly and Fabrication Platform to Make Functional Devices &amp; Robots},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445692},
doi = {10.1145/3411764.3445692},
abstract = {LaserFactory is an integrated fabrication process that augments a commercially available fabrication machine to support the manufacture of fully functioning devices without human intervention. In addition to creating 2D and 3D mechanical structures, LaserFactory creates conductive circuit traces with arbitrary geometries, picks-and-places electronic and electromechanical components, and solders them in place. To enable this functionality, we make four contributions. First, we build a hardware add-on to the laser cutter head that can deposit silver circuit traces and assemble components. Second, we develop a new method to cure dispensed silver using a CO2 laser. Third, we build a motion-based signaling method that allows our system to be readily integrated with commercial laser cutters. Finally, we provide a design and visualization tool for making functional devices with LaserFactory. Having described the LaserFactory system, we demonstrate how it is used to fabricate devices such as a fully functioning quadcopter and a sensor-equipped wristband. Our evaluation shows that LaserFactory can assemble a variety of differently sized components (up to 65g), that these can be connected by narrow traces (down to 0.75mm) that become highly conductive after laser soldering (3.2Ω/m), and that our acceleration-based sensing scheme works reliably (to 99.5% accuracy).},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {663},
numpages = {15},
keywords = {printed electronics, robotics, Human-computer interaction, personal fabrication, rapid prototyping},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445689,
author = {Alexandrovsky, Dmitry and Friehs, Maximilian Achim and Grittner, Jendrik and Putze, Susanne and Birk, Max V. and Malaka, Rainer and Mandryk, Regan L},
title = {Serious Snacking: A Survival Analysis of How Snacking Mechanics Affect Attrition in a Mobile Serious Game},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445689},
doi = {10.1145/3411764.3445689},
abstract = {Many serious games are most effective when played regularly; however, little is known about how individual game elements support player adherence over time. This work draws on evidence from existing frameworks and game design theories as well as from the design of casual games to investigate how individual game mechanics affect player attrition in a serious game. We implemented a math-learning game in which we could individually layer various game mechanics, and over the course of 3 weeks, 99 participants played one of six versions: Baseline, Rewards, Novelty, Completion, Waiting, or Blocking. We compared the game versions by analyzing the players’ performance as well as behaviour. Using survival analysis, we identified that the addition of Completion and Blocking mechanics facilitated the strongest sustained engagement. These findings are congruent with existing theories of player experience and promote the development of guidelines on designing for sustained engagement in serious games.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {113},
numpages = {18},
keywords = {blocking, adherence, missions, design, rewards, game mechanics, waiting, novelty, Game mechanics, snacking.},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445670,
author = {Devakumar, Anjali and Modh, Jay and Saket, Bahador and Baumer, Eric P. S. and De Choudhury, Munmun},
title = {A Review on Strategies for Data Collection, Reflection, and Communication in Eating Disorder Apps},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445670},
doi = {10.1145/3411764.3445670},
abstract = {Eating disorders (EDs) constitute a mental illness with the highest mortality. Today, mobile health apps provide promising means to ED patients for managing their condition. Apps enable users to monitor their eating habits, thoughts, and feelings, and offer analytic insights for behavior change. However, not only have scholars critiqued the clinical validity of these apps, their underlying design principles are not well understood. Through a review of 34 ED apps, we uncovered 11 different data types ED apps collect, and 9 strategies they employ to support collection and reflection. Drawing upon personal health informatics and visualization frameworks, we found that most apps did not adhere to best practices on what and how data should be collected from and reflected to users, or how data-driven insights should be communicated. Our review offers suggestions for improving the design of ED apps such that they can be useful and meaningful in ED recovery.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {547},
numpages = {19},
keywords = {apps, self-tracking, eating disorder, reflection},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445664,
author = {K. Miller, Matthew and Johannes Dechant, Martin and L. Mandryk, Regan},
title = {Meeting You, Seeing Me: The Role of Social Anxiety, Visual Feedback, and Interface Layout in a Get-to-Know-You Task via Video Chat.},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445664},
doi = {10.1145/3411764.3445664},
abstract = {The growing number of video chat users includes socially anxious people, but it is not known how video chat interfaces affect their interpersonal interactions. In our first study, we use a get-to-know-you task to show that when video feedback of oneself is disabled, higher social anxiety is associated with more public self-awareness, use of 2nd person pronouns, and experienced anxiety. Higher social anxiety was linked to discussing more topics, but discussing more topics only elicited higher self-disclosure and trust when social anxiety was low. In our second study, we assess these same effects using a presentation layout video chat interface and observe no effects of social anxiety on public self-awareness, 2nd person pronoun use, or number of topics discussed; no effect of feedback on experienced anxiety; and no link between number of topics and self-disclosure. Video chat adopters and designers should consider how feedback and interface layout affect conversations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {339},
numpages = {14},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445661,
author = {Raju, Dani Kalarikalayil and Seunarine, Krishna and Reitmaier, Thomas and Thomas, Gethin and Meena, Yogesh Kumar and Zhang, Chi and Pockett, Adam and Pearson, Jennifer and Robinson, Simon and Carnie, Matt and Sahoo, Deepak Ranjan and Jones, Matt},
title = {PV-Pix: Slum Community Co-Design of Self-Powered Deformable Smart Messaging Materials},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445661},
doi = {10.1145/3411764.3445661},
abstract = {Working with emergent users in two of Mumbai’s slums, we explored the value and uses of photovoltaic (PV) self-powering digital materials. Through a series of co-design workshops, a diary study and responses by artists and craftspeople, we developed the PV-Pix concept for inter-home connections. Each PV-Pix element consists of a deformable energy harvesting material that, when actuated by a person in one home, changes its physical state both there and in a connected home. To explore the concept we considered two forms of PV-Pix: one uses rigid materials and the other flexible ones. We deployed two low-fidelity prototypes, each constructed of a grid of one PV-Pix type, in four slum homes over a four week period to further understand the usability and uses of the materials, eliciting interesting inter-family communication practices. Encouraged by these results we report on a first-step towards working prototypes and demonstrate the technical viability of the approach.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {14},
keywords = {interaction design, connected home, Self-powered devices, Internet of Things, sustainability},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445658,
author = {Raptis, George E. and Katsini, Christina and Cen, Andrew Jian-lan and Arachchilage, Nalin Asanka Gamagedara and Nacke, Lennart E.},
title = {Better, Funner, Stronger: A Gameful Approach to Nudge People into Making Less Predictable Graphical Password Choices},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445658},
doi = {10.1145/3411764.3445658},
abstract = {Graphical user authentication (GUA) is a common alternative to text-based user authentication, where people are required to draw graphical passwords on background images. Such schemes are theoretically considered remarkably secure because they offer a large password space. However, people tend to create their passwords on salient image areas introducing high password predictability. Aiming to help people use the password space more effectively, we propose a gameful password creation process. In this paper, we present GamePass, a gamified mechanism that integrates the GUA password creation process. We provide the first evidence that it is possible to nudge people towards better password choices by gamifying the process. GamePass randomly guides participants’ attention to areas other than the salient areas of authentication images, makes the password creation process more fun, and people are more engaged. Gamifying the password creation process enables users to interact better and make less predictable graphical password choices instead of being forced to use a strict password policy.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {112},
numpages = {17},
keywords = {graphical passwords, behavior change, gamification, games and play},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445636,
author = {Foong, Eureka and Gerber, Elizabeth},
title = {Understanding Gender Differences in Pricing Strategies in Online Labor Marketplaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445636},
doi = {10.1145/3411764.3445636},
abstract = {The growing online gig economy provides ways for women to participate in a flexible, remote workforce and close the offline gender pay and participation gap. While women in online labor marketplaces earn about as much overall as men, women set lower bill rates suggesting gender differences in pricing strategies. In this study, we surveyed 392 freelancers in the United States (US) on the popular marketplace platform, Upwork, to understand strategies used to set hourly bill rates. We did not find gender differences in pricing strategies that were significantly related to bill rate. Instead, we found that other factors, such as full-time freelancer status and level of self-esteem, may help explain gender differences in bill rates. To better support equity and fairness in the growing gig economy, CHI researchers must identify, assess, and address the complex interaction between societal conditions in online labor markets.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {135},
numpages = {16},
keywords = {online work, pricing, survey, Gender, online labor marketplaces, bill rate, freelancing, gig economy},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445628,
author = {Tsaknaki, Vasiliki and Cotton, Kelsey and Karpashevich, Pavel and Sanches, Pedro},
title = {“Feeling the Sensor Feeling You”: A Soma Design Exploration on Sensing Non-Habitual Breathing},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445628},
doi = {10.1145/3411764.3445628},
abstract = {Though seemingly straightforward and habitual, breathing is a complex bodily function. Problematising the space of designing for breathing as a non-habitual act pertaining to different bodies or situations, we conducted a soma design exploration together with a classical singer. Reflecting on how sensors could capture the impact and somatic experience of being sensed led us to develop a new sensing mechanism using shape-change technologies integrated in the Breathing Shell: a wearable that evokes a reciprocal experience of “feeling the sensor feeling you” when breathing. We contribute with two design implications: 1) Enabling reflections of the somatic impact of being sensed in tandem with the type of data captured, 2) creating a tactile impact of the sensor data on the body. Both implications aim to deepen one’s understanding of how the whole soma relates to or with biosensors and ultimately leading to designing for symbiotic experiences between biosensors and bodies.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {266},
numpages = {16},
keywords = {actuation, shape-change, autobiographical design, non-habitual, soma design, breathing, sensing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445627,
author = {W\"{o}hler, Leslie and Zembaty, Martin and Castillo, Susana and Magnor, Marcus},
title = {Towards Understanding Perceptual Differences between Genuine and Face-Swapped Videos},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445627},
doi = {10.1145/3411764.3445627},
abstract = {In this paper, we report on perceptual experiments indicating that there are distinct and quantitatively measurable differences in the way we visually perceive genuine versus face-swapped videos. Recent progress in deep learning has made face-swapping techniques a powerful tool for creative purposes, but also a means for unethical forgeries. Currently, it remains unclear why people are misled, and which indicators they use to recognize potential manipulations. Here, we conduct three perceptual experiments focusing on a wide range of aspects: the conspicuousness of artifacts, the viewing behavior using eye tracking, the recognition accuracy for different video lengths, and the assessment of emotions. Our experiments show that responses differ distinctly when watching manipulated as opposed to original faces, from which we derive perceptual cues to recognize face swaps. By investigating physiologically measurable signals, our findings yield valuable insights that may also be useful for advanced algorithmic detection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {240},
numpages = {13},
keywords = {face swapping, eye tracking, human perception, video manipulation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445623,
author = {Fruchard, Bruno and Strohmeier, Paul and Bennewitz, Roland and Steimle, J\"{u}rgen},
title = {Squish This: Force Input on Soft Surfacesfor Visual Targeting Tasks},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445623},
doi = {10.1145/3411764.3445623},
abstract = {Today’s typical input device is flat, rigid and made of glass. However, advances in sensing technology and interaction design suggest thinking about input on other surface, including soft materials. While touching rigid and soft materials might feel similar, they clearly feel different when pressure is applied to them. Yet, to date, studies only investigated force input on rigid surfaces. We present a first systematic evaluation of the effects of compliance on force input. Results of a visual targeting task for three levels of softness indicate that high force levels appear more demanding for soft surfaces, but that performance is otherwise similar. Performance remained very high (∼ 5% for 20 force levels) regardless of the compliance, suggesting force input was underestimated so far. We infer implications for the design of force input on soft surfaces and conclude that interaction models used on rigid surfaces might be used on soft surfaces.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {219},
numpages = {9},
keywords = {User Study, Soft Surfaces, Pressure Input, Force Input},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445622,
author = {Petersen Matjeka, Louise and Hobye, Mads and Larsen, Henrik Svarrer},
title = {Restraints as a Mechanic for Bodily Play},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445622},
doi = {10.1145/3411764.3445622},
abstract = {This paper presents restraints - directly imposed restrictions on players' bodily movements, as a mechanic for bodily play in HCI. While this is a familiar mechanic in non-digital movement-based games, its potential in designing bodily play experiences in HCI has been scarcely explored. Three types of restraints observed in non-digital movement-based games, are explored here: fixating body parts,&nbsp;excluding body parts and&nbsp;depriving/manipulating bodily senses. Then, we investigate the experiential dynamics of restraints as a bodily play mechanic bridging a phenomenological perspective on bodily movement with theories on play. These investigations form the theoretical framework for the subsequent analysis of five digital body game examples. Building on this analysis and theoretical framework, we formulate five design strategies for implementing restraints as a mechanic for bodily play in HCI. We propose restraints as a generative resource for researchers and designers interested in understanding and designing bodily play experiences in HCI.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {441},
numpages = {14},
keywords = {Phenomenology, Bodily Play, Bodily Play Experiences, Body Games, Game Design, Interaction Design, Movement-Based Games, Restraints},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445621,
author = {Streli, Paul and Holz, Christian},
title = {CapContact: Super-Resolution Contact Areas from Capacitive Touchscreens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445621},
doi = {10.1145/3411764.3445621},
abstract = {Touch input is dominantly detected using mutual-capacitance sensing, which measures the proximity of close-by objects that change the electric field between the sensor lines. The exponential drop-off in intensities with growing distance enables software to detect touch events, but does not reveal true contact areas. In this paper, we introduce CapContact, a novel method to precisely infer the contact area between the user’s finger and the surface from a single capacitive image. At 8 \texttimes{} super-resolution, our convolutional neural network generates refined touch masks from 16-bit capacitive images as input, which can even discriminate adjacent touches that are not distinguishable with existing methods. We trained and evaluated our method using supervised learning on data from 10 participants who performed touch gestures. Our capture apparatus integrates optical touch sensing to obtain ground-truth contact through high-resolution frustrated total internal reflection. We compare our method with a baseline using bicubic upsampling as well as the ground truth from FTIR images. We separately evaluate our method’s performance in discriminating adjacent touches. CapContact successfully separated closely adjacent touch contacts in 494 of 570 cases (87%) compared to the baseline’s 43 of 570 cases (8%). Importantly, we demonstrate that our method accurately performs even at half of the sensing resolution at twice the grid-line pitch across the same surface area, challenging the current industry-wide standard of a ∼ 4&nbsp;mm sensing pitch. We conclude this paper with implications for capacitive touch sensing in general and for touch-input accuracy in particular.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {289},
numpages = {14},
keywords = {Capacitive sensing, Generative adversarial networks;, Touch input, Accuracy, Contact area, Super-resolution},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445616,
author = {Tahaei, Mohammad and Vaniea, Kami and Beznosov, Konstantin (Kosta) and Wolters, Maria K},
title = {Security Notifications in Static Analysis Tools: Developers’ Attitudes, Comprehension, and Ability to Act on Them},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445616},
doi = {10.1145/3411764.3445616},
abstract = {Static analysis tools (SATs) have the potential to assist developers in finding and fixing vulnerabilities in the early stages of software development, requiring them to be able to understand and act on tools’ notifications. To understand how helpful such SAT guidance is to developers, we ran an online experiment (N=132) where participants were shown four vulnerable code samples (SQL injection, hard-coded credentials, encryption, and logging sensitive data) along with SAT guidance, and asked to indicate the appropriate fix. Participants had a positive attitude towards both SAT notifications and particularly liked the example solutions and vulnerable code. Seeing SAT notifications also led to more detailed open-ended answers and slightly improved code correction answers. Still, most SAT (SpotBugs 67%, SonarQube 86%) and Control (96%) participants answered at least one code-correction question incorrectly. Prior software development experience, perceived vulnerability severity, and answer confidence all positively impacted answer accuracy.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {691},
numpages = {17},
keywords = {software developers, usable security, static analysis tools, security notifications},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445615,
author = {Samrose, Samiha and McDuff, Daniel and Sim, Robert and Suh, Jina and Rowan, Kael and Hernandez, Javier and Rintel, Sean and Moynihan, Kevin and Czerwinski, Mary},
title = {MeetingCoach: An Intelligent Dashboard for Supporting Effective &amp; Inclusive Meetings},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445615},
doi = {10.1145/3411764.3445615},
abstract = {Video-conferencing is essential for many companies, but its limitations in conveying social cues can lead to ineffective meetings. We present MeetingCoach, an intelligent post-meeting feedback dashboard that summarizes contextual and behavioral meeting information. Through an exploratory survey&nbsp;(N=120), we identified important signals&nbsp;(e.g., turn taking, sentiment) and used these insights to create a wireframe dashboard. The design was evaluated with in situ participants&nbsp;(N=16) who helped identify the components they would prefer in a post-meeting dashboard. After recording video-conferencing meetings of eight teams over four weeks, we developed an AI system to quantify the meeting features and created personalized dashboards for each participant. Through interviews and surveys&nbsp;(N=23), we found that reviewing the dashboard helped improve attendees’ awareness of meeting dynamics, with implications for improved effectiveness and inclusivity. Based on our findings, we provide suggestions for future feedback system designs of video-conferencing meetings.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {252},
numpages = {13},
keywords = {meeting, group, sensing, feedback, video-conferencing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445613,
author = {Muthukumarana, Sachith and Messerschmidt, Moritz Alexander and Matthies, Denys J.C. and Steimle, J\"{u}rgen and Scholl, Philipp M. and Nanayakkara, Suranga},
title = {ClothTiles: A Prototyping Platform to Fabricate Customized Actuators on Clothing Using 3D Printing and Shape-Memory Alloys},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445613},
doi = {10.1145/3411764.3445613},
abstract = {Emerging research has demonstrated the viability of on-textile actuation mechanisms, however, an easily customizable and versatile on-cloth actuation mechanism is yet to be explored. In this paper, we present ClothTiles along with its rapid fabrication technique that enables actuation of clothes. ClothTiles leverage flexible 3D-printing and Shape-Memory Alloys (SMAs) alongside new parametric actuation designs. We validate the concept of fabric actuation using a base element, and then systematically explore methods of aggregating, scaling, and orienting prospects for extended actuation in garments. A user study demonstrated that our technique enables multiple actuation types applied across a variety of clothes. Users identified both aesthetic and functional applications of ClothTiles. We conclude with a number of insights for the Do-It-Yourself community on how to employ 3D-printing with SMAs to enable actuation on clothes.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {510},
numpages = {12},
keywords = {Textile, Do-It-Yourself, Smart Textiles, Clothing, Shape-memory Alloy, Actuation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445610,
author = {Mathur, Arunesh and Kshirsagar, Mihir and Mayer, Jonathan},
title = {What Makes a Dark Pattern... Dark? Design Attributes, Normative Considerations, and Measurement Methods},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445610},
doi = {10.1145/3411764.3445610},
abstract = {There is a rapidly growing literature on dark patterns, user interface designs—typically related to shopping or privacy—that researchers deem problematic. Recent work has been predominantly descriptive, documenting and categorizing objectionable user interfaces. These contributions have been invaluable in highlighting specific designs for researchers and policymakers. But the current literature lacks a conceptual foundation: What makes a user interface a dark pattern? Why are certain designs problematic for users or society? We review recent work on dark patterns and demonstrate that the literature does not reflect a singular concern or consistent definition, but rather, a set of thematically related considerations. Drawing from scholarship in psychology, economics, ethics, philosophy, and law, we articulate a set of normative perspectives for analyzing dark patterns and their effects on individuals and society. We then show how future research on dark patterns can go beyond subjective criticism of user interface designs and apply empirical methods grounded in normative perspectives.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {360},
numpages = {18},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445598,
author = {Koshy, Vinay and Park, Joon Sung Sung and Cheng, Ti-Chung and Karahalios, Karrie},
title = {“We Just Use What They Give Us”: Understanding Passenger User Perspectives in Smart Homes},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445598},
doi = {10.1145/3411764.3445598},
abstract = {With a plethora of off-the-shelf smart home devices available commercially, people are increasingly taking a do-it-yourself approach to configuring their smart homes. While this allows for customization, users responsible for smart home configuration often end up with more control over the devices than other household members. This separates those who introduce new functionality to the smart home (pilot users) from those who do not (passenger users). To investigate the prevalence and impact of pilot-passenger user relationships, we conducted a Mechanical Turk survey and a series of one-hour interviews. Our results suggest that pilot-passenger relationships are common in multi-user households and shape how people form habits around devices. We find from interview data that smart homes reflect the values of their pilot users, making it harder for passenger users to incorporate their devices into daily life. We conclude the paper with design recommendations to improve passenger and pilot user experience.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {41},
numpages = {14},
keywords = {smart homes, passenger users, internet of things, mixed-methods study, user experience, domestication theory, pilot users},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445592,
author = {M\'{a}rquez Segura, Elena and Rogers, Katja and Martin-Niedecken, Anna Lisa and Niedecken, Stephan and Vidal, Laia Turmo},
title = {Exploring the Design Space of Immersive Social Fitness Games: The ImSoFit Games Model},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445592},
doi = {10.1145/3411764.3445592},
abstract = {The design space of social exergames remains narrow despite the many benefits of playing and exercising together. Towards opening this design space, we followed a Research through Design (RtD) approach focused on exergames that can be fun and immersive social training experiences. Through embodied sketching activities with designers and 10 pairs of players, we explored future games for the ExerCube, an immersive exergame platform. Our work contributes with forms of intermediate-level knowledge: a design space model (the Immersive Social Fitness—ImSoFit—Games model); and a novel design vocabulary including new bodily orientations in co-located physical interaction. We illustrate their use and value scrutinizing three of our games and applying three analytical lenses to 1) understand how design choices impact how players move together; 2) evaluate design expectations and analyze players’ behavior in relation to design choices; and 3) potentially extend the design space of immersive co-located social fitness games.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {14},
keywords = {social immersion, design space, exergame, fitness game, multiplayer, mixed reality, embodied sketching},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445590,
author = {To, Alexandra and Carey, Hillary and Kaufman, Geoff and Hammer, Jessica},
title = {Reducing Uncertainty and Offering Comfort: Designing Technology for Coping with Interpersonal Racism},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445590},
doi = {10.1145/3411764.3445590},
abstract = {Ranging from subtle to overt, unintentional to systemic, navigating racism is additional everyday work for many people. Yet the needs of people who experience racism have been overlooked as a fertile ground for better technology. Through a series of workshops we call Foundational Fiction, we engaged BIPOC (Black, Indigenous, People of Color) in participatory design to identify qualities of technology that can support people coping before, during, and after a racist interaction. Participants developed storyboards for digital tools that offer advice, predict consequences, identify racist remarks and intervene, educate both targets and perpetrators about interpersonal and systemic racism, and more. In the paper we present our workshop method utilizing interactive fiction, participants’ design concepts, prevalent themes (reducing uncertainty and offering comfort), and we provide critical analysis of the complexity of technology in these contexts. This work identifies specific opportunities for exploring anti-racist social tools.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {398},
numpages = {17},
keywords = {microaggressions, uncertainty, participatory design, racism, design workshops, interactive fiction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445587,
author = {Kirchner, Susanne and Schroeder, Jessica and Fogarty, James and Munson, Sean A.},
title = {“They Don’t Always Think about That”: Translational Needs in the Design of Personal Health Informatics Applications},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445587},
doi = {10.1145/3411764.3445587},
abstract = {Personal health informatics continues to grow in both research and practice, revealing many challenges of designing applications that address people’s needs in their health, everyday lives, and collaborations with clinicians. Research suggests strategies to address such challenges, but has struggled to translate these strategies into design practice. This study examines translation of insights from personal health informatics research into resources to support designers. Informed by a review of relevant literature, we present our development of a prototype set of design cards intended to support designers in re-thinking potential assumptions about personal health informatics. We examined our design cards in semi-structured interviews, first with 12 student designers and then with 12 health-focused professional designers and researchers. Our results and discussion reveal tensions and barriers designers encounter, the potential for translational resources to inform the design of health-related technologies, and a need to support designers in addressing challenges of knowledge, advocacy, and evidence in designing for health.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {210},
numpages = {16},
keywords = {Health Design, Translational Research, Personal Health Informatics},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445575,
author = {Currano, Rebecca and Park, So Yeon and Moore, Dylan James and Lyons, Kent and Sirkin, David},
title = {Little Road Driving HUD: Heads-Up Display Complexity Influences Drivers’ Perceptions of Automated Vehicles},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445575},
doi = {10.1145/3411764.3445575},
abstract = {Modern vehicles are using AI and increasingly sophisticated sensor suites to improve Advanced Driving Assistance Systems (ADAS) and support automated driving capabilities. Heads-Up-Displays (HUDs) provide an opportunity to visually inform drivers about vehicle perception and interpretation of the driving environment. One approach to HUD design may be to reveal to drivers the vehicle’s full contextual understanding, though it is not clear if the benefits of additional information outweigh the drawbacks of added complexity, or if this balance holds across drivers. We designed and tested an Augmented Reality (AR) HUD in an online study (N = 298), focusing on the influence of HUD visualizations on drivers’ situation awareness and perceptions. Participants viewed two driving scenes with one of three HUD conditions. Results were nuanced: situation awareness declined with increasing driving context complexity, and contrary to expectation, also declined with the presence of a HUD compared to no HUD. Significant differences were found by varying HUD complexity, which led us to explore different characterizations of complexity, including counts of scene items, item categories, and illuminated pixels. Our analysis finds that driving style interacts with driving context and HUD complexity, warranting further study.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {511},
numpages = {15},
keywords = {heads-up-display, situation awareness, augmented reality, vehicle interface, interaction design, user interface},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445563,
author = {Pakdamanian, Erfan and Sheng, Shili and Baee, Sonia and Heo, Seongkook and Kraus, Sarit and Feng, Lu},
title = {DeepTake: Prediction of Driver Takeover Behavior Using Multimodal Data},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445563},
doi = {10.1145/3411764.3445563},
abstract = {Automated vehicles promise a future where drivers can engage in non-driving tasks without hands on the steering wheels for a prolonged period. Nevertheless, automated vehicles may still need to occasionally hand the control back to drivers due to technology limitations and legal requirements. While some systems determine the need for driver takeover using driver context and road condition to initiate a takeover request, studies show that the driver may not react to it. We present DeepTake, a novel deep neural network-based framework that predicts multiple aspects of takeover behavior to ensure that the driver is able to safely take over the control when engaged in non-driving tasks. Using features from vehicle data, driver biometrics, and subjective measurements, DeepTake predicts the driver’s intention, time, and quality of takeover. We evaluate DeepTake performance using multiple evaluation metrics. Results show that DeepTake reliably predicts the takeover intention, time, and quality, with an accuracy of 96%, 93%, and 83%, respectively. Results also indicate that DeepTake outperforms previous state-of-the-art methods on predicting driver takeover time and quality. Our findings have implications for the algorithm development of driver monitoring and state detection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {103},
numpages = {14},
keywords = {Takeover behavior, Multimodal data, Automated driving, Deep neural networks, Human-automation interaction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445561,
author = {Park, Soomi and Healey, Patrick G. T. and Kaniadakis, Antonios},
title = {Should Robots Blush?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445561},
doi = {10.1145/3411764.3445561},
abstract = {Social interaction is the most complex challenge in daily life. Inevitably, social robots will encounter interactions that are outside their competence. This raises a basic design question: how can robots fail gracefully in social interaction? The characteristic human response to social failure is embarrassment. Usefully, embarrassment signals both recognition of a problem and typically enlists sympathy and assistance to resolve it. This could enhance robot acceptability and provides an opportunity for interactive learning. Using a speculative design approach we explore how, when and why robots might communicate embarrassment. A series of specially developed cultural probes, scenario development and low-fidelity prototyping exercises suggest that: embarrassment is relevant for managing a diverse range of social scenarios, impacts on both humanoid and non-humanoid robot design, and highlights the critical importance of understanding interactional context. We conclude that embarrassment is fundamental to competent social functioning and provides a potentially fertile area for interaction design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {717},
numpages = {14},
keywords = {Speculative Design, Human-Robot Interactions, Embarrassment, Design Workshop, Symbolic Interactionism, Cultural Probes, Affective Robotics},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445557,
author = {Robertson, Ronald E and Olteanu, Alexandra and Diaz, Fernando and Shokouhi, Milad and Bailey, Peter},
title = {“I Can’t Reply with That”: Characterizing Problematic Email Reply Suggestions},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445557},
doi = {10.1145/3411764.3445557},
abstract = {In email interfaces, providing users with reply suggestions may simplify or accelerate correspondence. While the “success” of such systems is typically quantified using the number of suggestions selected by users, this ignores the impact of social context, which can change how suggestions are perceived. To address this, we developed a mixed-methods framework involving qualitative interviews and crowdsourced experiments to characterize problematic email reply suggestions. Our interviews revealed issues with over-positive, dissonant, cultural, and gender-assuming replies, as well as contextual politeness. In our experiments, crowdworkers assessed email scenarios that we generated and systematically controlled, showing that contextual factors like social ties and the presence of salutations impacts users’ perceptions of email correspondence. These assessments created a novel dataset of human-authored corrections for problematic email replies. Our study highlights the social complexity of providing suggestions for email correspondence, raising issues that may apply to all social messaging systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {724},
numpages = {18},
keywords = {smart compose, algorithm auditing, smart reply, AI-assisted writing, email, CMC, AI-MC},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445540,
author = {Carstensdottir, Elin and Kleinman, Erica and Williams, Ryan and Seif El-Nasr, Magy Seif},
title = {”Naked and on Fire”: Examining Player Agency Experiences in Narrative-Focused Gameplay},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445540},
doi = {10.1145/3411764.3445540},
abstract = {Player agency is central to interactive narrative and games. While previous work focuses on analyzing player perception of agency through various lenses and phenomena, like meaningful choice and expectations, it is largely theoretical. Few user studies within games explore how players reason about and judge their own agency within interactive narratives. We present an interview study where participants rated their agency experiences within narrative-focused games and described their reasoning. The analysis suggests that agency perception depends on multiple factors beyond meaningful choice, such as social investment and genre-conventions. Participants described varying preferences and value judgements for different factors, indicating that individual differences have a deep impact on agency perception in narrative-focused gameplay. We discuss the implications of these cognitive variables on design, how they can be leveraged with other factors, and how our findings can help future work enhance and measure player agency, within interactive narrative and beyond.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {121},
numpages = {13},
keywords = {user experience, player experience, interactive narrative, storytelling, video games, player agency},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445537,
author = {Li, Nianlong and Zhang, Zhengquan and Liu, Can and Yang, Zengyao and Fu, Yinan and Tian, Feng and Han, Teng and Fan, Mingming},
title = {VMirror: Enhancing the Interaction with Occluded or Distant Objects in VR with Virtual Mirrors},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445537},
doi = {10.1145/3411764.3445537},
abstract = {Interacting with out of reach or occluded VR objects can be cumbersome. Although users can change their position and orientation, such as via teleporting, to help observe and select, doing so frequently may cause loss of spatial orientation or motion sickness. We present vMirror, an interactive widget leveraging reflection of mirrors to observe and select distant or occluded objects. We first designed interaction techniques for placing mirrors and interacting with objects through mirrors. We then conducted a formative study to explore a semi-automated mirror placement method with manual adjustments. Next, we conducted a target-selection experiment to measure the effect of the mirror’s orientation on users’ performance. Results showed that vMirror can be as efficient as direct target selection for most mirror orientations. We further compared vMirror with teleport technique in a virtual treasure hunt game and measured participants’ task performance and subjective experiences. Finally, we discuss vMirorr user experience and present future directions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {132},
numpages = {11},
keywords = {out of reach, Virtual mirror, occlusion, Virtual Reality, VR, DOF, vMirror, target selection, raycasting},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445528,
author = {Liebers, Jonathan and Abdelaziz, Mark and Mecke, Lukas and Saad, Alia and Auda, Jonas and Gruenefeld, Uwe and Alt, Florian and Schneegass, Stefan},
title = {Understanding User Identification in Virtual Reality Through Behavioral Biometrics and the Effect of Body Normalization},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445528},
doi = {10.1145/3411764.3445528},
abstract = {Virtual Reality (VR) is becoming increasingly popular both in the entertainment and professional domains. Behavioral biometrics have recently been investigated as a means to continuously and implicitly identify users in VR. Applications in VR can specifically benefit from this, for example, to adapt virtual environments and user interfaces as well as to authenticate users. In this work, we conduct a lab study (N = 16) to explore how accurately users can be identified during two task-driven scenarios based on their spatial movement. We show that an identification accuracy of up to 90% is possible across sessions recorded on different days. Moreover, we investigate the role of users’ physiology in behavioral biometrics by virtually altering and normalizing their body proportions. We find that body normalization in general increases the identification rate, in some cases by up to 38%; hence, it improves the performance of identification systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {517},
numpages = {11},
keywords = {virtual reality, usable security, task-driven biometrics, identification},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445508,
author = {Zheng, Rebecca and Fern\'{a}ndez Camporro, Marina and Romat, Hugo and Henry Riche, Nathalie and Bach, Benjamin and Chevalier, Fanny and Hinckley, Ken and Marquardt, Nicolai},
title = {Sketchnote Components, Design Space Dimensions, and Strategies for Effective Visual Note Taking},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445508},
doi = {10.1145/3411764.3445508},
abstract = {Sketchnoting is a form of visual note taking where people listen to, synthesize, and visualize ideas from a talk or other event using a combination of pictures, diagrams, and text. Little is known about the design space of this kind of visual note taking. With an eye towards informing the implementation of digital equivalents of sketchnoting, inking, and note taking, we introduce a classification of sketchnote styles and techniques, with a qualitative analysis of 103 sketchnotes, and situated in context with six semi-structured follow up interviews. Our findings distill core sketchnote components (content, layout, structuring elements, and visual styling) and dimensions of the sketchnote design space, classifying levels of conciseness, illustration, structure, personification, cohesion, and craftsmanship. We unpack strategies to address particular note taking challenges, for example dealing with constraints of live drawings, and discuss relevance for future digital inking tools, such as recomposition, styling, and design suggestions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {466},
numpages = {15},
keywords = {taxonomy, visual note taking, digital ink, digital sketching, graphical styles, sketchnotes, classification, sketching},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445487,
author = {Xue, Tong and El Ali, Abdallah and Zhang, Tianyi and Ding, Gangyi and Cesar, Pablo},
title = {RCEA-360VR: Real-Time, Continuous Emotion Annotation in 360° VR Videos for Collecting Precise Viewport-Dependent Ground Truth Labels},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445487},
doi = {10.1145/3411764.3445487},
abstract = {Precise emotion ground truth labels for 360° virtual reality (VR) video watching are essential for fine-grained predictions under varying viewing behavior. However, current annotation techniques either rely on post-stimulus discrete self-reports, or real-time, continuous emotion annotations (RCEA) but only for desktop/mobile settings. We present RCEA for 360° VR videos (RCEA-360VR), where we evaluate in a controlled study (N=32) the usability of two peripheral visualization techniques: HaloLight and DotSize. We furthermore develop a method that considers head movements when fusing labels. Using physiological, behavioral, and subjective measures, we show that (1) both techniques do not increase users’ workload, sickness, nor break presence (2) our continuous valence and arousal annotations are consistent with discrete within-VR and original stimuli ratings (3) users exhibit high similarity in viewing behavior, where fused ratings perfectly align with intended labels. Our work contributes usable and effective techniques for collecting fine-grained viewport-dependent emotion labels in 360° VR.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {513},
numpages = {15},
keywords = {continuous, viewport-dependent, Emotion, virtual reality, real-time, 360° video, ground truth, labels, annotation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445469,
author = {Hong, Freddie and Myant, Connor and Boyle, David E},
title = {Thermoformed Circuit Boards: Fabrication of Highly Conductive Freeform 3D Printed Circuit Boards with Heat Bending},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445469},
doi = {10.1145/3411764.3445469},
abstract = {Fabricating 3D printed electronics using desktop printers has become more accessible with recent developments in conductive thermoplastic filaments. Because of their high resistance and difficulties in printing traces in vertical directions, most applications are restricted to capacitive sensing. In this paper, we introduce Thermoformed Circuit Board (TCB), a novel approach that employs the thermoformability of the 3D printed plastics to construct various double-sided, rigid and highly conductive freeform circuit boards that can withstand high current applications through copper electroplating. To illustrate the capability of the TCB, we showcase a range of examples with various shapes, electrical characteristics and interaction mechanisms. We also demonstrate a new design tool extension to an existing CAD environment that allows users to parametrically draw the substrate and conductive trace, and export 3D printable files. TCB is an inexpensive and highly accessible fabrication technique intended to broaden HCI researcher participation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {669},
numpages = {10},
keywords = {conductive filament, 3D printed electronics, hybrid additive manufacturing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445465,
author = {Reinhardt, Daniel and Borchard, Johannes and Hurtienne, J\"{o}rn},
title = {Visual Interactive Privacy Policy: The Better Choice?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445465},
doi = {10.1145/3411764.3445465},
abstract = {Online privacy policies should enable users to make informed decisions. Current text policies, however, lack usability: users often miss crucial information and consent to them without reading. Visual representation formats may increase comprehension, but are rarely used in practice. In an iterative design process we gathered qualitative feedback on typical policy contents and on existing and newly designed representation formats. We developed design guidelines and a Visual Interactive Privacy Policy based on the Privacy Policy Nutrition Label enriched with control options and further interactive elements. In an empirical evaluation, both visual representations received higher ratings of attractiveness, stimulation, novelty and transparency compared to a standard policy long text. Interactivity improved time spent with the policy. There were no effects on conversion rate, perceived control or perceived trust, efficiency and perspicuity. More research is needed, especially with regard to the cost-benefit ratio of visual privacy policies.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {66},
numpages = {12},
keywords = {Privacy Policy Nutrition Label, Privacy Policy, Privacy},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445460,
author = {Saquib, Nazmus and Kazi, Rubaiat Habib and Wei, Li-yi and Mark, Gloria and Roy, Deb},
title = {Constructing Embodied Algebra by Sketching},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445460},
doi = {10.1145/3411764.3445460},
abstract = {Mathematical models and expressions traditionally evolved as symbolic representations, with cognitively arbitrary rules of symbol manipulation. The embodied mathematics philosophy posits that abstract math concepts are layers of metaphors grounded in our intuitive arithmetic capabilities, such as categorizing objects and part-whole analysis. We introduce a design framework that facilitates the construction and exploration of embodied representations for algebraic expressions, using interactions inspired by innate arithmetic capabilities. We instantiated our design in a sketch interface that enables construction of visually interpretable compositions that are directly mappable to algebraic expressions and explorable through a ladder of abstraction [47]. The emphasis is on bottom-up construction, with the user sketching pictures while the system generates corresponding algebra. We present diverse examples created by our prototype system. A coverage of the US Common Core curriculum and playtesting studies with children point to the future direction and potential for a sketch-based design paradigm for mathematics.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {428},
numpages = {16},
keywords = {sketching, embodied cognition, embodied math, math modeling},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445458,
author = {Subramanian, Krishna and Maas, Johannes and Borchers, Jan and Hollan, James},
title = {From Detectables to Inspectables: Understanding Qualitative Analysis of Audiovisual Data},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445458},
doi = {10.1145/3411764.3445458},
abstract = {Audiovisual recordings of user studies and interviews provide important data in qualitative HCI research. Even when a textual transcription is available, researchers frequently turn to these recordings due to their rich information content. However, the temporal, unstructured nature of audiovisual recordings makes them less efficient to work with than text. Through interviews and a survey, we explored how HCI researchers work with audiovisual recordings. We investigated researchers’ transcription and annotation practice, their overall analysis workflow, and the prevalence of direct analysis of audiovisual recordings. We found that a key task was locating and analyzing inspectables, interesting segments in recordings. Since locating inspectables can be time consuming, participants look for detectables, visual or auditory cues that indicate the presence of an inspectable. Based on our findings, we discuss the potential for automation in locating detectables in qualitative audiovisual analysis.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {518},
numpages = {10},
keywords = {information behavior, researchers, Video analysis, qualitative research},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445442,
author = {Kim, Daehwa and Park, Keunwoo and Lee, Geehyuk},
title = {AtaTouch: Robust Finger Pinch Detection for a VR Controller Using RF Return Loss},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445442},
doi = {10.1145/3411764.3445442},
abstract = {Handheld controllers are an essential part of VR systems. Modern sensing techniques enable them to track users’ finger movements to support natural interaction using hands. The sensing techniques, however, often fail to precisely determine whether two fingertips touch each other, which is important for the robust detection of a pinch gesture. To address this problem, we propose AtaTouch, which is a novel, robust sensing technique for detecting the closure of a finger pinch. It utilizes a change in the coupled impedance of an antenna and human fingers when the thumb and finger form a loop. We implemented a prototype controller in which AtaTouch detects the finger pinch of the grabbing hand. A user test with the prototype showed a finger-touch detection accuracy of 96.4%. Another user test with the scenarios of moving virtual blocks demonstrated low object-drop rate (2.75%) and false-pinch rate (4.40%). The results and feedback from the participants support the robustness and sensitivity of AtaTouch.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {11},
numpages = {9},
keywords = {Antenna, Virtual Reality (VR), Touch segmentation, RF Sensing, Hand gesture},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445441,
author = {Chen, Yuxin and Yang, Zhuolin and Abbou, Ruben and Lopes, Pedro and Zhao, Ben Y. and Zheng, Haitao},
title = {User Authentication via Electrical Muscle Stimulation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445441},
doi = {10.1145/3411764.3445441},
abstract = {We propose a novel modality for active biometric authentication: electrical muscle stimulation (EMS). To explore this, we engineered an interactive system, which we call ElectricAuth, that stimulates the user’s forearm muscles with a sequence of electrical impulses (i.e., EMS challenge) and measures the user’s involuntary finger movements (i.e., response to the challenge). ElectricAuth leverages EMS’s intersubject variability, where the same electrical stimulation results in different movements in different users because everybody’s physiology is unique (e.g., differences in bone and muscular structure, skin resistance and composition, etc.). As such, ElectricAuth allows users to login without memorizing passwords or PINs. ElectricAuth’s challenge-response structure makes it secure against data breaches and replay attacks, a major vulnerability facing today’s biometrics such as facial recognition and fingerprints. Furthermore, ElectricAuth never reuses the same challenge twice in authentications – in just one second of stimulation it encodes one of 68M possible challenges. In our user studies, we found that ElectricAuth resists: (1) impersonation attacks (false acceptance rate: 0.17% at 5% false rejection rate); (2) replay attacks (false acceptance rate: 0.00% at 5% false rejection rate); and, (3) synthesis attacks (false acceptance rates: 0.2-2.5%). Our longitudinal study also shows that ElectricAuth produces consistent results over time and across different humidity and muscle conditions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {6},
numpages = {15},
keywords = {electrical muscle stimulation, biometric authentication, wearable},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445432,
author = {Wang, Dakuo and Wang, Liuping and Zhang, Zhan and Wang, Ding and Zhu, Haiyi and Gao, Yvonne and Fan, Xiangmin and Tian, Feng},
title = {“Brilliant AI Doctor” in Rural Clinics: Challenges in AI-Powered Clinical Decision Support System Deployment},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445432},
doi = {10.1145/3411764.3445432},
abstract = {Artificial intelligence (AI) technology has been increasingly used in the implementation of advanced Clinical Decision Support Systems (CDSS). Research demonstrated the potential usefulness of AI-powered CDSS (AI-CDSS) in clinical decision making scenarios. However, post-adoption user perception and experience remain understudied, especially in developing countries. Through observations and interviews with 22 clinicians from 6 rural clinics in China, this paper reports the various tensions between the design of an AI-CDSS system (“Brilliant Doctor”) and the rural clinical context, such as the misalignment with local context and workflow, the technical limitations and usability barriers, as well as issues related to transparency and trustworthiness of AI-CDSS. Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as “a doctor’s AI assistant” to realize a Human-AI Collaboration future in clinical settings. Finally we draw on our findings to discuss implications for designing AI-CDSS interventions for rural clinical contexts in developing countries.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {697},
numpages = {18},
keywords = {AI, Future of Work, Human AI Interaction, China, Collaborative AI, CDSS, Human AI Collaboration, Clinical Decision Making, AI Deployment, Workflow, Developing Country, Rural Clinic, Decision Making, Trust AI, Implementation, Healthcare},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445407,
author = {Voskobojnikov, Artemij and Wiese, Oliver and Mehrabi Koushki, Masoud and Roth, Volker and Beznosov, Konstantin (Kosta)},
title = {The U in Crypto Stands for Usable: An Empirical Study of User Experience with Mobile Cryptocurrency Wallets},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445407},
doi = {10.1145/3411764.3445407},
abstract = {In a corpus of 45,821 app reviews of the top five mobile cryptocurrency wallets, we identified and qualitatively analyzed 6,859 reviews pertaining to the user experience (UX) with those wallets. Our analysis suggests that both new and experienced users struggle with general and domain-specific UX issues that, aside from frustration and disengagement, might lead to dangerous errors and irreversible monetary losses. We reveal shortcomings of current wallet UX as well as users’ misconceptions, some of which can be traced back to a reliance on their understanding of conventional payment systems. For example, some users believed that transactions were free, reversible, and could be canceled anytime, which is not the case in reality. Correspondingly, these beliefs often resulted in unmet expectations. Based on our findings, we provide recommendations on how to design cryptocurrency wallets that both alleviate the identified issues and counteract some of the misconceptions in order to better support newcomers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {642},
numpages = {14},
keywords = {review analysis, thematic analysis, Cryptocurrency, natural language processing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445382,
author = {Nobre, Carolina and Wootton, Dylan and Cutler, Zach and Harrison, Lane and Pfister, Hanspeter and Lex, Alexander},
title = {ReVISit: Looking Under the Hood of Interactive Visualization Studies},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445382},
doi = {10.1145/3411764.3445382},
abstract = {Quantifying user performance with metrics such as time and accuracy does not show the whole picture when researchers evaluate complex, interactive visualization tools. In such systems, performance is often influenced by different analysis strategies that statistical analysis methods cannot account for. To remedy this lack of nuance, we propose a novel analysis methodology for evaluating complex interactive visualizations at scale. We implement our analysis methods in reVISit, which enables analysts to explore participant interaction performance metrics and responses in the context of users’ analysis strategies. Replays of participant sessions can aid in identifying usability problems during pilot studies and make individual analysis processes salient. To demonstrate the applicability of reVISit to visualization studies, we analyze participant data from two published crowdsourced studies. Our findings show that reVISit can be used to reveal and describe novel interaction patterns, to analyze performance differences between different analysis strategies, and to validate or challenge design decisions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {25},
numpages = {13},
keywords = {Visualization, event sequences., user studies, evaluation methodology, provenance},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445366,
author = {Lam, Kevin C. and Gutwin, Carl and Klarkowski, Madison and Cockburn, Andy},
title = {The Effects of System Interpretation Errors on Learning New Input Mechanisms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445366},
doi = {10.1145/3411764.3445366},
abstract = {Input mechanisms can produce noisy signals that computers must interpret, and this interpretation can misconstrue the user’s intention. Researchers have studied how interpretation errors can affect users’ task performance, but little is known about how these errors affect learning, and whether they help or hinder the transition to expertise. Previous findings suggest that increasing the user’s attention can facilitate learning, so frequent interpretation errors may increase attention and learning; alternatively, however, interpretation errors may negatively interfere with skill development. To explore these potentially important effects, we conducted studies where participants learned commands with various rates of artificially injected interpretation errors. Our results showed that higher rates of interpretation error led to worse memory retention, higher completion times, higher occurrences of user error (beyond those injected by the system), and greater perceived effort. These findings indicate that when input mechanisms must interpret the user’s input, interpretation errors cause problems for user learning.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {713},
numpages = {13},
keywords = {memory-based retrieval, input techniques, expertise development},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445361,
author = {Hirzle, Teresa and Cordts, Maurice and Rukzio, Enrico and Gugenheimer, Jan and Bulling, Andreas},
title = {A Critical Assessment of the Use of SSQ as a Measure of General Discomfort in VR Head-Mounted Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445361},
doi = {10.1145/3411764.3445361},
abstract = {Based on a systematic literature review of more than 300 papers published over the last 10 years, we provide indicators that the simulator sickness questionnaire (SSQ) is extensively used and widely accepted as a general discomfort measure in virtual reality (VR) research – although it actually only accounts for one category of symptoms. This results in important other categories (digital eye strain (DES) and ergonomics) being largely neglected. To contribute to a more comprehensive picture of discomfort in VR head-mounted displays, we further conducted an online study (N=352) on the severity and relevance of all three symptom categories. Most importantly, our results reveal that symptoms of simulator sickness are significantly less severe and of lower prevalence than those of DES and ergonomics. In light of these findings, we critically discuss the current use of SSQ as the only discomfort measure and propose a more comprehensive factor model that also includes DES and ergonomics.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {530},
numpages = {14},
keywords = {virtual reality, simulator sickness, digital eye strain, SSQ, head-mounted displays, discomfort},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445359,
author = {Chen, Janet X. and Vitale, Francesco and McGrenere, Joanna},
title = {What Happens After Death? Using a Design Workbook to Understand User Expectations for Preparing Their Data},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445359},
doi = {10.1145/3411764.3445359},
abstract = {Digital data has become a key part of everyday life: people manage increasingly large and disparate collections of photos, documents, media, etc. But what happens after death? How can users select and prepare what data to leave behind before their eventual death? To explore how to support users, we first ran an ideation workshop to generate design ideas; then, we created a design workbook with 12 speculative concepts that explore diverging approaches and perspectives. We elicited reactions to the concepts from 20 participants (18-81, varied occupations). We found that participants anticipated different types of motivation at different life stages, wished for tools to feel personal and intimate, and preferred individual control on their post-death self-representation. They also found comprehensive data replicas creepy and saw smart assistants as potential aides for suggesting meaningful data. Based on the results, we discuss key directions for designing more personalized and respectful death-preparation tools.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {169},
numpages = {13},
keywords = {data management, design, Death, design workbook, digital legacy},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445326,
author = {Zhong, Mingyuan and Li, Gang and Li, Yang},
title = {Spacewalker: Rapid UI Design Exploration Using Lightweight Markup Enhancement and Crowd Genetic Programming},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445326},
doi = {10.1145/3411764.3445326},
abstract = {User interface design is a complex task that involves designers examining a wide range of options. We present Spacewalker, a tool that allows designers to rapidly search a large design space for an optimal web UI with integrated support. Designers first annotate each attribute they want to explore in a typical HTML page, using a simple markup extension we designed. Spacewalker then parses the annotated HTML specification, and intelligently generates and distributes various configurations of the web UI to crowd workers for evaluation. We enhanced a genetic algorithm to accommodate crowd worker responses from pairwise comparison of UI designs, which is crucial for obtaining reliable feedback. Based on our experiments, Spacewalker allows designers to effectively search a large design space of a UI, using the language they are familiar with, and improve their design rapidly at a minimal cost.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {315},
numpages = {11},
keywords = {design search, Markup language, genetic programming, crowdsourcing, tools},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445311,
author = {Sun, Lingyun and Li, Jiaji and Chen, Yu and Yang, Yue and Yu, Zhi and Luo, Danli and Gu, Jianzhe and Yao, Lining and Tao, Ye and Wang, Guanyun},
title = {FlexTruss: A Computational Threading Method for Multi-Material, Multi-Form and Multi-Use Prototyping},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445311},
doi = {10.1145/3411764.3445311},
abstract = {3D printing, as a rapid prototyping technique, usually fabricates objects that are difficult to modify physically. This paper presents FlexTruss, a design and construction pipeline based on the assembly of modularized truss-shaped objects fabricated with conventional 3D printers and assembled by threading. To create an end-to-end system, a parametric design tool with an optimal Euler path calculation method is developed, which can support both inverse and forward design workflow and multi-material construction of modular parts. In addition, the assembly of truss modules by threading is evaluated with a series of application cases to demonstrate the affordance of FlexTruss. We believe that FlexTruss extends the design space of 3D printing beyond typically hard and fixed forms, and it will provide new capabilities for designers and researchers to explore the use of such flexible truss structures in human-object interaction.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {432},
numpages = {12},
keywords = {Euler path, Personal fabrication, 3D printing, Mesh structures, Shape-changing interfaces},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445302,
author = {Jiang, Ying and Zhang, Congyi and Fu, Hongbo and Cannav\`{o}, Alberto and Lamberti, Fabrizio and Lau, Henry Y K and Wang, Wenping},
title = {HandPainter - 3D Sketching in VR with Hand-Based Physical Proxy},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445302},
doi = {10.1145/3411764.3445302},
abstract = {3D sketching in virtual reality (VR) enables users to create 3D virtual objects intuitively and immersively. However, previous studies showed that mid-air drawing may lead to inaccurate sketches. To address this issue, we propose to use one hand as a canvas proxy and the index finger of the other hand as a 3D pen. To this end, we first perform a formative study to compare two-handed interaction with tablet-pen interaction for VR sketching. Based on the findings of this study, we design HandPainter, a VR sketching system which focuses on the direct use of two hands for 3D sketching without requesting any tablet, pen, or VR controller. Our implementation is based on a pair of VR gloves, which provide hand tracking and gesture capture. We devise a set of intuitive gestures to control various functionalities required during 3D sketching, such as canvas panning and drawing positioning. We show the effectiveness of HandPainter by presenting a number of sketching results and discussing the outcomes of a user study-based comparison with mid-air drawing and tablet-based sketching tools.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {412},
numpages = {13},
keywords = {3D sketching, VR, hand-based interaction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445301,
author = {Eun Song, Ji and You, Jaeyoun and Lee, Joongseek},
title = {“I Might Be Using His… But It is Also Mine!”: Ownership and Control in Accounts Designed for Sharing},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445301},
doi = {10.1145/3411764.3445301},
abstract = {A user's ownership perception of virtual objects, such as cloud files, is generally uncertain. Is this valid for streaming platforms featuring accounts designed for sharing (DS)? We observe sharing practices within DS accounts of streaming platforms and identify their ownership characteristics and unexpected complications through two mixed-method studies. Casual and Cost-splitting are the two sharing practices identified. The owner is the sole payer for the account in the former, whereas profile holders split the cost in the latter. We distinguish two types of ownership in each practice—Primary and Dual. In Primary ownership, the account owner has the power to allow others to use the account; in Dual ownership, Primary ownership appears in conjunction with joint ownership, notably displaying asymmetric ownership perceptions among users. Conflicts arise when the sharing agreements collapse. Therefore, we propose design recommendations that bridge ownership differences based on sharing practices of DS accounts.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {178},
numpages = {13},
keywords = {multiple profile, account sharing, control, DS accounts, shared ownership},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445297,
author = {Ahn, Sunggeun and Santosa, Stephanie and Parent, Mark and Wigdor, Daniel and Grossman, Tovi and Giordano, Marcello},
title = {StickyPie: A Gaze-Based, Scale-Invariant Marking Menu Optimized for AR/VR},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445297},
doi = {10.1145/3411764.3445297},
abstract = {This work explores the design of marking menus for gaze-based AR/VR menu selection by expert and novice users. It first identifies and explains the challenges inherent in ocular motor control and current eye tracking hardware, including overshooting, incorrect selections, and false activations. Through three empirical studies, we optimized and validated design parameters to mitigate these errors while reducing completion time, task load, and eye fatigue. Based on the findings from these studies, we derived a set of design guidelines to support gaze-based marking menus in AR/VR. To overcome the overshoot errors found with eye-based expert marking menu behaviour, we developed StickyPie, a marking menu technique that enables scale-independent marking input by estimating saccade landing positions. An evaluation of StickyPie revealed that StickyPie was easier to learn than the traditional technique (i.e., RegularPie) and was 10% more efficient after 3 sessions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {739},
numpages = {16},
keywords = {eye gaze input, AR/VR, marking menu, head-worn display},
location = {Yokohama, Japan},
series = {CHI '21}
}

