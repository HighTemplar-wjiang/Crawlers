@inproceedings{10.1145/3411764.3445555,
author = {G. Mitchell, Elliot and M. Heitkemper, Elizabeth and Burgermaster, Marissa and E. Levine, Matthew and Miao, Yishen and L. Hwang, Maria and M. Desai, Pooja and Cassells, Andrea and N. Tobin, Jonathan and G. Tabak, Esteban and J. Albers, David and M. Smaldone, Arlene and Mamykina, Lena},
title = {From Reflection to Action: Combining Machine Learning with Expert Knowledge for Nutrition Goal Recommendations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445555},
doi = {10.1145/3411764.3445555},
abstract = {Self-tracking can help personalize self-management interventions for chronic conditions like type 2 diabetes (T2D), but reflecting on personal data requires motivation and literacy. Machine learning (ML) methods can identify patterns, but a key challenge is making actionable suggestions based on personal health data. We introduce GlucoGoalie, which combines ML with an expert system to translate ML output into personalized nutrition goal suggestions for individuals with T2D. In a controlled experiment, participants with T2D found that goal suggestions were understandable and actionable. A 4-week in-the-wild deployment study showed that receiving goal suggestions augmented participants’ self-discovery, choosing goals highlighted the multifaceted nature of personal preferences, and the experience of following goals demonstrated the importance of feedback and context. However, we identified tensions between abstract goals and concrete eating experiences and found static text too ambiguous for complex concepts. We discuss implications for ML-based interventions and the need for systems that offer more interactivity, feedback, and negotiation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {206},
numpages = {17},
keywords = {Machine learning, Diabetes self-management, Personal Informatics, Goal setting},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445544,
author = {Sampath, Harini and Merrick, Alice and Macvean, Andrew},
title = {Accessibility of Command Line Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445544},
doi = {10.1145/3411764.3445544},
abstract = {Command-line interfaces (CLIs) remain a popular tool among developers and system administrators. Since CLIs are text-based interfaces, they are sometimes considered accessible alternatives to predominantly visual developer tools like IDEs. However, there is no systematic evaluation of the accessibility of CLIs in the literature. In this paper, we describe two studies with 12 developers on their experience of using CLIs with screen readers. Our findings show that CLIs have their own set of accessibility issues - the most important being CLIs are unstructured text interfaces. Based on our results, we provide a set of recommendations for improving the accessibility of command-line interfaces.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {489},
numpages = {10},
keywords = {command-line interfaces, developers with visual impairments, accessibility, screen reader users},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445543,
author = {Mazursky, Alex and Teng, Shan-Yuan and Nith, Romain and Lopes, Pedro},
title = {MagnetIO: Passive yet Interactive Soft Haptic Patches Anywhere},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445543},
doi = {10.1145/3411764.3445543},
abstract = {We propose a new type of haptic actuator, which we call MagnetIO, that is comprised of two parts: one battery-powered voice-coil worn on the user's fingernail and any number of interactive soft patches that can be attached onto any surface (everyday objects, user's body, appliances, etc.). When the user's finger wearing our voice-coil contacts any of the interactive patches it detects its magnetic signature via magnetometer and vibrates the patch, adding haptic feedback to otherwise input-only interactions. To allow these passive patches to vibrate, we make them from silicone with regions doped with polarized neodymium powder, resulting in soft and stretchable magnets. This stretchable form-factor allows them to be wrapped to the user's body or everyday objects of various shapes. We demonstrate how these add haptic output to many situations, such as adding haptic buttons to the walls of one's home. In our technical evaluation, we demonstrate that our interactive patches can be excited across a wide range of frequencies (0-500 Hz) and can be tuned to resonate at specific frequencies based on the patch's geometry. Furthermore, we demonstrate that MagnetIO's vibration intensity is as powerful as a typical linear resonant actuator (LRA); yet, unlike these rigid actuators, our passive patches operate as springs with multiple modes of vibration, which enables a wider band around its resonant frequency than an equivalent LRA.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {213},
numpages = {15},
keywords = {ubiquitous haptics, fabrication, soft magnets},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445542,
author = {Esterwood, Connor and Essenmacher, Kyle and Yang, Han and Zeng, Fanpan and Robert, Lionel Peter},
title = {A Meta-Analysis of Human Personality and Robot Acceptance in Human-Robot Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445542},
doi = {10.1145/3411764.3445542},
abstract = {Human personality has been identified as a predictor of robot acceptance in the human–robot interaction (HRI) literature. Despite this, the HRI literature has provided mixed support for this assertion. To better understand the relationship between human personality and robot acceptance, this paper conducts a meta-analysis of 26 studies. Results found a positive relationship between human personality and robot acceptance. However, this relationship varied greatly by the specific personality trait along with the study sample’s age, gender diversity, task, and global region. This meta-analysis also identified gaps in the literature. Namely, additional studies are needed that investigate both the big five personality traits and other personality traits, examine a more diverse age range, and utilize samples from previously unexamined regions of the globe.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {711},
numpages = {18},
keywords = {Robot Acceptance, Human-Robot Interaction, Personality, Adaptability, HRI, Trust, Social Presence, Meta-Analysis, Enjoyment, Sociability, Individual Differences, Anxiety},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445526,
author = {Wang, Dakuo and Andres, Josh and Weisz, Justin D. and Oduor, Erick and Dugan, Casey},
title = {AutoDS: Towards Human-Centered Automation of Data Science},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445526},
doi = {10.1145/3411764.3445526},
abstract = {Data science (DS) projects often follow a lifecycle that consists of laborious tasks for data scientists and domain experts (e.g., data exploration, model training, etc.). Only till recently, machine learning(ML) researchers have developed promising automation techniques to aid data workers in these tasks. This paper introduces AutoDS, an automated machine learning (AutoML) system that aims to leverage the latest ML automation techniques to support data science projects. Data workers only need to upload their dataset, then the system can automatically suggest ML configurations, preprocess data, select algorithm, and train the model. These suggestions are presented to the user via a web-based graphical user interface and a notebook-based programming user interface. Our goal is to offer a systematic investigation of user interaction and perceptions of using an AutoDS system in solving a data science task. We studied AutoDS with 30 professional data scientists, where one group used AutoDS, and the other did not, to complete a data science project. As expected, AutoDS improves productivity; Yet surprisingly, we find that the models produced by the AutoDS group have higher quality and less errors, but lower human confidence scores. We reflect on the findings by presenting design implications for incorporating automation techniques into human work in the data science lifecycle.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {79},
numpages = {12},
keywords = {automated machine learning, XAI, AutoDS, human-AI collaboration, model building, Data science, automated data science, AI, collaborative AI, human-in-the-loop, AutoML},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445516,
author = {Ebert, Nico and Alexander Ackermann, Kurt and Scheppler, Bj\"{o}rn},
title = {Bolder is Better: Raising User Awareness through Salient and Concise Privacy Notices},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445516},
doi = {10.1145/3411764.3445516},
abstract = {This paper addresses the question whether the recently proposed approach of concise privacy notices in apps and on websites is effective in raising user awareness. To assess the effectiveness in a realistic setting, we included concise notices in a fictitious but realistic fitness tracking app and asked participants recruited from an online panel to provide their feedback on the usability of the app as a cover story. Importantly, after giving feedback, users were also asked to recall the data practices described in the notices. The experimental setup included the variation of different levels of saliency and riskiness of the privacy notices. Based on a total sample of 2,274 participants, our findings indicate that concise privacy notices are indeed a promising approach to raise user awareness for privacy information when displayed in a salient way, especially in case the notices describe risky data practices. Our results may be helpful for regulators, user advocates and transparency-oriented companies in creating or enforcing better privacy transparency towards average users that do not read traditional privacy policies.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {67},
numpages = {12},
keywords = {privacy communication, information saliency, Privacy notices, privacy awareness, experimental design, information systems},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445510,
author = {South, Laura and Saffo, David and Borkin, Michelle A.},
title = {Detecting and Defending Against Seizure-Inducing GIFs in Social Media},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445510},
doi = {10.1145/3411764.3445510},
abstract = {Despite recent improvements in online accessibility, the Internet remains an inhospitable place for users with photosensitive epilepsy, a chronic condition in which certain light stimuli can trigger seizures and even lead to death in extreme cases. In this paper, we explore how current risk detection systems have allowed attackers to take advantage of design oversights and target vulnerable users with photosensitivity on popular social media platforms. Through interviews with photosensitive individuals and a critical review of existing systems, we constructed design requirements for consumer-driven protective systems and developed a prototype browser extension for actively detecting and disarming potentially seizure-inducing GIFs and videos. We validate our system with a comprehensive dataset of simulated GIFs and GIFs collected from social media. Finally, we conduct a novel quantitative analysis of the prevalence of seizure-inducing GIFs across popular social media platforms and contribute recommendations for improving online accessibility for individuals with photosensitivity. All study materials are available at https://osf.io/5a3dy/.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {273},
numpages = {17},
keywords = {human-computer interaction, GIFs, photosensitive epilepsy, accessibility},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445509,
author = {Gorman, Benjamin M. and Crabb, Michael and Armstrong, Michael},
title = {Adaptive Subtitles: Preferences and Trade-Offs in Real-Time Media Adaption},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445509},
doi = {10.1145/3411764.3445509},
abstract = {Subtitles can help improve the understanding of media content. People enable subtitles based on individual characteristics (e.g., language or hearing ability), viewing environment, or media context (e.g., drama, quiz show). However, some people find that subtitles can be distracting and that they negatively impact their viewing experience. We explore the challenges and opportunities surrounding interaction with real-time personalisation of subtitled content. To understand how people currently interact with subtitles, we first conducted an online questionnaire with 102 participants. We used our findings to elicit requirements for a new approach called Adaptive Subtitles that allows the viewer to alter which speakers have subtitles displayed in real-time. We evaluated our approach with 19 participants to understand the interaction trade-offs and challenges within real-time adaptations of subtitled media. Our evaluation findings suggest that granular controls and structured onboarding allow viewers to make informed trade-offs when adapting media content, leading to improved viewing experiences.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {733},
numpages = {11},
keywords = {Adaptive-Interfaces, Closed-captions, Captions, Subtitles, Media},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445505,
author = {Bentvelzen, Marit and Niess, Jasmin and Wo\'{z}niak, Pawe\l{} W.},
title = {The Technology-Mediated Reflection Model: Barriers and Assistance in Data-Driven Reflection},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445505},
doi = {10.1145/3411764.3445505},
abstract = {Current personal informatics models consider reflection as an important stage in users’ journeys with trackers. However, these models describe reflection from a meta perspective and it remains unclear what this stage entails. To design interactive technologies that support reflection, we need a more thorough understanding of how people reflect on their personal data in practice. To that end, we conducted semi-structured interviews with users of fitness trackers and an online survey to study practices in reflecting on fitness data. Our results show that users reported reflecting on data despite lacking reflection support from their tracking technology. Based on our results, we introduce the Technology-Mediated Reflection Model, which describes conditions and barriers for reflection on personal data. Our model consists of the temporal and conceptual cycles of reflection and helps designers identify the possible barriers a user might face when using a system for reflection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {246},
numpages = {12},
keywords = {reflection, tracking, construal, fitness trackers, personal informatics},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445466,
author = {Abdullah, Muhammad and Taraz, Martin and Kommana, Yannis and Katakura, Shohei and Kovacs, Robert and Shigeyama, Jotaro and Roumen, Thijs and Baudisch, Patrick},
title = {FastForce: Real-Time Reinforcement of Laser-Cut Structures},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445466},
doi = {10.1145/3411764.3445466},
abstract = {We present fastForce, a software tool that detects structural flaws in laser cut 3D models and fixes them by introducing additional plates into the model, thereby making models up to 52x stronger. By focusing on a specific type of structural issue, i.e., poorly connected sub-structures in closed box structures, fastForce achieves real-time performance (106x faster than finite element analysis, in the specific case of the wheelbarrow from Figure 1). This allows fastForce to fix structural issues continuously in the background, while users stay focused on editing their models and without ever becoming aware of any structural issues.In our study, six of seven participants inadvertently introduced severe structural flaws into the guitar stands they designed. Similarly, we found 286 of 402 relevant models in the kyub [1] model library to contain such flaws. We integrated fastForce into a 3D editor for lasercutting (kyub) and found that even with high plate counts fastForce achieves real-time performance.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {673},
numpages = {12},
keywords = {structural reinforcement, structural analysis, lasercutting, Personal fabrication},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445464,
author = {Reichherzer, Carolin and Cunningham, Andrew and Coleman, Tracey and Cao, Ruochen and McManus, Kurt and Sheppard, Dion and Kohler, Mark and Billinghurst, Mark and Thomas, Bruce H},
title = {Bringing the Jury to the Scene of the Crime: Memory and Decision-Making in a Simulated Crime Scene},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445464},
doi = {10.1145/3411764.3445464},
abstract = {This paper investigates the use of immersive virtual reconstructions as an aid for jurors during a courtroom trial. The findings of a between-participant user study on memory and decision-making are presented in the context of viewing a simulated hit-run-death scenario. Participants listened to the opening statement of a prosecutor and a defence attorney before viewing the crime scene in Virtual Reality (VR) or as still images. We compare the effects on cognition and usability of using VR over images presented on a screen. We found several significant improvements, including that VR led to more consistent decision-making among participants. This shows that VR could provide a promising solution for the court to present crime scenes when site visitations are not possible.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {709},
numpages = {12},
keywords = {spatial memory, crime scene, Virtual Reality, interactive virtual environment, jury, 3D Reconstruction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445461,
author = {Goldenberg, Yulia and Tractinsky, Noam},
title = {Towards the Right Direction in BiDirectional User Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445461},
doi = {10.1145/3411764.3445461},
abstract = {Hundreds of millions of speakers of bidirectional (BiDi) languages rely on writing systems that mix the native right-to-left script with left-to-right strings. The global reach of interactive digital technologies requires special attention to these people, whose perception of interfaces is affected by this script mixture. However, empirical research on this topic is scarce. Although leading software vendors provide guidelines for BiDi design, bidirectional interfaces demonstrate inconsistent and incorrect directionality of UI elements, which may cause user confusion and errors.Through a websites' review, we identified problematic UI items and considered reasons for their existence. In an online survey with 234 BiDi speakers, we observed that in many cases, users' direction preferences were inconsistent with the guidelines. The findings provide potential insights for design rules and empirical evidence for the problem's complexity, suggesting the need for further empirical research and greater attention by the HCI community to the BiDi design problem.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {149},
numpages = {13},
keywords = {UI element direction, Localization, Right-to-left design, Bidirectional interface, Bidirectional design, BiDi},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445457,
author = {Kang, Woojin and Jung, In-Taek and Lee, DaeHo and Hong, Jin-Hyuk},
title = {Styling Words: A Simple and Natural Way to Increase Variability in Training Data Collection for Gesture Recognition},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445457},
doi = {10.1145/3411764.3445457},
abstract = {Due to advances in deep learning, gestures have become a more common tool for human-computer interaction. When implementing a large amount of training data, deep learning models show remarkable performance in gesture recognition. Since it is expensive and time consuming to collect gesture data from people, we are often confronted with a practicality issue when managing the quantity and quality of training data. It is a well-known fact that increasing training data variability can help to improve the generalization performance of machine learning models. Thus, we directly intervene in the collection of gesture data to increase human gesture variability by adding some words (called styling words) into the data collection instructions, e.g., giving the instruction "perform gesture #1 faster" as opposed to "perform gesture #1." Through an in-depth analysis of gesture features and video-based gesture recognition, we have confirmed the advantageous use of styling words in gesture training data collection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {318},
numpages = {12},
keywords = {Data collection, Human gesture variability, Styling words, Gesture recognition, Machine learning},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445452,
author = {Ge, Tong and Lee, Bongshin and Wang, Yunhai},
title = {CAST: Authoring Data-Driven Chart Animations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445452},
doi = {10.1145/3411764.3445452},
abstract = {We present CAST, an authoring tool that enables the interactive creation of chart animations. It introduces the visual specification of chart animations consisting of keyframes that can be played sequentially or simultaneously, and animation parameters (e.g., duration, delay). Building on Canis&nbsp;[19], a declarative chart animation grammar that leverages data-enriched SVG charts, CAST supports auto-completion for constructing both keyframes and keyframe sequences. It also enables users to refine the animation specification (e.g., aligning keyframes across tracks to play them together, adjusting delay) with direct manipulation and other parameters for animation effects (e.g., animation type, easing function) using a control panel. In addition to describing how CAST infers recommendations for auto-completion, we present a gallery of examples to demonstrate the expressiveness of CAST and a user study to verify its learnability and usability. Finally, we discuss the limitations and potentials of CAST as well as directions for future research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {24},
numpages = {15},
keywords = {interactive system, chart animation specification, data visualization, chart animation authoring, Chart animation},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445450,
author = {Benabdallah, Gabrielle and Bourgault, Sam and Peek, Nadya and Jacobs, Jennifer},
title = {Remote Learners, Home Makers: How Digital Fabrication Was Taught Online During a Pandemic},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445450},
doi = {10.1145/3411764.3445450},
abstract = {Digital fabrication courses that relied on physical makerspaces were severely disrupted by COVID-19. As universities shut down in Spring 2020, instructors developed new models for digital fabrication at a distance. Through interviews with faculty and students and examination of course materials, we recount the experiences of eight remote digital fabrication courses. We found that learning with hobbyist equipment and online social networks could emulate using industrial equipment in shared workshops. Furthermore, at-home digital fabrication offered unique learning opportunities including more iteration, machine tuning, and maintenance. These opportunities depended on new forms of labor and varied based on student living situations. Our findings have implications for remote and in-person digital fabrication instruction. They indicate how access to tools was important, but not as critical as providing opportunities for iteration; they show how remote fabrication exacerbated student inequities; and they suggest strategies for evaluating trade-offs in remote fabrication models with respect to learning objectives.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {350},
numpages = {14},
keywords = {Digital Fabrication, Pandemic, Remote Learning},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445449,
author = {Jain, Vidit and Leekha, Maitree and Shah, Rajiv Ratn and Shukla, Jainendra},
title = {Exploring Semi-Supervised Learning for Predicting Listener Backchannels},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445449},
doi = {10.1145/3411764.3445449},
abstract = {Developing human-like conversational agents is a prime area in HCI research and subsumes many tasks. Predicting listener backchannels is one such actively-researched task. While many studies have used different approaches for backchannel prediction, they all have depended on manual annotations for a large dataset. This is a bottleneck impacting the scalability of development. To this end, we propose using semi-supervised techniques to automate the process of identifying backchannels, thereby easing the annotation process. To analyze our identification module’s feasibility, we compared the backchannel prediction models trained on (a) manually-annotated and (b) semi-supervised labels. Quantitative analysis revealed that the proposed semi-supervised approach could attain 95% of the former’s performance. Our user-study findings revealed that almost 60% of the participants found the backchannel responses predicted by the proposed model more natural. Finally, we also analyzed the impact of personality on the type of backchannel signals and validated our findings in the user-study.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {395},
numpages = {12},
keywords = {Conversational Agents, Backchanneling, Multimodal analysis.},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445446,
author = {Peng, Zhenhui and Ma, Xiaojuan and Yang, Diyi and Tsang, Ka Wing and Guo, Qingyu},
title = {Effects of Support-Seekers’ Community Knowledge on Their Expressed Satisfaction with the Received Comments in Mental Health Communities},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445446},
doi = {10.1145/3411764.3445446},
abstract = {Online mental health communities (OMHCs) are prominent resources for improving people’s mental wellbeing. An immediate cue of such improvement is support-seekers’ satisfaction expressed in their replies to the received comments. However, the comments that seekers find satisfying may change with their community knowledge, e.g., measured by tenure and posting experience in that community. In this paper, we first model the amount of satisfaction conveyed in the support-seekers’ replies to the received comments. Then we quantitatively examine how seekers’ expressed satisfaction is affected by their community knowledge, sought and received support in an OMHC. Results show that support-seekers with more posting experience generally display less contentment to the received comments. Compared to newcomers, higher tenured members express less satisfaction when receiving informational support. We also found that support matching positively predicts seekers’ satisfaction regardless of their community knowledge. Our findings have implications for OMHCs to satisfy support-seekers through their community knowledge.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {536},
numpages = {12},
keywords = {Mental health, reply behaviors, online community, tenure, satisfaction, emotional support, familiarity, informational support},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445443,
author = {Kim, Dae Hyun and Setlur, Vidya and Agrawala, Maneesh},
title = {Towards Understanding How Readers Integrate Charts and Captions: A Case Study with Line Charts},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445443},
doi = {10.1145/3411764.3445443},
abstract = {Charts often contain visually prominent features that draw attention to aspects of the data and include text captions that emphasize aspects of the data. Through a crowdsourced study, we explore how readers gather takeaways when considering charts and captions together. We first ask participants to mark visually prominent regions in a set of line charts. We then generate text captions based on the prominent features and ask participants to report their takeaways after observing chart-caption pairs. We find that when both the chart and caption describe a high-prominence feature, readers treat the doubly emphasized high-prominence feature as the takeaway; when the caption describes a low-prominence chart feature, readers rely on the chart and report a higher-prominence feature as the takeaway. We also find that external information that provides context, helps further convey the caption’s message to the reader. We use these findings to provide guidelines for authoring effective chart-caption pairs.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {610},
numpages = {11},
keywords = {takeaways., Captions, visually prominent features, line charts},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445429,
author = {Kalinowski, Robert D and Xu, Ying and Salen, Katie},
title = {The Ecological Context of Preschool-Aged Children’s Selection of Media Content},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445429},
doi = {10.1145/3411764.3445429},
abstract = {Today, preschool-aged children have an abundance of digital content to choose from, with some more desirable than others from a developmental perspective. We aim to describe and better understand the interplay of factors that influence children’s selection of media content using a year-long, multi-case ethnography of 13 diverse families in Southern California. We found that young children’s media content selection may be best understood as an ecologically situated process involving the interplay between the content, the child, their family, community, and societal spheres. Children do not make media selections on their own. Rather, these choices are supported or constrained by a range of resource, culture, and policy factors specific to family and community background. We argue that policy makers and technology designers are better served by an ecological perspective if they wish to understand how digital content is selected and used by children in sociocultural context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {349},
numpages = {14},
keywords = {screen media, children, content selection, ecological perspective},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445412,
author = {Mack, Kelly and McDonnell, Emma and Jain, Dhruv and Lu Wang, Lucy and E. Froehlich, Jon and Findlater, Leah},
title = {What Do We Mean by “Accessibility Research”? A Literature Survey of Accessibility Papers in CHI and ASSETS from 1994 to 2019},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445412},
doi = {10.1145/3411764.3445412},
abstract = {Accessibility research has grown substantially in the past few decades, yet there has been no literature review of the field. To understand current and historical trends, we created and analyzed a dataset of accessibility papers appearing at CHI and ASSETS since ASSETS’ founding in 1994. We qualitatively coded areas of focus and methodological decisions for the past 10 years (2010-2019, N=506 papers), and analyzed paper counts and keywords over the full 26 years (N=836 papers). Our findings highlight areas that have received disproportionate attention and those that are underserved—for example, over 43% of papers in the past 10 years are on accessibility for blind and low vision people. We also capture common study characteristics, such as the roles of disabled and nondisabled participants as well as sample sizes (e.g., a median of 13 for participant groups with disabilities and older adults). We close by critically reflecting on gaps in the literature and offering guidance for future work in the field.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {371},
numpages = {18},
keywords = {literature review, disability, Accessibility, assistive technology},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445408,
author = {Hamidi, Foad and Stamato, Lydia and Scheifele, Lisa and Hammond, Rian Ciela Visscher and Asgarali-Hoffman, S. Nisa},
title = {“Turning the Invisible Visible”: Transdisciplinary Bioart Explorations in Human-DNA Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445408},
doi = {10.1145/3411764.3445408},
abstract = {Hybrid interactive systems that combine living and digital components can engage, educate, and inform users, and are of growing interest in the HCI community. Advances in synthetic biology are transforming what is possible to do with these living media interfaces (LMIs). Bioart is a practice in which artists, often using synthetic biology methods, work with living organisms to creatively explore the human relationship with nonhuman organisms. We present results from an interview study with expert bioartists as well as our hands-on experience in a bioart project where we created poetry-infused wine by encoding and inserting a Persian Sufi poem into the DNA sequence of living yeast cells. We find that engaging in bioart practice generates transdisciplinary fluency with implications for access and activism and our understanding of the qualities of living media. We further explore the qualitative aspects of interacting directly with DNA and implications for sustainable futures.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {592},
numpages = {15},
keywords = {transgenic art, biotechnology, synthetic biology, DIYbio, bioart, community science, Living organisms},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445399,
author = {Rubya, Sabirat and Numainville, Joseph and Yarosh, Svetlana},
title = {Comparing Generic and Community-Situated Crowdsourcing for Data Validation in the Context of Recovery from Substance Use Disorders},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445399},
doi = {10.1145/3411764.3445399},
abstract = {Targeting the right group of workers for crowdsourcing often achieves better quality results. One unique example of targeted crowdsourcing is seeking community-situated workers whose familiarity with the background and the norms of a particular group can help produce better outcome or accuracy. These community-situated crowd workers can be recruited in different ways from generic online crowdsourcing platforms or from online recovery communities. We evaluate three different approaches to recruit generic and community-situated crowd in terms of the time and the cost of recruitment, and the accuracy of task completion. We consider the context of Alcoholics Anonymous (AA), the largest peer support group for recovering alcoholics, and the task of identifying and validating AA meeting information. We discuss the benefits and trade-offs of recruiting paid vs. unpaid community-situated workers and provide implications for future research in the recovery context and relevant domains of HCI, and for the design of crowdsourcing ICT systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {449},
numpages = {17},
keywords = {Crowdsourcing, Alcoholics Anonymous, community-situated crowd},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445398,
author = {Arevalo Arboleda, Stephanie and R\"{u}cker, Franziska and Dierks, Tim and Gerken, Jens},
title = {Assisting Manipulation and Grasping in Robot Teleoperation with Augmented Reality Visual Cues},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445398},
doi = {10.1145/3411764.3445398},
abstract = {Teleoperating industrial manipulators in co-located spaces can be challenging. Facilitating robot teleoperation by providing additional visual information about the environment and the robot affordances using augmented reality (AR), can improve task performance in manipulation and grasping. In this paper, we present two designs of augmented visual cues, that aim to enhance the visual space of the robot operator through hints about the position of the robot gripper in the workspace and in relation to the target. These visual cues aim to improve the distance perception and thus, the task performance. We evaluate both designs against a baseline in an experiment where participants teleoperate a robotic arm to perform pick-and-place tasks. Our results show performance improvements in different levels, reflecting in objective and subjective measures with trade-offs in terms of time, accuracy, and participants’ views of teleoperation. These findings show the potential of AR not only in teleoperation, but in understanding the human-robot workspace.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {728},
numpages = {14},
keywords = {robot teleoperation, augmented reality, visual cues, human-robot interaction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445387,
author = {Habib, Hana and Zou, Yixin and Yao, Yaxing and Acquisti, Alessandro and Cranor, Lorrie and Reidenberg, Joel and Sadeh, Norman and Schaub, Florian},
title = {Toggles, Dollar Signs, and Triangles: How to (In)Effectively Convey Privacy Choices with Icons and Link Texts},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445387},
doi = {10.1145/3411764.3445387},
abstract = {Increasingly, icons are being proposed to concisely convey privacy-related information and choices to users. However, complex privacy concepts can be difficult to communicate. We investigate which icons effectively signal the presence of privacy choices. In a series of user studies, we designed and evaluated icons and accompanying textual descriptions (link texts) conveying choice, opting-out, and sale of personal information&nbsp;—&nbsp;the latter an opt-out mandated by the California Consumer Privacy Act (CCPA). We identified icon-link text pairings that conveyed the presence of privacy choices without creating misconceptions, with a blue stylized toggle icon paired with “Privacy Options” performing best. The two CCPA-mandated link texts (“Do Not Sell My Personal Information” and “Do Not Sell My Info”) accurately communicated the presence of do-not-sell opt-outs with most icons. Our results provide insights for the design of privacy choice indicators and highlight the necessity of incorporating user testing into policy making.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {63},
numpages = {25},
keywords = {CCPA., choice, Privacy, icon design},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445380,
author = {Oppenlaender, Jonas and Kuosmanen, Elina and Lucero, Andr\'{e}s and Hosio, Simo},
title = {Hardhats and Bungaloos: Comparing Crowdsourced Design Feedback with Peer Design Feedback in the Classroom},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445380},
doi = {10.1145/3411764.3445380},
abstract = {Feedback is an important aspect of design education, and crowdsourcing has emerged as a convenient way to obtain feedback at scale. In this paper, we investigate how crowdsourced design feedback compares to peer design feedback within a design-oriented HCI class and across two metrics: perceived quality and perceived fairness. We also examine the perceived monetary value of crowdsourced feedback, which provides an interesting contrast to the typical requester-centric view of the value of labor on crowdsourcing platforms. Our results reveal that the students (N = 106) perceived the crowdsourced design feedback as inferior to peer design feedback in multiple ways. However, they also identified various positive aspects of the online crowds that peers cannot provide. We discuss the meaning of the findings and provide suggestions for teachers in HCI and other researchers interested in crowd feedback systems on using crowds as a potential complement to peers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {570},
numpages = {14},
keywords = {peer review, design feedback, classroom study, crowd feedback system, crowdsourcing},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445377,
author = {Lin, Phoebe and Van Brummelen, Jessica},
title = {Engaging Teachers to Co-Design Integrated AI Curriculum for K-12 Classrooms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445377},
doi = {10.1145/3411764.3445377},
abstract = {Artificial Intelligence (AI) education is an increasingly popular topic area for K-12 teachers. However, little research has investigated how AI curriculum and tools can be designed to be more accessible to all teachers and learners. In this study, we take a Value-Sensitive Design approach to understanding the role of teacher values in the design of AI curriculum and tools, and identifying opportunities to integrate AI into core curriculum to leverage learners’ interests. We organized co-design workshops with 15 K-12 teachers, where teachers and researchers co-created lesson plans using AI tools and embedding AI concepts into various core subjects. We found that K-12 teachers need additional scaffolding in AI tools and curriculum to facilitate ethics and data discussions, and value supports for learner evaluation and engagement, peer-to-peer collaboration, and critical reflection. We present an exemplar lesson plan that shows entry points for teaching AI in non-computing subjects and reflect on co-designing with K-12 teachers in a remote setting.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {239},
numpages = {12},
keywords = {K-12 Education, Artificial Intelligence, Co-Design},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445376,
author = {Oyg\"{u}r, I\th{}il and Su, Zhaoyuan and A. Epstein, Daniel and Chen, Yunan},
title = {The Lived Experience of Child-Owned Wearables: Comparing Children's and Parents’ Perspectives on Activity Tracking},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445376},
doi = {10.1145/3411764.3445376},
abstract = {Children are increasingly using wearables with physical activity tracking features. Although research has designed and evaluated novel features for supporting parent-child collaboration with these wearables, less is known about how families naturally adopt and use these technologies in their everyday life. We conducted interviews with 17 families who have naturally adopted child-owned wearables to understand how they use wearables individually and collaboratively. Parents are primarily motivated to use child-owned wearables for children's long-term health and wellbeing, whereas children mostly seek out entertainment and feeling accomplished through reaching goals. Children are often unable to interpret or contextualize the measures that wearables record, while parents do not regularly track these measures and focus on deviations from their children's routines. We discuss opportunities for making naturally-occurring family moments educational to positively contribute to children's conceptual understanding of health, such as developing age-appropriate trackable metrics for shared goal-setting and data reflection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {480},
numpages = {12},
keywords = {Wearable Computers, Children/Parents, Health-Wellbeing, Personal Data/Tracking},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445373,
author = {Lin, Anan and Scheller, Meike and Feng, Feng and Proulx, Michael J and Metatla, Oussama},
title = {Feeling Colours: Crossmodal Correspondences Between Tangible 3D Objects, Colours and Emotions},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445373},
doi = {10.1145/3411764.3445373},
abstract = {With increasing interest in multisensory experiences in HCI there is a need to consider the potential impact of crossmodal correspondences (CCs) between sensory modalities on perception and interpretation. We investigated CCs between active haptic experiences of tangible 3D objects, visual colour and emotion using the “Bouba/Kiki” paradigm. We asked 30 participants to assign colours and emotional categories to 3D-printed objects with varying degrees of angularity and complexity. We found tendencies to associate high degrees of complexity and angularity with red colours, low brightness and high arousal levels. Less complex round shapes were associated with blue colours, high brightness and positive valence levels. These findings contrast previously reported crossmodal effects triggered by 2D shapes of similar angularity and complexity, suggesting that designers cannot simply extrapolate potential perceptual and interpretive experiences elicited by 2D shapes to seemingly similar 3D tangible objects. Instead, we propose a design space for creating tangible multisensory artefacts that can trigger specific emotional percepts and discuss implications for exploiting CCs in the design of interactive technology.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {187},
numpages = {12},
keywords = {Emotions, Bouba, Crossmodal Correspondences, Touch, 3D Printing, Colour, Multisensory Interaction, Kiki},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445353,
author = {Park, So Yeon and Santero, Nicole K. and Kaneshiro, Blair and Lee, Jin Ha},
title = {Armed in ARMY: A Case Study of How BTS Fans Successfully Collaborated to #MatchAMillion for Black Lives Matter},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445353},
doi = {10.1145/3411764.3445353},
abstract = {Music fans strategically support their artists. Their collective efforts can extend to social causes as well: In 2020 for example, ARMY—the fandom of the music group BTS—successfully organized the #MatchAMillion campaign to raise over one million USD to support Black Lives Matter. To better understand factors of fandoms’ collaborative success for arguably unrelated social goals, we conducted a survey focusing on ARMYs’ perceptions of their fandom and their social effort. Most ARMYs viewed the fandom as a community, loosely structured with pillar accounts. They reported trust in each other as well as high team composition, which mediated the relationship between their neutral psychological safety and high efficacy. Respondents attributed their success in #MatchAMillion to shared values, good teamwork, and established infrastructure. Our findings elucidate contextual factors that contribute to ARMY’s collaborative success and highlight themes that may be applied to studying other fandoms and their collaborative efforts.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {336},
numpages = {14},
keywords = {Collaboration, Teamwork, Fan activism, Fandom, Collaborative success, Online community, Philanthropy},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445342,
author = {Fender, Andreas Rene and Martinez Plasencia, Diego and Subramanian, Sriram},
title = {ArticuLev: An Integrated Self-Assembly Pipeline for Articulated Multi-Bead Levitation Primitives},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445342},
doi = {10.1145/3411764.3445342},
abstract = {Acoustic levitation is gaining popularity as an approach to create physicalized mid-air content by levitating different types of levitation primitives. Such primitives can be independent particles or particles that are physically connected via threads or pieces of cloth to form shapes in mid-air. However, initialization (i.e., placement of such primitives in their mid-air target locations) currently relies on either manual placement or specialized ad-hoc implementations, which limits their practical usage. We present ArticuLev, an integrated pipeline that deals with the identification, assembly and mid-air placement of levitated shape primitives. We designed ArticuLev with the physical properties of commonly used levitation primitives in mind. It enables experiences that seamlessly combine different primitives into meaningful structures (including fully articulated animated shapes) and supports various levitation display approaches (e.g., particles moving at high speed). In this paper, we describe our pipeline and demonstrate it with heterogeneous combinations of levitation primitives.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {422},
numpages = {12},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445322,
author = {Wu, Zihan and Yu, Chun and Xu, Xuhai and Wei, Tong and Zou, Tianyuan and Wang, Ruolin and Shi, Yuanchun},
title = {LightWrite: Teach Handwriting to The Visually Impaired with A Smartphone},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445322},
doi = {10.1145/3411764.3445322},
abstract = {Learning to write is challenging for blind and low vision (BLV) people because of the lack of visual feedback. Regardless of the drastic advancement of digital technology, handwriting is still an essential part of daily life. Although tools designed for teaching BLV to write exist, many are expensive and require the help of sighted teachers. We propose LightWrite, a low-cost, easy-to-access smartphone application that uses voice-based descriptive instruction and feedback to teach BLV users to write English lowercase letters and Arabian digits in a specifically designed font. A two-stage study with 15 BLV users with little prior writing knowledge shows that LightWrite can successfully teach users to learn handwriting characters in an average of 1.09 minutes for each letter. After initial training and 20-minute daily practice for 5 days, participants were able to write an average of 19.9 out of 26 letters that are recognizable by sighted raters.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {32},
numpages = {15},
keywords = {Handwriting Learning, Blind and Visually-Impaired Users, Accessibility},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445320,
author = {Mallari, Keri and Williams, Spencer and Hsieh, Gary},
title = {Understanding Analytics Needs of Video Game Streamers},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445320},
doi = {10.1145/3411764.3445320},
abstract = {Live streaming is a rapidly growing industry, with millions of content creators using platforms like Twitch to share games, art, and other activities. However, with this rise in popularity, most streamers often fail to attract viewers and grow their platforms. Analytic tools—which have shown success in other business and learning contexts—may be one potential solution, but their use in streaming settings remains unexplored. In this study, we focused on game streaming and interviewed 18 game streamers on Twitch and Mixer about their information needs and current use of tools, supplemented by explorations into their Discord communities. We find that streamers have a range of content, marketing, and community information needs, many of which are not being met by available tools. We conclude with design implications for developing more streamer-centered analytics for video game streamers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {12},
keywords = {streamers, live streaming, analytics, video games},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445318,
author = {Bae Brandtz\ae{}g, Petter Bae and Skjuve, Marita and Kristoffer Dysthe, Kim Kristoffer and F\o{}lstad, Asbj\o{}rn},
title = {When the Social Becomes Non-Human: Young People's Perception of Social Support in Chatbots},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445318},
doi = {10.1145/3411764.3445318},
abstract = {Although social support is important for health and well-being, many young people are hesitant to reach out for support. The emerging uptake of chatbots for social and emotional purposes entails opportunities and concerns regarding non-human agents as sources of social support. To explore this, we invited 16 participants (16–21 years) to use and reflect on chatbots as sources of social support. Our participants first interacted with a chatbot for mental health (Woebot) for two weeks. Next, they participated in individual in-depth interviews. As part of the interview session, they were presented with a chatbot prototype providing information to young people. Two months later, the participants reported on their continued use of Woebot. Our findings provide in-depth knowledge about how young people may experience various types of social support—appraisal, informational, emotional, and instrumental support—from chatbots. We summarize implications for theory, practice, and future research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {257},
numpages = {13},
keywords = {Young people, Chatbots, Artificial Intelligence, Social support},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445313,
author = {Karusala, Naveena and Seeh, David Odhiambo and Mugo, Cyrus and Guthrie, Brandon and Moreno, Megan A and John-Stewart, Grace and Inwani, Irene and Anderson, Richard and Ronen, Keshet},
title = {“That Courage to Encourage”: Participation and Aspirations in Chat-Based Peer Support for Youth Living with HIV},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445313},
doi = {10.1145/3411764.3445313},
abstract = {We present a qualitative study of a six-month pilot of WhatsApp-based facilitated peer support groups, serving youth living with human immunodeficiency virus (HIV) in an informal settlement in Nairobi, Kenya. Popular chat apps are increasingly being leveraged to make a combination of patient-provider communication and peer support more accessible beyond formal healthcare settings. However, how these interventions are experienced in Global South contexts with phone sharing and intermittent data access is understudied. The context of stigmatized illnesses like HIV further complicates privacy concerns. We draw on chat records and interviews with youth and the facilitator to describe their experience of the intervention. We find that despite tensions in group dynamics, intermittent participation, and contingencies around privacy, youth were motivated by newfound aspirations and community to manage their health. We use our findings to discuss implications for the design of chat-based peer interventions, negotiation of privacy in mobile health applications, and the role of aspirations in health interventions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {223},
numpages = {17},
keywords = {WhatsApp, Kenya, peer support, health, chat apps, aspirations},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445312,
author = {Langevin, Raina and Lordon, Ross J and Avrahami, Thi and Cowan, Benjamin R. and Hirsch, Tad and Hsieh, Gary},
title = {Heuristic Evaluation of Conversational Agents},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445312},
doi = {10.1145/3411764.3445312},
abstract = {Conversational interfaces have risen in popularity as businesses and users adopt a range of conversational agents, including chatbots and voice assistants. Although guidelines have been proposed, there is not yet an established set of usability heuristics to guide and evaluate conversational agent design. In this paper, we propose a set of heuristics for conversational agents adapted from Nielsen’s heuristics and based on expert feedback. We then validate the heuristics through two rounds of evaluations conducted by participants on two conversational agents, one chatbot and one voice-based personal assistant. We find that, when using our heuristics to evaluate both interfaces, evaluators were able to identify more usability issues than when using Nielsen’s heuristics. We propose that our heuristics successfully identify issues related to dialogue content, interaction design, help and guidance, human-like characteristics, and data privacy.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {632},
numpages = {15},
keywords = {heuristic evaluation, user interface design, conversational agents},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445308,
author = {Cheng, Hao-Fei and Stapleton, Logan and Wang, Ruiqi and Bullock, Paige and Chouldechova, Alexandra and Wu, Zhiwei Steven Steven and Zhu, Haiyi},
title = {Soliciting Stakeholders’ Fairness Notions in Child Maltreatment Predictive Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445308},
doi = {10.1145/3411764.3445308},
abstract = {Recent work in fair machine learning has proposed dozens of technical definitions of algorithmic fairness and methods for enforcing these definitions. However, we still lack an understanding of how to develop machine learning systems with fairness criteria that reflect relevant stakeholders’ nuanced viewpoints in real-world contexts. To address this gap, we propose a framework for eliciting stakeholders’ subjective fairness notions. Combining a user interface that allows stakeholders to examine the data and the algorithm’s predictions with an interview protocol to probe stakeholders’ thoughts while they are interacting with the interface, we can identify stakeholders’ fairness beliefs and principles. We conduct a user study to evaluate our framework in the setting of a child maltreatment predictive system. Our evaluations show that the framework allows stakeholders to comprehensively convey their fairness viewpoints. We also discuss how our results can inform the design of predictive systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {390},
numpages = {17},
keywords = {child welfare, machine learning, human-centered AI, algorithm-assisted decision-making, algorithmic fairness},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445305,
author = {Carlos Alvarez de la Vega, Juan and E. Cecchinato, Marta and Rooksby, John},
title = {“Why Lose Control?” A Study of Freelancers’ Experiences with Gig Economy Platforms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445305},
doi = {10.1145/3411764.3445305},
abstract = {Freelancing platforms, such as Upwork, represent an expansion of the gig economy to encompass knowledge-based work. Prior research in HCI has primarily focused on forms of gig work such as ride-sharing and microwork but has not addressed how freelancing platforms are disrupting high-skilled knowledge work. To understand freelancers’ perspectives on how these platforms are disrupting their work we have collected and thematically analysed 528 posts with 7499 comments from four relevant subforums on Reddit. The qualitative findings reveal tensions between wanting autonomy and control and the necessity of opportunities and convenience. Freelancing platforms are perceived as systems that present advantages to find clients, gain experience and mitigate precarity. However, these platforms constrain the control over their work that freelancers value. The paper contributes an improved understanding of freelance work, the role and potential for freelancing platforms in the knowledge-based gig economy, and directions for worker-centred design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {14},
keywords = {Fiverr, Reddit, Freelancing platforms, Worker-centered design, Gig economy, Freelance work, Upwork},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445300,
author = {Brooks, Jas and Teng, Shan-Yuan and Wen, Jingxuan and Nith, Romain and Nishida, Jun and Lopes, Pedro},
title = {Stereo-Smell via Electrical Trigeminal Stimulation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445300},
doi = {10.1145/3411764.3445300},
abstract = {We propose a novel type of olfactory device that creates a stereo-smell experience, i.e., directional information about the location of an odor, by rendering the readings of external odor sensors as trigeminal sensations using electrical stimulation of the user's nasal septum. The key is that the sensations from the trigeminal nerve, which arise from nerve-endings in the nose, are perceptually fused with those of the olfactory bulb (the brain region that senses smells). As such, we propose that electrically stimulating the trigeminal nerve is an ideal candidate for stereo-smell augmentation/substitution that, unlike other approaches, does not require implanted electrodes in the olfactory bulb. To realize this, we engineered a self-contained device that users wear across their nasal septum. Our device outputs by stimulating the user's trigeminal nerve using electrical impulses with variable pulse-widths; and it inputs by sensing the user's inhalations using a photoreflector. It measures 10x23 mm and communicates with external gas sensors using Bluetooth. In our user study, we found the key electrical waveform parameters that enable users to feel an odor's intensity (absolute electric charge) and direction (phase order and net charge). In our second study, we demonstrated that participants were able to localize a virtual smell source in the room by using our prototype without any previous training. Using these insights, our device enables expressive trigeminal sensations and could function as an assistive device for people with anosmia, who are unable to smell.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {502},
numpages = {13},
keywords = {Electrical stimulation, intranasal, olfaction, trigeminal},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445295,
author = {Lee, Hyunsoo and Kim, Auk and Hong, Hwajung and Lee, Uichin},
title = {Sticky Goals: Understanding Goal Commitments for Behavioral Changes in the Wild},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445295},
doi = {10.1145/3411764.3445295},
abstract = {A commitment device, an attempt to bind oneself for a successful goal achievement, has been used as an effective strategy to promote behavior change. However, little is known about how commitment devices are used in the wild, and what aspects of commitment devices are related to goal achievements. In this paper, we explore a large-scale dataset from stickK, an online behavior change support system that provides both financial and social commitments. We characterize the patterns of behavior change goals (e.g., topics and commitment setting) and then perform a series of multilevel regression analyses on goal achievements. Our results reveal that successful goal achievements are largely dependent on the configuration of financial and social commitment devices, and a mixed commitment setting is considered beneficial. We discuss how our findings could inform the design of effective commitment devices, and how large-scale data can be leveraged to support data-driven goal elicitation and customization.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {230},
numpages = {16},
keywords = {Usage Data Analysis, Online Behavior Change Support Systems, Commitment Device, Goal-Setting},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445286,
author = {Denisova, Alena and Bopp, Julia Ayumi and Nguyen, Thuy Duong and Mekler, Elisa D},
title = {“Whatever the Emotional Experience, It’s Up to Them”: Insights from Designers of Emotionally Impactful Games},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445286},
doi = {10.1145/3411764.3445286},
abstract = {Emotionally impactful game experiences have garnered increasing interest within HCI games research. Yet the perspectives of designers have, to date, remained largely overlooked. We interviewed 14 indie game designers regarding their values and practices in designing emotionally impactful games. Counter to the focus of recent player experience (PX) studies, we find that while designers typically have a clear vision for the intended emotional impact, they aim for their games to provide a space for players to have their own personal experiences and interpretations. Despite this player-centric orientation, players were rarely involved before and during the production to evaluate the emotional experience. Based on these findings, we identify gaps between design practice and PX research, raise open questions around the design and evaluation of emotionally impactful game experiences, and outline opportunities for HCI games research to more productively support game designers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {120},
numpages = {9},
keywords = {design practice, agency, emotionally impactful games, emotion, Emotional challenge, game designer, video games, player experience},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445283,
author = {Huang, Gaoping and Qian, Xun and Wang, Tianyi and Patel, Fagun and Sreeram, Maitreya and Cao, Yuanzhi and Ramani, Karthik and Quinn, Alexander J.},
title = {AdapTutAR: An Adaptive Tutoring System for Machine Tasks in Augmented Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445283},
doi = {10.1145/3411764.3445283},
abstract = {Modern manufacturing processes are in a state of flux, as they adapt to increasing demand for flexible and self-configuring production. This poses challenges for training workers to rapidly master new machine operations and processes, i.e. machine tasks. Conventional in-person training is effective but requires time and effort of experts for each worker trained and not scalable. Recorded tutorials, such as video-based or augmented reality (AR), permit more efficient scaling. However, unlike in-person tutoring, existing recorded tutorials lack the ability to adapt to workers’ diverse experiences and learning behaviors. We present AdapTutAR, an adaptive task tutoring system that enables experts to record machine task tutorials via embodied demonstration and train learners with different AR tutoring contents adapting to each user’s characteristics. The adaptation is achieved by continually monitoring learners’ tutorial-following status and adjusting the tutoring content on-the-fly and in-situ. The results of our user study evaluation have demonstrated that our adaptive system is more effective and preferable than the non-adaptive one.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {417},
numpages = {15},
keywords = {manufacturing, training/learning, adaptation, user state recognition},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445275,
author = {K. Chua, Phoebe and Mazmanian, Melissa},
title = {What Are You Doing With Your Phone? How Social Class Frames Parent-Teen Tensions around Teens’ Smartphone Use},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445275},
doi = {10.1145/3411764.3445275},
abstract = {Social class contexts shape parents’ guiding principles around teens’ smartphone use. These contexts can affect how parents coach and censor their teens’ smartphone use and can create tensions in the home. Through 174 interviews (87 parent-teen dyads), we find that upper-middle-class families generally adopt an orientation toward scaffolded achievements and working-class families tend to embrace an orientation toward empowered self-sufficiency. We further find that these class-based orientations contribute to parent-teen tensions. For upper-middle-class families, tensions arise when parents insist that teens should use smartphones to get help with academic and enrichment activities and teens disagree about whether their phone-related activities align with this goal. In contrast, we find that conflict can occur in working-class families when teens use their smartphones to get assistance and parents interpret such activity as teens being lazy or not self-sufficient. These findings highlight the role of social class contexts in shaping families’ orientations toward teens’ smartphone use and phone-related tensions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {353},
numpages = {12},
keywords = {smartphones, tensions, social class, teens, parents},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445262,
author = {Tsai, Hsin-Ruey and Chang, Yuan-Chia and Wei, Tzu-Yun and Tsao, Chih-An and Koo, Xander Chin-yuan and Wang, Hao-Chuan and Chen, Bing-Yu},
title = {GuideBand: Intuitive 3D Multilevel Force Guidance on a Wristband in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445262},
doi = {10.1145/3411764.3445262},
abstract = {For haptic guidance, vibrotactile feedback is a commonly-used mechanism, but requires users to interpret its complicated patterns especially in 3D guidance, which is not intuitive and increases their mental effort. Furthermore, for haptic guidance in virtual reality (VR), not only guidance performance but also realism should be considered. Since vibrotactile feedback interferes with and reduces VR realism, it may not be proper for VR haptic guidance. Therefore, we propose a wearable device, GuideBand, to provide intuitive 3D multilevel force guidance upon the forearm, which reproduces an effect that the forearm is pulled and guided by a virtual guider or telepresent person in VR. GuideBand uses three motors to pull a wristband at different force levels in 3D space. Such feedback usually requires much larger and heavier robotic arms or exoskeletons. We conducted a just-noticeable difference study to understand users’ force level distinguishability. Based on the results, we performed a study to verify that compared with state-of-the-art vibrotactile guidance, GuideBand is more intuitive, needs a lower level of mental effort, and achieves similar guidance performance. We further conducted a VR experience study to observe how users combine and complement visual and force guidance, and prove that GuideBand enhances realism in VR guidance.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {134},
numpages = {13},
keywords = {force feedback, force guidance, motion guidance, virtual reality, wearable device., Haptic feedback},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445261,
author = {Lee, Michelle Seng Ah and Singh, Jat},
title = {The Landscape and Gaps in Open Source Fairness Toolkits},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445261},
doi = {10.1145/3411764.3445261},
abstract = {With the surge in literature focusing on the assessment and mitigation of unfair outcomes in algorithms, several open source ‘fairness toolkits’ recently emerged to make such methods widely accessible. However, little studied are the differences in approach and capabilities of existing fairness toolkits, and their fit-for-purpose in commercial contexts. Towards this, this paper identifies the gaps between the existing open source fairness toolkit capabilities and the industry practitioners’ needs. Specifically, we undertake a comparative assessment of the strengths and weaknesses of six prominent open source fairness toolkits, and investigate the current landscape and gaps in fairness toolkits through an exploratory focus group, a semi-structured interview, and an anonymous survey of data science/machine learning (ML) practitioners. We identify several gaps between the toolkits’ capabilities and practitioner needs, highlighting areas requiring attention and future directions towards tooling that better support ‘fairness in practice.’},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {699},
numpages = {13},
keywords = {bias detection, algorithm auditing, open source toolkits, bias mitigation, algorithmic fairness, fairness, fairness toolkits, bias},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445255,
author = {Saidi, Houssem and Dubois, Emmanuel and Serrano, Marcos},
title = {HoloBar: Rapid Command Execution for Head-Worn AR Exploiting Around the Field-of-View Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445255},
doi = {10.1145/3411764.3445255},
abstract = {Inefficient menu interfaces lead to system and application commands being tedious to execute in Immersive Environments. HoloBar is a novel approach to ease the interaction with multi-level menus in immersive environments: with HoloBar, the hierarchical menu splits between the field of view (FoV) of the Head Mounted Display and the smartphone (SP). Command execution is based on around-the-FoV interaction with the SP, and touch input on the SP display. The HoloBar offers a unique combination of features, namely rapid mid-air activation, implicit selection of top-level items and preview of second-level items on the SP, ensuring rapid access to commands. In a first study we validate its activation method, which consists in bringing the SP within an activation distance from the FoV. In a second study, we compare the HoloBar to two alternatives, including the standard HoloLens menu. Results show that the HoloBar shortens each step of a multi-level menu interaction (menu activation, top-level item selection, second-level item selection and validation), with a high success rate. A follow-up study confirms that these results remain valid when compared with the two validation mechanisms of HoloLens (Air-Tap and clicker).},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {745},
numpages = {17},
keywords = {Augmented reality, Menu interaction, Smartphone based interactions},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445246,
author = {Johnson, Janet G and Gasques, Danilo and Sharkey, Tommy and Schmitz, Evan and Weibel, Nadir},
title = {Do You Really Need to Know Where “That” Is? Enhancing Support for Referencing in Collaborative Mixed Reality Environments},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445246},
doi = {10.1145/3411764.3445246},
abstract = {Mixed Reality has been shown to enhance remote guidance and is especially well-suited for physical tasks. Conversations during these tasks are heavily anchored around task objects and their spatial relationships in the real world, making referencing - the ability to refer to an object in a way that is understood by others - a crucial process that warrants explicit support in collaborative Mixed Reality systems. This paper presents a 2x2 mixed factorial experiment that explores the effects of providing spatial information and system-generated guidance to task objects. It also investigates the effects of such guidance on the remote collaborator’s need for spatial information. Our results show that guidance increases performance and communication efficiency while reducing the need for spatial information, especially in unfamiliar environments. Our results also demonstrate a reduced need for remote experts to be in immersive environments, making guidance more scalable, and expertise more accessible.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {514},
numpages = {14},
keywords = {Remote Guidance, Mixed Reality, Referencing, Collaboration},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445226,
author = {Ali, Safinah and DiPaola, Daniella and Lee, Irene and Hong, Jenna and Breazeal, Cynthia},
title = {Exploring Generative Models with Middle School Students},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445226},
doi = {10.1145/3411764.3445226},
abstract = {Applications of generative models such as Generative Adversarial Networks (GANs) have made their way to social media platforms that children frequently interact with. While GANs are associated with ethical implications pertaining to children, such as the generation of Deepfakes, there are negligible efforts to educate middle school children about generative AI. In this work, we present a generative models learning trajectory (LT), educational materials, and interactive activities for young learners with a focus on GANs, creation and application of machine-generated media, and its ethical implications. The activities were deployed in four online workshops with 72 students (grades 5-9). We found that these materials enabled children to gain an understanding of what generative models are, their technical components and potential applications, and benefits and harms, while reflecting on their ethical implications. Learning from our findings, we propose an improved learning trajectory for complex socio-technical systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {678},
numpages = {13},
keywords = {Generative Machine Learning, AI Education, Generative Adversarial Networks, Artificial Intelligence},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445225,
author = {Dixon, Emma and Piper, Anne Marie and Lazar, Amanda},
title = {“Taking Care of Myself as Long as I Can”: How People with Dementia Configure Self-Management Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445225},
doi = {10.1145/3411764.3445225},
abstract = {Self-management research in HCI has addressed a variety of conditions. Yet, this literature has largely focused on neurotypical populations and chronic conditions that can be managed, leaving open questions of what self-management might look like for populations with progressive cognitive impairment. Grounded in interviews with seventeen technology savvy people with mild to moderate dementia, our analysis reveals their use of technological and social resources as part of the work of self-management. We detail how participants design self-management systems to enable desired futures, function well in their social world, and maintain control. Our discussion broadens the notion of self-management to include future-oriented, sociotechnical, self-determinate design. We advocate for expanding the way technologists, designers, and HCI scholars view people with mild to moderate dementia to recognize them as inventive creators and capable actors in self-management.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {656},
numpages = {14},
keywords = {Self-management Technology, Chronic Care, Self-determination, Dementia, Self-management, Sociotechnical Systems},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445223,
author = {Pfeil, Kevin and Masnadi, Sina and Belga, Jacob and Sera-Josef, Jose-Valentin T and LaViola, Joseph},
title = {Distance Perception with a Video See-Through Head-Mounted Display},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445223},
doi = {10.1145/3411764.3445223},
abstract = {In recent years, pass-through cameras have resurfaced as inclusions for virtual reality (VR) hardware. With modern cameras that now have increased resolution and frame rate, Video See-Through (VST) Head-Mounted Displays (HMD) can be used to provide an Augmented Reality (AR) experience. However, because users see their surroundings through video capture and HMD lenses, there is question surrounding how people perceive their environment with these devices. We conducted a user study with 26 participants to help understand if distance perception is altered when viewing surroundings with a VST HMD. Although previous work shows that distance estimation in VR with an HTC Vive is comparable to that in the real world, our results show that the inclusion of a ZED Mini pass-through camera causes a significant difference between normal, unrestricted viewing and that through a VST HMD.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {528},
numpages = {9},
keywords = {Video See-Through, User Study, Pass-Through Camera, Virtual Reality, Distance Perception},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411764.3445216,
author = {Uriu, Daisuke and Obushi, Noriyasu and Kashino, Zendai and Hiyama, Atsushi and Inami, Masahiko},
title = {Floral Tribute Ritual in Virtual Reality: Design and Validation of SenseVase with Virtual Memorial},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445216},
doi = {10.1145/3411764.3445216},
abstract = {While floral tributes are commonly used for the public commemoration of victims of disasters, war, and other accidents, flowers in vases color everyday life. In this research, these features of flowers are intertwined with the recent phenomenon of online memorials to develop a virtual floral tribute concept that includes physical rituals. We designed SenseVase, a smart vase to detect flowers placed in it, and a 3DCG Virtual Memorial that illustrates floral tributes given by people using SenseVases at home. This paper describes how we developed our design concept by reviewing previous literature and social aspects, and presents a video illustrating the concept. To validate the current concept, we interviewed several experts knowledgeable in public commemorations, virtual and online communities, and the floral business. Through a discussion of our findings from the design process and interviews, we propose a new direction for how HCI technology can contribute to public commemoration in addition to personal memorialization.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {628},
numpages = {15},
keywords = {Research through Design, Techno-spiritual Practices, Memorialization, Mourning, Thanatosensitive Design, Commemoration, Online Memorial, Death Rituals},
location = {Yokohama, Japan},
series = {CHI '21}
}

