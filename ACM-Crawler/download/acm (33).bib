@inproceedings{10.1145/3334480.3382944,
author = {Dinneen, Jesse David and Frissen, Ilja},
title = {Mac Users Do It Differently: The Role of Operating System and Individual Differences in File Management},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382944},
doi = {10.1145/3334480.3382944},
abstract = {Despite much discussion in HCI research about how individual differences likely determine computer users' personal information management (PIM) practices, the extent of the influence of several important factors remains unclear, including users' personalities, spatial abilities, and the different software used to manage their collections. We therefore analyse data from prior CHI work to explore (1) associations of people's file collections with personality and spatial ability, and (2) differences between collections managed with different operating systems and file managers. We find no notable associations between users' attributes and their collections, and minimal predictive power, but do find considerable and surprising differences across operating systems. We discuss these findings and how they can inform future research.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {personal information management, spatial ability, computer files, personality traits},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382824,
author = {Shen, Yilu and Kelly, Ryan M.},
title = {CoasterMe: Supporting Informal Workplace Awareness Through the Everyday Behaviour of Drinking},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382824},
doi = {10.1145/3334480.3382824},
abstract = {Maintaining awareness of the presence of colleagues can be difficult when collaboration is distributed across separate offices. In this paper we present CoasterMe, a situated desktop widget that leverages the natural behaviour of drinking to support informal awareness of a colleague's availability in the workplace. A pilot field trial showed that CoasterMe helped coworkers to build in-the-moment awareness of availability and supported an improved understanding of work routines, enhancing social coordination and preventing wasted effort. CoasterMe also created a sense of co-presence and connectedness by making users feel as if they are sharing a drink over distance.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {office awareness, workplace communication, coordination},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375229,
author = {Magyar, Nathan and Xu, Xuenan and Maher, Molly},
title = {Creating and Evaluating a Goal Setting Prototype for MOOCs},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375229},
doi = {10.1145/3334480.3375229},
abstract = {This case study focuses on the design and evaluation of a goal setting web application for use in online courses. Our process included background research, competitive analysis, internal feature brainstorming, persona creation, a Lightning Decision Jam, and high-fidelity prototyping [2]. We assessed our design using e-Learning System Evaluations and usability tests [1]. Key takeaways include: (a) the Lightning Decision Jam is an engaging, inclusive, and helpful exercise for narrowing down a project's scope; (b) e-Learning System Evaluations elicit more detailed feedback than usability tests, but they may not be well-suited for testing prototypes with limited functionality; and (c) the conversational nature of usability tests may lead to more ideas for new features, but these tests do not give participants the opportunity to think deeply before providing feedback. These findings have implications for user experience designers and researchers, as well as those interested in new brainstorming and system evaluation methods.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {goal setting, MOOC, online learning},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375025,
author = {Tejada, Carlos E.},
title = {Print-and-Play: 3D-Printed Interactive Objects Without Assembly or Calibration},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375025},
doi = {10.1145/3334480.3375025},
abstract = {In recent years, 3D-printing technology has become widely accessible to non-experts and hobbyists, enabling them to fabricate objects of varying geometries. In contrast to this new ease of producing new forms, fabricating objects that can sense user input traditionally requires the assembly of complex circuits and physical parts. With my work, I explore what I call pap: 3D-printed interactive objects without requiring any post-print activities such as assembly or calibration. I approach this by by externally sensing how the user's actions interact with well-studied physical phenomena (e.g., acoustic resonance and fluid dynamics). I have developed two novel techniques using this principle: , a blow-based interaction technique for fabricated objects using acoustic resonance; and , a technique for fabricating touch-sensitive objects using pneumatic sensing and fluid dynamics principles.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {interactive fabricated objects, fabrication, 3d-printing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375022,
author = {Wang, Yan},
title = {Understanding the Design of Playful Gustosonic Experiences},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375022},
doi = {10.1145/3334480.3375022},
abstract = {Sound plays a vital role in our relationship with food, this is highlighted through the term "gustosonic experience". However, when it comes to designing celebratory technology for eating - i.e. technology that celebrates the experiential and in particular often playful aspects of eating , the use of sound has been mostly underexplored. My PhD research explores the opportunity to use interactive technology to enrich playful eating experiences through sounds. Via a research-through-design approach, I designed and evaluated two systems that generate digital sounds as a result of eating ice cream, contributing to our understanding of the design of interactive gustosonic experiences. I hope that this work can guide designers in creating gustosonic experiences supporting a more playful relationship with food.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {gustosonic, sounds, human-food-interaction, play},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383179,
author = {Vasquez, Joshua and Twigg-Smith, Hannah and Tran O'Leary, Jasper and Peek, Nadya},
title = {Jubilee Demo: An Extensible Machine for Multi-Tool Fabrication},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383179},
doi = {10.1145/3334480.3383179},
abstract = {We present Jubilee, an open-source motion platform extensible to custom applications and application media by means of interchangeable bed plates and automatic tool-changing. We describe Jubilee as an piece of infrastructure that can be readily adapted to a specialty task requiring precise computer control of one more tools without necessitating machine design expertise. To this end, Jubilee is designed to be readily reproduced solely from the documentation in a worldwide setting without relying on specialized manufacturing processes or volume discounts. Additionally, our paper provides a series of application examples involving various tools spanning from multimaterial 3D printing to multicolor pen plotting to multi-syringe liquid handling to microscopy.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {multi-tool workflows, toolchanging, digital fabrication},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383170,
author = {Wu, Shengzhi and Byrne, Daragh and Steenson, Molly Wright},
title = {"Megereality": Leveraging Physical Affordances for Multi-Device Gestural Interaction in Augmented Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383170},
doi = {10.1145/3334480.3383170},
abstract = {We present a novel gestural interaction strategy for multi-device interactions in augmented reality (AR), in which we leverage existing physical affordances of everyday products and spaces for intuitive interactions in AR. To explore this concept, we designed and prototyped three demo scenarios: pulling virtual sticky notes from a tablet, pulling a 3D model from a computer display, and 'slurping' color from the real-world environment to smart lights with a virtual eyedropper. By merging the boundary of digital and physical, utilizing metaphors in AR and embodying the abstract process, we demonstrate an interaction strategy that harnesses the physical affordances to assist digital interaction in AR with hand gestures.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {multi-device controls, augmented reality, gestural interaction, physical affordances},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383154,
author = {Byun, Jeongmin and Park, Jungkook and Oh, Alice},
title = {Cocode: Co-Learner Screen Sharing for Social Translucence in Online Programming Courses},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383154},
doi = {10.1145/3334480.3383154},
abstract = {Online courses are popular among learners of programming, but many learners have trouble completing the courses. A common approach to increase learner engagement is to provide co-learner presence via chat and forums. In this work, we present Cocode, an online learning system where learners can share their presence without any explicit action; their normal learning activities would signal co-learner presence. Cocode is a web application for online programming courses that shows other learners' code editors and running screens in the programming environment to the learners while working on exercises. Results from our between-subject studies show that learners with Cocode are more engaged and work on more programming exercises compared to the learners using the system without social features.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {social translucence, online course, education, programming course},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383150,
author = {Li, Guozheng and Tian, Min and Xu, Qinmei and McGuffin, Michael J. and Yuan, Xiaoru},
title = {Tree Illustrator: Interactive Construction of Tree Visualizations},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383150},
doi = {10.1145/3334480.3383150},
abstract = {We present Tree Illustrator, an interactive authoring tool of tree visualizations. Tree Illustrator is based on GoTree, a declarative grammar allowing users to create tree visualizations by configuring three aspects: visual elements, layout, and coordinate system. Within the set of all possible tree visualization techniques, we identify a subset of techniques that are both "unit-decomposable" and "axis-decomposable" (terms we define). For tree visualizations within this subset, Tree Illustrator provides the users with flexible and fine-grained control over the parameters of the techniques, supporting not only existing techniques but also undiscovered and hybrid visualizations.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {authoring tool, tree visualization, declarative grammar},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383135,
author = {Han, Changyo and Takahashi, Ryo and Yahagi, Yuchi and Naemura, Takeshi},
title = {PneuModule: Using Inflatable Pin Arrays for Reconfigurable Physical Controls on Pressure-Sensitive Touch Surfaces},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383135},
doi = {10.1145/3334480.3383135},
abstract = {We present PneuModule, a tangible interface platform that enables users to reconfigure physical controls on pressure-sensitive touch surfaces using pneumatically-actuated inflatable pin arrays. PneuModule consists of two types of different passive modules: a main module and extension modules. The main module can be customized by attaching extension modules that have distinct physical input modalities. The extension modules are hot-swappable, enable users to quickly customize the interface layout. We showcase the feasibility of PneuModule through a series of interactive demonstrations.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {tangible user interfaces, pneumatic actuation, pressure-sensitive touch surfaces, reconfigurable physical controls},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383056,
author = {Chen, Si and Cheng, Haocong and Huang, Yun},
title = {Who Is Changing Your Question on a Social Q&amp;A Website?},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383056},
doi = {10.1145/3334480.3383056},
abstract = {Effective moderation of online communities is an important, but challenging, topic in HCI. In this paper, we study people's co-editing behavior on one of the most popular social Q&amp;A websites in China, called Zhihu.com. We examined question logs to understand who/when/how a question is edited differently by multiple users; we also conducted semi-structured interviews with users who edited others' questions on Zhihu to understand their motivations and their perceptions of co-editing behavior, as well as their concerns and suggestions for future website designs for moderating such behavior. Our findings reveal that although co-editing questions is perceived as a positive and effective approach for improving questions' answerability and shaping norms in the online community, effective moderation mechanisms need to be designed to improve transparency and communication about co-editing behavior and to address possible tensions as a result of co-editing wars.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {social Q&amp;A, co-editing questions, online communities, moderation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383026,
author = {Roebuck Williams, Rhoslyn and Varcoe, Xan and Glowacki, Becca R. and Gale, Ella M. and Jamieson-Binnie, Alexander and Glowacki, David R.},
title = {Subtle Sensing: Detecting Differences in the Flexibility of Virtually Simulated Molecular Objects},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383026},
doi = {10.1145/3334480.3383026},
abstract = {During VR demos we have performed over last few years, many participants (in the absence of any haptic feedback) have commented on their perceived ability to 'feel' differences between simulated molecular objects. The mechanisms for such 'feeling' are not entirely clear: observing from outside VR, one can see that there is nothing physical for participants to 'feel'. Here we outline exploratory user studies designed to evaluate the extent to which participants can distinguish quantitative differences in the flexibility of VR-simulated molecular objects. The results suggest that an individual's capacity to detect differences in molecular flexibility is enhanced when they can interact with and manipulate the molecules, as opposed to merely observing the same interaction. Building on these results, we intend to carry out further studies investigating humans' ability to sense quantitative properties of VR simulations without haptic technology.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {virtual reality, molecular simulation, sensing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382962,
author = {Babic, Teo and Perteneder, Florian and Reiterer, Harald and Haller, Michael},
title = {Simo: Interactions with Distant Displays by Smartphones with Simultaneous Face and World Tracking},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382962},
doi = {10.1145/3334480.3382962},
abstract = {The interaction with distant displays often demands complex, multi-modal inputs which need to be achieved with a very simple hardware solution so that users can perform rich inputs wherever they encounter a distant display. We present Simo, a novel approach, that transforms a regular smartphone into a highly-expressive user motion tracking device and controller for distant displays. Both the front and back cameras of the smartphone are used simultaneously to track the user's hand as well as the head, and body movements in real-world space and scale. In this work, we first define the possibilities for simultaneous face- and world-tracking using current off-the-shelf smartphones. Next, we present the implementation of a smartphone app enabling hand, head, and body motion tracking. Finally, we present a technical analysis outlining the possible tracking range.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {augmented reality, 3D interaction, spatial interaction, smartphone, motion tracking, mobile devices, distant displays},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382956,
author = {Nukarinen, Tomi and Istance, Howell O. and Rantala, Jussi and M\"{a}kel\"{a}, John and Korpela, Kalevi and Ronkainen, Kimmo and Surakka, Veikko and Raisamo, Roope},
title = {Physiological and Psychological Restoration in Matched Real and Virtual Natural Environments},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382956},
doi = {10.1145/3334480.3382956},
abstract = {We present a study comparing physiological and psychological restoration in matched real and virtual natural environments. Participants (n=24) experienced a real forest, or one of two audiovisual virtual forests wearing a head-mounted display: A 3D forest or a 360-degree video. The results showed that some of the benefits of the real forest could also be obtained using virtual equivalents. Furthermore, we found the 3D forest to be emotionally more restorative than the 360-degree video forest. The findings can be used in creating restorative virtual environments for people who are unable to visit real natural environments.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {virtual reality, head-mounted display, restoration, virtual natural environment},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382947,
author = {Britain, Gabriel and Jain, Ajit and Lupfer, Nic and Kerne, Andruid and Perrine, Aaron and Seo, Jinsil and Sungkajun, Annie},
title = {Design is (A)Live: An Environment Integrating Ideation and Assessment},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382947},
doi = {10.1145/3334480.3382947},
abstract = {Design coursework is iterative and continuously-evolving. Separation of digital tools used in design courses disaffects instructors' and students' iterative process experiences.We present a system that integrates support for design ideation with a learning analytics dashboard. A preliminary study deployed the system in two courses, each with ~15 students and 1 instructor, for three months. We conducted semi-structured interviews to understand user experiences.Findings indicate benefits when systems contextualize creative work with assessment by integrating support for ideation with a learning analytics dashboard. Instructors are better able to track students and their work. Students are supported in reflecting on relationships among deliverables. We derive implications for contextualizing design with feedback to support creativity, learning, and teaching.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {iterative design, design assessment, design ideation, creativity, design education, learning analytics dashboard},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382910,
author = {Prange, Sarah and Alt, Florian},
title = {I Wish You Were Smart(Er): Investigating Users' Desires and Needs Towards Home Appliances},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382910},
doi = {10.1145/3334480.3382910},
abstract = {In this work, we present findings from an online survey (N=77) in which we assessed situations of users wishing for features or devices in their home to be smart(er). Our work is motivated by the fact that on one hand, several successful smart devices and features found their way into users' homes (e.g., smart TVs, smart assistants, smart toothbrushes). On the other hand, a more holistic understanding of when and why users would like devices and features to be smart is missing as of today. Such knowledge is valuable for researchers and practitioners to inform the design of future smart home devices and features, in particular with regards to interaction techniques, privacy mechanisms, and, ultimately, acceptance and uptake. We found that users would appreciate smart features for various use cases, including remote control and multi-tasking, and are willing to share devices. We believe our work to be useful for designers and HCI researchers by supporting the design and evaluation of future smart devices.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {smart devices, smart homes, online survey},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382908,
author = {Ahn, Sunggeun and Son, Jeongmin and Lee, Sangyoon and Lee, Geehyuk},
title = {Verge-It: Gaze Interaction for a Binocular Head-Worn Display Using Modulated Disparity Vergence Eye Movement},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382908},
doi = {10.1145/3334480.3382908},
abstract = {The Midas touch problem is a well-known problem in eye gaze interaction techniques. We present Verge-it as a Midas touch free input technique using modulated disparity vergence eye movement for a binocular head-worn display. We conducted a feasibility study under two different visual background conditions, namely dynamic background (TV) and static background (Wall) conditions. This study revealed a low false positive rate (TV: 0%, Wall: 2.10%) for Verge-it and acceptable performance.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {gaze input, vergence eye movements, AR/VR, modulated disparity vergence, head-worn display, midas-touch},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382848,
author = {Schmidmaier, Matthias and Hu\ss{}mann, Heinrich and Runge, Dominik Maurice},
title = {Beep Beep: Building Trust with Sound},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382848},
doi = {10.1145/3334480.3382848},
abstract = {Audio is one modality that besides content transmission offers non-verbal cues that influence emotional perception. This allows to increase trust for example in privacy-sensitive systems like digital assistants. In this work we focus on basic audio feedback and explore how parameters like melody, pitch or tempo influence the creation of trust. We refer to related research in trust perception of voice, and evaluate if the derived concepts can be universally applied to simple sound patterns. Our study (n=39) shows significant effects for melody and mode, while tendencies were found for pitch and individual user preferences. We consider our findings to serve as basis for research towards the design of unobtrusive and trustworthy user experiences.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {affective interaction design, trustful HCI, audio feedback},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382818,
author = {Samson, Briane Paul V. and Sumi, Yasuyuki},
title = {Are Two Heads Better than One? Exploring Two-Party Conversations for Car Navigation Voice Guidance},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382818},
doi = {10.1145/3334480.3382818},
abstract = {Voice guidance for car navigation typically considers drivers as docile actors. Recent works highlight limitations to this assumption which make drivers rely less on given directions. To explore how drivers can make better navigation decisions, we conducted a pilot Wizard-of-Oz study that gives turn suggestions in conversations between two voice agents. We asked 30 participants to drive in a simulation environment using voice guidance that gives three types of suggestions: familiar, optimal, and new routes. We examined their route choices, perceived workload and utterances while driving. We found that while most drivers followed directions appropriate for the given scenarios, they were more likely to make inappropriate choices after hearing alternatives in conversations. On the other hand, two-party conversations allowed drivers to better reflect on their choices after trips. We conclude by discussing preliminary design implications for car navigation voice guidance specifically and recommender systems in general.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {two-party conversation, driving, voice guidance, recommender systems, voice agents, navigation applications},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381811,
author = {Kirman, Ben and Lawson, Shaun and Linehan, Conor},
title = {What's Your Problem with the Dog Internet?},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381811},
doi = {10.1145/3334480.3381811},
abstract = {In this paper, we make an argument for using "the absurd" as a useful lens through which to critique modern developments in interactive technology. We argue that absurd positions are generative and engaging; they provide scope and direction for developing artefacts that people want to talk about and discuss. We argue for adopting absurd positions because; 1) as publicly funded academics, unbeholden to commercial interests, we can, 2) it's fun, and 3) doing so draws out, highlights, and plays with the often weird, fake, nonsense, bizarre, and surreal aspects of modern interactive technology artefacts - and the often weird situations that arise when interacting with those artefacts. In order to illustrate this argument, we present a number of case studies drawn from 10 years of our absurd research papers, many of which were published at previous iterations of this conference.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {adversarial design, critical design, alt.chi, absurd, troublemaking},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381661,
author = {Shah, Ajmal},
title = {On The Other Side: An Interactive Narrative to Incite Awareness and Empathy Towards Social Effects of Chronic Pain},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381661},
doi = {10.1145/3334480.3381661},
abstract = {Chronic pain is an ailment that affects over 60 million [1] people all over the world. It is a poorly understood condition by both clinicians and the society at large. Chronic pain manifests in many different forms and imposes immense physical limitations on the sufferer's body. However, the social and mental issues associated with chronic pain are often overlooked. Although modern medicine alleviates the physical symptoms of chronic pain, it fails to address issues that feast on the sufferer's mental health. Moreover, awareness, acceptance and empathy towards the sufferers are lacking in the society. On the other side is an interactive narrative that employs gameplay as a medium to induce empathy and awareness about social stigmatization and isolation that patients with chronic pain conditions face. The narrative transports the player into the troubled life of a chronic pain patient and their altered relationship with their own body.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {storyboarding, conceptualization, gameplay, mobile experience, chronic pain, empathy},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381066,
author = {Talkad Sukumar, Poorna and Avellino, Ignacio and Remy, Christian and DeVito, Michael A. and Dillahunt, Tawanna R. and McGrenere, Joanna and Wilson, Max L.},
title = {Transparency in Qualitative Research: Increasing Fairness in the CHI Review Process},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381066},
doi = {10.1145/3334480.3381066},
abstract = {Transparency in process and its reporting is paramount for establishing the rigor of qualitative studies. However, the CHI conference receives submissions with varying levels of transparency and oftentimes, papers that are more transparent can be inadvertently subjected to more scrutiny in the review process, raising issues of fairness. In this panel, we bring together researchers with diverse qualitative work experiences to present examples of transparency-related initiatives and their corresponding review responses. We aim to work towards setting standards for transparent reporting in qualitative-work submissions and increasing fairness in the review process. We focus on the challenges in achieving transparency in qualitative research and current workarounds to overcome frictions in the reviewing process through engaging discussions involving panelists and the audience.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {open research, qualitative research, transparency, peer review},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381054,
author = {Schartm\"{u}ller, Clemens and Sarcar, Sayan and Riener, Andreas and Kun, Andrew L. and Shaer, Orit and Boyle, Linda Ng and Iqbal, Shamsi},
title = {Automated Cars as Living Rooms and Offices: Challenges and Opportunities},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381054},
doi = {10.1145/3334480.3381054},
abstract = {With increasing automation of the driving task, cars' cockpits are transforming towards living spaces rather than pure modalities of transport. The promise of automated vehicles being individual places for relaxation and productivity while on-the-go, however, requires significant research. Not only safety-critical questions, but also issues related to ergonomic design, human factors for interactive systems, and social aspects have to be investigated. This special interests group presents an opportunity for connecting various CHI communities on these problems, which need to be solved under time-pressure, because automated vehicles are coming - whether or not the HCI-related issues are solved.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {well-being, automated driving, work, special interests group},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375231,
author = {Kliman-Silver, Clara and Siy, Oliver and Awadalla, Kira and Lentz, Alison and Convertino, Gregorio and Churchill, Elizabeth},
title = {Adapting User Experience Research Methods for AI-Driven Experiences},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375231},
doi = {10.1145/3334480.3375231},
abstract = {This short paper describes how to adapt user experience research methods for artificial intelligence (AI)-driven applications. Presently, there is a dearth of guidance for conducting UX research on AI-driven experiences. We describe what makes this class of experiences unique, propose a preliminary foundational framework to categorize AI-driven experiences, and within the framework we show an example of methodological adaptations via a case study.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {methods, user experience research, artificial intelligence, internet of things},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375212,
author = {Baba, Jun and Sichao, Song and Nakanishi, Junya and Kuramoto, Itaru and Ogawa, Kohei and Yoshikawa, Yuichiro and Ishiguro, Hiroshi},
title = {Teleoperated Robot Acting Autonomous for Better Customer Satisfaction},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375212},
doi = {10.1145/3334480.3375212},
abstract = {In recent years, an increasing number of teleoperated robots have been used to provide services from a remote location. Most earlier teleoperated robot systems informed the customers that the robots are being remotely controlled, while the customers believed that they were communicating with the operators through the robots. However, it has already been shown that there are some disadvantages in informing customers about the robot teleoperation. To investigate whether customers could accept and use teleoperated robots that acted as if they were autonomous, we developed a teleoperated system in which operators represent autonomous robots. Our system was experimentally tested by employing operators that provided services to customers in a real field. It was found that many customers were particularly satisfied with the service of the teleoperated robots that behaved as if they were autonomous, while we demonstrated that customers who did not realize the robot teleoperation rated the service higher than the customers who realized the same.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {led, voice changer, teleoperated robot, webrtc, autonomous, human robot interaction, speech recognition, design prototyping},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375176,
author = {Bellini, Rosanna and Dell, Nicola and Whitty, Monica and Bhattacharya, Debasis and Wall, David and Briggs, Pamela},
title = {Crime and/or Punishment: Joining the Dots between Crime, Legality and HCI},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375176},
doi = {10.1145/3334480.3375176},
abstract = {We aim to bring together a number of designers, researchers and practitioners to share their experience of the influence of crime and legality on their work. Through these discussions, we aspire to highlight the existing knowledge base for discussions of crime within HCI, provide a space for sharing researcher's personal experiences in their work with and against crime, and highlight best practice going forwards. We will do this by using three considerations to inform our critical focus on crime: (1) mapping out the existing ways that HCI has addressed crime; (2) considering what part crime plays in approaches to social justice; (3) questioning who is thus morally responsible for the criminal activity of others, and what does this entail for ensuring fair approaches within technical design.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {theories of justice, social justice, legality, criminal justice system, law enforcement},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375162,
author = {Sadeghian Borojeni, Shadan and Meschtscherjakov, Alexander and Pfleging, Bastian and Donmez, Birsen and Riener, Andreas and Janssen, Christian P. and Kun, Andrew L. and Ju, Wendy and Remy, Christian and Wintersberger, Philipp},
title = {Should I Stay or Should I Go? Automated Vehicles in the Age of Climate Change},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375162},
doi = {10.1145/3334480.3375162},
abstract = {Will automated driving help or hurt our efforts to remedy climate change? The overall impact of transportation and mobility on the global ecosystem is clear: changes to that system can greatly affect climate outcomes. The design of mobility and automotive systems will influence key factors such as driving style, fuel choice, ride sharing, traffic patterns, and total mileage. However, to date, there are few research efforts that explicitly focus on these overlapping themes (automated driving &amp; climate changes) within the HCI and AutomotiveUI communities. Our intention is to grow this community and awareness of the related problems. Specifically, in this workshop, we invite designers, researchers, and practitioners from the sustainable HCI, persuasive design, AutomotiveUI, and mobility communities to collaborate in finding ways to make future mobility more sustainable. Using embodied design improvisation and design fiction methods, we will explore the ways that systems affect behavior which then affect the environment.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {CO2 reduction, automated driving, climate change, collective optimization, future mobility, energy efficient driving},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375150,
author = {Spiel, Katta and Gerling, Kathrin and Bennett, Cynthia L. and Brul\'{e}, Emeline and Williams, Rua M. and Rode, Jennifer and Mankoff, Jennifer},
title = {Nothing About Us Without Us: Investigating the Role of Critical Disability Studies in HCI},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375150},
doi = {10.1145/3334480.3375150},
abstract = {Accessibility concerns play an increasing role in Human-Computer Interaction (HCI) research. This workshop takes a look at the role Critical Disability Studies currently plays in the development of assistive technologies and the accessibility of technologies more generally. Accordingly, it has been ten years since Mankoff's seminal paper on "Disability Studies as a Source of Critical Inquiry for the Field of Assistive Technology'' drew out the requirement of actively involving disabled people in research about them. We find it a fitting time for reflecting on and revitalising the topic. We will examine untapped research opportunities and identify systemic obstacles that keep disabled scholars in the margins of associated research. The gathering additionally serves to establish a community of researchers interested in pursuing the perspective of Critical Disability Studies within HCI.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {participatory research, critical disability studies, interaction design, assistive technologies},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375147,
author = {Li, Yang and Kumar, Ranjitha and Lasecki, Walter S. and Hilliges, Otmar},
title = {Artificial Intelligence for HCI: A Modern Approach},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375147},
doi = {10.1145/3334480.3375147},
abstract = {Artificial intelligence (AI) and Human Computer Interaction (HCI) share common roots and early work on conversational agents has laid the foundation for both fields. However, in subsequent decades the initial tight connection between the fields has become less pronounced. The recent rise of deep learning has revolutionized AI and has led to a raft of practical methods and tools that significantly impact areas outside of core-AI. In particular, modern AI techniques now power new ways for machines and humans to interact. Thus it is timely to investigate how modern AI can propel HCI research in new ways and how HCI research can help direct AI developments. This workshop offers a forum for researchers to discuss new opportunities that lie in bringing modern AI methods into HCI research, identifying important problems to investigate, showcasing computational and scientific methods that can be applied, and sharing datasets and tools that are already available or proposing those that should be further developed. The topics we are interested in including deep learning methods for understanding and modeling human behaviors and enabling new interaction modalities, hybrid intelligence that combine human and machine intelligence to solve difficult tasks, and tools and methods for interaction data curation and large-scale data-driven design. At the core of these topics, we want to start the conversation on how data-driven and data-centric approaches of modern AI can impact HCI.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {data-driven design and modeling, crowdsourcing, design guidelines, algorithms and tools, artificial intelligence, deep learning, sensing, human computer interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382995,
author = {Maus, Natalie and Rutledge, Dalton and Al-Khazraji, Sedeeq and Bailey, Reynold and Alm, Cecilia Ovesdotter and Shinohara, Kristen},
title = {Gaze-Guided Magnification for Individuals with Vision Impairments},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382995},
doi = {10.1145/3334480.3382995},
abstract = {Video-based eye trackers increasingly have potential to improve on-screen magnification for low-vision computer users. Yet, little is known about the viability of eye tracking hardware for gaze-guided magnification. We employed a magnification prototype to assess eye tracking quality for low-vision users as they performed reading and search tasks. We show that a high degree of tracking loss prevents current video-based eye tracking from capturing gaze input for low-vision users. Our findings show current technologies were not made with low vision users in mind, and we offer suggestions to improve gaze-tracking for diverse eye input.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {low vision, magnifier, video-based eye tracking},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382953,
author = {Zenner, Andr\'{e} and Kosmalla, Felix and Ehrlich, Jan and Hell, Philip and Kahl, Gerrit and Murlowski, Christian and Speicher, Marco and Daiber, Florian and Heinrich, Daniel and Kr\"{u}ger, Antonio},
title = {A Virtual Reality Couch Configurator Leveraging Passive Haptic Feedback},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382953},
doi = {10.1145/3334480.3382953},
abstract = {When configuring furniture during sales consultancy in a furniture store, customers are usually confronted with abstract 2D drawings or simplistic renderings of the discussed configuration on a display. We present a novel application based on virtual reality (VR) to support furniture store consultations. Our system allows customers to elaborate different configurations of a couch in dialogue with a sales expert and lets customers experience them through immersive VR in a variety of virtual environments. While the sales-expert can modify the couch layout and fabric, the customer can stay immersed and experience a realistic tactile feeling of the configured couch through passive haptic feedback provided by a sample piece the customer can sit on. A preliminary field study in a furniture store showed that the system is immersive, conveying realistic impressions of the couch configurations. Customers perceived the VR configurator as useful since it would make their purchase decisions easier.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {user study, virtual reality, immersion, passive haptic feedback, application, furniture configuration},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381809,
author = {Seymour, William and Van Kleek, Max},
title = {Does Siri Have a Soul? Exploring Voice Assistants Through Shinto Design Fictions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381809},
doi = {10.1145/3334480.3381809},
abstract = {It can be difficult to critically reflect on technology that has become part of everyday rituals and routines. To combat this, speculative and fictional approaches have previously been used by HCI to decontextualise the familiar and imagine alternatives. In this work we turn to Japanese Shinto narratives as a way to defamiliarise voice assistants, inspired by the similarities between how assistants appear to 'inhabit' objects similarly to kami. Describing an alternate future where assistant presences live inside objects, this approach foregrounds some of the phenomenological quirks that can otherwise easily become lost. Divorced from the reality of daily life, this approach allows us to reevaluate some of the common interactions and design patterns that are common in the virtual assistants of the present.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice assistants, design fiction, shinto, critical design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375211,
author = {Barba, Evan and Lioon, Anthony and Miller, Christopher and Khan, Yasir Majeed},
title = {Tele-Robotic Interface Design in Context: A Case for Recursive Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375211},
doi = {10.1145/3334480.3375211},
abstract = {Satellites have useful lifetimes of only a few decades; however, these could easily be extended if consumable resources could be replaced. Many groups are now exploring the possibility of using unmanned orbital robots to perform satellite servicing operations. These orbiting robots are currently semi-autonomous and require monitoring and control by highly trained ground teams in order to complete their activities. This provides for a unique and tightly constrained operating environment with very particular interface needs. Here, we document the process we used for developing a tele-robotic interface specific to NASA's Restore-L mission, and describe the choices and considerations we weighed when implementing our designs. We discuss the technical and mission parameters as well as the social and operational context of our work, and articulate the need for a design framework that is capable of better connecting these two domains.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {multi-scale design, systemic design, human-robot interaction, data visualization, recursive design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3386147,
author = {Dumais, Susan T.},
title = {SIGCHI Lifetime Research Award Talk: Interdisciplinary Perspectives on Search},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3386147},
doi = {10.1145/3334480.3386147},
abstract = {I have long been interested in how people seek information from external sources and make sense of the results. While the sources of information have continued to evolve over the years from libraries, to web search engines, to virtual assistants, many important challenges and opportunities remain. The success of any information retrieval systems depends critically on both the ability to support people in articulating their information needs and making sense of the results to solve the problem that motivated their search in the first place, as well as the need to efficiently and effectively find relevant information. My research combines these two dimensions into an interdisciplinary, user-centered perspective on information systems.My interest in information retrieval started in the early 1980's with the observation that different people use a surprisingly wide variety of words to describe the same object or concept. This fundamental characteristic of human language set limits on how well simple word-matching techniques can do in satisfying information needs. In a paper at the pre-CHI Gaithersburg conference in 1982 [6] we describe this problem as statistical semantics. (It is symptomatic of the problem that we subsequently used vocabulary mismatch, verbal disagreement, and statistical semantics to refer to the same problem.) Over the next decade, with colleagues at Bell Labs, I developed and evaluated solutions that involved collecting multiple descriptors for objects, and reducing the dimensionality of the representation using techniques like Latent Semantic Indexing (LSI) [3][7] to mitigate the disagreement between the vocabulary that authors use in writing and searchers use to express their information needs. Similar approaches (combined with a lot more data and compute) are used to power modern word-embedding techniques that widely used in natural language processing.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–3},
numpages = {3},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383178,
author = {Pietroszek, Krzysztof},
title = {"Vera"  Crossing the Fourth Wall},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383178},
doi = {10.1145/3334480.3383178},
abstract = {"Vera" is an adaptation of a short story by New Zealand's early XXth-century feminist writer, Katherine Mansfield. It is a unique artificial reality experience that allows viewers to cross the so-called fourth wall between the film reality and the audience's reality. The experience allows the viewer to "enter" a film frame via a mixed reality tabletop experience. To our knowledge, "Vera" is the first immersive experience that utilizes both volumetric capture (instead of avatar animation) and photogrammetric reconstruction of the set decoration and props. It is also the first experiment that literally rather than metaphorically crosses the fourth wall.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {augmented reality, holograms, virtual reality, computational theater, volumetric filmmaking, volumetric capture},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383161,
author = {Liao, Yi-Chi and Kim, Sunjun and Lee, Byungjoo and Oulasvirta, Antti},
title = {Press'Em: Simulating Varying Button Tactility via FDVV Models},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383161},
doi = {10.1145/3334480.3383161},
abstract = {Push-buttons provide rich haptic feedback during a press via mechanical structures. While different buttons have varying haptic qualities, few works have attempted to dynamically render such tactility, which limits designers from freely exploring buttons' haptic design. We extend the typical force-displacement (FD) model with vibration (V) and velocity-dependence characteristics (V) to form a novel FDVV model. We then introduce Press'Em, a 3D-printed prototype capable of simulating button tactility based on FDVV models. To drive Press'Em, an end-to-end simulation pipeline is presented that covers (1) capturing any physical buttons, (2) controlling the actuation signals, and (3) simulating the tactility. Our system can go beyond replicating existing buttons to enable designers to emulate and test non-existent ones with desired haptic properties. Press'Em aims to be a tool for future research to better understand and iterate over button designs.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {simulation, haptic rendering, FD model, force feedback, tactility, input device, button, FDVV model, haptic, modeling, vibration},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383157,
author = {Elkin, Lisa A. and Beau, Jean-Baptiste and Casiez, G\'{e}ry and Vogel, Daniel},
title = {A 26-Contact Tangible Pen-Like Input Device for Capacitive Displays},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383157},
doi = {10.1145/3334480.3383157},
abstract = {We designed and created a new self-contained tangible pen-like input device prototype that can sense all 26 contacts and works with any capacitive display using a conductive case designed with pliable corners. Contacts are distinguished using the device angle from an internal IMU. We further designed a 3D "mirror" visualization that displays a re-configurable mapping of commands to contacts to enable discovery of command-to-contact mappings.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {tangible interfaces, command selection, pen input},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383148,
author = {Strohmeier, Paul and Honnet, Cedric and Perner-Wilson, Hannah and Teyssier, Marc and Fruchard, Bruno and Baptista, Ana and Steimle, J\"{u}rgen},
title = {Demo of PolySense: How to Make Electrically Functional Textiles},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383148},
doi = {10.1145/3334480.3383148},
abstract = {We demonstrate a simple and accessible method for enhancing textiles with custom piezo-resistive properties. Based on in-situ polymerization, our method offers seamless integration at the material level, preserving a textile's haptic and mechanical properties. We demonstrate how to enhance a wide set of fabrics and yarns using only readily available tools. During each demo session, conference attendees may bring textile samples which will be polymerized in a shared batch. Attendees may keep these samples. While the polymerization is happening, attendees can inspect pre-made samples and explore how these might be integrated in functional circuits. Examples objects created using polymerization include rapid manufacturing of on-body interfaces, tie-dyed motion-capture clothing, and zippers that act as potentiometers.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {etextile, sensing, fabrication, piezoresistive},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383087,
author = {Sumini, Valentina and Muccillo, Manuel and Milliken, Jamie and Ekblaw, Ariel and Paradiso, Joseph},
title = {SpaceHuman: A Soft Robotic Prosthetic for Space Exploration},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383087},
doi = {10.1145/3334480.3383087},
abstract = {The project focuses on the human centered design approach for aiding crewed space operations in microgravity. The key element is enhancing the floating experience, while enabling humans to adapt in microgravity environments. The metaphor of the undersea world inspired the design of a body extension that can complement the interiors of Zero-G habitats. The analysis of the unique seahorse's tail structure became the insight into the overall biomimetic design. In fact, a seahorse tail enables movement, gripping and protection to the seahorse while floating. SpaceHuman is an additive prosthetic that can move around the body to grasp objects and handles in microgravity, protecting the wearer from injuries that might occur while floating in a confined habitat, while providing an adaptable and kinematically stable base. SpaceHuman has been designed through different computational design methods, to simulate its behavior in microgravity, and has been worn and tested on a Zero-G flight.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {microgravity, wearable soft-robotic device, additive prosthetic, biomimetic design, human space exploration},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383031,
author = {Taylor, Jennyfer Lawrence and Aboriginal Shire Council, Wujal Wujal and Soro, Alessandro and Esteban, Michael and Vallino, Andrew and Roe, Paul and Brereton, Margot},
title = {Crocodile Language Friend: Tangibles to Foster Children's Language Use},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383031},
doi = {10.1145/3334480.3383031},
abstract = {Active language use refers to people's use of a language in their everyday lives and activities. Tangible User Interfaces (TUIs) can facilitate children's participation in language activities such as language learning, communication, storytelling, and social play. However, few TUI projects take the lens of active language use, and exploit the benefits of tangibles for maintaining and revitalising endangered languages. We present the Crocodile Language Friend, co-designed with the Wujal Wujal community, to foster children's use of the Kuku Yalanji Aboriginal language. We contribute a discussion of the ways in which the crocodile's physical characteristics (e.g. size, shape, materials, and personalization) can encourage language use in individual and social activities beyond the affordances of screen-based systems.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {children, active language use, language learning, indigenous languages, tangible interfaces},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383027,
author = {Mancini, Maurizio and Niewiadomski, Radoslaw and Huisman, Gijs and Bruijnes, Merijn and Gallagher, Conor Patrick},
title = {Room for One More? - Introducing Artificial Commensal Companions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383027},
doi = {10.1145/3334480.3383027},
abstract = {Commensality is defined as "a social group that eats together" and eating in a commensality setting has a number of positive effects on humans. In this paper, we discuss how HCI and technology in general can be exploited to replicate the benefits of commensality for people who choose or are forced to eat alone. We discuss research into and the design of Artificial Commensal Companions that can provide social interactions during food consumption. We present the design of a system, consisting of a toy robot, computer vision tracking, and a simple interaction model, that can show non-verbal social behaviors to influence a user's food choice. Finally, we discuss future studies and applications of this system, and provide suggestions for future research into Artificial Commensal Companions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {food, commensality, companion, interaction, non-verbal, eating, robot, HCI},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383024,
author = {Nakamura, Takuto and Koike, Hideki},
title = {Golf Club-Type Device with Force Feedback for Modifying Club Posture},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383024},
doi = {10.1145/3334480.3383024},
abstract = {On the golf-swing, the trajectory and face angle (angle of the golf-club head) of the golf-club greatly affect the direction and trajectory of the ball. Though the instruction of the golf-swing has been conducted to the beginners by the instructor or the consumer device specialized in the golf-swing training, it was difficult to modify the posture of golf-club during the swing. This is because the users require time to understand and express the instruction. Also, these instructions cannot convey detailed information to the users. Therefore, we propose a golf club type device mounting ungrounded force feedback module to modify the posture of golf-club during the golf-swing. In this paper, we implemented a prototype of the proposed device and the application using the device. The prototype was evaluated its performance and the results suggested the prototype generate sufficient torque to move the golf-club grasped by the user.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {force feedback, golf swing, gyro-effect},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382963,
author = {Du, Na and Zhou, Feng and Pulver, Elizabeth and Tilbury, Dawn and Robert, Lionel P. and Pradhan, Anuj K. and Yang, X. Jessie},
title = {Predicting Takeover Performance in Conditionally Automated Driving},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382963},
doi = {10.1145/3334480.3382963},
abstract = {In conditionally automated driving, drivers decoupled from operational control of the vehicle have difficulty taking over control when requested. To address this challenge, we conducted a human-in-the-loop experiment wherein the drivers needed to take over control from an automated vehicle. We collected drivers' physiological data and data from the driving environment, and based on which developed random forest models for predicting drivers' takeover performance in real time. Drivers' subjective ratings of their takeover performance were treated as the ground truth. The best random forest model had an accuracy of 70.2% and an F1-score of 70.1%. We also discussed the implications on the design of an adaptive in-vehicle alert system.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {human-robot interaction, human-automation interaction, transition of control, predictive modeling, adaptive in-vehicle alert system},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382931,
author = {Edwards, Emory James and Sum, Cella Monet and Branham, Stacy M.},
title = {Three Tensions Between Personas and Complex Disability Identities},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382931},
doi = {10.1145/3334480.3382931},
abstract = {Literature on the challenges of building personas for marginalized populations has led to attempts to update or improve the format. Construction of personas for people with disabilities and intersecting identities are underexplored in this area. Drawing on past work on the importance of intersectionality in HCI, this paper presents results from a qualitative interview study of nine participants with a) multiple disabilities or b) a disability and one or more other marginalized identities. From these findings, the authors present considerations for designers or researchers interested in creating personas depicting users at the intersection of marginalized identities.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {accessible computing, interview study, intersectionality, identity, personas, disability},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382906,
author = {Kim, Tae Soo and Hong, Sungsoo (Ray) and Goyal, Nitesh and Kim, Jeongyeon and Kim, Juho},
title = {Consensus Building in Collaborative Sequencing with Visual Awareness},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382906},
doi = {10.1145/3334480.3382906},
abstract = {Collaborative Sequencing (CoSeq) is the process by which a group selects and arranges a set of items into a particular order. CoSeq is ubiquitous, occurring across diverse situations like trip planning or course scheduling. Although indicating preferences, communicating, and consensus building in CoSeq can be overwhelming for groups, little research has aimed at effectively supporting this process. To understand the design space of CoSeq, we ran a formative study to observe how participants utilize visualizations to strategically reduce their cognitive burden. We derived a novel design to enable sequence comparison using visualizations and evaluated its effect through a study. We found that attitudinal measures for the efficiency and effectiveness of the consensus building process were significantly improved with our design.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {visual awareness, decision-making, group work, consensus},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382883,
author = {Dong, Ze and Piumsomboon, Thammathip and Zhang, Jingjing and Clark, Adrian and Bai, Huidong and Lindeman, Rob},
title = {A Comparison of Surface and Motion User-Defined Gestures for Mobile Augmented Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382883},
doi = {10.1145/3334480.3382883},
abstract = {Advancements in Augmented Reality (AR) technologies and processing power of mobile devices have created a surge in the number of mobile AR applications. Nevertheless, many AR applications have adopted surface gestures as the default method for interaction with virtual content. In this paper, we investigate two gesture modalities, surface and motion, for operating mobile AR applications. In order to identify optimal gestures for various interactions, we conducted an elicitation study with 21 participants for 12 tasks, which yielded a total of 504 gestures. We classified and illustrated the two sets of gestures, and compared them in terms of goodness, ease of use, and engagement. The elicitation process yielded two separate sets of user-defined gestures; legacy surface gestures, which were familiar and easy to use by the participants, and motion gestures, which had better engagement. From the interaction patterns of this second set of gestures, we propose a new interaction class called TMR (Touch-Move-Release), which defines for mobile AR.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {mobile devices, elicitation study, surface gestures, gestures, augmented reality, motion gestures},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382875,
author = {Zhang, Ziyue and Huang, Jin and Tian, Feng},
title = {Modeling the Uncertainty in Pointing of Moving Targets with Arbitrary Shapes},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382875},
doi = {10.1145/3334480.3382875},
abstract = {When we try to acquire moving targets such as shooting enemies in computer games, the shapes of these targets are often varied. Considering the effects of target shape in moving target selection is essential for predicting user performances such as error rate in user interfaces involving dynamic content. In this paper, we propose a model to be descriptive of the endpoint uncertainty in pointing of moving targets with arbitrary shapes. The model combines the Gaussian mixture model (GMM) with a Ternary-Gaussian model to describe the impacts of target shape and target motion on selection endpoints of moving targets. Compared to the-state-of-the-art, our model achieved higher performance in the fitting of endpoint distribution and predicting selection error rate.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {error rate, arbitrary shape, moving target selection, endpoint distribution},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382813,
author = {Zhong, Sailin and Alavi, Hamed S. and Lalanne, Denis},
title = {Hilo-Wear: Exploring Wearable Interaction with Indoor Air Quality Forecast},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382813},
doi = {10.1145/3334480.3382813},
abstract = {The quality of air in office spaces can have far-reaching impacts on the well-being and productivity of office workers. We present a system, called Hilo, that can monitor the level of carbon dioxide (CO2) in an office and provide a fairly accurate forecast of its evolution in the next few minutes. The main objective is to inform and to support the users in taking preventive actions when a harmful level of CO2 is predicted. We elicited three main elements of such prediction — Risk, Temporal Proximity, and Certainty, and explored alternative ways of displaying indoor CO2 forecast through these elements. To evaluate our prototypes, we conducted a preliminary&nbsp;user study, in which three interfaces on Apple Watch were tested by 12 participants (within-subjects, a total of 36 sessions).&nbsp;In this paper, we describe the results of this study and discuss implications for future work on how to create an engaging interaction with the users about the quality of air in offices and particularly its forecast.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {human-building interaction, wearables, well-being, smart environments},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381827,
author = {Geeng, Christine and Author, Anonymous},
title = {EGregor: An Eldritch Privacy Mental Model for Smart Assistants},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381827},
doi = {10.1145/3334480.3381827},
abstract = {The increasing popularity of smart personal assistants has meant the rapid inclusion of data-collecting technology in homes. Research has shown that the privacy notices for these smart devices can be ineffective, as users often have incorrect mental models about what happens to data collected from them. To provide more effective data collection cues, we present a redesign of traditional, friendly smart assistant personas: eGregor, an eldritch hive mind being. Using science fiction concepts in conjunction with visceral notice, a concept that eschews purely text-based privacy indicators, eGregor more clearly represents the data practices of a hypothetical parent company. It has various aesthetic and auditory indicators and an intuitive and terrifying persona. We draw attention to the potential for major smart personal assistant companies to improve upon their user interface designs.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {security, privacy, iot, smart personal assistant, smart home},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381067,
author = {Kisselburgh, Lorraine and Beaudouin-Lafon, Michel and Cranor, Lorrie and Lazar, Jonathan and Hanson, Vicki L.},
title = {HCI Ethics, Privacy, Accessibility, and the Environment: A Town Hall Forum on Global Policy Issues},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381067},
doi = {10.1145/3334480.3381067},
abstract = {We seek to engage a broad and diverse audience in discussing emerging challenges in HCI technologies that have potential for significant social impact. In a town hall forum, members of the ACM Technology Policy Council will introduce four emerging challenges for discussion: ethical HCI in global contexts; privacy protection in human-AI interaction; accessible interactions in HCI design; and the environmental impact of HCI. Discussion will be launched with a question from the panel; additional questions will be posted and ranked from the audience. The session will support digital and remote audience participation, and participants will have access to a summary report when the session concludes. These discussions provide an opportunity for CHI members to contribute to emerging policy and governing environments to facilitate ethical, accessible, and environmentally sensitive HCI research, design, and development.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {policy, environment, ethics, privacy, social impact, hci},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

