@inproceedings{10.1145/3313831.3376732,
author = {Wambsganss, Thiemo and Niklaus, Christina and Cetto, Matthias and S\"{o}llner, Matthias and Handschuh, Siegfried and Leimeister, Jan Marco},
title = {AL: An Adaptive Learning Support System for Argumentation Skills},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376732},
doi = {10.1145/3313831.3376732},
abstract = {Recent advances in Natural Language Processing (NLP) bear the opportunity to analyze the argumentation quality of texts. This can be leveraged to provide students with individual and adaptive feedback in their personal learning journey. To test if individual feedback on students' argumentation will help them to write more convincing texts, we developed AL, an adaptive IT tool that provides students with feedback on the argumentation structure of a given text. We compared AL with 54 students to a proven argumentation support tool. We found students using AL wrote more convincing texts with better formal quality of argumentation compared to the ones using the traditional approach. The measured technology acceptance provided promising results to use this tool as a feedback application in different learning settings. The results suggest that learning applications based on NLP may have a beneficial use for developing better writing and reasoning for students in traditional learning settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {educational applications, pedagogical systems, adaptive learning, argumentation learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376709,
author = {Saint-Lot, Julie and Imbert, Jean-Paul and Dehais, Fr\'{e}d\'{e}ric},
title = {Red Alert: A Cognitive Countermeasure to Mitigate Attentional Tunneling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376709},
doi = {10.1145/3313831.3376709},
abstract = {Attentional tunneling, that is the inability to detect unexpected changes in the environment, has been shown to have critical consequences in air traffic control. The motivation of this study was to assess the design of a cognitive countermeasure dedicated to mitigate such failure of attention. The Red Alert cognitive countermeasure relies on a brief orange-red flash (300 ms) that masks the entire screen with a 15% opacity. Twenty-two air traffic controllers faced two demanding scenarios, with or without the cognitive countermeasure. The volunteers were not told about the Red Alert so as to assess the intuitiveness of the design without prior knowledge. Behavioral results indicated that the cognitive countermeasure reduced reaction time and improved the detection of the notification when compared to the classical operational design. Further analyses showed this effect was even stronger for half of our participants (91.7% detection rate) who intuitively understood the purpose of this design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {countermeasure, air traffic control, interruption, air traffic controller (atco), notification, attentional tunneling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376706,
author = {Kelliher, Aisling and Zilevu, Setor and Rikakis, Thanassis and Ahmed, Tamim and Truong, Yen and Wolf, Steven L.},
title = {Towards Standardized Processes for Physical Therapists to Quantify Patient Rehabilitation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376706},
doi = {10.1145/3313831.3376706},
abstract = {Physical rehabilitation typically requires therapists to make judgements about patient movement and functional improvement using subjective observation. This process makes it challenging to quantitatively track, compute and predict long-term patient improvement. We therefore propose a novel methodical approach to the standardized and interpretable quantification of patient movement during rehabilitation. We describe the expert-led development of a movement assessment rubric and an accompanying quantitative rating system. We present our movement capture and annotation computational tools designed to implement the rubric and assist therapists in the quantitative documentation and assessment of rehabilitation. We describe results from a movement capture study of the tool with nine stroke survivors and a movement rating study with four therapists. Findings from these studies highlight potential optimal methodical process paths for individuals engaged in capturing, understanding and predicting human movement performance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human movement capture, human movement assessment, stroke rehabilitation, home based rehabilitation therapy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376693,
author = {Bellini, Rosanna and Forrest, Simon and Westmarland, Nicole and Smeddinck, Jan David},
title = {Mechanisms of Moral Responsibility: Rethinking Technologies for Domestic Violence Prevention Work},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376693},
doi = {10.1145/3313831.3376693},
abstract = {This paper provides a critical examination of how digital systems within a charitable organisation in the North of England are being used to both support and challenge male perpetrators of domestic violence. While there exists a range of digital tools to support the victim-survivors of domestic violence, no tools are available to challenge the abusive and harmful behaviours of perpetrators. Through this work, we uncovered the compelling moral responsibilities intrinsic within interactions with technological systems between perpetrators and support workers. As such, we highlight four spaces of negotiation concerning a person's responsibility in changing their abusive behaviour, which we have coined as mechanisms to represent their fundamental and interconnected nature. These mechanisms include self-awareness, acknowledging the extent of harms, providing peer support and respecting authorities. These insights are the basis for offering some practical considerations for HCI scholars, policymakers and intervention designers in their work with perpetrators of violence.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {violence prevention, moral responsibility, third sector, civic technology, domestic violence, social care},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376684,
author = {Alfaras, Miquel and Tsaknaki, Vasiliki and Sanches, Pedro and Windlin, Charles and Umair, Muhammad and Sas, Corina and H\"{o}\"{o}k, Kristina},
title = {From Biodata to Somadata},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376684},
doi = {10.1145/3313831.3376684},
abstract = {Biosensing technologies are increasingly available as off-the-shelf products, yet for many designers, artists and non-engineers, these technologies remain difficult to design with. Through a soma design stance, we devised a novel approach for exploring qualities in biodata. Our explorative process culminated in the design of three artefacts, coupling biosignals to tangible actuation formats. By making biodata perceivable as sound, in tangible form or directly on the skin, it became possible to link qualities of the measurements to our own somatics - our felt experience of our bodily bioprocesses - as they dynamically unfold, spurring somatically-grounded design discoveries of novel possible interactions. We show that making biodata attainable for a felt experience - or as we frame it: turning biodata into somadata - enables not only first-person encounters, but also supports collaborative design processes as the somadata can be shared and experienced dynamically, right at the moment when we explore design ideas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {affective technology, soma design, interaction design, first-person perspective, biosensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376683,
author = {Naseem, Mustafa and Saleem, Bilal and St-Onge Ahmad, Sacha and Chen, Jay and Raza, Agha Ali},
title = {An Empirical Comparison of Technologically Mediated Advertising in Under-Connected Populations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376683},
doi = {10.1145/3313831.3376683},
abstract = {Information and Communication Technology interventions have the potential to improve outcomes in health and other development sectors in low-income settings. Large-scale impact, however, remains the central challenge for the HCI4D community as significant and diverse resources are typically required to scale such interventions beyond the pilot stage. In contrast, voice-based entertainment services accessible over simple phones, designed for similarly low-income, low-literate populations manage to scale 'virally' to tens of thousands of users with little to no advertising cost. Our study compares the outcomes of using voice-based entertainment to spread a maternal-health hotline against conventional advertisement channels including paper flyers, posters, radio, TV, social media and robocalls. Through an 11-week deployment in Pakistan where the hotline reached 21,770 users over 32,625 calls, we find that the entertainment service outperformed other channels on all popular user acquisition metrics, with the exception of robocalls, which lead in terms of spread.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pakistan, television, interactive voice response, under-connected, hci4d, mobile phone, flyers, ict4d, radio, tv, banners, social media, low-literate, ivr, advertisement, robocalls},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376679,
author = {Edwards, Gregory W. and Gonzales, Michael J. and Sullivan, Marc A.},
title = {Robocalling: STIRRED AND SHAKEN! - An Investigation of Calling Displays on Trust and Answer Rates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376679},
doi = {10.1145/3313831.3376679},
abstract = {Billions of robocalls annually have undermined the public's trust in the entire phone system. New functionality, called STIR/SHAKEN (S/S), hopes to help fix this issue by detecting whether a call is coming from the number it says it is. However, due to the nature of the system, at first only a portion of calls would go through the S/S system. This led us to question whether presenting this information would confuse users more than help. In this paper, we detail the results of online surveys, in-person interviews, and a lab-based simulation. The research recommends "Valid Number" for the label on the display and found that even with only 30% of calls being validated, S/S increased trust, answer frequency and consumer satisfaction. Based on these results, the launch of S/S could positively affect the current phone system and re-establish consumer trust.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {survey, UX research, robocalling, lab simulation, spoofing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376662,
author = {Shipman, Frank M. and Marshall, Catherine C.},
title = {Ownership, Privacy, and Control in the Wake of Cambridge Analytica: The Relationship between Attitudes and Awareness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376662},
doi = {10.1145/3313831.3376662},
abstract = {Has widespread news of abuse changed the public's perceptions of how user-contributed content from social networking sites like Facebook and LinkedIn can be used? We collected two datasets that reflect participants' attitudes about content ownership, privacy, and control, one in April 2018, while Cambridge Analytica was still in the news, and another in February 2019, after the event had faded from the headlines, and aggregated the data according to participants' awareness of the story, contrasting the attitudes of those who reported the greatest awareness with those who reported the least. Participants with the greatest awareness of the news story's details have more polarized attitudes about reuse, especially the reuse of content as data. They express a heightened desire for data mobility, greater concern about networked privacy rights, increased skepticism of algorithmically targeted advertising and news, and more willingness for social media platforms to demand corrections of inaccurate or deceptive content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {privacy, facebook, linkedin, data use, data monetization, cambridge analytica, social media attitudes, ownership},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376661,
author = {Koulouris, Jordan and Jeffery, Zoe and Best, James and O'Neill, Eamonn and Lutteroth, Christof},
title = {Me vs. Super(Wo)Man: Effects of Customization and Identification in a VR Exergame},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376661},
doi = {10.1145/3313831.3376661},
abstract = {Customised avatars are a powerful tool to increase identification, engagement and intrinsic motivation in digital games. We investigated the effects of customisation in a self-competitive VR exergame by modelling players and their previous performance in the game with customised avatars. In a first study we found that, similar to non-exertion games, customisation significantly increased identification and intrinsic motivation, as well as physical performance in the exergame. In a second study we identified a more complex relationship with the customisation style: idealised avatars increased wishful identification but decreased exergame performance compared to realistic avatars. In a third study, we found that 'enhancing' realistic avatars with idealised characteristics increased wishful identification, but did not have any adverse effects. We discuss the findings based on feedforward and self-determination theory, proposing notions of intrinsic identification (fostering a sense of self) and extrinsic identification (drawing away from the self) to explain the results.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {avatar customisation, identification, feedforward, exergaming, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376615,
author = {Abdul, Ashraf and von der Weth, Christian and Kankanhalli, Mohan and Lim, Brian Y.},
title = {COGAM: Measuring and Moderating Cognitive Load in Machine Learning Model Explanations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376615},
doi = {10.1145/3313831.3376615},
abstract = {Interpretable machine learning models trade -off accuracy for simplicity to make explanations more readable and easier to comprehend. Drawing from cognitive psychology theories in graph comprehension, we formalize readability as visual cognitive chunks to measure and moderate the cognitive load in explanation visualizations. We present Cognitive-GAM (COGAM) to generate explanations with desired cognitive load and accuracy by combining the expressive nonlinear generalized additive models (GAM) with simpler sparse linear models. We calibrated visual cognitive chunks with reading time in a user study, characterized the trade-off between cognitive load and accuracy for four datasets in simulation studies, and evaluated COGAM against baselines with users. We found that COGAM can decrease cognitive load without decreasing accuracy and/or increase accuracy without increasing cognitive load. Our framework and empirical measurement instruments for cognitive load will enable more rigorous assessment of the human interpretability of explainable AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {generalized additive models, cognitive load, explainable artificial intelligence, explanations, visual explanations},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376614,
author = {Lin, Chuan-en and Cheng, Ta Ying and Ma, Xiaojuan},
title = {ARchitect: Building Interactive Virtual Experiences from Physical Affordances by Bringing Human-in-the-Loop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376614},
doi = {10.1145/3313831.3376614},
abstract = {Automatic generation of Virtual Reality (VR) worlds which adapt to physical environments have been proposed to enable safe walking in VR. However, such techniques mainly focus on the avoidance of physical objects as obstacles and overlook their interaction affordances as passive haptics. Current VR experiences involving interaction with physical objects in surroundings still require verbal instruction from an assisting partner. We present ARchitect, a proof-of-concept prototype that allows flexible customization of a VR experience with human-in-the-loop. ARchitect brings in an assistant to map physical objects to virtual proxies of matching affordances using Augmented Reality (AR). In a within-subjects study (9 user pairs) comparing ARchitect to a baseline condition, assistants and players experienced decreased workload and players showed increased VR presence and trust in the assistant. Finally, we defined design guidelines of ARchitect for future designers and implemented three demonstrative experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, architect, affordance, passive haptics, asymmetric},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376607,
author = {Foong, Pin Sym and Lim, Charis Anne and Wong, Joshua and Lim, Chang Siang and Perrault, Simon Tangi and Koh, Gerald CH},
title = {"You Cannot Offer Such a Suggestion": Designing for Family Caregiver Input in Home Care Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376607},
doi = {10.1145/3313831.3376607},
abstract = {Previous work has looked closely at the challenges of using patient-generated data to enable remote assessment and monitoring by healthcare professionals. In this paper, we examine family caregivers who act as proxies for patients who may not have the capacity of capturing the necessary data. We worked with occupational therapists to develop an application for remote assessment of the safety of patients' homes by occupational therapists with the assistance of family caregivers. We evaluated the application with family caregivers and found two features unique to communication between family caregivers and healthcare professionals: Caregivers want to be able to direct healthcare professionals' attention to support problem-solving at home, and they include their perspective on how to best meet the patient's health needs. We discuss the importance of these findings for home systems in the domain of long-term chronic care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {healthcare, caregivers, chronic care, informatics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376601,
author = {Zhou, Qian and Wu, Fan and Fels, Sidney and Stavness, Ian},
title = {Closer Object Looks Smaller: Investigating the Duality of Size Perception in a Spherical Fish Tank VR Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376601},
doi = {10.1145/3313831.3376601},
abstract = {Fish Tank Virtual Reality (FTVR) displays provide compelling 3D experiences by rendering view-dependent imagery on a 2D screen. While users perceive a 3D object in space, they are actually looking at pixels on a 2D screen, thus, a perceptual duality exists between the object's pixels and the 3D percept potentially interfering with the experience. To investigate, we conducted an experiment to see whether the on-screen size of the 2D imagery affects the perceived object size in 3D space with different viewing conditions, including stereopsis. We found that the size of on-screen imagery significantly influenced object size perception, causing 83.3% under/overestimation of perceived size when viewing without stereopsis and reducing to 64.7% with stereopsis. Contrary to reality, objects look smaller when the viewer gets closer. Understanding the perceptual duality helps us to provide accurate perception of real-world objects depicted in the virtual environment and pave the way for 3D applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {fish tank virtual reality, 3d perception, spherical display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376593,
author = {Swearngin, Amanda and Wang, Chenglong and Oleson, Alannah and Fogarty, James and Ko, Amy J.},
title = {Scout: Rapid Exploration of Interface Layout Alternatives through High-Level Design Constraints},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376593},
doi = {10.1145/3313831.3376593},
abstract = {Although exploring alternatives is fundamental to creating better interface designs, current processes for creating alternatives are generally manual, limiting the alternatives a designer can explore. We present Scout, a system that helps designers rapidly explore alternatives through mixed-initiative interaction with high-level constraints and design feedback. Prior constraint-based layout systems use low-level spatial constraints and generally produce a single design. Tosupport designer exploration of alternatives, Scout introduces high-level constraints based on design concepts (e.g.,~semantic structure, emphasis, order) and formalizes them into low-level spatial constraints that a solver uses to generate potential layouts. In an evaluation with 18 interface designers, we found that Scout: (1) helps designers create more spatially diverse layouts with similar quality to those created with a baseline tool and (2) can help designers avoid a linear design process and quickly ideate layouts they do not believe they would have thought of on their own.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {program synthesis, alternatives, constraints, interface design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376583,
author = {Hsu, Silas and Vaccaro, Kristen and Yue, Yin and Rickman, Aimee and Karahalios, Karrie},
title = {Awareness, Navigation, and Use of Feed Control Settings Online},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376583},
doi = {10.1145/3313831.3376583},
abstract = {Control settings are abundant and have significant effects on user experiences. One example of an impactful but understudied area is feed settings. In this study, we investigated awareness, navigation, and use of feed settings. We began by creating a taxonomy of feed settings on social media and search sites. Via an online survey, we measured awareness of Facebook feed settings. An in-person interview study then investigated how people navigated to and chose to set feed settings on their own feeds. We discovered that many participants did not believe ad personalization feed settings existed. Furthermore, we discovered a misalignment in the expectation and the function of settings, especially of ad personalization settings for many participants. Despite all participants struggling to find at least one setting, participants overall wanted to use settings: 94% altered at least one setting they encountered. From these results, we discuss implications and suggest design guidelines for settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {feeds, settings, control, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376560,
author = {Gorkovenko, Katerina and Burnett, Daniel J. and Thorp, James K. and Richards, Daniel and Murray-Rust, Dave},
title = {Exploring The Future of Data-Driven Product Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376560},
doi = {10.1145/3313831.3376560},
abstract = {Connected devices present new opportunities to advance design through data collection in the wild, similar to the way digital services evolve through analytics. However, it is still unclear how live data transmitted by connected devices informs the design of these products, going beyond performance optimisation to support creative practices. Design can be enriched by data captured by connected devices, from usage logs to environmental sensors, and data about the devices and people around them. Through a series of workshops, this paper contributes industry and academia perspectives on the future of data-driven product design. We highlight HCI challenges, issues and implications, including sensemaking and the generation of design insight. We further challenge current notions of data-driven design and envision ways in which future HCI research can develop ways to work with data in the design process in a connected, rich, human manner.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {smart devices, human-centred design, design research, in the wild, data-driven design, iot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376553,
author = {Dayama, Niraj Ramesh and Todi, Kashyap and Saarelainen, Taru and Oulasvirta, Antti},
title = {GRIDS: Interactive Layout Design with Integer Programming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376553},
doi = {10.1145/3313831.3376553},
abstract = {Grid layouts are used by designers to spatially organise user interfaces when sketching and wireframing. However, their design is largely time consuming manual work. This is challenging due to combinatorial explosion and complex objectives, such as alignment, balance, and expectations regarding positions. This paper proposes a novel optimisation approach for the generation of diverse grid-based layouts. Our mixed integer linear programming (MILP) model offers a rigorous yet efficient method for grid generation that ensures packing, alignment, grouping, and preferential positioning of elements. Further, we present techniques for interactive diversification, enhancement, and completion of grid layouts. These capabilities are demonstrated using GRIDS, a wireframing tool that provides designers with real-time layout suggestions. We report findings from a ratings study (N = 13) and a design study (N = 16), lending evidence for the benefit of computational grid generation during early stages of design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {computational design, design tools, creativity support, optimisation, grid layouts, mixed-initiative},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376546,
author = {Kuzminykh, Anastasia and Rintel, Sean},
title = {Classification of Functional Attention in Video Meetings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376546},
doi = {10.1145/3313831.3376546},
abstract = {Participants in video meetings have long struggled with asymmetrical attention levels, especially when participants are distributed unevenly. While technological advances offer exciting opportunities to augment remote users' attention, the phenomenological complexity of attention means that to design attention-fostering features we must first understand what aspects of it are functionally meaningful to support. In this paper, we present a functional classification of observable attention for video meetings. The classification was informed by two studies on sense-making and selectiveness of attention in work meetings. It includes categories of attention accessible for technological support, their functions in a meeting process, and meeting-related activities that correspond to these functions. This classification serves as a multi-level representation of attention and informs the design of features aiming to support remote participants' attention in video meetings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {video-mediated communication, meetings, features, engagement, attention},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376541,
author = {Wells, Thomas and Houben, Steven},
title = {CollabAR  Investigating the Mediating Role of Mobile AR Interfaces on Co-Located Group Collaboration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376541},
doi = {10.1145/3313831.3376541},
abstract = {Mobile Augmented Reality (AR) technology is enabling new applications for different domains including architecture, education or medical work. As AR interfaces project digital data, information and models into the real world, it allows for new forms of collaborative work. However, despite the wide availability of AR applications, very little is known about how AR interfaces mediate and shape collaborative practices. This paper presents a study which examines how a mobile AR (M-AR) interface for inspecting and discovering AR models of varying complexity impacts co-located group practices. We contribute new insights into how current mobile AR interfaces impact co-located collaboration. Our results show that M-AR interfaces induce high mental load and frustration, cause a high number of context switches between devices and group discussion, and overall leads to a reduction in group interaction. We present design recommendations for future work focusing on collaborative AR interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-located collaboration, mobile augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376531,
author = {Wallace, Jayne and Montague, Kyle and Duncan, Trevor and Carvalho, Lu\'{\i}s P. and Koulidou, Nantia and Mahoney, Jamie and Morrissey, Kellie and Craig, Claire and Groot, Linnea Iris and Lawson, Shaun and Olivier, Patrick and Trueman, Julie and Fisher, Helen},
title = {ReFind: Design, Lived Experience and Ongoingness in Bereavement},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376531},
doi = {10.1145/3313831.3376531},
abstract = {We describe the design and use of ReFind, a handheld artefact made for people who are bereaved and are ready to re-explore their relationship to the deceased person. ReFind was made within a project seeking to develop new ways to curate and create digital media to support ongoingness - an active, dynamic component of continuing bonds. We draw on bereavement theory and care championing practices that enable a continued sense of connection between someone bereaved and a person who has died. We present the design development of ReFind and the lived experience of the piece by the first author. We discuss our wider methodology which includes autobiographical design and reflections on if and how the piece supported ongoing connections, the challenges faced, and insights gained.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {death, continuing bonds, ongoingness, relational selves, autobiographical, digital images, design, autoethnography, bereavement, lived experience, physical/digital, grief, photographs},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376529,
author = {Huang, Yue and Obada-Obieh, Borke and Beznosov, Konstantin (Kosta)},
title = {Amazon vs. My Brother: How Users of Shared Smart Speakers Perceive and Cope with Privacy Risks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376529},
doi = {10.1145/3313831.3376529},
abstract = {With the rapid adoption of smart speakers in people's homes, there is a corresponding increase in users' privacy and security concerns. In contrast to previous studies of users' concerns about smart speakers' divulging private information to their manufacturers, our study focused on investigating users' concerns with regard to housemates and external entities. We conducted semi-structured interviews with 26 participants living in 21 households. Our results suggest that users often have an inadequate understanding of what data their smart speakers makes available to all users and what is kept private. Although participants expressed different privacy concerns about their housemates and external entities, they adopted similar, yet suboptimal, risk management strategies. We provide recommendations for future speaker design to support more optimal coping with the perceived risks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {shared smart speaker, mitigation strategies, security and privacy concerns},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376525,
author = {Kristensson, Per Ola and Lilley, James and Black, Rolf and Waller, Annalu},
title = {A Design Engineering Approach for Quantitatively Exploring Context-Aware Sentence Retrieval for Nonspeaking Individuals with Motor Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376525},
doi = {10.1145/3313831.3376525},
abstract = {Nonspeaking individuals with motor disabilities typically have very low communication rates. This paper proposes a design engineering approach for quantitatively exploring context-aware sentence retrieval as a promising complementary input interface, working in tandem with a word-prediction keyboard. We motivate the need for complementary design engineering methodology in the design of augmentative and alternative communication and explain how such methods can be used to gain additional design insights. We then study the theoretical performance envelopes of a context-aware sentence retrieval system, identifying potential keystroke savings as a function of the parameters of the subsystems, such as the accuracy of the underlying auto-complete word prediction algorithm and the accuracy of sensed context information under varying assumptions. We find that context-aware sentence retrieval has the potential to provide users with considerable improvements in keystroke savings under reasonable parameter assumptions of the underlying subsystems. This highlights how complementary design engineering methods can reveal additional insights into design for augmentative and alternative communication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {design engineering, augmentative and alternative communication, sentence prediction, context-aware text entry, information retrieval, text entry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376520,
author = {Shi, Yang and Cao, Nan and Ma, Xiaojuan and Chen, Siji and Liu, Pei},
title = {EmoG: Supporting the Sketching of Emotional Expressions for Storyboarding},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376520},
doi = {10.1145/3313831.3376520},
abstract = {Storyboarding is an important ideation technique that uses sequential art to depict important scenarios of user experience. Existing data-driven support for storyboarding focuses on constructing user stories, but fail to address its benefit as a graphic narrative device. Instead, we propose to develop a data-driven design support tool that increases the expressiveness of user stories by facilitating sketching storyboards. To explore this, we focus on supporting the sketching of emotional expressions of characters in storyboards. In this paper, we present EmoG, an interactive system that generates sketches of characters with emotional expressions based on input strokes from the user. We evaluated EmoG with 21 participants in a controlled user study. The results showed that our tool has significantly better performance in usefulness, ease of use, and quality of results than the baseline system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {storyboarding, creativity support tools, data-driven design, emotional expression generation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376516,
author = {Zhao, Yuhang and Kupferstein, Elizabeth and Rojnirun, Hathaitorn and Findlater, Leah and Azenkot, Shiri},
title = {The Effectiveness of Visual and Audio Wayfinding Guidance on Smartglasses for People with Low Vision},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376516},
doi = {10.1145/3313831.3376516},
abstract = {Wayfinding is a critical but challenging task for people who have low vision, a visual impairment that falls short of blindness. Prior wayfinding systems for people with visual impairments focused on blind people, providing only audio and tactile feedback. Since people with low vision use their remaining vision, we sought to determine how audio feedback compares to visual feedback in a wayfinding task. We developed visual and audio wayfinding guidance on smartglasses based on de facto standard approaches for blind and sighted people and conducted a study with 16 low vision participants. We found that participants made fewer mistakes and experienced lower cognitive load with visual feedback. Moreover, participants with a full field of view completed the wayfinding tasks faster when using visual feedback. However, many participants preferred audio feedback because of its shorter learning curve. We propose design guidelines for wayfinding systems for low vision.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {audio feedback, visual feedback, low vision, accessibility, wayfinding, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376512,
author = {Preechayasomboon, Pornthep and Israr, Ali and Samad, Majed},
title = {Chasm: A Screw Based Expressive Compact Haptic Actuator},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376512},
doi = {10.1145/3313831.3376512},
abstract = {We present a compact broadband linear actuator, Chasm, that renders expressive haptic feedback on wearable and handheld devices. Unlike typical motor-based haptic devices with integrated gearheads, Chasm utilizes a miniature leadscrew coupled to a motor shaft, thereby directly translating the high-speed rotation of the motor to the linear motion of a nut carriage without an additional transmission. Due to this simplicity, Chasm can render low-frequency skin-stretch and high-frequency vibrations, simultaneously and independently. We present the design of the actuator assembly and validate its electromechanical and perceptual performance. We then explore use cases and show design solutions for embedding Chasm in device prototypes. Finally, we report investigations with Chasm in two VR embodiments, i.e., in a headgear band to induce locomotion cues and in a handheld pointer to enhance dynamic manual interactions. Our explorations show wide use for Chasm in enhancing user interactions and experience in virtual and augmented settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {handheld haptics, multidimensional haptics, skin stretch, wearable haptics, haptic devices},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376488,
author = {Cryan, Jenna and Tang, Shiliang and Zhang, Xinyi and Metzger, Miriam and Zheng, Haitao and Zhao, Ben Y.},
title = {Detecting Gender Stereotypes: Lexicon vs. Supervised Learning Methods},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376488},
doi = {10.1145/3313831.3376488},
abstract = {Biases in language influence how we interact with each other and society at large. Language affirming gender stereotypes is often observed in various contexts today, from recommendation letters and Wikipedia entries to fiction novels and movie dialogue. Yet to date, there is little agreement on the methodology to quantify gender stereotypes in natural language (specifically the English language). Common methodology (including those adopted by companies tasked with detecting gender bias) rely on a lexicon approach largely based on the original BSRI study from 1974.In this paper, we reexamine the role of gender stereotype detection in the context of modern tools, by comparatively analyzing efficacy of lexicon-based approaches and end-to-end, ML-based approaches prevalent in state-of-the-art natural language processing systems. Our efforts using a large dataset show that even compared to an updated lexicon-based approach, end-to-end classification approaches are significantly more robust and accurate, even when trained by moderately sized corpora.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {natural language processing, machine learning, gender bias, gender stereotypes, lexicon},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376467,
author = {Kim, Dae Hyun and Hoque, Enamul and Agrawala, Maneesh},
title = {Answering Questions about Charts and Generating Visual Explanations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376467},
doi = {10.1145/3313831.3376467},
abstract = {People often use charts to analyze data, answer questions and explain their answers to others. In a formative study, we find that such human-generated questions and explanations commonly refer to visual features of charts. Based on this study, we developed an automatic chart question answering pipeline that generates visual explanations describing how the answer was obtained. Our pipeline first extracts the data and visual encodings from an input Vega-Lite chart. Then, given a natural language question about the chart, it transforms references to visual attributes into references to the data. It next applies a state-of-the-art machine learning algorithm to answer the transformed question. Finally, it uses a template-based approach to explain in natural language how the answer is determined from the chart's visual features. A user study finds that our pipeline-generated visual explanations significantly outperform in transparency and are comparable in usefulness and trust to human-generated explanations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization, question answering, explainable ai},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376466,
author = {Pu, Xiaoying and Kay, Matthew},
title = {A Probabilistic Grammar of Graphics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376466},
doi = {10.1145/3313831.3376466},
abstract = {Visualizations depicting probabilities and uncertainty are used everywhere from medical risk communication to machine learning, yet these probabilistic visualizations are difficult to specify, prone to error, and their designs are cumbersome to explore. We propose a Probabilistic Grammar of Graphics (PGoG), an extension to Wilkinson's original framework. Inspired by the success of probabilistic programming languages, PGoG makes probability expressions, such as P(A|B), a first-class citizen in the language. PGoG abstractions also reflect the distinction between probability and frequency framing, a concept from the uncertainty communication literature. It is expressive, encompassing product plots, density plots, icon arrays, and dotplots, among other visualizations. Its coherent syntax ensures correctness (that the proportions of visual elements and their spatial placement reflect the underlying probability distribution) and reduces edit distance between probabilistic visualization specifications, potentially supporting more design exploration. We provide a proof-of-concept implementation of PGoG in R.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {uncertainty visualization, grammar of graphics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376462,
author = {Concannon, Shauna and Rajan, Natasha and Shah, Parthiv and Smith, Davy and Ursu, Marian and Hook, Jonathan},
title = {Brooke Leave Home: Designing a Personalized Film to Support Public Engagement with Open Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376462},
doi = {10.1145/3313831.3376462},
abstract = {Brooke Leave Home is a personalized film designed to engage a non-expert audience with open data about the support young adults receive when leaving the care system in England. The film draws upon a range of video-based data storytelling techniques to present each viewer with a personalized perspective on the topic based on data from their own local area. We present the film's design and describe how its storytelling techniques were developed to support viewers in understanding, and fostering empathic connections with, the data sources featured and the implications they have for care leavers. We also present a study with 47 viewers, which explores how these techniques were experienced and how effective they were in aiding engagement with the data included and its meaning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {narrative, film, storytelling, personalization, video, data},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376458,
author = {Tachtler, Franziska and Michel, Toni and Slov\'{a}k, Petr and Fitzpatrick, Geraldine},
title = {Supporting the Supporters of Unaccompanied Migrant Youth: Designing for Social-Ecological Resilience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376458},
doi = {10.1145/3313831.3376458},
abstract = {Unaccompanied migrant youth, fleeing to a new country without their parents, are exposed to mental health risks. Resilience interventions mitigate such risks, but access can be hindered by systemic and personal barriers. While much work has recently addressed designing technology to promote mental health, none has focused on the needs of these populations. This paper presents the results of interviews with 18 professional/ volunteer support workers and 5 unaccompanied migrant youths, followed by three design workshops. The results point to the diverse systems that can facilitate youths' resilience development. The relationship between the youth and volunteers acting as mentors is particularly important for increasing resilience but comes with challenges. This suggests the relevance of a social-ecological model of resilience with a focus on designing technology to support the mentors in order to help them better support the youth. We conclude by mapping out the design space for mentor support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mental health technology, care, resilience, refugees},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376449,
author = {B\^{a}ce, Mihai and Staal, Sander and Bulling, Andreas},
title = {Quantification of Users' Visual Attention During Everyday Mobile Device Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376449},
doi = {10.1145/3313831.3376449},
abstract = {We present the first real-world dataset and quantitative evaluation of visual attention of mobile device users in-situ, i.e. while using their devices during everyday routine. Understanding user attention is a core research challenge in mobile HCI but previous approaches relied on usage logs or self-reports that are only proxies and consequently do neither reflect attention completely nor accurately. Our evaluations are based on Everyday Mobile Visual Attention (EMVA) – a new 32-participant dataset containing around 472 hours of video snippets recorded over more than two weeks in real life using the front-facing camera as well as associated usage logs, interaction events, and sensor data. Using an eye contact detection method, we are first to quantify the highly dynamic nature of everyday visual attention across users, mobile applications, and usage contexts. We discuss key insights from our analyses that highlight the potential and inform the design of future mobile attentive user interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {in-the-wild study, mobile devices, attentive user interfaces, visual attention, eye contact detection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376425,
author = {Vasquez, Joshua and Twigg-Smith, Hannah and Tran O'Leary, Jasper and Peek, Nadya},
title = {Jubilee: An Extensible Machine for Multi-Tool Fabrication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376425},
doi = {10.1145/3313831.3376425},
abstract = {We present Jubilee, an open-source hardware machine with automatic tool-changing and interchangeable bed plates. As digital fabrication tools have become more broadly accessible, tailoring those machines to new users and novel workflows has become central to HCI research. However, the lack of hardware infrastructure makes custom application development cumbersome. We identify a need for an extensible platform to allow HCI researchers to develop workflows for fabrication, material exploration, and other applications. Jubilee addresses this need. It can automatically and repeatably change tools in the same operation. It can be built with a combination of simple 3D-printed and readily available parts. It has several standard head designs for a variety of applications including 3D printing, syringe-based liquid handling, imaging, and plotting. We present Jubilee with a comprehensive set of assembly instructions and kinematic mount templates for user-designed tools and bed plates. Finally we demonstrate Jubilee's multi-tool workflow functionality with a series of example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {digital fabrication, multi-tool workflows, toolchanging},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376406,
author = {Goodman, Steven and Kirchner, Susanne and Guttman, Rose and Jain, Dhruv and Froehlich, Jon and Findlater, Leah},
title = {Evaluating Smartwatch-Based Sound Feedback for Deaf and Hard-of-Hearing Users Across Contexts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376406},
doi = {10.1145/3313831.3376406},
abstract = {We present a qualitative study with 16 deaf and hard of hearing (DHH) participants examining reactions to smartwatch-based visual + haptic sound feedback designs. In Part 1, we conducted a Wizard-of-Oz (WoZ) evaluation of three smartwatch feedback techniques (visual alone, visual + simple vibration, and visual + tacton) and investigated vibrational patterns (tactons) to portray sound loudness, direction, and identity. In Part 2, we visited three public or semi-public locations where we demonstrated sound feedback on the smartwatch in situ to examine contextual influences and explore sound filtering options. Our findings characterize uses for vibration in multimodal sound awareness, both for push notification and for immediately actionable sound information displayed through vibrational patterns (tactons). In situ experiences caused participants to request sound filtering - particularly to limit haptic feedback - as a method for managing soundscape complexity. Additional concerns arose related to learnability, possibility of distraction, and system trust. Our findings have implications for future portable sound awareness systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sound awareness, deaf and hard of hearing, smartwatches},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376396,
author = {Kruzan, Kaylee Payne and Whitlock, Janis and Bazarova, Natalya N. and Miller, Katherine D. and Chapman, Julia and Won, Andrea Stevenson},
title = {Supporting Self-Injury Recovery: The Potential for Virtual Reality Intervention},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376396},
doi = {10.1145/3313831.3376396},
abstract = {In this paper, we explore the use of virtual reality (VR) in assisting individuals who self-injure. Past work on self-injury in HCI has focused almost exclusively on mobile applications and message boards. As VR systems become more common, it is worth exploring what unique affordances of the technology can be leveraged to support self-injury reduction and cessation. Research on VR intervention and self-injury treatment informed the design of three novel virtual reality experiences. Nineteen interviews were conducted with individuals with current, or a past history of, self-injury with the goals of uncovering overall impressions of the perceived efficacy of VR with this population, as well as better understanding key mechanisms which impact their experience. Our analysis reveals four key elements common across all experiences: transportation, embodiment, immersion/distraction, and sense of control, and additional themes within each unique experience. We discuss the implications of these findings for future intervention design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, self-injury, intervention},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376386,
author = {Bellini, Rosanna and Forrest, Simon and Westmarland, Nicole and Jackson, Dan and Smeddinck, Jan David},
title = {Choice-Point: Fostering Awareness and Choice with Perpetrators in Domestic Violence Interventions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376386},
doi = {10.1145/3313831.3376386},
abstract = {Learning about alternatives to violence is an essential part of change work with domestic violence perpetrators. This is complex work, seeking to tackle a sensitive issue by involving the development of deep, embodied learning for perpetrators who may lack perspective on their behaviour. Interactive storytelling has been providing users with the opportunity to explore speculative scenarios in a controlled environment. We discuss the design of Choice-Point: a web-based application that allows perpetrators adopt the role of different fictional characters in an abusive scenario for conveying the essential skill of perspective-taking. We evaluated Choice-Point through trials with three groups of perpetrators, a support group of victim-survivors and an expert critique from support workers. We discuss challenges in using such technologies - such as our system - for engagement; the value of perpetrator agency in supporting non-violent behaviours, and the potential to positively shape perpetrators' journeys to non-violence within social care settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {batterers intervention programmes, domestic violence, intimate partner violence, family violence, domestic violence prevention programmes, third-sector, interactive storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376380,
author = {Yen, Yu-Chun Grace and Kim, Joy O. and Bailey, Brian P.},
title = {Decipher: An Interactive Visualization Tool for Interpreting Unstructured Design Feedback from Multiple Providers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376380},
doi = {10.1145/3313831.3376380},
abstract = {Feedback from diverse audiences can vary in focus, differ in structure, and contradict each other, making it hard to interpret and act on. While prior work has explored generating quality feedback, our work helps a designer interpret that feedback. Through a formative study with professional designers (N=10), we discovered that the interpretation process includes categorizing feedback, identifying valuable feedback, and prioritizing which feedback to incorporate in a revision. We also found that designers leverage feedback topic and sentiment, and the status of the provider to aid interpretation. Based on the findings, we created a new tool (Decipher) that enables designers to visualize and navigate a collection of feedback using its topic and sentiment structure. In a preliminary evaluation (N=20), we found that Decipher helped users feel less overwhelmed during feedback interpretation tasks and better attend to critical issues and conflicting opinions compared to using a typical document-editing tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sense-making, creativity support tools, feedback, creativity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376377,
author = {Sarma, Abhraneel and Kay, Matthew},
title = {Prior Setting in Practice: Strategies and Rationales Used in Choosing Prior Distributions for Bayesian Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376377},
doi = {10.1145/3313831.3376377},
abstract = {Bayesian statistical analysis is steadily growing in popularity and use. Choosing priors is an integral part of Bayesian inference. While there exist extensive normative recommendations for prior setting, little is known about how priors are chosen in practice. We conducted a survey (N = 50) and interviews (N = 9) where we used interactive visualizations to elicit prior distributions from researchers experienced withBayesian statistics and asked them for rationales for those priors. We found that participants' experience and philosophy influence how much and what information they are willing to incorporate into their priors, manifesting as different levels of informativeness and skepticism. We also identified three broad strategies participants use to set their priors: centrality matching, interval matching, and visual mass allocation. We discovered that participants' understanding of the notion of 'weakly informative priors"-a commonly-recommended normative approach to prior setting-manifests very differently across participants. Our results have implications both for how to develop prior setting recommendations and how to design tools to elicit priors in Bayesian analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {descriptive analysis, bayesian inference, prior distributions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376375,
author = {Huffaker, Jordan S. and Kummerfeld, Jonathan K. and Lasecki, Walter S. and Ackerman, Mark S.},
title = {Crowdsourced Detection of Emotionally Manipulative Language},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376375},
doi = {10.1145/3313831.3376375},
abstract = {Detecting rhetoric that manipulates readers' emotions requires distinguishing intrinsically emotional content (IEC; e.g., a parent losing a child) from emotionally manipulative language (EML; e.g., using fear-inducing language to spread anti-vaccine propaganda). However, this remains an open classification challenge for both automatic and crowdsourcing approaches. Machine Learning approaches only work in narrow domains where labeled training data is available, and non-expert annotators tend to conflate IEC with EML. We introduce an approach, anchor comparison, that leverages workers' ability to identify and remove instances of EML in text to create a paraphrased "anchor text", which is then used as a comparison point to classify EML in the original content. We evaluate our approach with a dataset of news-style text snippets and show that precision and recall can be tuned for system builders' needs. Our contribution is a crowdsourcing approach that enables non-expert disentanglement of social references from content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {crowdsourcing, emotion, media manipulation, rhetoric},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376366,
author = {Nittala, Aditya Shekhar and Khan, Arshad and Kruttwig, Klaus and Kraus, Tobias and Steimle, J\"{u}rgen},
title = {PhysioSkin: Rapid Fabrication of Skin-Conformal Physiological Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376366},
doi = {10.1145/3313831.3376366},
abstract = {Advances in rapid prototyping platforms have made physiological sensing accessible to a wide audience. However, off-the-shelf electrodes commonly used for capturing biosignals are typically thick, non-conformal and do not support customization. We present PhysioSkin, a rapid, do-it-yourself prototyping method for fabricating custom multi-modal physiological sensors, using commercial materials and a commodity desktop inkjet printer. It realizes ultrathin skin-conformal patches (~1μm) and interactive textiles that capture sEMG, EDA and ECG signals. It further supports fabricating devices with custom levels of thickness and stretchability. We present detailed fabrication explorations on multiple substrate materials, functional inks and skin adhesive materials. Informed from the literature, we also provide design recommendations for each of the modalities. Evaluation results show that the sensor patches achieve a high signal-to-noise ratio. Example applications demonstrate the functionality and versatility of our approach for prototyping a next generation of physiological devices that intimately couple with the human body.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {e-textile, wearable devices, ink-jet printing, fabrication, rapid prototyping, physiological sensing, electronic skin},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376360,
author = {Schubhan, Marc and Altmeyer, Maximilian and Buchheit, Dominic and Lessel, Pascal},
title = {Investigating User-Created Gamification in an Image Tagging Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376360},
doi = {10.1145/3313831.3376360},
abstract = {Commonly, gamification is designed by developers and not by end-users. In this paper we investigate an approach where users take control of this process. Firstly, users were asked to describe their own gamification concepts which would motivate them to put more effort into an image tagging task. We selected this task as gamification has already been shown to be effective here in previous work. Based on these descriptions, an implementation was made for each concept and given to the creator. In a between-subjects study (n=71), our approach was compared to a no-gamification condition and two conditions with fixed gamification settings. We found that providing participants with an implementation of their own concept significantly increased the amount of generated tags compared to the other conditions. Although the quality of tags was lower, the number of usable tags remained significantly higher in comparison, suggesting the usefulness of this approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {motivation, user-driven game design, bottom-up, replication, customization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376346,
author = {Mohamed, Reham and Chametka, Paulina and Chiasson, Sonia},
title = {The Influence of Decaying the Representation of Older Social Media Content on Simulated Hiring Decisions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376346},
doi = {10.1145/3313831.3376346},
abstract = {Decaying representations gradually make social media content less visible to readers over time, which can help users disassociate from past online activities. We explore whether shrinking, one decaying representation, influences managers' assessments and simulated hiring decisions of job candidates, compared to seeing a full profile or an empty profile with no posts. Our 3 x 2 between-subjects crowdsourced survey (N = 360 US managers) shows that shrunk or empty profiles led to more positive decisions than profiles in their original full format. However, shrunk profiles also further contributed to more positive impressions of the candidates. Shrinking did not help the candidate of either gender more than the other and demographics of managers had limited impact on their assessment. Further, our managers regularly search job candidates' social media profiles in real life, suggesting that shrinking could support users' privacy. We finally present implications for individuals' privacy on social media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–19},
numpages = {19},
keywords = {online reputation management, decaying representations, online privacy, online social networks, hiring context},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376337,
author = {Logler, Nick and Pitt, Caroline and Gao, Xin and Hishikawa, Allison Marie and Yip, Jason and Friedman, Batya},
title = {"I Feel Like This is a Bad Thing": Investigating Disassembly in Action for Novices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376337},
doi = {10.1145/3313831.3376337},
abstract = {Materials are dynamic-they can be shaped and changed. Often however, our tools and technologies appear to fix materials in place. Disassembly is one practice that provides openings to explore and understand the dynamic nature of material. In this research, we investigate possibilities that emerge from disassembly. Specifically, we studied how novices disassembled a common digital artifact-desktop printers. We worked with 21 young people and family members across two evening workshops at a middle school. We report on the workshop interactions, categories of actions of disassembly, and four in-depth vignettes showcasing disassembly in action. In the discussion, we reflect on disassembly and permission, sustainability, the joy of disassembling, and design considerations in support of disassembly. Our contributions include: (1) extending existing theoretical framings about artifacts and materials; (2) an empirical study documenting the process by which novices disassemble; and (3) preliminary design and policy considerations that enable disassembly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {empowerment, materials, disassembly, making, novices, unmaking, play, design theory, design principles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376334,
author = {Ces\'{a}rio, Vanessa and Petrelli, Daniela and Nisi, Valentina},
title = {Teenage Visitor Experience: Classification of Behavioral Dynamics in Museums},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376334},
doi = {10.1145/3313831.3376334},
abstract = {Teenagers' engagement in museums is much talked about but little research has been done to understand their behavior and inform design. Findings from co-design sessions with teenagers suggested they value games and stories when thinking about enjoyable museum tours. Informed by these findings and working with a natural history museum, we designed: a story-based tour (Turning Point) and a game-based tour (Haunted Encounters), informed by similar content. The two strategies were evaluated with 78 teenagers (15-19 years old) visiting the museum as part of an educational school trip. We assessed teenagers' personality in class; qualitative and quantitative data on their engagement, experience, and usability of the apps were collected at the museum. The triangulation of quantitative and qualitative data show personality traits mapping into different behaviors. We offer implications for the design of museum apps targeted to teenagers, a group known as difficult to reach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-design, mobile experience, game, museums, storytelling, teenagers, visitor experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376331,
author = {Zarei, Niloofar and Chu, Sharon Lynn and Quek, Francis and Rao, Nanjie 'Jimmy' and Brown, Sarah Anne},
title = {Investigating the Effects of Self-Avatars and Story-Relevant Avatars on Children's Creative Storytelling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376331},
doi = {10.1145/3313831.3376331},
abstract = {Storytelling is a critical step in the cognitive development of children. Particularly, this requires children to mentally project into the story context and to identify with the thoughts of the characters in their stories. We propose to support free imagination in creative storytelling through an enactment-based approach that allows children to embody an avatar and perform as the story character. We designed our story creation interface with two modes of avatar: the story-relevant avatar and the self-avatar, to investigate the effects of avatar design on the quality of children's creative products. In our study with 20 child participants, the results indicate that self-avatars can create a stronger sense of identification and embodied presence, while story-relevant avatars can provide a scaffold for mental projection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {expressive writing, virtual reality, creativity, embodied interaction, storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376327,
author = {Lee, Chunggi and Kim, Sanghoon and Han, Dongyun and Yang, Hongjun and Park, Young-Woo and Kwon, Bum Chul and Ko, Sungahn},
title = {GUIComp: A GUI Design Assistant with Real-Time, Multi-Faceted Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376327},
doi = {10.1145/3313831.3376327},
abstract = {Users may face challenges while designing graphical user interfaces, due to a lack of relevant experience and guidance. This paper aims to investigate the issues users face during the design process, and how to resolve them. To this end, we conducted semi-structured interviews, based on which we built a GUI prototyping assistance tool called GUIComp. This tool can be connected to GUI design software as an extension, and it provides real-time, multi-faceted feedback on a user's current design. Additionally, we conducted two user studies, in which we asked participants to create mobile GUIs with or without GUIComp, and requested online workers to assess the created GUIs. The experimental results show that GUIComp facilitated iterative designs and the participants with GUIComp had better a user experience and produced more acceptable designs than those who did not use it.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gui design, design feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376322,
author = {Zhang, Xinlei and Miyaki, Takashi and Rekimoto, Jun},
title = {WithYou: Automated Adaptive Speech Tutoring With Context-Dependent Speech Recognition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376322},
doi = {10.1145/3313831.3376322},
abstract = {Learning to speak in foreign languages is hard. Speech shadowing has been rising as a proven way to practice speaking, which asks a learner to listen and repeat a native speech template as simultaneously as possible. However, shadowing can be hard to do because learners can frequently fail to follow the speech and unintentionally interrupt a practice session. Worse, as a technical way to evaluate shadowing performance in real-time has not been established, no automated solutions are available to help. In this paper, we propose a technical framework with context-dependent speech recognition to evaluate shadowing in real-time. We propose a shadowing tutor system called WithYou, which can automatically adjust the playback and the difficulty of a speech template when learners fail, so shadowing becomes smooth and tailored. Results from a user study show that WithYou provides greater speech improvements (14%) than the conventional method (2.7%) with a lower cognitive load.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {shadowing, speech recognition, computer assisted language learning (call), speaking, intelligent tutoring system, language learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376307,
author = {Clarke, Rachel Ivy and Schoonmaker, Sayward},
title = {The Critical Catalog: Library Information Systems, Tricksterism, and Social Justice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376307},
doi = {10.1145/3313831.3376307},
abstract = {In this paper, we describe the Critical Catalog, a grant-funded research through design project intended to investigate metadata elements, values, and organizational structures necessary to intentionally advocate for diversity and expose library users to resources from populations traditionally marginalized in literature and publishing. Drawing on principles from critical design, the prototype functions as a critical intervention intended to raise questions and stimulate debate, rather than a purely technical fix to deeply social concerns. A detailed reflective discussion of the design process reveals how existing infrastructural constraints shaped design decisions that led to increased advocacy and a stronger activist standpoint. We discuss the use of metadata as design material for social justice, the application of tricksterism in HCI, and how both practical limitations from professional contexts and imposed limitations based on identities and positions of power can lead to surprising places, meanings, and questions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tricksterism, whiteness, research through design, library catalogs, metadata},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376302,
author = {Dylan, Thomas and Wood, Gavin and Durrant, Abigail C. and Vines, John and Torres, Pablo E. and Ulrich, Philip I. N. and Cukurova, Mutlu and Carr, Amanda and \c{C}er\c{c}i, Sena and Lawson, Shaun},
title = {Designing IoT Resources to Support Outdoor Play for Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376302},
doi = {10.1145/3313831.3376302},
abstract = {We describe a Research-through-Design (RtD) project that explores the Internet of Things (IoT) as a resource for children's free play outdoors. Based on initial insights from a design ethnography, we developed four RtD prototypes for social play in different scenarios of use outdoors, including congregating on a street or in a park to play physical games with IoT. We observed these prototypes in use by children in their free play in two community settings, and report on the qualitative analysis of our fieldwork. Our findings highlight the designs' material qualities that encouraged social and physical play under certain conditions, suggesting social affordances that are central to the success of IoT designs for free play outdoors. We provide directions for future research that addresses the challenges faced when deploying IoT with children, contributing new considerations for interaction design with children in outdoor settings and free play contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {children, outdoor play, digital playing out, free play, pervasive play, internet of things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376288,
author = {Davis, Keith M. and Kangassalo, Lauri and Spap\'{e}, Michiel and Ruotsalo, Tuukka},
title = {Brainsourcing: Crowdsourcing Recognition Tasks via Collaborative Brain-Computer Interfacing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376288},
doi = {10.1145/3313831.3376288},
abstract = {This paper introduces brainsourcing: utilizing brain responses of a group of human contributors each performing a recognition task to determine classes of stimuli. We investigate to what extent it is possible to infer reliable class labels using data collected utilizing electroencephalography (EEG) from participants given a set of common stimuli. An experiment (N=30) measuring EEG responses to visual features of faces (gender, hair color, age, smile) revealed an improved F1 score of 0.94 for a crowd of twelve participants compared to an F1 score of 0.67 derived from individual participants and a random chance of 0.50. Our results demonstrate the methodological and pragmatic feasibility of brainsourcing in labeling tasks and opens avenues for more general applications using brain-computer interfacing in a crowdsourced setting.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {crowdsourcing, brainsourcing, brain-computer interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376282,
author = {Blank, Christopher and Zaman, Shaila and Wesley, Amanveer and Tsiamyrtzis, Panagiotis and Da Cunha Silva, Dennis R. and Gutierrez-Osuna, Ricardo and Mark, Gloria and Pavlidis, Ioannis},
title = {Emotional Footprints of Email Interruptions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376282},
doi = {10.1145/3313831.3376282},
abstract = {Working in an environment with constant interruptions is known to affect stress, but how do interruptions affect emotional expression? Emotional expression can have significant impact on interactions among coworkers. We analyzed the video of 26 participants who performed an essay task in a laboratory while receiving either continual email interruptions or receiving a single batch of email. Facial videos of the participants were run through a convolutional neural network to determine the emotional mix via decoding of facial expressions. Using a novel co-occurrence matrix analysis, we showed that with batched email, a neutral emotional state is dominant with sadness being a distant second, and with continual interruptions, this pattern is reversed, and sadness is mixed with fear. We discuss the implications of these results for how interruptions can impact employees' well-being and organizational climate.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {co-occurence matrix, facial expressions, emotions, email interruptions, convolutional neural network},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

