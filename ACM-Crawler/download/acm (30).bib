@inproceedings{10.1145/3334480.3382794,
author = {Zhi, Qiyu and Metoyer, Ronald},
title = {GameBot: A Visualization-Augmented Chatbot for Sports Game},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382794},
doi = {10.1145/3334480.3382794},
abstract = {The major sports leagues, including The National Basketball Association (NBA) and the EPL (the English Premier League), are adopting conversational systems (chatbots) as an innovative outlet to deliver game information and engage fans. However, current sports chatbots only provide scores and game highlight videos, which are often inadequate for statistical data related requests. We present GameBot, an interactive chatbot for sports fans to explore game statistical data. GameBot features (1) the direct answers to user's stats-related questions, and (2) the use of data visualizations as supporting context for sports fans' stats-related questions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {basketball, chatbot, sports chatbot, gamebot, sports visualization, visual chatbot},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381055,
author = {Alvarado Garcia, Adriana and Badillo-Urquiola, Karla and Barrera Machuca, Mayra D. and Cibrian, Franceli L. and Ciolfi Felice, Marianela and Gayt\'{a}n-Lugo, Laura S. and G\'{o}mez-Zar\'{a}, Diego and Griggio, Carla F. and Perusquia-Hernandez, Monica and Silva-Prietch, Soraia and Tejada, Carlos E. and Wong-Villacres, Marisol},
title = {Fostering HCI Research in, by, and for Latin America},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381055},
doi = {10.1145/3334480.3381055},
abstract = {Over the last 20 years, the Latin American Human-Computer Interaction (HCI) community has been working to shed light on how the diverse populations in the region are adopting, using, and making sense of computational technologies. Latin America's tense socio-political context, plurality of languages, collectivist culture, and historical relationship with the Global North make it a unique and rich space for HCI research. Considering the growing number of studies about Latin American communities and the emergent efforts to contribute to the HCI literature, we propose to host a SIG meeting at the 2020 ACM CHI conference. Our goal is to consolidate these efforts to better promote HCI research in, by, and for Latin America, by (1) bringing together researchers, practitioners, and students who are interested in engaging with Latin America through their research and practice, (2) envisioning a shared research agenda, and (3) identifying strategies for making its contributions more visible and impactful in the international community.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {latinx, hci research, latin america},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375056,
author = {Schiphorst, Thecla and Loke, Lian and H\"{o}\"{o}k, Kristina},
title = {Designing for Sensory Appreciation: Cultivating Somatic Approaches to Experience Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375056},
doi = {10.1145/3334480.3375056},
abstract = {This course explores somatic approaches to experience design in HCI. Designing for Sensory Appreciation focuses on cultivating our bodily sensory experience as a resource for design. This course exemplifies how somatic approaches can be applied through sensory appreciation in the form of case studies that incorporate experience-based activities. We invite a rethinking of the process of designing for technology based on the emerging somatic turn within Human Computer Interaction that acknowledges design for the experience of the self and recognizes the interiority of human experience as an equal partner in technological design processes.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {attention, embodiment, somaesthetics, somatic facilitation, bodyweather, soma-design, somatic connoisseurship, user experience, design process, bodily experience, movement awareness, somatics},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383179,
author = {Vasquez, Joshua and Twigg-Smith, Hannah and Tran O'Leary, Jasper and Peek, Nadya},
title = {Jubilee Demo: An Extensible Machine for Multi-Tool Fabrication},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383179},
doi = {10.1145/3334480.3383179},
abstract = {We present Jubilee, an open-source motion platform extensible to custom applications and application media by means of interchangeable bed plates and automatic tool-changing. We describe Jubilee as an piece of infrastructure that can be readily adapted to a specialty task requiring precise computer control of one more tools without necessitating machine design expertise. To this end, Jubilee is designed to be readily reproduced solely from the documentation in a worldwide setting without relying on specialized manufacturing processes or volume discounts. Additionally, our paper provides a series of application examples involving various tools spanning from multimaterial 3D printing to multicolor pen plotting to multi-syringe liquid handling to microscopy.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {multi-tool workflows, toolchanging, digital fabrication},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383170,
author = {Wu, Shengzhi and Byrne, Daragh and Steenson, Molly Wright},
title = {"Megereality": Leveraging Physical Affordances for Multi-Device Gestural Interaction in Augmented Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383170},
doi = {10.1145/3334480.3383170},
abstract = {We present a novel gestural interaction strategy for multi-device interactions in augmented reality (AR), in which we leverage existing physical affordances of everyday products and spaces for intuitive interactions in AR. To explore this concept, we designed and prototyped three demo scenarios: pulling virtual sticky notes from a tablet, pulling a 3D model from a computer display, and 'slurping' color from the real-world environment to smart lights with a virtual eyedropper. By merging the boundary of digital and physical, utilizing metaphors in AR and embodying the abstract process, we demonstrate an interaction strategy that harnesses the physical affordances to assist digital interaction in AR with hand gestures.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {multi-device controls, augmented reality, gestural interaction, physical affordances},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383154,
author = {Byun, Jeongmin and Park, Jungkook and Oh, Alice},
title = {Cocode: Co-Learner Screen Sharing for Social Translucence in Online Programming Courses},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383154},
doi = {10.1145/3334480.3383154},
abstract = {Online courses are popular among learners of programming, but many learners have trouble completing the courses. A common approach to increase learner engagement is to provide co-learner presence via chat and forums. In this work, we present Cocode, an online learning system where learners can share their presence without any explicit action; their normal learning activities would signal co-learner presence. Cocode is a web application for online programming courses that shows other learners' code editors and running screens in the programming environment to the learners while working on exercises. Results from our between-subject studies show that learners with Cocode are more engaged and work on more programming exercises compared to the learners using the system without social features.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {social translucence, online course, education, programming course},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383150,
author = {Li, Guozheng and Tian, Min and Xu, Qinmei and McGuffin, Michael J. and Yuan, Xiaoru},
title = {Tree Illustrator: Interactive Construction of Tree Visualizations},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383150},
doi = {10.1145/3334480.3383150},
abstract = {We present Tree Illustrator, an interactive authoring tool of tree visualizations. Tree Illustrator is based on GoTree, a declarative grammar allowing users to create tree visualizations by configuring three aspects: visual elements, layout, and coordinate system. Within the set of all possible tree visualization techniques, we identify a subset of techniques that are both "unit-decomposable" and "axis-decomposable" (terms we define). For tree visualizations within this subset, Tree Illustrator provides the users with flexible and fine-grained control over the parameters of the techniques, supporting not only existing techniques but also undiscovered and hybrid visualizations.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {authoring tool, tree visualization, declarative grammar},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383135,
author = {Han, Changyo and Takahashi, Ryo and Yahagi, Yuchi and Naemura, Takeshi},
title = {PneuModule: Using Inflatable Pin Arrays for Reconfigurable Physical Controls on Pressure-Sensitive Touch Surfaces},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383135},
doi = {10.1145/3334480.3383135},
abstract = {We present PneuModule, a tangible interface platform that enables users to reconfigure physical controls on pressure-sensitive touch surfaces using pneumatically-actuated inflatable pin arrays. PneuModule consists of two types of different passive modules: a main module and extension modules. The main module can be customized by attaching extension modules that have distinct physical input modalities. The extension modules are hot-swappable, enable users to quickly customize the interface layout. We showcase the feasibility of PneuModule through a series of interactive demonstrations.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {tangible user interfaces, pneumatic actuation, pressure-sensitive touch surfaces, reconfigurable physical controls},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383056,
author = {Chen, Si and Cheng, Haocong and Huang, Yun},
title = {Who Is Changing Your Question on a Social Q&amp;A Website?},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383056},
doi = {10.1145/3334480.3383056},
abstract = {Effective moderation of online communities is an important, but challenging, topic in HCI. In this paper, we study people's co-editing behavior on one of the most popular social Q&amp;A websites in China, called Zhihu.com. We examined question logs to understand who/when/how a question is edited differently by multiple users; we also conducted semi-structured interviews with users who edited others' questions on Zhihu to understand their motivations and their perceptions of co-editing behavior, as well as their concerns and suggestions for future website designs for moderating such behavior. Our findings reveal that although co-editing questions is perceived as a positive and effective approach for improving questions' answerability and shaping norms in the online community, effective moderation mechanisms need to be designed to improve transparency and communication about co-editing behavior and to address possible tensions as a result of co-editing wars.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {social Q&amp;A, co-editing questions, online communities, moderation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383026,
author = {Roebuck Williams, Rhoslyn and Varcoe, Xan and Glowacki, Becca R. and Gale, Ella M. and Jamieson-Binnie, Alexander and Glowacki, David R.},
title = {Subtle Sensing: Detecting Differences in the Flexibility of Virtually Simulated Molecular Objects},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383026},
doi = {10.1145/3334480.3383026},
abstract = {During VR demos we have performed over last few years, many participants (in the absence of any haptic feedback) have commented on their perceived ability to 'feel' differences between simulated molecular objects. The mechanisms for such 'feeling' are not entirely clear: observing from outside VR, one can see that there is nothing physical for participants to 'feel'. Here we outline exploratory user studies designed to evaluate the extent to which participants can distinguish quantitative differences in the flexibility of VR-simulated molecular objects. The results suggest that an individual's capacity to detect differences in molecular flexibility is enhanced when they can interact with and manipulate the molecules, as opposed to merely observing the same interaction. Building on these results, we intend to carry out further studies investigating humans' ability to sense quantitative properties of VR simulations without haptic technology.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {virtual reality, molecular simulation, sensing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382962,
author = {Babic, Teo and Perteneder, Florian and Reiterer, Harald and Haller, Michael},
title = {Simo: Interactions with Distant Displays by Smartphones with Simultaneous Face and World Tracking},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382962},
doi = {10.1145/3334480.3382962},
abstract = {The interaction with distant displays often demands complex, multi-modal inputs which need to be achieved with a very simple hardware solution so that users can perform rich inputs wherever they encounter a distant display. We present Simo, a novel approach, that transforms a regular smartphone into a highly-expressive user motion tracking device and controller for distant displays. Both the front and back cameras of the smartphone are used simultaneously to track the user's hand as well as the head, and body movements in real-world space and scale. In this work, we first define the possibilities for simultaneous face- and world-tracking using current off-the-shelf smartphones. Next, we present the implementation of a smartphone app enabling hand, head, and body motion tracking. Finally, we present a technical analysis outlining the possible tracking range.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {augmented reality, 3D interaction, spatial interaction, smartphone, motion tracking, mobile devices, distant displays},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382956,
author = {Nukarinen, Tomi and Istance, Howell O. and Rantala, Jussi and M\"{a}kel\"{a}, John and Korpela, Kalevi and Ronkainen, Kimmo and Surakka, Veikko and Raisamo, Roope},
title = {Physiological and Psychological Restoration in Matched Real and Virtual Natural Environments},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382956},
doi = {10.1145/3334480.3382956},
abstract = {We present a study comparing physiological and psychological restoration in matched real and virtual natural environments. Participants (n=24) experienced a real forest, or one of two audiovisual virtual forests wearing a head-mounted display: A 3D forest or a 360-degree video. The results showed that some of the benefits of the real forest could also be obtained using virtual equivalents. Furthermore, we found the 3D forest to be emotionally more restorative than the 360-degree video forest. The findings can be used in creating restorative virtual environments for people who are unable to visit real natural environments.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {virtual reality, head-mounted display, restoration, virtual natural environment},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382947,
author = {Britain, Gabriel and Jain, Ajit and Lupfer, Nic and Kerne, Andruid and Perrine, Aaron and Seo, Jinsil and Sungkajun, Annie},
title = {Design is (A)Live: An Environment Integrating Ideation and Assessment},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382947},
doi = {10.1145/3334480.3382947},
abstract = {Design coursework is iterative and continuously-evolving. Separation of digital tools used in design courses disaffects instructors' and students' iterative process experiences.We present a system that integrates support for design ideation with a learning analytics dashboard. A preliminary study deployed the system in two courses, each with ~15 students and 1 instructor, for three months. We conducted semi-structured interviews to understand user experiences.Findings indicate benefits when systems contextualize creative work with assessment by integrating support for ideation with a learning analytics dashboard. Instructors are better able to track students and their work. Students are supported in reflecting on relationships among deliverables. We derive implications for contextualizing design with feedback to support creativity, learning, and teaching.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {iterative design, design assessment, design ideation, creativity, design education, learning analytics dashboard},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382910,
author = {Prange, Sarah and Alt, Florian},
title = {I Wish You Were Smart(Er): Investigating Users' Desires and Needs Towards Home Appliances},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382910},
doi = {10.1145/3334480.3382910},
abstract = {In this work, we present findings from an online survey (N=77) in which we assessed situations of users wishing for features or devices in their home to be smart(er). Our work is motivated by the fact that on one hand, several successful smart devices and features found their way into users' homes (e.g., smart TVs, smart assistants, smart toothbrushes). On the other hand, a more holistic understanding of when and why users would like devices and features to be smart is missing as of today. Such knowledge is valuable for researchers and practitioners to inform the design of future smart home devices and features, in particular with regards to interaction techniques, privacy mechanisms, and, ultimately, acceptance and uptake. We found that users would appreciate smart features for various use cases, including remote control and multi-tasking, and are willing to share devices. We believe our work to be useful for designers and HCI researchers by supporting the design and evaluation of future smart devices.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {smart devices, smart homes, online survey},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382908,
author = {Ahn, Sunggeun and Son, Jeongmin and Lee, Sangyoon and Lee, Geehyuk},
title = {Verge-It: Gaze Interaction for a Binocular Head-Worn Display Using Modulated Disparity Vergence Eye Movement},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382908},
doi = {10.1145/3334480.3382908},
abstract = {The Midas touch problem is a well-known problem in eye gaze interaction techniques. We present Verge-it as a Midas touch free input technique using modulated disparity vergence eye movement for a binocular head-worn display. We conducted a feasibility study under two different visual background conditions, namely dynamic background (TV) and static background (Wall) conditions. This study revealed a low false positive rate (TV: 0%, Wall: 2.10%) for Verge-it and acceptable performance.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {gaze input, vergence eye movements, AR/VR, modulated disparity vergence, head-worn display, midas-touch},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382848,
author = {Schmidmaier, Matthias and Hu\ss{}mann, Heinrich and Runge, Dominik Maurice},
title = {Beep Beep: Building Trust with Sound},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382848},
doi = {10.1145/3334480.3382848},
abstract = {Audio is one modality that besides content transmission offers non-verbal cues that influence emotional perception. This allows to increase trust for example in privacy-sensitive systems like digital assistants. In this work we focus on basic audio feedback and explore how parameters like melody, pitch or tempo influence the creation of trust. We refer to related research in trust perception of voice, and evaluate if the derived concepts can be universally applied to simple sound patterns. Our study (n=39) shows significant effects for melody and mode, while tendencies were found for pitch and individual user preferences. We consider our findings to serve as basis for research towards the design of unobtrusive and trustworthy user experiences.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {affective interaction design, trustful HCI, audio feedback},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382818,
author = {Samson, Briane Paul V. and Sumi, Yasuyuki},
title = {Are Two Heads Better than One? Exploring Two-Party Conversations for Car Navigation Voice Guidance},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382818},
doi = {10.1145/3334480.3382818},
abstract = {Voice guidance for car navigation typically considers drivers as docile actors. Recent works highlight limitations to this assumption which make drivers rely less on given directions. To explore how drivers can make better navigation decisions, we conducted a pilot Wizard-of-Oz study that gives turn suggestions in conversations between two voice agents. We asked 30 participants to drive in a simulation environment using voice guidance that gives three types of suggestions: familiar, optimal, and new routes. We examined their route choices, perceived workload and utterances while driving. We found that while most drivers followed directions appropriate for the given scenarios, they were more likely to make inappropriate choices after hearing alternatives in conversations. On the other hand, two-party conversations allowed drivers to better reflect on their choices after trips. We conclude by discussing preliminary design implications for car navigation voice guidance specifically and recommender systems in general.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {two-party conversation, driving, voice guidance, recommender systems, voice agents, navigation applications},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381811,
author = {Kirman, Ben and Lawson, Shaun and Linehan, Conor},
title = {What's Your Problem with the Dog Internet?},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381811},
doi = {10.1145/3334480.3381811},
abstract = {In this paper, we make an argument for using "the absurd" as a useful lens through which to critique modern developments in interactive technology. We argue that absurd positions are generative and engaging; they provide scope and direction for developing artefacts that people want to talk about and discuss. We argue for adopting absurd positions because; 1) as publicly funded academics, unbeholden to commercial interests, we can, 2) it's fun, and 3) doing so draws out, highlights, and plays with the often weird, fake, nonsense, bizarre, and surreal aspects of modern interactive technology artefacts - and the often weird situations that arise when interacting with those artefacts. In order to illustrate this argument, we present a number of case studies drawn from 10 years of our absurd research papers, many of which were published at previous iterations of this conference.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {adversarial design, critical design, alt.chi, absurd, troublemaking},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381661,
author = {Shah, Ajmal},
title = {On The Other Side: An Interactive Narrative to Incite Awareness and Empathy Towards Social Effects of Chronic Pain},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381661},
doi = {10.1145/3334480.3381661},
abstract = {Chronic pain is an ailment that affects over 60 million [1] people all over the world. It is a poorly understood condition by both clinicians and the society at large. Chronic pain manifests in many different forms and imposes immense physical limitations on the sufferer's body. However, the social and mental issues associated with chronic pain are often overlooked. Although modern medicine alleviates the physical symptoms of chronic pain, it fails to address issues that feast on the sufferer's mental health. Moreover, awareness, acceptance and empathy towards the sufferers are lacking in the society. On the other side is an interactive narrative that employs gameplay as a medium to induce empathy and awareness about social stigmatization and isolation that patients with chronic pain conditions face. The narrative transports the player into the troubled life of a chronic pain patient and their altered relationship with their own body.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {storyboarding, conceptualization, gameplay, mobile experience, chronic pain, empathy},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381066,
author = {Talkad Sukumar, Poorna and Avellino, Ignacio and Remy, Christian and DeVito, Michael A. and Dillahunt, Tawanna R. and McGrenere, Joanna and Wilson, Max L.},
title = {Transparency in Qualitative Research: Increasing Fairness in the CHI Review Process},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381066},
doi = {10.1145/3334480.3381066},
abstract = {Transparency in process and its reporting is paramount for establishing the rigor of qualitative studies. However, the CHI conference receives submissions with varying levels of transparency and oftentimes, papers that are more transparent can be inadvertently subjected to more scrutiny in the review process, raising issues of fairness. In this panel, we bring together researchers with diverse qualitative work experiences to present examples of transparency-related initiatives and their corresponding review responses. We aim to work towards setting standards for transparent reporting in qualitative-work submissions and increasing fairness in the review process. We focus on the challenges in achieving transparency in qualitative research and current workarounds to overcome frictions in the reviewing process through engaging discussions involving panelists and the audience.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {open research, qualitative research, transparency, peer review},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381054,
author = {Schartm\"{u}ller, Clemens and Sarcar, Sayan and Riener, Andreas and Kun, Andrew L. and Shaer, Orit and Boyle, Linda Ng and Iqbal, Shamsi},
title = {Automated Cars as Living Rooms and Offices: Challenges and Opportunities},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381054},
doi = {10.1145/3334480.3381054},
abstract = {With increasing automation of the driving task, cars' cockpits are transforming towards living spaces rather than pure modalities of transport. The promise of automated vehicles being individual places for relaxation and productivity while on-the-go, however, requires significant research. Not only safety-critical questions, but also issues related to ergonomic design, human factors for interactive systems, and social aspects have to be investigated. This special interests group presents an opportunity for connecting various CHI communities on these problems, which need to be solved under time-pressure, because automated vehicles are coming - whether or not the HCI-related issues are solved.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {well-being, automated driving, work, special interests group},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375231,
author = {Kliman-Silver, Clara and Siy, Oliver and Awadalla, Kira and Lentz, Alison and Convertino, Gregorio and Churchill, Elizabeth},
title = {Adapting User Experience Research Methods for AI-Driven Experiences},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375231},
doi = {10.1145/3334480.3375231},
abstract = {This short paper describes how to adapt user experience research methods for artificial intelligence (AI)-driven applications. Presently, there is a dearth of guidance for conducting UX research on AI-driven experiences. We describe what makes this class of experiences unique, propose a preliminary foundational framework to categorize AI-driven experiences, and within the framework we show an example of methodological adaptations via a case study.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {methods, user experience research, artificial intelligence, internet of things},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375212,
author = {Baba, Jun and Sichao, Song and Nakanishi, Junya and Kuramoto, Itaru and Ogawa, Kohei and Yoshikawa, Yuichiro and Ishiguro, Hiroshi},
title = {Teleoperated Robot Acting Autonomous for Better Customer Satisfaction},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375212},
doi = {10.1145/3334480.3375212},
abstract = {In recent years, an increasing number of teleoperated robots have been used to provide services from a remote location. Most earlier teleoperated robot systems informed the customers that the robots are being remotely controlled, while the customers believed that they were communicating with the operators through the robots. However, it has already been shown that there are some disadvantages in informing customers about the robot teleoperation. To investigate whether customers could accept and use teleoperated robots that acted as if they were autonomous, we developed a teleoperated system in which operators represent autonomous robots. Our system was experimentally tested by employing operators that provided services to customers in a real field. It was found that many customers were particularly satisfied with the service of the teleoperated robots that behaved as if they were autonomous, while we demonstrated that customers who did not realize the robot teleoperation rated the service higher than the customers who realized the same.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {led, voice changer, teleoperated robot, webrtc, autonomous, human robot interaction, speech recognition, design prototyping},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375176,
author = {Bellini, Rosanna and Dell, Nicola and Whitty, Monica and Bhattacharya, Debasis and Wall, David and Briggs, Pamela},
title = {Crime and/or Punishment: Joining the Dots between Crime, Legality and HCI},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375176},
doi = {10.1145/3334480.3375176},
abstract = {We aim to bring together a number of designers, researchers and practitioners to share their experience of the influence of crime and legality on their work. Through these discussions, we aspire to highlight the existing knowledge base for discussions of crime within HCI, provide a space for sharing researcher's personal experiences in their work with and against crime, and highlight best practice going forwards. We will do this by using three considerations to inform our critical focus on crime: (1) mapping out the existing ways that HCI has addressed crime; (2) considering what part crime plays in approaches to social justice; (3) questioning who is thus morally responsible for the criminal activity of others, and what does this entail for ensuring fair approaches within technical design.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {theories of justice, social justice, legality, criminal justice system, law enforcement},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375162,
author = {Sadeghian Borojeni, Shadan and Meschtscherjakov, Alexander and Pfleging, Bastian and Donmez, Birsen and Riener, Andreas and Janssen, Christian P. and Kun, Andrew L. and Ju, Wendy and Remy, Christian and Wintersberger, Philipp},
title = {Should I Stay or Should I Go? Automated Vehicles in the Age of Climate Change},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375162},
doi = {10.1145/3334480.3375162},
abstract = {Will automated driving help or hurt our efforts to remedy climate change? The overall impact of transportation and mobility on the global ecosystem is clear: changes to that system can greatly affect climate outcomes. The design of mobility and automotive systems will influence key factors such as driving style, fuel choice, ride sharing, traffic patterns, and total mileage. However, to date, there are few research efforts that explicitly focus on these overlapping themes (automated driving &amp; climate changes) within the HCI and AutomotiveUI communities. Our intention is to grow this community and awareness of the related problems. Specifically, in this workshop, we invite designers, researchers, and practitioners from the sustainable HCI, persuasive design, AutomotiveUI, and mobility communities to collaborate in finding ways to make future mobility more sustainable. Using embodied design improvisation and design fiction methods, we will explore the ways that systems affect behavior which then affect the environment.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {CO2 reduction, automated driving, climate change, collective optimization, future mobility, energy efficient driving},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375150,
author = {Spiel, Katta and Gerling, Kathrin and Bennett, Cynthia L. and Brul\'{e}, Emeline and Williams, Rua M. and Rode, Jennifer and Mankoff, Jennifer},
title = {Nothing About Us Without Us: Investigating the Role of Critical Disability Studies in HCI},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375150},
doi = {10.1145/3334480.3375150},
abstract = {Accessibility concerns play an increasing role in Human-Computer Interaction (HCI) research. This workshop takes a look at the role Critical Disability Studies currently plays in the development of assistive technologies and the accessibility of technologies more generally. Accordingly, it has been ten years since Mankoff's seminal paper on "Disability Studies as a Source of Critical Inquiry for the Field of Assistive Technology'' drew out the requirement of actively involving disabled people in research about them. We find it a fitting time for reflecting on and revitalising the topic. We will examine untapped research opportunities and identify systemic obstacles that keep disabled scholars in the margins of associated research. The gathering additionally serves to establish a community of researchers interested in pursuing the perspective of Critical Disability Studies within HCI.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {participatory research, critical disability studies, interaction design, assistive technologies},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375147,
author = {Li, Yang and Kumar, Ranjitha and Lasecki, Walter S. and Hilliges, Otmar},
title = {Artificial Intelligence for HCI: A Modern Approach},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375147},
doi = {10.1145/3334480.3375147},
abstract = {Artificial intelligence (AI) and Human Computer Interaction (HCI) share common roots and early work on conversational agents has laid the foundation for both fields. However, in subsequent decades the initial tight connection between the fields has become less pronounced. The recent rise of deep learning has revolutionized AI and has led to a raft of practical methods and tools that significantly impact areas outside of core-AI. In particular, modern AI techniques now power new ways for machines and humans to interact. Thus it is timely to investigate how modern AI can propel HCI research in new ways and how HCI research can help direct AI developments. This workshop offers a forum for researchers to discuss new opportunities that lie in bringing modern AI methods into HCI research, identifying important problems to investigate, showcasing computational and scientific methods that can be applied, and sharing datasets and tools that are already available or proposing those that should be further developed. The topics we are interested in including deep learning methods for understanding and modeling human behaviors and enabling new interaction modalities, hybrid intelligence that combine human and machine intelligence to solve difficult tasks, and tools and methods for interaction data curation and large-scale data-driven design. At the core of these topics, we want to start the conversation on how data-driven and data-centric approaches of modern AI can impact HCI.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {data-driven design and modeling, crowdsourcing, design guidelines, algorithms and tools, artificial intelligence, deep learning, sensing, human computer interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382995,
author = {Maus, Natalie and Rutledge, Dalton and Al-Khazraji, Sedeeq and Bailey, Reynold and Alm, Cecilia Ovesdotter and Shinohara, Kristen},
title = {Gaze-Guided Magnification for Individuals with Vision Impairments},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382995},
doi = {10.1145/3334480.3382995},
abstract = {Video-based eye trackers increasingly have potential to improve on-screen magnification for low-vision computer users. Yet, little is known about the viability of eye tracking hardware for gaze-guided magnification. We employed a magnification prototype to assess eye tracking quality for low-vision users as they performed reading and search tasks. We show that a high degree of tracking loss prevents current video-based eye tracking from capturing gaze input for low-vision users. Our findings show current technologies were not made with low vision users in mind, and we offer suggestions to improve gaze-tracking for diverse eye input.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {low vision, magnifier, video-based eye tracking},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382953,
author = {Zenner, Andr\'{e} and Kosmalla, Felix and Ehrlich, Jan and Hell, Philip and Kahl, Gerrit and Murlowski, Christian and Speicher, Marco and Daiber, Florian and Heinrich, Daniel and Kr\"{u}ger, Antonio},
title = {A Virtual Reality Couch Configurator Leveraging Passive Haptic Feedback},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382953},
doi = {10.1145/3334480.3382953},
abstract = {When configuring furniture during sales consultancy in a furniture store, customers are usually confronted with abstract 2D drawings or simplistic renderings of the discussed configuration on a display. We present a novel application based on virtual reality (VR) to support furniture store consultations. Our system allows customers to elaborate different configurations of a couch in dialogue with a sales expert and lets customers experience them through immersive VR in a variety of virtual environments. While the sales-expert can modify the couch layout and fabric, the customer can stay immersed and experience a realistic tactile feeling of the configured couch through passive haptic feedback provided by a sample piece the customer can sit on. A preliminary field study in a furniture store showed that the system is immersive, conveying realistic impressions of the couch configurations. Customers perceived the VR configurator as useful since it would make their purchase decisions easier.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {user study, virtual reality, immersion, passive haptic feedback, application, furniture configuration},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381809,
author = {Seymour, William and Van Kleek, Max},
title = {Does Siri Have a Soul? Exploring Voice Assistants Through Shinto Design Fictions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381809},
doi = {10.1145/3334480.3381809},
abstract = {It can be difficult to critically reflect on technology that has become part of everyday rituals and routines. To combat this, speculative and fictional approaches have previously been used by HCI to decontextualise the familiar and imagine alternatives. In this work we turn to Japanese Shinto narratives as a way to defamiliarise voice assistants, inspired by the similarities between how assistants appear to 'inhabit' objects similarly to kami. Describing an alternate future where assistant presences live inside objects, this approach foregrounds some of the phenomenological quirks that can otherwise easily become lost. Divorced from the reality of daily life, this approach allows us to reevaluate some of the common interactions and design patterns that are common in the virtual assistants of the present.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice assistants, design fiction, shinto, critical design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375211,
author = {Barba, Evan and Lioon, Anthony and Miller, Christopher and Khan, Yasir Majeed},
title = {Tele-Robotic Interface Design in Context: A Case for Recursive Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375211},
doi = {10.1145/3334480.3375211},
abstract = {Satellites have useful lifetimes of only a few decades; however, these could easily be extended if consumable resources could be replaced. Many groups are now exploring the possibility of using unmanned orbital robots to perform satellite servicing operations. These orbiting robots are currently semi-autonomous and require monitoring and control by highly trained ground teams in order to complete their activities. This provides for a unique and tightly constrained operating environment with very particular interface needs. Here, we document the process we used for developing a tele-robotic interface specific to NASA's Restore-L mission, and describe the choices and considerations we weighed when implementing our designs. We discuss the technical and mission parameters as well as the social and operational context of our work, and articulate the need for a design framework that is capable of better connecting these two domains.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {multi-scale design, systemic design, human-robot interaction, data visualization, recursive design},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3386149,
author = {Baecker, Ronald (Ron) M.},
title = {SIGCHI Social Impact Award Talk: A Call to Action},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3386149},
doi = {10.1145/3334480.3386149},
abstract = {Our world has been animated and enriched by digital technologies used for creativity, collaboration, learning, health, politics, and commerce. Yet there is much that is troubling. We depend upon software that nobody truly understands and that is vulnerable to hackers and cyberterrorism. Privacy has been overrun by governments and surveillance capitalism. Our children are addicted to their devices; we have become workaholics. Jobs and livelihoods are being demolished without adequate social safety nets. A few digital technology leviathans threated to control not only their domains, but all commerce. Among all these issues, I am most deeply concerned about the hype associated with modern artificial intelligence, and the risks to society stemming from premature use of AI software. We are particularly vulnerable in domains such as medical diagnosis, criminal justice, seniors care, driving, and warfare. Here AI applications have begun or are imminent. Yet much current AIs are unreliable and inconsistent, without common sense; deceptive in hiding that they are algorithms and not people; mute and unable to explain decisions and actions; unfair and unjust; free from accountability and responsibility; and used but not trusted. Happily, we are not helpless victims of forces totally outside our control. We can raise our voices as citizens; we can enact procedures and legislation as a society. My talk will mention steps of both kinds, then focus on what we as digital technology, HCI, and usability professionals can and must do.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–3},
numpages = {3},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383164,
author = {Lee, Kyungwon and Jung, Jaewoo and Lee, Seung Ah},
title = {MicroAquarium: An Immersive and Interactive Installation with Living Microorganisms},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383164},
doi = {10.1145/3334480.3383164},
abstract = {We present MicroAquarium, a new hybrid digital-biological installation that provides an immersive experience of interacting with real living cells. MicroAquarium uses a custom-built light-projection microscope equipped with an interactive input device and an immersive display to mediate the interaction between humans and microorganisms. Users' hand motions are recognized and converted into a pattern of light that is projected onto the photo-tactic microorganisms inside the microscope. The view inside the microscope is displayed on a large screen display, providing users with an immersive experience of being inside an aquarium of living cells. Our system effectively bridges the differences in size and the sensing modalities between human users and microscopic organisms and allows for unique playful and exploratory inter-species interactions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {animal computer interaction, biological hci, human biology interaction, hybrid digital-biological system},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383064,
author = {Ekambaranathan, Anirudh and Zhao, Jun and Van Kleek, Max},
title = {Understanding Value and Design Choices Made by Android Family App Developers},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383064},
doi = {10.1145/3334480.3383064},
abstract = {The rapidly expanding family mobile app market provides a great opportunity for children's education and development. However, recent research has revealed a prevalence of persuasive designs and tracking of children's data in these apps, which may harm children's online privacy and self-regulation development. We conducted 20 interviews with Android family app developers to understand their design practices. We used the lens of Value Sensitive Design to identify developer's values and how they translate them into design choices. Our findings show that though developer values are generally aligned with the best interest of users, they often must make compromises due to market pressure, lack of monetisation options, and the use of biased design guidelines. Our findings show a need for centralised actionable guidelines and important directions for HCI research to support both end-users' and developers' values.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {developer practices, responsible design, value sensitive design, child safety online},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383055,
author = {Race, Lauren and Kearney-Volpe, Claire and Fleet, Chancey and Miele, Joshua A. and Igoe, Tom and Hurst, Amy},
title = {Designing Educational Materials for a Blind Arduino Workshop},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383055},
doi = {10.1145/3334480.3383055},
abstract = {There is an overall shortage of accessible educational material available for blind and low vision learners. This shortage is especially pronounced in the domain of electronics, where the materials are historically visually-rendered and complex. To address this, we took a qualitative approach to designing and evaluating tactile graphics and textual descriptions when building circuits. To gain an understanding of their efficacy, we provided a circuit description [3], component diagrams (Figure 4), and a tactile schematic [9] as educational materials in a Blind Arduino workshop with eight participants and interviewed these participants about their experience. Our research revealed the complexities of designing these materials: our tactile component diagrams were usable and helpful, whereas our tactile schematics and circuit descriptions presented learning barriers in a microcontroller workshop. We provide recommendations for future research to design accessible materials to teach electronics.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {inclusive design, tactile graphics, electronic circuits, accessibility, schematics, blind},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383045,
author = {Alldridge, Tom and Barlow, Michael and Teh, Xiao Xuan and Barker, Edward and Sutherland-Dee, Samuel and Roudaut, Anne},
title = {PaNDa-Glove: A Sensory Substitution Glove for Peripheral Neuropathy},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383045},
doi = {10.1145/3334480.3383045},
abstract = {Peripheral Neuropathy (PN) is a condition which causes diminished and potentially lost sensation in the extremities of the body, typically affecting diabetics and the elderly. We present PaNDa-Glove (Peripheral Neuropathy Displacement Glove), an arm-mounted device which displaces tactile sensation in the fingertips to the forearm, and substitutes thermosensitivity of the hand with vibrotactile and audio feedback. We hypothesize PaNDa-Glove will help patients with PN better recognise the tightness of their grip, and reduce the frequency of burns to the hand. A preliminary quantitative experiment with healthy users strongly suggests that PaNDa-Glove enhances the sensitivity of grip, and an informal qualitative study suggests that the substituted feedback is clear, distinguishable and comfortable.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {wearable device, peripheral neuropathy, sensory displacement, sensory substitution, tactile feedback},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383044,
author = {Zhang, Yixuan and Parker, Andrea G.},
title = {Eat4Thought: A Design of Food Journaling},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383044},
doi = {10.1145/3334480.3383044},
abstract = {Food journaling is an effective method to help people identify their eating patterns and encourage healthy eating habits as it requires self-reflection on eating behaviors. Current tools have predominately focused on tracking food intake, such as carbohydrates, proteins, fats, and calories. Other factors, such as contextual information and momentary thoughts and feelings that are internal to an individual, are also essential to help people reflect upon and change attitudes about eating behaviors. However, current dietary tracking tools rarely support capturing these elements as a way to foster deep reflection. In this work, we present Eat4Thought - a food journaling application that allows users to track their emotional, sensory, and spatio-temporal elements of meals as a means of supporting self-reflection. The application enables vivid documentation of experiences and self-reflection on the past through video recording. We describe our design process and an initial evaluation of the application. We also provide design recommendations for future work on food journaling.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {personal health informatics, food journal, eating behaivors, reflection},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383040,
author = {Schrapel, Maximilian and Herzog, Florian and Ryll, Steffen and Rohs, Michael},
title = {Watch My Painting: The Back of the Hand as a Drawing Space for Smartwatches},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383040},
doi = {10.1145/3334480.3383040},
abstract = {Smartwatches can be used independently from smartphones, but input tasks like messaging are cumbersome due to the small display size. Parts of the display are hidden during interaction, which can lead to incorrect input. For simplicity, instead of general text input a small set of answer options are often provided, but these are limited and impersonal. In contrast, free-form drawings can answer messages in a very personal way, but are difficult to produce on small displays. To enable precise drawing input on smartwatches we present a magnetic stylus that is tracked on the back of the hand. In an evaluation of several algorithms we show that 3D position estimation with a 7.5x20mm magnet reaches a worst-case 6% relative position error on the back of the hand. Furthermore, the results of a user study are presented, which show that in the case of drawing applications the presented technique is faster and more precise than direct finger input.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {digital pens, mobile interaction, around-device interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383033,
author = {van Rijen, Karlijn and Cobbenhagen, Tom and Janssen, Rens and Olsen, Maria and Brankaert, Rens and Houben, Maarten and Lu, Yuan},
title = {RelivRing: Reliving Social Activities for People with Dementia},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383033},
doi = {10.1145/3334480.3383033},
abstract = {Memory loss is one of the most frequent symptoms associated with dementia. Losing the memories of meaningful social activities, such as visits from family, can be confronting not only for the person with dementia, but also for relatives and caretakers. Through an iterative design process involving people with dementia, caretakers and relatives, the RelivRing concept was developed. The RelivRing enables people with dementia to relive the positive experience of visits from relatives. It allows relatives to leave audio messages of their visits, which the person with dementia might have otherwise forgotten. When listening to these messages, the person with dementia can re-experience the positive feeling of the visit. The design is adapted to a person with dementia's cognitive and perceptual abilities following literature research and in-context user studies. With the RelivRing, we aim to maintain and strengthen existing social relations between people with dementia and their relatives.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {reminiscence, dementia, social activity, design, audio messages},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382998,
author = {Liu, Dongyu and Smith, Micah J. and Veeramachaneni, Kalyan},
title = {Understanding User-Bot Interactions for Small-Scale Automation in Open-Source Development},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382998},
doi = {10.1145/3334480.3382998},
abstract = {Small-scale automation tools, or "bots," have been widely deployed in open-source software development to support manual project maintenance tasks. Though interactions between these bots and human developers can have significant effects on user experience, previous research has instead mostly focused on project outcomes. We reviewed existing small-scale bots in wide use on GitHub. After an in-depth qualitative and quantitative evaluation, we compiled several important design principles for human-bot interaction in this context. Following the requirements, we further propose a workflow to support bot developers.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {software and its engineering, software creation and management, HCI design and evaluation methods, human-centered computing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382984,
author = {Miyashita, Homei},
title = {Norimaki Synthesizer: Taste Display Using Ion Electrophoresis in Five Gels},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382984},
doi = {10.1145/3334480.3382984},
abstract = {This study describes the production of a novel taste display which uses ion electrophoresis in five gels containing electrolytes that supply controlled amounts of each of the five basic tastes to apply an arbitrary taste to the user's tongue, analogous to optical displays that produce arbitrary colors from lights of three basic colors. When applied to the tongue with no voltage, the user can taste all five tastes. However, when an electric potential is applied, the cations in the gel move to the cathode side and away from the tongue, so that the flavor is tasted weakly. In this way, we have developed a taste display that reproduces an arbitrary taste by individually suppressing the sensation of each of the five basic tastes (like subtractive synthesis.) Our study differs from previous work in that it uses an electric current for electrophoresis rather than electrically stimulating the tongue, and it does not involve ingestion of a solution to deliver the taste.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {taste display, electric taste},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382977,
author = {Das, Nilaksh and Park, Haekyu and Wang, Zijie J. and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},
title = {Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382977},
doi = {10.1145/3334480.3382977},
abstract = {Deep neural networks (DNNs) are increasingly powering high-stakes applications such as autonomous cars and healthcare; however, DNNs are often treated as "black boxes" in such applications. Recent research has also revealed that DNNs are highly vulnerable to adversarial attacks, raising serious concerns over deploying DNNs in the real world. To overcome these deficiencies, we are developing Massif, an interactive tool for deciphering adversarial attacks. Massif identifies and interactively visualizes neurons and their connections inside a DNN that are strongly activated or suppressed by an adversarial attack. Massif provides both a high-level, interpretable overview of the effect of an attack on a DNN, and a low-level, detailed description of the affected neurons. Massif's tightly coupled views help people better understand which input features are most vulnerable and important for correct predictions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {visual analytics, attribution graph, scalable summarization, adversarial attack, deep learning interpretability},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382969,
author = {Bell, Lewis and Lees, Jay and Smith, Will and Harding, Charlie and Lee, Ben and Bennett, Daniel},
title = {PauseBoard: A Force-Feedback Keyboard for Unintrusively Encouraging Regular Typing Breaks},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382969},
doi = {10.1145/3334480.3382969},
abstract = {Maintaining positive digital well-being has become essential as we spend more and more time working at desks in offices, interacting with computers and typing for hours at a time. In this paper we present PauseBoard: A computer keyboard designed to unintrusively encourage users to take regular breaks. Through the use of motorised linear potentiometers, the force required to activate each key is increased towards the end of a set work period, until a maximum level of resistance is reached. Preliminary testing shows that 75% of users respond well to this novel gentle encouragement, being reminded to take breaks while still being able to concentrate and finish their current task, especially when the resistance is increased slowly over time.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {stress, digital well-being, force-feedback, keyboard, productivity},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382932,
author = {Baghaei, Nilufar and Stemmet, Lehan and Hlasnik, Andrej and Emanov, Konstantin and Hach, Sylvia and Naslund, John A. and Billinghurst, Mark and Khaliq, Imran and Liang, Hai-Ning},
title = {Time to Get Personal: Individualised Virtual Reality for Mental Health},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382932},
doi = {10.1145/3334480.3382932},
abstract = {Mental health conditions pose a major challenge to healthcare providers and society at large. Early intervention can have significant positive impact on a person's prognosis, particularly important in improving mental health outcomes and functioning for young people. Virtual Reality (VR) in mental health is an emerging and innovative field. Recent studies support the use of VR technology in the treatment of anxiety, phobia, eating disorders, addiction, and pain management. However, there is little research on using VR for supporting, treatment and prevention of depression - a field that is very much emerging. There is also very little work done in offering individualised VR experience to users with mental health issues. This paper proposes iVR, a novel individualised VR for improving users' self-compassion, and in the long run, their positive mental health. We describe the concept, design, architecture and implementation of iVR and outline future work. We believe this contribution will pave the way for large-scale efficacy testing, clinical use, and potentially cost-effective delivery of VR technology for mental health therapy in future.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {self-compassion, individualisation, user experience, virtual reality, mental health, user models, depression},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382894,
author = {Sadka, Ofir and Antle, Alissa},
title = {Interactive Technologies for Emotion-Regulation Training: Opportunities and Challenges},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382894},
doi = {10.1145/3334480.3382894},
abstract = {Emotion regulation (ER) is foundational to mental health and well-being. In the last ten years, there has been an increasing focus on this use of interactive technologies to support ER training in a variety of contexts. However, work has been done by researchers from diverse fields, and no cohesive research agenda exists that explicates how and why interactive technologies may benefit ER training. To address this gap, this paper presents the initial results of a descriptive review of 38 peer-reviewed papers on this topic. Qualitative analysis revealed four opportunity themes where interactive technologies appear to provide unique benefits. The analysis also revealed three challenge themes where design guidance, particularly around emotion representation, is ambiguous or underspecified. Based on our findings, we propose future research in these thematic areas; we also propose intersectional themes and underexplored areas that researchers and designers may find productive to explore.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {descriptive literature review, emotion regulation training, interactive technology},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382857,
author = {Jensen, Walther and Streubel Kristensen, Thomas and Sand Kirk, Christoffer and Hameed, Hassan Abdul and Bergmann Villadsen, Daniel and L\"{o}chtefeld, Markus},
title = {Hybrid Settlers - Integrating Dynamic Tiles into a Physical Board Game Using Electrochromic Displays},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382857},
doi = {10.1145/3334480.3382857},
abstract = {In this paper we present a novel method of hybridizing physical board games by adding dynamic and digitally controlled fields utilizing electrochromic inks. In particular we built electrochromic displays that fit the hexagon fields on the Settlers of Catan board game and thereby added the ability to change a fields resources during game play. In this paper we report on the prototypical implementation and two preliminary studies that indicate how these dynamic fields can increase the excitement and reward of playing the game.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {settlers of catan, electrochromic displays, boardgames},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382854,
author = {Poisson, C\'{e}line and Barr\'{e}, Jessy and Bourmaud, Ga\"{e}tan and Forzy, Jean-Fran\c{c}ois},
title = {Driver Behavior in Conditional Automation: Comparison of Driving Simulator and Wizard of Oz Conditions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382854},
doi = {10.1145/3334480.3382854},
abstract = {In this paper, we analyzed driver behavior during automated driving in two experimental conditions, a Driving Simulator (DS) and a Wizard of Oz vehicle (WOz). Twenty-nine drivers in the DS condition and nine drivers in the WOz condition performed three different requests to intervene (RTI) during automated driving (AD). Three variables were measured, the number of control checks during AD and non-driving related tasks (NDRT), the reaction time to resume manual control and the strategy used to recover control. Differences were found concerning road monitoring during NDRT, there are more interruptions in the WOz condition than in the DS condition. Additionally, the strategies used to recover control were different between conditions, the steering wheel and brake pedal were used more often in the WOz condition while the accelerator was used more often in the DS condition. However, no difference was found concerning reaction time to resume control.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {non-driving related tasks, human factors, wizard of oz, automated driving, simulator, request to intervene},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382852,
author = {You, Yuhui and Fogelson, Mitchell and Cheng, Kelvin and Stenger, Bjorn},
title = {EMI: An Expressive Mobile Interactive Robot},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382852},
doi = {10.1145/3334480.3382852},
abstract = {In this paper, we explore how the emotional behavior of a robot affects interactions with humans. We introduce the EMI platform - an expressive, mobile and interactive robot - consisting of a circular diff-drive robot base equipped with a rear-projected expressive face, and omni-directional microphone for voice-interaction. We exhibited the EMI robot at a public event, in which attendees were given the option to interact with the robot and participate in a survey and observational study. The survey and observations focused on the effects of the robot's expressiveness in interactions with users of different ages and cultural backgrounds. From the survey responses, video observations and informal interviews we highlight key design decisions in EMI that resulted in positive user reactions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {emotional robot, robot tolerance, robot design, human-robot interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382842,
author = {Bruzzese, Tommy and Gao, Irena and Dietz, Griffin and Ding, Christina and Romanos, Alyssa},
title = {Effect of Confidence Indicators on Trust in AI-Generated Profiles},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382842},
doi = {10.1145/3334480.3382842},
abstract = {Artificial Intelligence (AI) is increasingly augmenting and generating online content, but research suggests that users distrust content which they believe to be AI-generated. In this paper, we study whether introducing a confidence indicator, a text rating of an algorithm's confidence in its source data alongside rationale for why the data is more or less trustworthy, affects this distrust in Airbnb host profiles believed to be computer-generated. Our results indicate that a low-confidence indicator decreases participant trust in the rental host, but high-confidence indicators have no significant impact on trust. These findings suggest that user trust of AI-generated content can be negatively, but not positively, affected by a confidence indicator.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {computer-mediated communication (CMC), artificial intelligence-mediated communication (AI-MC), artificial intelligence, trust},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382837,
author = {Brun, Damien and George, S\'{e}bastien and Gouin-Vallerand, Charles},
title = {Keycube: Text Entry Evaluation with a Cubic Device},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382837},
doi = {10.1145/3334480.3382837},
abstract = {The keycube is a tangible cubic device including a text entry interface for different apparatuses such as augmented, mixed or virtual reality headsets, as well as smart TVs, desktop computers, laptops, tablets. The keycube comprises 80 keys equally disposed on 5 faces. In this paper we investigate keycube text entry performances and the potential typing skill transfer from traditional keyboard. Using prototype implementations, we conducted a user study comparing different cubic layouts and included a baseline from traditional keyboards. Experiments show that users are able to attain about 19 words per minute within one hundred minutes of practice with a QWERTY-based cubic layout, more than twice the speed of an unknown-based cubic layout with similar error rate, and about 30% of their speed with a traditional keyboard.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {input speed, evaluation, device, cube, text entry, keyboard},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

