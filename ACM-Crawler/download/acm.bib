@inproceedings{10.1145/3313831.3376887,
author = {Heyer, Jeremy and Raveendranath, Nirmal Kumar and Reda, Khairi},
title = {Pushing the (Visual) Narrative: The Effects of Prior Knowledge Elicitation in Provocative Topics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376887},
doi = {10.1145/3313831.3376887},
abstract = {Narrative visualization is a popular style of data-driven storytelling. Authors use this medium to engage viewers with complex and sometimes controversial issues. A challenge for authors is to not only deliver new information, but to also overcome people's biases and misconceptions. We study how people adjust their attitudes toward (or away from) a message experienced through a narrative visualization. In a mixed-methods analysis, we investigate whether eliciting participants' prior beliefs, and visualizing those beliefs alongside actual data, can increase narrative persuasiveness. We find that incorporating priors does not significantly affect attitudinal change. However, participants who externalized their beliefs expressed greater surprise at the data. Their comments also indicated a greater likelihood of acquiring new information, despite the minimal change in attitude. Our results also extend prior findings, showing that visualizations are more persuasive than equivalent textual data representations for exposing contentious issues. We discuss the implications and outline future research directions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {narrative visualization, debiasing, persuasion, belief elicitation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376883,
author = {Beneteau, Erin},
title = {Who Are You Asking?: Qualitative Methods for Involving AAC Users as Primary Research Participants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376883},
doi = {10.1145/3313831.3376883},
abstract = {When trying to understand people's perspectives, qualitative researchers in HCI often use methods which assume participants can easily communicate verbally. There are few dedicated resources in HCI which provide an overview of qualitative methods to effectively gather the perspectives of people who cannot easily communicate verbally; specifically, people who use Augmentative and Alternative Communication (AAC). As a result, AAC users might be excluded from studies using methods such as interviews or focus groups, even if they fit the researcher's target population. To address this problem, I review literature from both HCI and therapeutic AAC research fields to discuss methods used with AAC users. In addition, I present relevant case examples from my own qualitative research and propose a framework to guide HCI researchers on choosing appropriate methods when involving AAC users as central research participants. I also identify design opportunities for HCI researchers to innovate on the tools and methods used for qualitative research with AAC users. This paper provides an easily accessible overview of qualitative methods HCI researchers can use with AAC users as participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci, qualitative research, augmentative and alternative communication, disabilities, aac, methods},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376861,
author = {Foley, Margaret and Casiez, G\'{e}ry and Vogel, Daniel},
title = {Comparing Smartphone Speech Recognition and Touchscreen Typing for Composition and Transcription},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376861},
doi = {10.1145/3313831.3376861},
abstract = {Ruan et al. found transcribing short phrases with speech recognition nearly 200% faster than typing on a smartphone. We extend this comparison to a novel composition task, using a protocol that enables a controlled comparison with transcription. Results show that both composing and transcribing with speech is faster than typing. But, the magnitude of this difference is lower with composition, and speech has a lower error rate than keyboard during composition, but not during transcription. When transcribing, speech outperformed typing in most NASA-TLX measures, but when composing, there were no significant differences between typing and speech for any measure except physical demand.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {mobile phones, speech recognition, text entry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376853,
author = {Kulp, Leah and Sarcevic, Aleksandra and Zheng, Yinan and Cheng, Megan and Alberto, Emily and Burd, Randall},
title = {Checklist Design Reconsidered: Understanding Checklist Compliance and Timing of Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376853},
doi = {10.1145/3313831.3376853},
abstract = {We examine the association between user interactions with a checklist and task performance in a time-critical medical setting. By comparing 98 logs from a digital checklist for trauma resuscitation with activity logs generated by video review, we identified three non-compliant checklist use behaviors: failure to check items for completed tasks, falsely checking items when tasks were not performed, and inaccurately checking items for incomplete tasks. Using video review, we found that user perceptions of task completion were often misaligned with clinical practices that guided activity coding, thereby contributing to non-compliant check-offs. Our analysis of associations between different contexts and the timing of check-offs showed longer delays when (1) checklist users were absent during patient arrival, (2) patients had penetrating injuries, and (3) resuscitations were assigned to the highest acuity. We discuss opportunities for reconsidering checklist designs to reduce non-compliant checklist use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {checklist design, video review, trauma resuscitation, mixed methods, dynamic checklist, medical checklist},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376830,
author = {Kim, Yoojung and Bhattacharya, Arpita and Kientz, Julie A. and Lee, Jin Ha},
title = {"It Should Be a Game for Fun, Not Exercise": Tensions in Designing Health-Related Features for Pok\'{e}mon GO},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376830},
doi = {10.1145/3313831.3376830},
abstract = {Leveraging existing popular games such as Pok\'{e}mon GO to promote health can engage people in healthy activities without sacrificing gaming appeal. However, little is known about what potential tensions arise from incorporating new health-related features to already existing and popular games and how to resolve those tensions from players' perspectives. In this paper, we identify design tensions surrounding the appeals of Pok\'{e}mon GO, perspectives on different health needs, and mobile health technologies. By conducting surveys and design workshops with 20 avid Pok\'{e}mon GO players, we demonstrate four design tensions: (1) diverse goals and rewards vs. data accuracy, (2) strong bonds between players and characters vs. gaming obsession, (3) collaborative play vs. social anxiety, and (4) connection of in-real-life experiences with the game vs. different individual contexts. We provide design implications to resolve these tensions in Pok\'{e}mon GO and discuss how to extend our findings to the broader context of health promotion in location-based games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {health-related game feature, game design, location-based game, health promotion, augmented reality game, pokemon go, design tension},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376825,
author = {Agrawal, Ankit and Abraham, Sophia J. and Burger, Benjamin and Christine, Chichi and Fraser, Luke and Hoeksema, John M. and Hwang, Sarah and Travnik, Elizabeth and Kumar, Shreya and Scheirer, Walter and Cleland-Huang, Jane and Vierhauser, Michael and Bauer, Ryan and Cox, Steve},
title = {The Next Generation of Human-Drone Partnerships: Co-Designing an Emergency Response System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376825},
doi = {10.1145/3313831.3376825},
abstract = {The use of semi-autonomous Unmanned Aerial Vehicles (UAV) to support emergency response scenarios, such as fire surveillance and search and rescue, offers the potential for huge societal benefits. However, designing an effective solution in this complex domain represents a "wicked design" problem, requiring a careful balance between trade-offs associated with drone autonomy versus human control, mission functionality versus safety, and the diverse needs of different stakeholders. This paper focuses on designing for situational awareness (SA) using a scenario-driven, participatory design process. We developed SA cards describing six common design-problems, known as SA demons, and three new demons of importance to our domain. We then used these SA cards to equip domain experts with SA knowledge so that they could more fully engage in the design process. We designed a potentially reusable solution for achieving SA in multi-stakeholder, multi-UAV, emergency response applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emergency response, participatory design, human-CPS interactions, situational awareness, unmanned aerial vehicles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376821,
author = {Rietzler, Michael and Deubzer, Martin and Dreja, Thomas and Rukzio, Enrico},
title = {Telewalk: Towards Free and Endless Walking in Room-Scale Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376821},
doi = {10.1145/3313831.3376821},
abstract = {Natural navigation in VR is challenging due to spatial limitations. While Teleportation enables navigation within very small physical spaces and without causing motion sickness symptoms, it may reduce the feeling of presence and spacial awareness. Redirected walking (RDW), in contrast, allows users to naturally walk while staying inside a finite, but still very large, physical space. We present Telewalk, a novel locomotion approach that combines curvature and translation gains known from RDW research in a perceivable way. This combination enables Telewalk to be applied even within a physical space of 3m x 3m. Utilizing the head rotation as input device enables directional changes without any physical turns to keep the user always on an optimal circular path inside the real world while freely walking inside the virtual one. In a user study we found that even though motion sickness susceptible participants reported respective symptoms, Telewalk did result in stronger feelings of presence and immersion and was seen as more natural then Teleportation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {redirected walking, virtual reality, Telewalk},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376809,
author = {Ayobi, Amid and Marshall, Paul and Cox, Anna L.},
title = {Trackly: A Customisable and Pictorial Self-Tracking App to Support Agency in Multiple Sclerosis Self-Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376809},
doi = {10.1145/3313831.3376809},
abstract = {Self-tracking is an important part of self-care. However, predefined self-tracking approaches can impede people's agency in managing their health. We investigated a customisable and pictorial self-tracking approach in multiple sclerosis self-management by implementing and conducting a field study of Trackly: a prototype app that supports people in defining and colouring pictorial trackers, such as body shapes. We found that participants utilised the elements of Trackly designed to support agentive behaviour: they defined personally meaningful tracking parameters in their own words, and particularly valued being able to flexibly colour in and make sense of their pictorial trackers. Having been able to support their individual self-care intentions with Trackly, participants reported a spectrum of interrelated experiences of agency, including a sense of ownership, identity, self-awareness, mindfulness, and control. Our findings demonstrate the importance of supporting people's individual needs and creative capacities to foster mindful and personally meaningful engagement with health and wellbeing data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {symptom monitoring, perceived control, self-reflection, mindfulness, self-tracking, customisation, mood tracking, customization, self-awareness, agency, bullet journaling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376808,
author = {Zhang, Tianyi and El Ali, Abdallah and Wang, Chen and Hanjalic, Alan and Cesar, Pablo},
title = {RCEA: Real-Time, Continuous Emotion Annotation for Collecting Precise Mobile Video Ground Truth Labels},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376808},
doi = {10.1145/3313831.3376808},
abstract = {Collecting accurate and precise emotion ground truth labels for mobile video watching is essential for ensuring meaningful predictions. However, video-based emotion annotation techniques either rely on post-stimulus discrete self-reports, or allow real-time, continuous emotion annotations (RCEA) only for desktop settings. Following a user-centric approach, we designed an RCEA technique for mobile video watching, and validated its usability and reliability in a controlled, indoor (N=12) and later outdoor (N=20) study. Drawing on physiological measures, interaction logs, and subjective workload reports, we show that (1) RCEA is perceived to be usable for annotating emotions while mobile video watching, without increasing users' mental workload (2) the resulting time-variant annotations are comparable with intended emotion attributes of the video stimuli (classification error for valence: 8.3%; arousal: 25%). We contribute a validated annotation technique and associated annotation fusion method, that is suitable for collecting fine-grained emotion annotations while users watch mobile videos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {real-time, annotation, mobile, labels, video, emotion, continuous},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376807,
author = {Xie, Yao and Chen, Melody and Kao, David and Gao, Ge and Chen, Xiang 'Anthony'},
title = {CheXplain: Enabling Physicians to Explore and Understand Data-Driven, AI-Enabled Medical Imaging Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376807},
doi = {10.1145/3313831.3376807},
abstract = {The recent development of data-driven AI promises to automate medical diagnosis; however, most AI functions as 'black boxes' to physicians with limited computational knowledge. Using medical imaging as a point of departure, we conducted three iterations of design activities to formulate CheXplain — a system that enables physicians to explore and understand AI-enabled chest X-ray analysis: (i) a paired survey between referring physicians and radiologists reveals whether, when, and what kinds of explanations are needed; (ii) a low-fidelity prototype co-designed with three physicians formulates eight key features; and (iii) a high-fidelity prototype evaluated by another six physicians provides detailed summative insights on how each feature enables the exploration and understanding of AI. We summarize by discussing recommendations for future work to design and implement explainable medical AI systems that encompass four recurring themes: motivation, constraint, explanation, and justification.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {explainable artificial intelligence, physician-centered design, system design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376802,
author = {Monastero, Beatrice and McGookin, David and Takala, Tapio},
title = {"I Just Leaned on It!" Exploring Opportunistic Social Discovery of a Technologically Augmented Cushion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376802},
doi = {10.1145/3313831.3376802},
abstract = {While personal devices are often used to connect online with others far away, public media rarely offers opportunities to connect with collocated individuals. We explore novel interaction strategies to enhance opportunistic collocated sociality through technologically augmented daily objects. ThinkCushion is an augmented cushion allowing users to record and playback audio messages either explicitly or implicitly by leaning on it. We deployed ThinkCushion in an open coworking space and gathered quantitative and qualitative data over one month to unveil how individuals discovered it and interacted. We individuate three modes of discovery (serendipitous, spectated and facilitated) and their relations with situated socio-spatial aspects. We discuss the interplay of active and passive interaction modalities for locally accessing and creating content, and how verbal content can be used in either performative or informative ways. We suggest future research on how to design public technologies supporting collocated sociality already from the phase of technological discovery.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sociality, opportunistic interaction, embedded systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376788,
author = {Niforatos, Evangelos and Palma, Adam and Gluszny, Roman and Vourvopoulos, Athanasios and Liarokapis, Fotis},
title = {Would You Do It?: Enacting Moral Dilemmas in Virtual Reality for Understanding Ethical Decision-Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376788},
doi = {10.1145/3313831.3376788},
abstract = {A moral dilemma is a decision-making paradox without unambiguously acceptable or preferable options. This paper investigates if and how the virtual enactment of two renowned moral dilemmas---the Trolley and the Mad Bomber---influence decision-making when compared with mentally visualizing such situations. We conducted two user studies with two gender-balanced samples of 60 participants in total that compared between paper-based and virtual-reality (VR) conditions, while simulating 5 distinct scenarios for the Trolley dilemma, and 4 storyline scenarios for the Mad Bomber's dilemma. Our findings suggest that the VR enactment of moral dilemmas further fosters utilitarian decision-making, while it amplifies biases such as sparing juveniles and seeking retribution. Ultimately, we theorize that the VR enactment of renowned moral dilemmas can yield ecologically-valid data for training future Artificial Intelligence (AI) systems on ethical decision-making, and we elicit early design principles for the training of such systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {VR, decision-making, moral dilemmas, ethics, ethical AI},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376769,
author = {Marky, Karola and Zimmermann, Verena and Funk, Markus and Daubert, J\"{o}rg and Bleck, Kira and M\"{u}hlh\"{a}user, Max},
title = {Improving the Usability and UX of the Swiss Internet Voting Interface},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376769},
doi = {10.1145/3313831.3376769},
abstract = {Up to 20% of residential votes and up to 70% of absentee votes in Switzerland are cast online. The Swiss system aims to provide individual verifiability by different verification codes. The voters have to carry out verification on their own, making the usability and UX of the interface of great importance. To improve the usability, we first performed an evaluation with 12 human-computer interaction experts to uncover usability weaknesses of the Swiss Internet voting interface. Based on the experts' findings, related work, and an exploratory user study with 36 participants, we propose a redesign that we evaluated in a user study with 49 participants. Our study confirmed that the redesign indeed improves the detection of incorrect votes by 33% and increases the trust and understanding of the voters. Our studies furthermore contribute important lessons for designing verifiable e-voting systems in general.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {individual verifiability, usability evaluation, e-voting},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376753,
author = {Hu, Donghan and Lee, Sang Won},
title = {ScreenTrack: Using a Visual History of a Computer Screen to Retrieve Documents and Web Pages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376753},
doi = {10.1145/3313831.3376753},
abstract = {Computers are used for various purposes and frequent context switch is inevitable. In this setting, retrieving the documents, files, and web pages that have been used for a task can be a challenge. While modern applications provide a history of recent documents for users to resume work, this is not sufficient to retrieve all the digital resources relevant to a given primary document. The histories currently available - file names, web page titles, or URLs - does not take into account the complex dependencies that exist among resources across applications. To address this problem, we tested the idea of using a visual history of a computer screen to retrieve digital resources within a few days through the development of ScreenTrack. ScreenTrack is software that captures screenshots of a computer at regular intervals. It then generates a time-lapse video from the captured screenshots and lets users retrieve a recently opened document or web page from a screenshot that they recognize from its visuals. Through a controlled user study, it was found that participants were able to retrieve requested information more quickly with ScreenTrack than under the control condition. A follow-up study showed that the participants used ScreenTrack to retrieve previously used resources, in order to resume interrupted tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {task resumption, productivity, self-tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376742,
author = {Osmers, Niklas and Prilla, Michael},
title = {Getting out of Out of Sight: Evaluation of AR Mechanisms for Awareness and Orientation Support in Occluded Multi-Room Settings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376742},
doi = {10.1145/3313831.3376742},
abstract = {Augmented Reality can provide orientation and awareness in situations in which objects or people are occluded by physical structures. This is relevant for many situations in the workplace, where objects are scattered across rooms and people are out of sight. While several AR mechanisms have been proposed to provide awareness and orientation in these situations, little is known about their effect on people's performance when searching objects and coordinating with each other. In this paper, we compare three AR based mechanisms (map, x-ray, compass) according to their utility, usability, social presence, task load and users' preferences. 48 participants had to work together in groups of four to find people and objects located around different rooms. Results show that map and x-ray performed best but provided least social presence among participants. We discuss these and other observations as well as potential impacts on designing AR awareness and orientation support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {ar, occlusion, awareness, cooperation, orientation support, social presence, coordination},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376741,
author = {Klefeker, Josephine and striegl, libi and Devendorf, Laura},
title = {What HCI Can Learn from ASMR: Becoming Enchanted with the Mundane},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376741},
doi = {10.1145/3313831.3376741},
abstract = {In this paper we explore how the qualities of Autonomous Sensory Meridian Response (ASMR) media - its pairing of sonic and visual design, ability to subvert fast-paced technology for slow experiences, production of somatic responses, and attention to the everyday-might reveal new design possibilities for interactions with wearable technology. We recount our year-long design inquiry into the subject which began with an interview with a "live" ASMR creator and design probes, a series of first-person design exercises, and resulted in the creation of two interactive garments for attending, noticing, and becoming enchanted with our our everyday surroundings. We conclude by suggesting that these ASMR inspired designs cultivate personal, intimate, embodied, and felt practices of attention within our everyday, mundane, environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {smart textiles, enchantment, wearable technology, sonic interaction, asmr media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376738,
author = {Agarwal, Mohit and Sivakumar, Raghupathy},
title = {Charge for a Whole Day: Extending Battery Life for BCI Wearables Using a Lightweight Wake-Up Command},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376738},
doi = {10.1145/3313831.3376738},
abstract = {Commercially available EEG-based Brain-Computer Interface (BCI) wearable headsets are always-on and are thus power hungry, requiring users to charge the headsets multiple times a day. In this paper, we tackle the problem of wake-up command design and detection for BCI headsets, and explore how battery life can be made to last for approximately a whole day. The key challenge that we address is enabling the headset to operate in a near-sleep mode but still reliably detect and interpret an EEG-based wake-up command from the user. Towards addressing the challenge, we present a solution that is built upon eye-blinks. Our core contribution is Trance, a user-friendly and robust wake-up command for BCI headsets that is computationally lightweight. We show using experimental results coupled with multiple data sets collected through user-studies that Trance can extend battery life by approximately 2.7x or to approximately 10 hours for a typical wearable battery, while remaining user-friendly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {brain-computer interfaces (bcis), interaction design, wearable systems, input techniques, eye tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376698,
author = {Li, Nianlong and Han, Teng and Tian, Feng and Huang, Jin and Sun, Minghui and Irani, Pourang and Alexander, Jason},
title = {Get a Grip: Evaluating Grip Gestures for VR Input Using a Lightweight Pen},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376698},
doi = {10.1145/3313831.3376698},
abstract = {The use of Virtual Reality (VR) in applications such as data analysis, artistic creation, and clinical settings requires high precision input. However, the current design of handheld controllers, where wrist rotation is the primary input approach, does not exploit the human fingers' capability for dexterous movements for high precision pointing and selection. To address this issue, we investigated the characteristics and potential of using a pen as a VR input device. We conducted two studies. The first examined which pen grip allowed the largest range of motion---we found a tripod grip at the rear end of the shaft met this criterion. The second study investigated target selection via 'poking' and ray-casting, where we found the pen grip outperformed the traditional wrist-based input in both cases. Finally, we demonstrate potential applications enabled by VR pen input and grip postures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {handheld controller, grip postures, pen input, finger and wrist dexterity, virtual reality, spatial target selection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376695,
author = {Peng, Zhenhui and Guo, Qingyu and Tsang, Ka Wing and Ma, Xiaojuan},
title = {Exploring the Effects of Technological Writing Assistance for Support Providers in Online Mental Health Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376695},
doi = {10.1145/3313831.3376695},
abstract = {Textual comments from peers with informational and emotional support are beneficial to members of online mental health communities (OMHCs). However, many comments are not of high quality in reality. Writing support technologies that assess (AS) the text or recommend (RE) writing examples on the fly could potentially help support providers to improve the quality of their comments. However, how providers perceive and work with such technologies are under-investigated. In this paper, we present a technological prototype MepsBot which offers providers in-situ writing assistance in either AS or RE mode. Results of a mixed-design study with 30 participants show that both types of MepsBots improve users' confidence in and satisfaction with their comments. The AS-mode MepsBot encourages users to refine expressions and is deemed easier to use, while the RE-mode one stimulates more support-related content re-editions. We report concerns on MepsBot and propose design considerations for writing support technologies in OMHCs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {online community, emotional support, writing support tools, informational support, mental health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376685,
author = {Slegers, Karin and Kouwenberg, Kristel and Lou\v{c}ova, Tereza and Daniels, Ramon},
title = {Makers in Healthcare: The Role of Occupational Therapists in the Design of DIY Assistive Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376685},
doi = {10.1145/3313831.3376685},
abstract = {Advancements in personal fabrication technologies (e.g. 3D printing) resulted in a rising interest in 'do-it-yourself assistive technology' (DIY AT). Clinical knowledge is considered fundamental for DIY AT design, but research into making DIY AT by clinicians is limited. In this paper, we explore occupational therapists' attitudes towards 3D printing both before and after gaining hands-on experience with 3D modelling software. In addition, as clinicians indicate to prefer collaborations with experienced designers, we organized a codesign study with occupational therapists and professional designers to conceptualize a feasible collaborative DIY-AT design process. The results of our studies show an overall enthusiasm of occupational therapists towards 3D printing, but the perceived impact of 3D printing on their job performance decreased after gaining hands-on experience. Collaborating with designers seems a viable way forward. We propose a model for a collaborative design process, highlighting different phases and the roles that occupational therapists and designers play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {DIY assistive technology, occupational therapy, digital fabrication, 3D printing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376656,
author = {Uhde, Alarith and Schlicker, Nadine and Wallach, Dieter P. and Hassenzahl, Marc},
title = {Fairness and Decision-Making in Collaborative Shift Scheduling Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376656},
doi = {10.1145/3313831.3376656},
abstract = {The strains associated with shift work decrease healthcare workers' well-being. However, shift schedules adapted to their individual needs can partially mitigate these problems. From a computing perspective, shift scheduling was so far mainly treated as an optimization problem with little attention given to the preferences, thoughts, and feelings of the healthcare workers involved. In the present study, we explore fairness as a central, human-oriented attribute of shift schedules as well as the scheduling process. Three in-depth qualitative interviews and a validating vignette study revealed that while on an abstract level healthcare workers agree on equality as the guiding norm for a fair schedule, specific scheduling conflicts should foremost be resolved by negotiating the importance of individual needs. We discuss elements of organizational fairness, including transparency and team spirit. Finally, we present a sketch for fair scheduling systems, summarizing key findings for designers in a readily usable way.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {equality, equity, healthcare, nurse scheduling problem, allocation norms, shift scheduling, fairness, work-life balance, hospital, conflict resolution, roster, shift work, need, interview, organizational justice},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376649,
author = {Glowacki, David R. and Wonnacott, Mark D. and Freire, Rachel and Glowacki, Becca R. and Gale, Ella M. and Pike, James E. and de Haan, Tiu and Chatziapostolou, Mike and Metatla, Oussama},
title = {Isness: Using Multi-Person VR to Design Peak Mystical Type Experiences Comparable to Psychedelics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376649},
doi = {10.1145/3313831.3376649},
abstract = {Studies combining psychotherapy with psychedelic drugs (Ds) have demonstrated positive outcomes that are often associated with 'Ds' ability to induce 'mystical-type' experiences (MTEs) i.e., subjective experiences whose characteristics include a sense of connectedness, transcendence, and ineffability. We suggest that both PsiDs and virtual reality can be situated on a broader spectrum of psychedelic technologies. To test this hypothesis, we used concepts, methods, and analysis strategies from D research to design and evaluate 'Isness', a multi-person VR journey where participants experience the collective emergence, fluctuation, and dissipation of their bodies as energetic essences. A study (N=57) analyzing participant responses to a commonly used D experience questionnaire (MEQ30) indicates that Isness participants reported MTEs comparable to those reported in double-blind clinical studies after high doses of psilocybin and LSD. Within a supportive setting and conceptual framework, VR phenomenology can create the conditions for MTEs from which participants derive insight and meaning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mystical-type experiences, virtual reality, user experience, meaning in HCI, altered states, psychedelic drugs},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376631,
author = {Garg, Radhika and Sengupta, Subhasree},
title = {Conversational Technologies for In-Home Learning: Using Co-Design to Understand Children's and Parents' Perspectives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376631},
doi = {10.1145/3313831.3376631},
abstract = {Today, Conversational Agents (CA) are deeply integrated into the daily lives of millions of families, which has led children to extensively interact with such devices. Studies have suggested that the social nature of CA makes them a good learning companion for children. Therefore, to understand children's preferences for the use of CAs for the purpose of in-home learning, we conducted three participatory design sessions. In order to identify parents' requirements in this regard, we also included them in the third session. We found that children expect such devices to possess a personality and an advanced level of intelligence, and support multiple content domains and learning modes and human-like conversations. Parents desire such devices to include them in their children's learning activities, foster social engagement, and to allow them to monitor their children's use. This understanding will inform the design of future CAs for the purpose of in-home learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {learning technology, conversational agents, children, co-design, participatory design, cooperative inquiry, learning companion, parents, learning, home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376622,
author = {Mentis, Helena M. and Feng, Yuanyuan and Semsar, Azin and Ponsky, Todd A.},
title = {Remotely Shaping the View in Surgical Telementoring},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376622},
doi = {10.1145/3313831.3376622},
abstract = {Distributed collaboration on physical tasks is a social process that involves all actors iteratively proposing, assessing and modifying the view of a shared workspace. In this paper, we describe the ways in which a view of a shared workspace is shaped by a remote expert to weave their expertise into the accomplishment of a complex physical task during surgical telementoring. We focus on the communicative functions of talk and actions used by the remote experts and local workers and identify strategies the experts employ to remotely shape the view. This analysis reveals the possibility for collaborative shaping of a view in surgical telementoring as well as other mechanism for a remote expert to craft and present a view of the shared workspace.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tele-conferencing, instruction, telestration, surgery training, video, distributed},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376621,
author = {Yildirim, Nur and McCann, James and Zimmerman, John},
title = {Digital Fabrication Tools at Work: Probing Professionals' Current Needs and Desired Futures},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376621},
doi = {10.1145/3313831.3376621},
abstract = {Digital fabrication tools have transformed how people work in micro- and small-scale manufacturing settings. While increasing efficiency and precision, these tools raise concerns around user agency and control. This paper describes an exploratory study investigating the felt work experience and desired futures of professionals who use fabrication tools. We conducted co-design workshops with 23 professionals who use 3D printers, laser cutters, and CNC routers. We probed about current practices; machine awareness and autonomy; and user agency. Our findings reveal that current tools are not very professional. They are unreliable and untrustworthy. Participants desired smarter tools that can actively prevent errors and perform self-calibration and self-maintenance. They had few concerns that more intelligence would impact agency. They desired tools that could negotiate trade-offs between time, cost, and quality; and that can operate as super-human shop assistants. We discuss the implications of these findings as opportunities for research that can improve professionals' work experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {future of work, co-design, user experience, intelligent systems, digital fabrication, 3d printing, laser cutting, cnc},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376616,
author = {Luo, Yuhan and Lee, Bongshin and Choe, Eun Kyoung},
title = {TandemTrack: Shaping Consistent Exercise Experience by Complementing a Mobile App with a Smart Speaker},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376616},
doi = {10.1145/3313831.3376616},
abstract = {Smart speakers such as Amazon Echo present promising opportunities for exploring voice interaction in the domain of in-home exercise tracking. In this work, we examine if and how voice interaction complements and augments a mobile app in promoting consistent exercise. We designed and developed TandemTrack, which combines a mobile app and an Alexa skill to support exercise regimen, data capture, feedback, and reminder. We then conducted a four-week between-subjects study deploying TandemTrack to 22 participants who were instructed to follow a short daily exercise regimen: one group used only the mobile app and the other group used both the app and the skill. We collected rich data on individuals' exercise adherence and performance, and their use of voice and visual interactions, while examining how TandemTrack as a whole influenced their exercise experience. Reflecting on these data, we discuss the benefits and challenges of incorporating voice interaction to assist daily exercise, and implications for designing effective multimodal systems to support self-tracking and promote consistent exercise.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multimodal interaction, smart speaker, self-tracking, field deployment study, exercise, mobile app},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376609,
author = {Lee, Sung-Chul and Song, Jaeyoon and Ko, Eun-Young and Park, Seongho and Kim, Jihee and Kim, Juho},
title = {SolutionChat: Real-Time Moderator Support for Chat-Based Structured Discussion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376609},
doi = {10.1145/3313831.3376609},
abstract = {Online chat is an emerging channel for discussing community problems. It is common practice for communities to assign dedicated moderators to maintain a structured discussion and enhance the problem-solving experience. However, due to the synchronous nature of online chat, moderators face a high managerial overhead in tasks like discussion stage management, opinion summarization, and consensus-building support. To assist moderators with facilitating a structured discussion for community problem-solving, we introduce SolutionChat, a system that (1) visualizes discussion stages and featured opinions and (2) recommends contextually appropriate moderator messages. Results from a controlled lab study (n=55, 12 groups) suggest that participants' perceived discussion trackability was significantly higher with SolutionChat than without. Also, moderators provided better summarization with less effort and better managerial support using system-generated messages with SolutionChat than without. With SolutionChat, we envision untrained moderators to effectively facilitate chat-based discussions of important community matters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online discussion, structured discussion, computer mediated communication, moderator},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376606,
author = {Tanenbaum, Theresa Jean and Hartoonian, Nazely and Bryan, Jeffrey},
title = {"How Do I Make This Thing Smile?": An Inventory of Expressive Nonverbal Communication in Commercial Social Virtual Reality Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376606},
doi = {10.1145/3313831.3376606},
abstract = {Despite the proliferation of platforms for social Virtual Reality (VR) communicating emotional expression via an avatar remains a significant design challenge. In order to better understand the design space for expressive Nonverbal Communication (NVC) in social VR we undertook an inventory of the ten most prominent social VR platforms. Our inventory identifies the dominant design strategies for movement, facial control, and gesture in commercial VR applications, and identifies opportunities and challenges for future design and research into social expression in VR. Specifically, we highlight the paucity of interaction paradigms for facial expression and the near nonexistence of meaningful control over ambient aspects of nonverbal communication such as posture, pose, and social status.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {nonverbal communication, social interactions, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376582,
author = {Bahng, Sojung and Kelly, Ryan M. and McCormack, Jon},
title = {Reflexive VR Storytelling Design Beyond Immersion: Facilitating Self-Reflection on Death and Loneliness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376582},
doi = {10.1145/3313831.3376582},
abstract = {This research examines the reflexive dimensions of cinematic virtual reality (CVR) storytelling. We created Anonymous, an interactive CVR piece that employs a reflexive storytelling method. This method is based on distancing effects and is used to elicit audience awareness and self-reflection about loneliness and death. To understand the audience's experiences, we conducted in-depth interviews to study which design factors and elements prompted reflexive thoughts and feelings. Our findings highlight how the audience experience was impacted by four reflexive dimensions: abstract and minimal aesthetics, everyday materials and textures, the restriction of control, and multiple, disembodied points of view. We use our findings to discuss how these dimensions can inform the design of VR storytelling experiences that provoke self and social reflection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {estrangement, immersive storytelling, reflexivity, alienation, virtual reality, distancing effect, cinematic vr},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376578,
author = {Voelker, Simon and Hueber, Sebastian and Holz, Christian and Remy, Christian and Marquardt, Nicolai},
title = {GazeConduits: Calibration-Free Cross-Device Collaboration through Gaze and Touch},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376578},
doi = {10.1145/3313831.3376578},
abstract = {We present GazeConduits, a calibration-free ad-hoc mobile interaction concept that enables users to collaboratively interact with tablets, other users, and content in a cross-device setting using gaze and touch input. GazeConduits leverages recently introduced smartphone capabilities to detect facial features and estimate users' gaze directions. To join a collaborative setting, users place one or more tablets onto a shared table and position their phone in the center, which then tracks users present as well as their gaze direction to determine the tablets they look at. We present a series of techniques using GazeConduits for collaborative interaction across mobile devices for content selection and manipulation. Our evaluation with 20 simultaneous tablets on a table shows that GazeConduits can reliably identify which tablet or collaborator a user is looking at.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {cross-device interaction, touch input, gaze input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376577,
author = {Houben, Maarten and Brankaert, Rens and Bakker, Saskia and Kenning, Gail and Bongers, Inge and Eggen, Berry},
title = {The Role of Everyday Sounds in Advanced Dementia Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376577},
doi = {10.1145/3313831.3376577},
abstract = {The representation of sounds derived from everyday life can be beneficial for people with dementia by evoking memories and emotional responses. Despite this potential, integrating sound and sound-based interventions in care facilities has not received much research attention. In this paper, we present the findings from a field study that explored the responses of 19 people with advanced dementia to a selection of everyday sounds presented to them in a care home and the role of these responses in the care environment. To study this, we deployed Vita, a 'pillow-like' sound player, in two dementia care facilities for four weeks, during which observations were recorded. Afterwards, we conducted interviews with caregivers who used Vita in everyday care practice. Our findings reveal how everyday sounds provided by Vita stimulated meaningful conversation, playfulness, and connection between residents and caregivers. Furthermore, we propose design implications for integrating everyday sounds in dementia care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {care home, soundscapes, dementia, everyday sounds, design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376575,
author = {Ebert, Nico and Ackermann, Kurt Alexander and Heinrich, Peter},
title = {Does Context in Privacy Communication Really Matter?  A Survey on Consumer Concerns and Preferences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376575},
doi = {10.1145/3313831.3376575},
abstract = {Privacy policies as a means of communicating with customers still prove ineffective. Researchers have recently suggested that a specific usage context should be considered to make privacy notices more relevant to users. To explore this approach further, we conducted an explorative online survey of privacy concerns and privacy information preferences with 642 participants for two different contexts (loyalty cards and fitness tracking). Our data shows some support for the suggestion that context may be a significant moderator of concerns and preferences. However, the corresponding effects are rather small and limited to specific concerns and information categories. In line with other research, the data supports the known hierarchy of concerns regarding unauthorized secondary use and improper data access, which seem to exceed concerns about erroneous data processing or excessive data collection in both contexts. Furthermore, participants considered information on personal rights and processing purposes more relevant than information on contact persons.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {user preferences, privacy concerns, policy, privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376571,
author = {Mohaddesi, Omid and Sun, Yifan and Azghandi, Rana and Doroudi, Rozhin and Snodgrass, Sam and Ergun, Ozlem and Griffin, Jacqueline and Kaeli, David and Marsella, Stacy and Harteveld, Casper},
title = {Introducing Gamettes: A Playful Approach for Capturing Decision-Making for Informing Behavioral Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376571},
doi = {10.1145/3313831.3376571},
abstract = {Agent-based simulations are widely used for modeling human behavior in various contexts. However, such simulations may oversimplify human decision-making. We propose the use of Gamettes to extract rich data on human decision-making and help in improving the human behavioral aspects of models underlying agent-based simulations. We show how Gamettes are designed and provide empirical validation for using Gamettes in an experimental supply chain setting to study human decision-making. Our results show that Gamettes are successful in capturing the expected behaviors and patterns in supply chain decisions, and, thus, we find evidence for the capability of Gamettes to inform behavioral models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {beer game, agent-based model, supply chain, simulation, human behavior, gamette, decision-making},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376568,
author = {Bennett, Cynthia L. and Rosner, Daniela K. and Taylor, Alex S.},
title = {The Care Work of Access},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376568},
doi = {10.1145/3313831.3376568},
abstract = {Current approaches to AI and Assistive Technology (AT) often foreground task completion over other encounters such as expressions of care. Our paper challenges and complements such task-completion approaches by attending to the care work of access-the continual affective and emotional adjustments that people make by noticing and attending to one another. We explore how this work impacts encounters among people with and without vision impairments who complete tasks together. We find that bound up in attempts to get things done are concerns for one another and how well people are doing together. Reading this work through emerging disability studies and feminist STS scholarship, we account for two important forms of work that give rise to access: (1) mundane attunements and (2) non-innocent authorizations. Together these processes work as sensitizing concepts to help HCI scholars account for the ways that intelligent ATs both produce access while sometimes subverting people with disabilities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {disability, vision impaired, care, interdependence, blind, assistance, artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376554,
author = {Blaga, Andreea Dalia and Frutos-Pascual, Maite and Creed, Chris and Williams, Ian},
title = {Too Hot to Handle: An Evaluation of the Effect of Thermal Visual Representation on User Grasping Interaction in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376554},
doi = {10.1145/3313831.3376554},
abstract = {Influence of interaction fidelity and rendering quality on perceived user experience have been largely explored in Virtual Reality (VR). However, differences in interaction choices triggered by these rendering cues have not yet been explored. We present a study analysing the effect of thermal visual cues and contextual information on 50 participants' approach to grasp and move a virtual mug. This study comprises 3 different temperature cues (baseline empty, hot and cold) and 4 contextual representations; all embedded in a VR scenario. We evaluate 2 different hand representations (abstract and human) to assess grasp metrics. Results show temperature cues influenced grasp location, with the mug handle being predominantly grasped with a smaller grasp aperture for the hot condition, while the body and top were preferred for baseline and cold conditions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {hand interaction, grasping metrics, hand tracking, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376548,
author = {Hua, Yiqing and Naaman, Mor and Ristenpart, Thomas},
title = {Characterizing Twitter Users Who Engage in Adversarial Interactions against Political Candidates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376548},
doi = {10.1145/3313831.3376548},
abstract = {Social media provides a critical communication platform for political figures, but also makes them easy targets for harassment. In this paper, we characterize users who adversarially interact with political figures on Twitter using mixed-method techniques. The analysis is based on a dataset of 400 thousand users' 1.2 million replies to 756 candidates for the U.S. House of Representatives in the two months leading up to the 2018 midterm elections. We show that among moderately active users, adversarial activity is associated with decreased centrality in the social graph and increased attention to candidates from the opposing party. When compared to users who are similarly active, highly adversarial users tend to engage in fewer supportive interactions with their own party's candidates and express negativity in their user profiles. Our results can inform the design of platform moderation mechanisms to support political figures countering online harassment.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {twitter, user behavior, online harassment, political candidates},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376544,
author = {Moorthy, K. L. Bhanu and Kumar, Moneish and Subramanian, Ramanathan and Gandhi, Vineet},
title = {GAZED Gaze-Guided Cinematic Editing of Wide-Angle Monocular Video Recordings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376544},
doi = {10.1145/3313831.3376544},
abstract = {We present GAZED– eye GAZe-guided EDiting for videos captured by a solitary, static, wide-angle and high-resolution camera. Eye-gaze has been effectively employed in computational applications as a cue to capture interesting scene content; we employ gaze as a proxy to select shots for inclusion in the edited video. Given the original video, scene content and user eye-gaze tracks are combined to generate an edited video comprising cinematically valid actor shots and shot transitions to generate an aesthetic and vivid representation of the original narrative. We model cinematic video editing as an energy minimization problem over shot selection, whose constraints capture cinematographic editing conventions. Gazed scene locations primarily determine the shots constituting the edited video. Effectiveness of GAZED against multiple competing methods is demonstrated via a psychophysical study involving 12 users and twelve performance videos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {dynamic programming, eye gaze, cinematic video editing, stage performance, static wide-angle recording, gaze potential, shot selection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376539,
author = {Hauser, Sabrina and Suto, Melinda J. and Holsti, Liisa and Ranger, Manon and MacLean, Karon E.},
title = {Designing and Evaluating Calmer, a Device for Simulating Maternal Skin-to-Skin Holding for Premature Infants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376539},
doi = {10.1145/3313831.3376539},
abstract = {We describe the design and deployment of Calmer, a technology that simulates key aspects of maternal skin-to-skin holding for prematurely born infants: its inspiration, approach, physical design, and introduction into the Neonatal Intensive Care Unit. Maternal skin-to-skin holding can mitigate neonatal pain during medical procedures by as much as 50%, which can improve weight gain, sleep and later development. However, parents cannot always be present, and some infants are too fragile to be held. Interventions targeting this gap could be perceived as supplanting the mother in this intimate role, exposing her to depression and endangering her maternal bond. Over 10 years, we iteratively developed Calmer and demonstrated infant health benefit in a randomized clinical trial. Here, we report and reflect on pursuing this goal in a socially and technologically complex context: constraints, strategies, features, reception of the device, and surprises, such as leading to mothers feeling channeled rather than replaced.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {parents, premature infants, automation, neonatal intensive care, research through design, nicu, pain reduction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376537,
author = {Draxler, Fiona and Labrie, Audrey and Schmidt, Albrecht and Chuang, Lewis L.},
title = {Augmented Reality to Enable Users in Learning Case Grammar from Their Real-World Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376537},
doi = {10.1145/3313831.3376537},
abstract = {Augmented Reality (AR) provides a unique opportunity to situate learning content in one's environment. In this work, we investigated how AR could be developed to provide an interactive context-based language learning experience. Specifically, we developed a novel handheld-AR app for learning case grammar by dynamically creating quizzes, based on real-life objects in the learner's surroundings. We compared this to the experience of learning with a non-contextual app that presented the same quizzes with static photographic images. Participants found AR suitable for use in their everyday lives and enjoyed the interactive experience of exploring grammatical relationships in their surroundings. Nonetheless, Bayesian tests provide substantial evidence that the interactive and context-embedded AR app did not improve case grammar skills, vocabulary retention, and usability over the experience with equivalent static images. Based on this, we propose how language learning apps could be designed to combine the benefits of contextual AR and traditional approaches.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {contextual learning, grammar, language learning, self-directed learning, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376532,
author = {Parker, Callum and Tomitsch, Martin and Davies, Nigel and Valkanova, Nina and Kay, Judy},
title = {Foundations for Designing Public Interactive Displays That Provide Value to Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376532},
doi = {10.1145/3313831.3376532},
abstract = {Public interactive displays (PID) are a promising technology for providing information and collecting feedback in public spaces. Research on PIDs has shown that, like all public displays, their efficacy is reduced by display blindness. Rather than increase the visual attention-grabbing nature of PIDs, we propose that additional understanding is required around how and when these displays are able to offer value to users. We tackle this through a systematic analysis of PID studies published in the literature, which led to 9 aspects of value across 4 factors: people, location, community, and time. We discuss the identified aspects and their utility for the design of PIDs through a review of our own deployments carried out by 4 different labs across 5 countries. We conclude with a set of recommendations for identifying and optimising the intended value of future PIDs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {literature review, public displays, design recommendations, public interactive displays, in-the-wild, deployments, value},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376517,
author = {Williford, Blake and Runyon, Matthew and Li, Wayne and Linsey, Julie and Hammond, Tracy},
title = {Exploring the Potential of an Intelligent Tutoring System for Sketching Fundamentals},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376517},
doi = {10.1145/3313831.3376517},
abstract = {Sketching is a practical and useful skill that can benefit communication and problem solving. However, it remains a difficult skill to learn because of low confidence and motivation among students and limited availability for instruction and personalized feedback among teachers. There is an need to improve the educational experience for both groups, and we hypothesized that integrating technology could provide a variety of benefits. We designed and developed an intelligent tutoring system for sketching fundamentals called Sketchtivity, and deployed it in to six existing courses at the high school and university level during the 2017-2018 school year. 268 students used the tool and produced more than 116,000 sketches of basic primitives. We conducted semi-structured interviews with the six teachers who implemented the software, as well as nine students from a course where the tool was used extensively. Using grounded theory, we found ten categories which unveiled the benefits and limitations of integrating an intelligent tutoring system for sketching fundamentals in to existing pedagogy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sketch recognition, intelligent tutoring system, design education, human-computer interaction, art education, drawing, user experience design, sketching},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376506,
author = {Schaekermann, Mike and Beaton, Graeme and Sanoubari, Elaheh and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Ambiguity-Aware AI Assistants for Medical Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376506},
doi = {10.1145/3313831.3376506},
abstract = {Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ambiguity, artificial intelligence, medical data analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376496,
author = {Cockburn, Andy and Lewis, Blaine and Quinn, Philip and Gutwin, Carl},
title = {Framing Effects Influence Interface Feature Decisions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376496},
doi = {10.1145/3313831.3376496},
abstract = {Studies in psychology have shown that framing effects, where the positive or negative attributes of logically equivalent choices are emphasised, influence people's decisions. When outcomes are uncertain, framing effects also induce patterns of choice reversal, where decisions tend to be risk averse when gains are emphasised and risk seeking when losses are emphasised. Studies of these effects typically use potent framing stimuli, such as the mortality of people suffering from diseases or personal financial standing. We examine whether these effects arise in users' decisions about interface features, which typically have less visceral consequences, using a crowd-sourced study based on snap-to-grid drag-and-drop tasks (n = 842). The study examined several framing conditions: those similar to prior psychological research, and those similar to typical interaction choices (enabling/disabling features). Results indicate that attribute framing strongly influences users' decisions, that these decisions conform to patterns of risk seeking for losses, and that patterns of choice reversal occur.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {interface decisions, attribute framing, risky choice framing, framing effects},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376490,
author = {Neate, Timothy and Roper, Abi and Wilson, Stephanie and Marshall, Jane and Cruice, Madeline},
title = {CreaTable Content and Tangible Interaction in Aphasia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376490},
doi = {10.1145/3313831.3376490},
abstract = {Multimedia digital content (combining pictures, text and music) is ubiquitous. The process of creating such content using existing tools typically requires complex, language-laden interactions which pose a challenge for users with aphasia (a language impairment following brain injury). Tangible interactions offer a potential means to address this challenge, however, there has been little work exploring their potential for this purpose. In this paper, we present CreaTable a platform that enables us to explore tangible interaction as a means of supporting digital content creation for people with aphasia. We report details of the co-design of CreaTable and findings from a digital creativity workshop. Workshop findings indicated that CreaTable enabled people with aphasia to create something they would not otherwise have been able to. We report how users' aphasia profiles affected their experience, describe tensions in collaborative content creation and provide insight into more accessible content creation using tangibles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {creativity support, multimedia, content creation, creativity, accessibility, tangibles, aphasia, co-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376474,
author = {Hudson, Lorraine and Amponsah, Clement and Bampoe, Josephine Ohenewa and Marshall, Julie and Owusu, Nana Akua Victoria and Hussein, Khalid and Linington, Jess and Banks Gross, Zoe and Stokes, Jane and McNaney, R\'{o}is\'{\i}n},
title = {Co-Designing Digital Tools to Enhance Speech and Language Therapy Training in Ghana},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376474},
doi = {10.1145/3313831.3376474},
abstract = {Ghana has a population of over 27 million people, of which 1 in 15 may have a communication disability. The number of speech and language therapists (SLTs) available to support these people remains remarkably small, presenting a major workforce challenge. As an emerging profession, there remain significant challenges around educating the first generation of SLTs. Ghana, however, has a healthy digital infrastructure which can be taken advantage of. We describe a comprehensive study which aimed to co-design a set of locally appropriate digital tools to enhance SLT training in Ghana. We contribute insights into how digital tools could support social learning and the transition from student to independent practitioner and future clinical supervisor. We offer a set of design recommendations for creating an online Community of Practice to enhance continuing professional development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ghana, co-design, speech and language therapy, mobile learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376473,
author = {Wang, Yihong and Papangelis, Konstantinos and Saker, Michael and Lykourentzou, Ioanna and Chamberlain, Alan and Khan, Vassilis-Javed},
title = {Crowdsourcing in China: Exploring the Work Experiences of Solo Crowdworkers and Crowdfarm Workers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376473},
doi = {10.1145/3313831.3376473},
abstract = {Recent research highlights the potential of crowdsourcing in China. Yet very few studies explore the workplace context and experiences of Chinese crowdworkers. Those that do, focus mainly on the work experiences of solo crowdworkers but do not deal with issues pertaining to the substantial amount of people working in 'crowdfarms'. This article addresses this gap as one of its primary concerns. Drawing on a study that involves 48 participants, our research explores, compares and contrasts the work experiences of solo crowdworkers to those of crowdfarm workers. Our findings illustrate that the work experiences and context of the solo workers and crowdfarm workers are substantially different, with regards to their motivations, the ways they engage with crowdsourcing, the tasks they work on, and the crowdsourcing platforms they utilize. Overall, our study contributes to furthering the understandings on the work experiences of crowdworkers in China.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {platform satisfaction, crowdworkers, work experience, tasks, motivations and attitudes, crowdsourcing, work life balance, reputation management, crowdfarms},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376471,
author = {Campo Woytuk, Nadia and S\o{}ndergaard, Marie Louise Juul and Ciolfi Felice, Marianela and Balaam, Madeline},
title = {Touching and Being in Touch with the Menstruating Body},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376471},
doi = {10.1145/3313831.3376471},
abstract = {We describe a Research through Design project-Curious Cycles-a collection of objects and interactions which encourage people to be in close contact with their menstruating body. Throughout a full menstrual cycle, five participants used Curious Cycles to look at their bodies in unfamiliar ways and to touch their bodily fluids, specifically, menstrual blood, saliva, and cervical mucus. The act of touching and looking led to the construction of new knowledge about the self and to a nurturing appreciation for the changing body. Yet, participants encountered and reflected upon frictions within themselves, their home, and their social surroundings, which stem from societal stigma and preconceptions about menstruation and bodily fluids. We call for and show how interaction design can engage with technologies that mediate self-touch as a first step towards reconfiguring the way menstruating bodies are treated in society.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {feminist hci, research through design, menstrual cycles, touching, menstruation, women's health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376469,
author = {Diana, Nicholas and Stamper, John and Koedinger, Ken},
title = {Towards Value-Adaptive Instruction: A Data-Driven Method for Addressing Bias in Argument Evaluation Tasks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376469},
doi = {10.1145/3313831.3376469},
abstract = {As the media landscape is increasingly populated by less than reputable sources of information, educators have turned to argument evaluation training as a potential solution. Unfortunately, the bias literature suggests that our ability to objectively evaluate an argument is, to a large extent, determined by the relationship between our own beliefs and the beliefs latent in the argument we are evaluating. If the argument supports our worldview, we are much more likely to overlook logical errors. Teachers recognize this need to adapt argument evaluation instruction to the specific beliefs of students. For instance, a teacher might intentionally assign a student an argument that the student disagrees with. Unfortunately, this kind of value-adaptive instruction is infrequent due to its unscalability. We propose a novel method for data-driven value-adaptive instruction in instructional technologies. This method can be used to combat bias in real-world contexts and support human reasoning during media consumption.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {educational technology, civic education, civic technology, human-computer interaction, adaptive instruction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376468,
author = {Soni, Nikita and Gleaves, Schuyler and Neff, Hannah and Morrison-Smith, Sarah and Esmaeili, Shaghayegh and Mayne, Ian and Bapat, Sayli and Schuman, Carrie and Stofer, Kathryn A. and Anthony, Lisa},
title = {Adults' and Children's Mental Models for Gestural Interactions with Interactive Spherical Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376468},
doi = {10.1145/3313831.3376468},
abstract = {Interactive spherical displays offer numerous opportunities for engagement and education in public settings. Prior work established that users' touch-gesture patterns on spherical displays differ from those on flatscreen tabletops, and speculated that these differences stem from dissimilarity in how users conceptualize interactions with these two form factors. We analyzed think-aloud data collected during a gesture elicitation study to understand adults' and children's (ages 7 to 11) conceptual models of interaction with spherical displays and compared them to conceptual models of interaction with tabletop displays from prior work. Our findings confirm that the form factor strongly influenced users' mental models of interaction with the sphere. For example, participants conceptualized that the spherical display would respond to gestures in a similar way as real-world spherical objects like physical globes. Our work contributes new understanding of how users draw upon the perceived affordances of the sphere as well as prior touchscreen experience during their interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touchscreen displays, interactive spherical displays, touchscreen gestures, children, adults, mental models},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376460,
author = {Smith, Taliesin L. and Moore, Emily B.},
title = {Storytelling to Sensemaking: A Systematic Framework for Designing Auditory Description Display for Interactives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376460},
doi = {10.1145/3313831.3376460},
abstract = {Auditory description display is verbalized text typically used to describe live, recorded, or graphical displays to support access for people who are blind or visually impaired. Significant prior research has resulted in guidelines for auditory description for non-interactive or minimally interactive contexts. A lack of auditory description for complex interactive environments remains a tremendous barrier to access for people with visual impairments. In this work, we present a systematic design framework for designing auditory description within complex interactive environments. We illustrate how modular descriptions aligned with this framework can result in an interactive storytelling experience constructed through user interactions. This framework has been used in a set of published and widely used interactive science simulations, and in its generalized form could be applied to a variety of contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {non-visual access, auditory description display, description design, interactive information spaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

