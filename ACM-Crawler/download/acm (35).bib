@inproceedings{10.1145/3491102.3502057,
author = {Wang, Ge and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
title = {Informing Age-Appropriate AI: Examining Principles and Practices of AI for Children},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502057},
doi = {10.1145/3491102.3502057},
abstract = {AI systems are becoming increasingly pervasive within children’s devices, apps, and services. However, it is not yet well-understood how risks and ethical considerations of AI relate to children. This paper makes three contributions to this area: first, it identifies ten areas of alignment between general AI frameworks and codes for age-appropriate design for children. Then, to understand how such principles relate to real application contexts, we conducted a landscape analysis of children’s AI systems, via a systematic literature review including 188 papers. This analysis revealed a wide assortment of applications, and that most systems’ designs addressed only a small subset of principles among those we identified. Finally, we synthesised our findings in a framework to inform a new “Code for Age-Appropriate AI”, which aims to provide timely input to emerging policies and standards, and inspire increased interactions between the AI and child-computer interaction communities.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {536},
numpages = {29},
keywords = {AI for children, systematic literature review, age appropriate design},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502040,
author = {Allen, Jennifer and Martel, Cameron and Rand, David G},
title = {Birds of a Feather Don’t Fact-Check Each Other: Partisanship and the Evaluation of News in Twitter’s Birdwatch Crowdsourced Fact-Checking Program},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502040},
doi = {10.1145/3491102.3502040},
abstract = {There is a great deal of interest in the role that partisanship, and cross-party animosity in particular, plays in interactions on social media. Most prior research, however, must infer users’ judgments of others’ posts from engagement data. Here, we leverage data from Birdwatch, Twitter’s crowdsourced fact-checking pilot program, to directly measure judgments of whether other users’ tweets are misleading, and whether other users’ free-text evaluations of third-party tweets are helpful. For both sets of judgments, we find that contextual features – in particular, the partisanship of the users – are far more predictive of judgments than the content of the tweets and evaluations themselves. Specifically, users are more likely to write negative evaluations of tweets from counter-partisans; and are more likely to rate evaluations from counter-partisans as unhelpful. Our findings provide clear evidence that Birdwatch users preferentially challenge content from those with whom they disagree politically. While not necessarily indicating that Birdwatch is ineffective for identifying misleading content, these results demonstrate the important role that partisanship can play in content evaluation. Platform designers must consider the ramifications of partisanship when implementing crowdsourcing programs.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {245},
numpages = {19},
keywords = {crowdsourcing, fact-checking, misinformation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502037,
author = {Das Swain, Vedant and Chen, Victor and Mishra, Shrija and Mattingly, Stephen M. and Abowd, Gregory D. and De Choudhury, Munmun},
title = {Semantic Gap in Predicting Mental Wellbeing through Passive Sensing},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502037},
doi = {10.1145/3491102.3502037},
abstract = {When modeling passive data to infer individual mental wellbeing, a common source of ground truth is self-reports. But these tend to represent the psychological facet of mental states, which might not align with the physiological facet of that state. Our paper demonstrates that when what people “feel” differs from what people “say they feel”, we witness a semantic gap that limits predictions. We show that predicting mental wellbeing with passive data (offline sensors or online social media) is related to how the ground-truth is measured (objective arousal or self-report). Features with psycho-social signals (e.g., language) were better at predicting self-reported anxiety and stress. Conversely, features with behavioral signals (e.g., sleep), were better at predicting stressful arousal. Regardless of the source of ground truth, integrating both signals boosted prediction. To reduce the semantic gap, we provide recommendations to evaluate ground truth measures and adopt parsimonious sensing.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {374},
numpages = {16},
keywords = {Social Media, Activity Patterns, Passive Sensing, Mental Wellbeing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502008,
author = {Sykownik, Philipp and Maloney, Divine and Freeman, Guo and Masuch, Maic},
title = {Something Personal from the Metaverse: Goals, Topics, and Contextual Factors of Self-Disclosure in Commercial Social VR},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502008},
doi = {10.1145/3491102.3502008},
abstract = {Current Social VR literature provides limited insight on one of the most critical behaviors for developing and maintaining interpersonal relationships: self-disclosure. Therefore, we present an online survey (N = 126) investigating how users disclose personal information to each other in Social VR. Our results indicate that many participants see in Social VR access to authentic connections with others despite tending towards skepticism and privacy concerns. Most users disclose sexuality-related information, lifestyle preferences, and personal goals. In contrast, information that breaks anonymity, such as real names and more intimate aspects of oneself, are shared less commonly. Thereby, self-disclosure decisions depend on factors like the relationship to or age of disclosure recipients, the privacy of a virtual environment, the group size, or the activity context, and is driven by different goals, i.a., relational development or exploration of oneself. These insights advance the understanding of current Social VR users and their behavior by directing future research on self-disclosure-based relationship building in Social VR and outlying broader design implications for the future metaverse.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {632},
numpages = {17},
keywords = {online social interaction, social virtual reality, self-disclosure},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501994,
author = {Popova, Kristina and Garrett, Rachael and N\'{u}\~{n}ez-Pacheco, Claudia and Lampinen, Airi and H\"{o}\"{o}k, Kristina},
title = {Vulnerability as an Ethical Stance in Soma Design Processes},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501994},
doi = {10.1145/3491102.3501994},
abstract = {We articulate vulnerability as an ethical stance in soma design processes and discuss the conditions of its emergence. We argue that purposeful vulnerability – an act of taking risk, exposing oneself, and resigning part of one’s autonomy – is a necessary although often neglected part of design, and specifically soma design, which builds on felt experience and stimulates designers to engage with the non-habitual by challenging norms, habitual movements, and social interactions. With the help of ethnography, video analysis, and micro-phenomenological interviews, we document an early design exploration around drones, describing how vulnerability is accomplished in collaboration between members of the design team and the design materials. We (1) define vulnerability as an active ethical stance; (2) make vulnerability visible as a necessary but often neglected part of an exploratory design process; and (3) discuss the conditions of its emergence, demonstrating the importance of deliberating ethics within the design process.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {178},
numpages = {13},
keywords = {ethics, soma design, drones, vulnerability},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501978,
author = {N\'{u}\~{n}ez-Pacheco, Claudia and Loke, Lian},
title = {Focusing for Interaction Design: An Introspective Somatic Method},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501978},
doi = {10.1145/3491102.3501978},
abstract = {Attending to the challenges of describing first-person experience, this article illustrates different uses of the Focusing method in interaction design and HCI, offering a systematic way of accessing the subtle qualities of lived experiences for design use. In this approach, the implicit bodily knowledge -or felt sense- becomes the material capture of aesthetic experiences used to inform data collection, ideation and prototyping. We offer a high-level, yet systematic coverage of Focusing applied to two case studies, informing both a set of instructions to use the method and a series of design considerations to adopt this understudied tool of introspection in interaction design research and practice.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {177},
numpages = {18},
keywords = {Design Methods, Interaction Design, Soma Design, HCI, Focusing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501967,
author = {Rechkemmer, Amy and Yin, Ming},
title = {When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501967},
doi = {10.1145/3491102.3501967},
abstract = {Previous research shows that laypeople’s trust in a machine learning model can be affected by both performance measurements of the model on the aggregate level and performance estimates on individual predictions. However, it is unclear how people would trust the model when multiple performance indicators are presented at the same time. We conduct an exploratory human-subject experiment to answer this question. We find that while the level of model confidence significantly affects people’s belief in model accuracy, both the model’s stated and observed accuracy generally have a larger impact on people’s willingness to follow the model’s predictions as well as their self-reported levels of trust in the model, especially after observing the model’s performance in practice. We hope the empirical evidence reported in this work could open doors to further studies to advance understanding of how people perceive, process, and react to performance-related information of machine learning.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {535},
numpages = {14},
keywords = {trust, accuracy, human-subject experiments, Machine learning, confidence},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501960,
author = {Shen, Vivian and Shultz, Craig and Harrison, Chris},
title = {Mouth Haptics in VR Using a Headset Ultrasound Phased Array},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501960},
doi = {10.1145/3491102.3501960},
abstract = {Today’s consumer virtual reality (VR) systems offer limited haptic feedback via vibration motors in handheld controllers. Rendering haptics to other parts of the body is an open challenge, especially in a practical and consumer-friendly manner. The mouth is of particular interest, as it is a close second in tactile sensitivity to the fingertips, offering a unique opportunity to add fine-grained haptic effects. In this research, we developed a thin, compact, beamforming array of ultrasonic transducers, which can render haptic effects onto the mouth. Importantly, all components are integrated into the headset, meaning the user does not need to wear an additional accessory, or place any external infrastructure in their room. We explored several effects, including point impulses, swipes, and persistent vibrations. Our haptic sensations can be felt on the lips, teeth and tongue, which can be incorporated into new and interesting VR experiences.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {275},
numpages = {14},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501956,
author = {Waycott, Jenny and Kelly, Ryan M. and Baker, Steven and Barbosa Neves, Barbara and Thach, Kong Saoane and Lederman, Reeva},
title = {The Role of Staff in Facilitating Immersive Virtual Reality for Enrichment in Aged Care: An Ethic of Care Perspective},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501956},
doi = {10.1145/3491102.3501956},
abstract = {Immersive virtual reality (VR) is being used as an enriching experience for people living in residential aged care, or nursing homes, where care staff play a critical role supporting clients to use VR. In HCI research concerned with technology use in aged care, however, the role of formal caregivers has received limited attention. We conducted interviews with 11 caregivers working in care homes that have implemented VR as part of the social program offered to residents. Our findings highlight tensions between the opportunities created by the immersive VR experience and the risks and challenges full immersion presents for people in aged care. In this paper, we draw on an ethics of care framework to make visible the care practices involved in facilitating VR in aged care homes, highlighting the care required to ensure that older adults experience benefits when using immersive VR, while risks and challenges are carefully managed.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {414},
numpages = {17},
keywords = {Aging, Ethics of Care, Aged Care, Virtual Reality},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501946,
author = {Luo, Weizhou and Lehmann, Anke and Widengren, Hjalmar and Dachselt, Raimund},
title = {Where Should We Put It? Layout and Placement Strategies of Documents in Augmented Reality for Collaborative Sensemaking},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501946},
doi = {10.1145/3491102.3501946},
abstract = {Future offices are likely reshaped by Augmented Reality (AR) extending the display space while maintaining awareness of surroundings, and thus promise to support collaborative tasks such as brainstorming or sensemaking. However, it is unclear how physical surroundings and co-located collaboration influence the spatial organization of virtual content for sensemaking. Therefore, we conducted a study (N=28) to investigate the effect of office environments and work styles during a document classification task using AR with regard to content placement, layout strategies, and sensemaking workflows. Results show that participants require furniture, especially tables and whiteboards, to assist sensemaking and collaboration regardless of room settings, while generous free spaces (e.g., walls) are likely used when available. Moreover, collaborating participants tend to use furniture despite personal layout preferences. We identified different placement and layout strategies, as well as the transitions in-between. Finally, we propose design implications for future immersive sensemaking applications and beyond.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {627},
numpages = {16},
keywords = {affordance, collaborative sensemaking, sensemaking, spatiality, spatial layout, Augmented Reality, content organization, Mixed Reality, qualitative user study},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501941,
author = {Yeh, Su-Fang and Wu, Meng-Hsin and Chen, Tze-Yu and Lin, Yen-Chun and Chang, XiJing and Chiang, You-Hsuan and Chang, Yung-Ju},
title = {How to Guide Task-Oriented Chatbot Users, and When: A Mixed-Methods Study of Combinations of Chatbot Guidance Types and Timings},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501941},
doi = {10.1145/3491102.3501941},
abstract = {The popularity of task-oriented chatbots is constantly growing, but smooth conversational progress with them remains profoundly challenging. In recent years, researchers have argued that chatbot systems should include guidance for users on how to converse with them. Nevertheless, empirical evidence about what to place in such guidance, and when to deliver it, has been lacking. Using a mixed-methods approach that integrates results from a between-subjects experiment and a reflection session, this paper compares the effectiveness of eight combinations of two guidance types (example-based and rule-based) at four guidance timings (service-onboarding, task-intro, after-failure, and upon-request), as measured by users’ task performance, improvement on subsequent tasks, and subjective experience. It establishes that each guidance type and timing has particular strengths and weaknesses, thus that each type/timing combination has a unique impact on performance metrics, learning outcomes, and user experience. On that basis, it presents guidance-design recommendations for future task-oriented chatbots.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {488},
numpages = {16},
keywords = {non-progress, lab study, guidance, chatbot},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501940,
author = {An, Pengcheng and Zhou, Ziqi and Liu, Qing and Yin, Yifei and Du, Linghao and Huang, Da-Yuan and Zhao, Jian},
title = {VibEmoji: Exploring User-Authoring Multi-Modal Emoticons in Social Communication},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501940},
doi = {10.1145/3491102.3501940},
abstract = {Emoticons are indispensable in online communications. With users’ growing needs for more customized and expressive emoticons, recent messaging applications begin to support (limited) multi-modal emoticons:, enhancing emoticons with animations or vibrotactile feedback. However, little empirical knowledge has been accumulated concerning how people create, share and experience multi-modal emoticons in everyday communication, and how to better support them through design. To tackle this, we developed VibEmoji, a user-authoring multi-modal emoticon interface for mobile messaging. Extending existing designs, VibEmoji grants users greater flexibility to combine various emoticons, vibrations, and animations on-the-fly, and offers non-aggressive recommendations based on these components’ emotional relevance. Using VibEmoji as a probe, we conducted a four-week field study with 20 participants, to gain new understandings from in-the-wild usage and experience, and extract implications for design. We thereby contribute to both a novel system and various insights for supporting users’ creation and communication of multi-modal emoticons.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {493},
numpages = {17},
keywords = {Social communication, emotional expression, animation, mobile interfaces., haptic feedback, emoticons, multi-modal interaction},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501932,
author = {Head, Andrew and Xie, Amber and Hearst, Marti A.},
title = {Math Augmentation: How Authors Enhance the Readability of Formulas Using Novel Visual Design Practices},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501932},
doi = {10.1145/3491102.3501932},
abstract = {With the increasing growth and impact of machine learning and other math-intensive fields, it is more important than ever to broaden access to mathematical notation. Can new visual and interactive displays help a wider readership successfully engage with notation? This paper provides the first detailed qualitative analysis of math augmentation—the practice of embellishing notation with novel visual design patterns to improve its readability. We present two qualitative studies of the practice of math augmentation. First is an analysis of 1.1k augmentations to 281 formulas in 47 blogs, textbooks, and other documents containing mathematical expressions. Second is an interview study with 12 authors who had previously designed custom math augmentations (“maugs”). This paper contributes a comprehensive inventory of the kinds of maugs that appear in math documents, and a detailed account of how authors’ tools ought to be redesigned to support efficient creation of math augmentations. These studies open a critical new design space for HCI researchers and interface designers.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {18},
keywords = {mathematical notation, authoring, visual links, details-on-demand},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501915,
author = {Papenmeier, Andrea and Kern, Dagmar and Hienert, Daniel and Kammerer, Yvonne and Seifert, Christin},
title = {How Accurate Does It Feel? – Human Perception of Different Types of Classification Mistakes},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501915},
doi = {10.1145/3491102.3501915},
abstract = {Supervised machine learning utilizes large datasets, often with ground truth labels annotated by humans. While some data points are easy to classify, others are hard to classify, which reduces the inter-annotator agreement. This causes noise for the classifier and might affect the user’s perception of the classifier’s performance. In our research, we investigated whether the classification difficulty of a data point influences how strongly a prediction mistake reduces the “perceived accuracy”. In an experimental online study, 225 participants interacted with three fictive classifiers with equal accuracy (73%). The classifiers made prediction mistakes on three different types of data points (easy, difficult, impossible). After the interaction, participants judged the classifier’s accuracy. We found that not all prediction mistakes reduced the perceived accuracy equally. Furthermore, the perceived accuracy differed significantly from the calculated accuracy. To conclude, accuracy and related measures seem unsuitable to represent how users perceive the performance of classifiers.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {180},
numpages = {13},
keywords = {Accuracy, Ground Truth, Perception, Annotations},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501903,
author = {Liu, Zhe and Chen, Chunyang and Wang, Junjie and Huang, Yuekai and Hu, Jun and Wang, Qing},
title = {Guided Bug Crush: Assist Manual GUI Testing of Android Apps via Hint Moves},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501903},
doi = {10.1145/3491102.3501903},
abstract = {Mobile apps are indispensable for people’s daily life. Complementing with automated GUI testing, manual testing is the last line of defence for app quality. However, the repeated actions and easily missing of functionalities make manual testing time-consuming and inefficient. Inspired by the game candy crush with flashy candies as hint moves for players, we propose an approach named NaviDroid for navigating testers via highlighted next operations for more effective and efficient testing. Within NaviDroid, we construct an enriched state transition graph with the triggering actions as the edges for two involved states. Based on it, we utilize the dynamic programming algorithm to plan the exploration path, and augment the GUI with visualized hints for testers to quickly explore untested activities and avoid duplicate explorations. The automated experiments demonstrate the high coverage and efficient path planning of NaviDroid and a user study further confirms its usefulness. The NaviDroid can help us develop more robust software that works in more mission-critical settings, not only by performing more thorough testing with the same effort that has been put in before, but also by integrating these techniques into different parts of development pipeline.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {557},
numpages = {14},
keywords = {Software Engineering, Quality Assurance, GUI testing, Android App},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501891,
author = {Bao, Calvin S. and Li, Siyao and Flores, Sarah G and Correll, Michael and Battle, Leilani},
title = {Recommendations for Visualization Recommendations: Exploring Preferences and Priorities in Public Health},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501891},
doi = {10.1145/3491102.3501891},
abstract = {The promise of visualization recommendation systems is that analysts will be automatically provided with relevant and high-quality visualizations that will reduce the work of manual exploration or chart creation. However, little research to date has focused on what analysts value in the design of visualization recommendations. We interviewed 18 analysts in the public health sector and explored how they made sense of a popular in-domain dataset1 in service of generating visualizations to recommend to others. We also explored how they interacted with a corpus of both automatically- and manually-generated visualization recommendations, with the goal of uncovering how the design values of these analysts are reflected in current visualization recommendation systems. We find that analysts champion simple charts with clear takeaways that are nonetheless connected with existing semantic information or domain hypotheses. We conclude by recommending that visualization recommendation designers explore ways of integrating context and expectation into their systems.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {411},
numpages = {17},
keywords = {automation, Visualization recommendation systems, recommendation source, algorithmic trust},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501875,
author = {Rogers, Katja and Karaosmanoglu, Sukran and Altmeyer, Maximilian and Suarez, Ally and Nacke, Lennart E.},
title = {Much Realistic, Such Wow! A Systematic Literature Review of Realism in Digital Games},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501875},
doi = {10.1145/3491102.3501875},
abstract = {Researchers reference realism in digital games without sufficient specificity. Without clarity about the dimensions of realism, we cannot assess how and when to aim for a higher degree of realism, when lower realism suffices, or when purposeful unrealism is ideal for a game and can benefit player experience (PX). To address this conceptual gap, we conducted a systematic review using thematic synthesis to distinguish between types of realism currently found in the digital games literature. We contribute qualitative themes that showcase contradictory design goals of realism/unrealism. From these themes, we created a framework (i.e., a hierarchical taxonomy and mapping) of realism dimensions in digital games as a conceptual foundation. Our themes and framework enable a workable specificity for designing or analyzing types of realism, equip future work to explore effects of specific realism types on PX, and offer a starting point for similar efforts in non-game applications.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {190},
numpages = {21},
keywords = {thematic synthesis, fidelity, systematic literature review, realism},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501853,
author = {Vandenberghe, Bert and Gerling, Kathrin and Geurts, Luc and Vanden Abeele, Vero},
title = {Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501853},
doi = {10.1145/3491102.3501853},
abstract = {Maker culture encourages do-it-yourself practices to create, repair, and repurpose technology. In Human-Computer Interaction (HCI) research, it is seen as a means of empowering people, providing affordable and customisable technology with potential to enrich areas such as education or assistive technology. To investigate this alleged potential, we performed an anthropological inquiry at an elementary school for disabled children that lasted one year, participating in everyday activities with students, teachers, and therapists. We observed ‘heterogeneity in a fluid environment’ and ‘creativity in the moment’ in an ‘endemically underfunded’ setting. We saw how technology is ‘injecting dependencies’, ‘reinforcing disability’, and ‘occupying time and space’, changing our view on the role that making can have. Leveraging Empowerment Theory, we highlight how (making) technology risks ignoring the intertwined dynamics between the individual, the organisational, and the community, and articulate points for reflection for technology in schools for disabled children for the HCI research community.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {546},
numpages = {18},
keywords = {school for disabled children, occupational therapy, anthropology, physical therapy, empowerment, disability, ethnography, making technology, non-use},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501847,
author = {Park, Su Han and Han, Bin and Kim, Gerard Jounghyun},
title = {Mixing in Reverse Optical Flow to Mitigate Vection and Simulation Sickness in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501847},
doi = {10.1145/3491102.3501847},
abstract = {Simulator sickness has been one of the major obstacles toward making virtual reality (VR) widely accepted and used. For example, virtual navigation produces vection, which is the illusion of self-motion as one perceives bodily motion despite no movement actually occurs. This, in turn, causes a sensory conflict between visual and actual (or vestibular) motion and sickness. In this study, we explore a method to reduce simulator sickness by visually mixing the optical flow patterns that are in the reverse direction of the virtual visual motion. As visual motion is mainly detected and perceived by the optical flow, artificial mixing in the reverse flow is hypothesized to induce a cancellation effect, thereby reducing the degree of the conflict with the vestibular sense and sickness. To validate our hypothesis, we developed a real-time algorithm to visualize the reverse optical flow and conducted experiments by comparing the before and after sickness levels in seven virtual navigation conditions. The experimental results confirmed the proposed method was effective for reducing the simulator sickness in a statistically significant manner. However, no dependency to the motion type or degrees of freedom were found. Significant distraction and negative influence to the sense of presence and immersion were observed only when the the artificially added reverse optical flow patterns were rather visually marked with high contrast to the background content.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {189},
numpages = {11},
keywords = {Virtual Reality, Vection, Optical Flow, Simulator Sickness},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501835,
author = {Wampfler, Rafael and Klingler, Severin and Solenthaler, Barbara and Schinazi, Victor R. and Gross, Markus and Holz, Christian},
title = {Affective State Prediction from Smartphone Touch and Sensor Data in the Wild},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501835},
doi = {10.1145/3491102.3501835},
abstract = {Knowledge of users’ affective states can improve their interaction with smartphones by providing more personalized experiences (e.g., search results and news articles). We present an affective state classification model based on data gathered on smartphones in real-world environments. From touch events during keystrokes and the signals from the inertial sensors, we extracted two-dimensional heat maps as input into a convolutional neural network to predict the affective states of smartphone users. For evaluation, we conducted a data collection in the wild with 82 participants over 10&nbsp;weeks. Our model accurately predicts three levels (low, medium, high) of valence (AUC up to 0.83), arousal (AUC up to 0.85), and dominance (AUC up to 0.84). We also show that using the inertial sensor data alone, our model achieves a similar performance (AUC up to 0.83), making our approach less privacy-invasive. By personalizing our model to the user, we show that performance increases by an additional 0.07&nbsp;AUC.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {403},
numpages = {14},
keywords = {Deep Learning, Smartphone, Affective Computing, Classification},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501828,
author = {Piitulainen, Roosa and H\"{a}m\"{a}l\"{a}inen, Perttu and Mekler, Elisa D},
title = {Vibing Together: Dance Experiences in Social Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501828},
doi = {10.1145/3491102.3501828},
abstract = {Dancing is a universal human activity, and also a domain of enduring significance in Human-Computer Interaction (HCI) research. However, there has been limited investigation into how computing supports the experiences of recreational dancers. Concurrently, a diverse and sizeable dance community has been emerging in VRChat. Little is known about these dancers’ experiences, motivations, and practices. Yet shedding light into these could inform both VR technology development and the design of systems that better support embodied and complex social interactions. To bridge this gap, we interviewed participants active in the VRChat dance scene. Through thematic analysis, we identified six central facets of their experiences related to freedom, community, dance as an individual experience, dance as a shared experience, dance as a performance, and self-expression and -exploration. Based on these findings, we discuss emerging tensions and highlight beneficial impacts of dancing in VR as well as problems that still await resolving.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {188},
numpages = {18},
keywords = {dancing, social VR, VRChat},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501825,
author = {Liu, Vivian and Chilton, Lydia B},
title = {Design Guidelines for Prompt Engineering Text-to-Image Generative Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501825},
doi = {10.1145/3491102.3501825},
abstract = {Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {384},
numpages = {23},
keywords = {multimodal generative models, AI co-creation, computational creativity, prompt engineering., text-to-image, design guidelines},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501819,
author = {Chung, John Joon Young and Kim, Wooseok and Yoo, Kang Min and Lee, Hwaran and Adar, Eytan and Chang, Minsuk},
title = {TaleBrush: Sketching Stories with Generative Pretrained Language Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501819},
doi = {10.1145/3491102.3501819},
abstract = {While advanced text generation algorithms (e.g., GPT-3) have enabled writers to co-create stories with an AI, guiding the narrative remains a challenge. Existing systems often leverage simple turn-taking between the writer and the AI in story development. However, writers remain unsupported in intuitively understanding the AI’s actions or steering the iterative generation. We introduce TaleBrush, a generative story ideation tool that uses line sketching interactions with a GPT-based language model for control and sensemaking of a protagonist’s fortune in co-created stories. Our empirical evaluation found our pipeline reliably controls story generation while maintaining the novelty of generated sentences. In a user study with 14 participants with diverse writing experiences, we found participants successfully leveraged sketching to iteratively explore and write stories according to their intentions about the character’s fortune while taking inspiration from generated stories. We conclude with a reflection on how sketching interactions can facilitate the iterative human-AI co-creation process.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {209},
numpages = {19},
keywords = {story generation, story writing, controlled generation, sketching, creativity support tool},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517717,
author = {Heuer, Hendrik and Glassman, Elena Leah},
title = {A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517717},
doi = {10.1145/3491102.3517717},
abstract = {During the COVID-19 pandemic, the World Health Organization provided a checklist to help people distinguish between accurate and misinformation. In controlled experiments in the United States and Germany, we investigated the utility of this ordered checklist and designed an interactive version to lower the cost of acting on checklist items. Across interventions, we observe non-trivial differences in participants’ performance in distinguishing accurate and misinformation between the two countries and discuss some possible reasons that may predict the future helpfulness of the checklist in different environments. The checklist item that provides source labels was most frequently followed and was considered most helpful. Based on our empirical findings, we recommend practitioners focus on providing source labels rather than interventions that support readers performing their own fact-checks, even though this recommendation may be influenced by the WHO’s chosen order. We discuss the complexity of providing such source labels and provide design recommendations.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {241},
numpages = {21},
keywords = {Misinformation, World Health Organization, Fact-check, Fake News, Propaganda, COVID-19, Disinformation, Social Media},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517693,
author = {Biehl, Jacob T. and Farzan, Rosta and Zhou, Yingfan},
title = {Can Anybody Help Me?: Using Community Help Desk Call Records to Examine the Impact of Digital Divides During a Global Pandemic},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517693},
doi = {10.1145/3491102.3517693},
abstract = {The COVID-19 global pandemic has ignited lightning-fast adoption of digital tools in our communities, organizations, and systems of governance. It also inspired an unprecedented level of providing access to digital devices to communities and individuals lacking prior access. The situation and circumstances provide a unique opportunity to understand digital divides through a new lens. In this work, we contribute a contemporaneous understanding of digital divides beyond access by qualitatively analyzing over 300 calls made to a volunteer-based community IT help desk. We highlight the intertwined network of challenges leading to ecosystem digital divides and contribute new insights into how the complex socio-technical systems of practice, and the tools to support them, must adapt to bridge digital divides more effectively.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {314},
numpages = {13},
keywords = {ICT use, pandemic response, digital divides},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517671,
author = {Feick, Martin and Regitz, Kora Persephone and Tang, Anthony and Kr\"{u}ger, Antonio},
title = {Designing Visuo-Haptic Illusions with Proxies in Virtual Reality: Exploration of Grasp, Movement Trajectory and Object Mass},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517671},
doi = {10.1145/3491102.3517671},
abstract = {Visuo-haptic illusions are a method to expand proxy-based interactions in VR by introducing unnoticeable discrepancies between the virtual and real world. Yet how different design variables affect the illusions with proxies is still unclear. To unpack a subset of variables, we conducted two user studies with 48 participants to explore the impact of (1) different grasping types and movement trajectories, and (2) different grasping types and object masses on the discrepancy which may be introduced. Our Bayes analysis suggests that grasping types and object masses (≤ 500 g) did not noticeably affect the discrepancy, but for movement trajectory, results were inconclusive. Further, we identified a significant difference between (un)restricted movement trajectories. Our data shows considerable differences in participants’ proprioceptive accuracy, which seem to correlate with their prior VR experience. Finally, we illustrate the impact of our key findings on the visuo-haptic illusion design process by showcasing a new design workflow.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {635},
numpages = {15},
keywords = {Grasp, Visuo-Haptic Illusions, Object Mass, Movement Trajectory},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517635,
author = {Lee, Cheuk Yin Phipson and Zhang, Zhuohao and Herskovitz, Jaylin and Seo, JooYoung and Guo, Anhong},
title = {CollabAlly: Accessible Collaboration Awareness in Document Editing},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517635},
doi = {10.1145/3491102.3517635},
abstract = {Collaborative document editing tools are widely used in professional and academic workplaces. While these tools provide basic accessibility support, it is challenging for blind users to gain collaboration awareness that sighted people can easily obtain using visual cues (e.g., who is editing where and what). Through a series of co-design sessions with a blind coauthor, we identified the current practices and challenges in collaborative editing, and iteratively designed CollabAlly, a system that makes collaboration awareness in document editing accessible to blind users. CollabAlly extracts collaborator, comment, and text-change information and their context from a document and presents them in a dialog box to provide easy access and navigation. CollabAlly uses earcons to communicate background events unobtrusively, voice fonts to differentiate collaborators, and spatial audio to convey the location of document activity. In a study with 11 blind participants, we demonstrate that CollabAlly provides improved access to collaboration awareness by centralizing scattered information, sonifying visual information, and simplifying complex operations.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {596},
numpages = {17},
keywords = {Blind, accessibility, visual impairment, spatial audio, voice font, collaboration awareness, screen reader, earcon, Collaborative writing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517633,
author = {Ku, Pin-Sung and Huang, Kunpeng and Kao, Cindy Hsin-Liu},
title = {Patch-O: Deformable Woven Patches for On-Body Actuation},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517633},
doi = {10.1145/3491102.3517633},
abstract = {We present Patch-O, a novel deformable interface devised as a woven patch that enables diverse movement-based interactions adaptive to garments or on-skin wearing. Patch-O interfaces are uniquely detachable and relocatable soft actuation units that can be sewn or attached to clothing or skin at various locations. To optimize the morphing effect while preserving a slim form factor, we introduce a construction approach that integrates actuators at a structural level and varies the texture and stiffness of the woven substrate locally. We implement three basic actuation primitives, including bending, expanding, and shrinking, and experiment with aggregation parameters to exhaustively extend the design space. A final workshop study inviting textile practitioners to create personalized designs of Patch-O provides insights into the expressiveness of the approach for wearable interactions. We conclude with three applications inspired by users’ designs and showcase the aesthetic and functional usages enabled by the deformable woven patches.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {615},
numpages = {12},
keywords = {Fabrication, Wearable Computers, Fashion/Clothing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517620,
author = {Tang, Kymeng and Gerling, Kathrin and Geurts, Luc},
title = {Virtual Feed: Design and Evaluation of a Virtual Reality Simulation Addressing the Lived Experience of Breastfeeding},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517620},
doi = {10.1145/3491102.3517620},
abstract = {Breastfeeding can be challenging, but it is difficult for antenatal education to convey issues associated with the lived experience of breastfeeding. In our work, we explore the potential of interactive simulations to support antenatal education, and present Virtual Feed, a Virtual Reality breastfeeding simulation for parents-to-be developed following a three-step process. (1) We created an experience prototype that features basic VR scenarios and a tangible baby, (2) we engaged in design sessions with 19 parents and parents-to-be to derive design implications to further refine the simulation, and (3) we evaluated the system through case studies to examine the perspectives of parents and parents-to-be on the simulation. Our results show that the simulation successfully engaged users and sparked curiosity, while also encouraging reflection about the challenges of breastfeeding. On this basis, we discuss challenges for the design of simulations with the purpose of supplementing antenatal education.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {438},
numpages = {17},
keywords = {breastfeeding, co-design, virtual reality, qualitative research},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517600,
author = {Das, Dipto and Semaan, Bryan},
title = {Collaborative Identity Decolonization as Reclaiming Narrative Agency: Identity Work of Bengali Communities on Quora},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517600},
doi = {10.1145/3491102.3517600},
abstract = {While people’s identities can be marginalized through various forces, colonialism is one of the primary ways that continues to influence people’s lives and identities. Colonialism refers to the policies and practices where foreign powers migrate to other lands and alter the social structures, and thus identities, of local populations. What is less understood is how online spaces can support people in the aftermath of colonization in revising, repairing, and strengthening their identities—the process of identity decolonization work. Using trace ethnography beginning on 15 May, 2020 and ending on 15 July, 2020 and drawing on Poka Laenui’s framework of decolonization, we explore how South Asian Bengalis on the platform Bengali Quora (BnQuora) engage in collaborative identity decolonization work to reclaim narrative agency. We discuss how narratives serve to help people bounce back from threat or vulnerability—a concept we dub narrative resilience. We also describe potential implications for future scholarship focused on decolonization that extends multiple ongoing conversations around ICT for development, social justice, decolonial HCI, and identity research within the CHI community.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {236},
numpages = {23},
keywords = {Decolonization, Bengali Quora, Colonial, Identity, Bengali},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517599,
author = {Ceha, Jessy and Law, Edith},
title = {Expressive Auditory Gestures in a Voice-Based Pedagogical Agent},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517599},
doi = {10.1145/3491102.3517599},
abstract = {In this paper, we explore how expressive auditory gestures added to the speech of a pedagogical agent influence the human-agent relationship and learning outcomes. In a between-subjects experiment, 41 participants assumed the role of a tutor to teach a voice-based agent. The agent used either: expressive interjections (e.g.,“yay”, “hmm”, “oh”), brief expressive musical executions, or no auditory gestures at all (control condition), throughout the interaction. Overall, the results indicate that both gestures can positively affect the interaction, but in particular, interjections can significantly increase feelings of emotional rapport with the agent and enhance motivation in learners. The implications of our findings are discussed as our work adds to the understanding of conversational agent design and can be useful for education as well as other domains in which dialogue systems are used.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {163},
numpages = {13},
keywords = {motivation, interjections, voice, agent, rapport, music, education},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517597,
author = {Hasselqvist, Hanna and Renstr\"{o}m, Sara and H\r{a}kansson, Maria and Str\"{o}mberg, Helena},
title = {Exploring Renewable Energy Futures through Household Energy Resilience},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517597},
doi = {10.1145/3491102.3517597},
abstract = {A transition to renewable energy increases the risks of disruptions when electricity supply does not meet demand.&nbsp;HCI&nbsp;has explored how digital technologies can mitigate such problems in households through support for reducing or shifting electricity use. However, faster transitions may be possible if some disturbances can be&nbsp;acceptable&nbsp;and households are supported in adapting to them. In this paper, we present a study of 21 Swedish households and their experiences of and ideas on how to manage disruptions in electricity supply. We call this perspective&nbsp;household energy resilience&nbsp;and identify three strategies for resilience: (1)&nbsp;response diversity, i.e., diversity in ways of carrying out normally electricity-dependent practices, (2) creating&nbsp;opportunities to develop resilience, and (3) building&nbsp;community energy resilience. Furthermore, we suggest how&nbsp;HCI&nbsp;can support these strategies, both by providing tools to increase resilience and by carefully designing technology and services to be more resilient in themselves.&nbsp;},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {333},
numpages = {18},
keywords = {Energy resilience, Sustainable HCI, Energy futures, Households, Renewable energy},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517594,
author = {Williamson, Julie R. and O'Hagan, Joseph and Guerra-Gomez, John Alexis and Williamson, John H and Cesar, Pablo and Shamma, David A.},
title = {Digital Proxemics: Designing Social and Collaborative Interaction in Virtual Environments},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517594},
doi = {10.1145/3491102.3517594},
abstract = {Behaviour in virtual environments might be informed by our experiences in physical environments, but virtual environments are not constrained by the same physical, perceptual, or social cues. Instead of replicating the properties of physical spaces, one can create virtual experiences that diverge from reality by dynamically manipulating environmental, aural, and social properties. This paper explores digital proxemics, which describe how we use space in virtual environments and how the presence of others influences our behaviours, interactions, and movements. First, we frame the open challenges of digital proxemics in terms of activity, social signals, audio design, and environment. We explore a subset of these challenges through an evaluation that compares two audio designs and two displays with different social signal affordances: head-mounted display (HMD) versus desktop PC. We use quantitative methods using instrumented tracking to analyse behaviour, demonstrating how personal space, proximity, and attention compare between desktop PC and HMDs.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {423},
numpages = {12},
keywords = {Social Signal Processing, Virtual Environments, Digital Proxemics, Quantitative Methods.},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517588,
author = {Varanasi, Rama Adithya and Pal, Joyojeet and Vashistha, Aditya},
title = {Accost, Accede, or Amplify: Attitudes towards COVID-19 Misinformation on WhatsApp in India},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517588},
doi = {10.1145/3491102.3517588},
abstract = {Social media has witnessed an unprecedented growth in users based in low-income communities in the Global South. However, much remains unknown about the drivers of misinformation in such communities. To fill this gap, we conducted an interview-based study to examine how rural and urban communities in India engage with misinformation on WhatsApp. We found that misinformation led to bitterness and conflict – rural users who had higher social status heavily influenced the perceptions and engagement of marginalized members. While urban users relied on the expertise of gatekeepers for verification, rural users engaged in collective deliberations in offline spaces. Both rural and urban users knowingly forwarded misinformation. However, rural users propagated hyperlocal misinformation, whereas urban users forwarded misinformation to reduce their efforts to assess information credibility. Using a public sphere lens, we propose that the reactions to misinformation provide a view of Indian society and its schisms around class, urbanity, and social interactions.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {17},
keywords = {public sphere, encrypted platforms, Misinformation, disinformation, WhatsApp, rural},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517575,
author = {Yadav, Deepika and Dabas, Kirti and Malik, Prerna and Bhandari, Anushka and Singh, Pushpendra},
title = {“Should I Visit the Clinic”: Analyzing WhatsApp-Mediated Online Health Support for Expectant and New Mothers in Rural India},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517575},
doi = {10.1145/3491102.3517575},
abstract = {Limited interaction with professionals, infrastructural, and social constraints put barriers in providing holistic support to expectant and new mothers in low-resource settings. We examine the use of digital support groups facilitated through WhatsApp by a non-government organization in India. Complementing prior research, these digital peer support groups inform about an open public space created over a chat platform where rural communities and health professionals can engage. By qualitatively analyzing six months of interaction among 588 group members and collecting the experiences of the group moderators, we inform about how the support groups acted as an important source for compensating the gaps in the existing healthcare, providing reassurance support on routine health, explanation on test reports, validation and counseling support in ongoing treatments. We also derive implications for the future of digital support groups and the need for further research on the use of unplatformed design models in resource-constrained settings.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {296},
numpages = {20},
keywords = {Maternal health, Digital support group, Social support, WhatsApp},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517568,
author = {Garcia, J\'{e}r\'{e}mie and Brock, Anke M.},
title = {CandyFly: Bringing Fun to Drone Pilots with Disabilities through Adapted and Adaptable Interactions},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517568},
doi = {10.1145/3491102.3517568},
abstract = {Flying drones is an increasingly popular activity. However, it is challenging due to the required perceptual and motor skills for following and stabilizing the drone, especially for people with special needs. This paper describes CandyFly, an application supporting people with diverse sensory, cognitive and motor impairments to pilot drones. We observed an existing accessible piloting workshop and evaluated CandyFly during eight additional workshops over three and a half years using a research-through-design process and ability-based design methods. We identified users’ needs, formulated requirements and explored adaptive interactions such as using pressure-sensitive keys, adjusting controls to the pilots’ range of motion, or limiting the drone’s degrees of freedom to cope with a broad range of disabilities. Our results show that the pilots and their caregivers enjoyed flying and emphasized CandyFly’s ability to be tailored to specific needs. Our findings offer a framework for designing adaptable systems and can support the design of future assistive and recreational systems.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {605},
numpages = {13},
keywords = {Automation, Human-Drone Interaction, Piloting, Accessibility, Unmanned Aerial Vehicles, Drones},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517564,
author = {Do, Tiffany D. and McMahan, Ryan P. and Wisniewski, Pamela J.},
title = {A New Uncanny Valley? The Effects of Speech Fidelity and Human Listener Gender on Social Perceptions of a Virtual-Human Speaker},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517564},
doi = {10.1145/3491102.3517564},
abstract = {Virtual humans can be used to deliver persuasive arguments; yet, those with synthetic text-to-speech (TTS) have been perceived less favorably than those with recorded human speech. In this paper, we investigate standard concatenative TTS and more advanced neural TTS. We conducted a 3x2 between-subjects experiment (n=79) to evaluate the effect of a virtual human’s speech fidelity at three levels (Standard TTS, Neural TTS, and Human speech) and the listener’s gender (male or female) on perceptions and persuasion. We found that the virtual human was perceived as significantly less trustworthy by both genders, if they used neural TTS compared to human speech, while male listeners (but not females) also perceived standard TTS as less trustworthy than human speech. Our findings indicate that neural TTS may not be an effective choice for persuasive virtual humans and that gender of the listener plays a role in how virtual humans are perceived.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {424},
numpages = {11},
keywords = {social perception, virtual humans, text-to-speech, speech fidelity},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517556,
author = {Michaelis, Joseph E and Di Canio, Daniela},
title = {Embodied Geometric Reasoning with a Robot: The Impact of Robot Gestures on Student Reasoning about Geometrical Conjectures},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517556},
doi = {10.1145/3491102.3517556},
abstract = {In this paper, we explore how the physically embodied nature of robots can influence learning through non-verbal communication, such as gesturing. We take an embodied cognition perspective to examine student interactions with a NAO robot that uses gestures while reasoning about geometry conjectures. College aged students (N = 30) were randomly assigned to either a dynamic condition, where the robot uses dynamic gestures that represent and manipulate geometric shapes in the conjectures, or control condition, where the robot uses beat gestures that match the rhythm of speech. Students in the dynamic condition: (1) use more gestures when they reason about geometry conjectures, (2) look more at the robot as it speaks, (3) feel the robot is a better study partner and uses effective gestures, but (4) were not more successful in correctly reasoning about geometry conjectures. We discuss implications for socially supported and embodied learning with a physically present robot.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {224},
numpages = {14},
keywords = {mathematics learning, human-robot interaction, embodied cognition, gesture},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517548,
author = {Masnadi, Sina and Pfeil, Kevin and Sera-Josef, Jose-Valentin T and LaViola, Joseph},
title = {Effects of Field of View on Egocentric Distance Perception in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517548},
doi = {10.1145/3491102.3517548},
abstract = {We performed a mixed-design study with 56 participants to compare the effect of horizontal FOV (hfov) and vertical FOV (vfov) on egocentric distance perception in four different realistic virtual environments (VEs). We also compared VE attributes of indoor/outdoor and cluttered/uncluttered. The participants blind-walked towards four different targets at 3m, 4m, 5m, and 6m distance while wearing a backpack computer and a wide FOV head-mounted display (HMD). The combinations of 165°, 110° and 45° hfovs, and 110° and 35° vfovs was simulated in the same HMD. The results indicated more accurate distance judgement with larger hfov with no significant effect of vfov. More accurate distance judgement in indoor VEs compared to outdoor VEs was observed. Also, participants judged distances more accurately in cluttered environments versus uncluttered environments. These results highlight that the environment is important in distance-critical VR applications and wider hfov should be considered for an improved distance judgment.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {613},
numpages = {10},
keywords = {virtual reality, outdoor, field of view, vertical FOV, clutter, FOV, horizontal FOV, distance perception, virtual environment, indoor, VR},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517547,
author = {Gaver, William and Boucher, Andy and Brown, Dean and Chatting, David and Matsuda, Naho and Ovalle, Liliana and Sheen, Andy and Vanis, Michail},
title = {Yo–Yo Machines: Self-Build Devices That Support Social Connections During the Pandemic},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517547},
doi = {10.1145/3491102.3517547},
abstract = {Yo–Yo Machines are playful communication devices designed to help people feel socially connected while physically separated. We designed them to reach as many people as possible, both to make a positive impact during the COVID-19 pandemic and to assess a self-build approach to circulating research products and the appeal of peripheral and expressive communication devices. A portfolio of four distinct designs, based on over 30 years of research, were made available for people to make by following simple online instructions (yoyomachines.io). Each involves connecting a pair of identical devices over the internet to allow simple communication at a distance. This paper describes our motivation for the project, previous work in the area, the design of the devices, supporting website and publicity, and how users have made and used Yo-Yo Machines. Finally, we reflect on what we learned about peripheral and expressive communication devices and implications for the self-build approach.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {458},
numpages = {17},
keywords = {design research, open source, peripheral and expressive communication, research through design, self-build, IoT},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517510,
author = {Sabir, Aafaq and Lafontaine, Evan and Das, Anupam},
title = {Hey Alexa, Who Am I Talking to?: Analyzing Users’ Perception and Awareness Regarding Third-Party Alexa Skills},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517510},
doi = {10.1145/3491102.3517510},
abstract = {The Amazon Alexa voice assistant provides convenience through automation and control of smart home appliances using voice commands. Amazon allows third-party applications known as skills to run on top of Alexa to further extend Alexa’s capability. However, as multiple skills can share the same invocation phrase and request access to sensitive user data, growing security and privacy concerns surround third-party skills. In this paper, we study the availability and effectiveness of existing security indicators or a lack thereof to help users properly comprehend the risk of interacting with different types of skills. We conduct an interactive user study (inviting active users of Amazon Alexa) where participants listen to and interact with real-world skills using the official Alexa app. We find that most participants fail to identify the skill developer correctly (i.e., they assume Amazon also develops the third-party skills) and cannot correctly determine which skills will be automatically activated through the voice interface. We also propose and evaluate a few voice-based skill type indicators, showcasing how users would benefit from such voice-based indicators.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {447},
numpages = {15},
keywords = {Third-party skills, Voice assistant, Security indicators},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517509,
author = {Ding, Xianghua(Sharon) and Kou, Yubo and Xu, Yiwen and Zhang, Peng},
title = {“As Uploaders, We Have the Responsibility”: Individualized Professionalization of Bilibili Uploaders},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517509},
doi = {10.1145/3491102.3517509},
abstract = {The prevalence of social media blurs the boundaries between consumer and producer, work and play, and leads to new social roles, professions, and identities (e.g. blogger, YouTuber, micro-celebrity). However, we still lack a clear understanding of how people come to identify with these new roles and how individual professional development is digitally mediated. This paper presents a study based on Bilibili, a popular Chinese social media platform featuring user-generated videos, and highlights a professionalization process through which individuals consciously distinguish between the roles of uploaders and consumers, develop a shared work ethos around the role of the uploader, and, as uploaders, improve their technical-professional expertise. We conclude by discussing individualized professionalization as a concept that describes the bottom-up and community-based process of professional development for User Generated Content (UGC) taking place in contemporary digital media environments.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {509},
numpages = {14},
keywords = {Online Creative Media, User Generated Content (UGC), Profession, Professionalization},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517508,
author = {Thoravi Kumaravel, Balasaravanan and Wilson, Andrew D},
title = {DreamStream: Immersive and Interactive Spectating in VR},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517508},
doi = {10.1145/3491102.3517508},
abstract = {Today spectating and streaming virtual reality (VR) activities typically involves spectators viewing a 2D stream of the VR user’s view. Streaming 2D videos of the game play is popular and well-supported by platforms such as Twitch. However, the generic streaming of full 3D representations is less explored. Thus, while the VR player’s experience may be fully immersive, spectators are limited to 2D videos. This asymmetry lessens the overall experience for spectators, who themselves may be eager to spectate in VR. DreamStream puts viewers in the virtual environment of the VR application, allowing them to look “over the shoulder” of the VR player. Spectators can view streamed VR content immersively in 3D, independently explore the VR scene beyond what the VR player sees and ultimately cohabit the virtual environment alongside the VR player. For the VR player, DreamStream provides a spatial awareness of all their spectators. DreamStream retrofits and works with existing VR applications. We discuss the design and implementation of DreamStream, and carry out three qualitative informal evaluations. These evaluations shed light on the strengths and weakness of using DreamStream for the purpose of interactive spectating. Our participants found that DreamStream’s VR viewer interface offered increased immersion, and made it easier to communicate and interact with the VR player.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {636},
numpages = {17},
keywords = {Collaborative Interactions, Virtual Reality, Streaming},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517502,
author = {Mlynar, Jakub and Bahrami, Farzaneh and Ourednik, Andr\'{e} and Mutzner, Nico and Verma, Himanshu and Alavi, Hamed},
title = {AI beyond Deus Ex Machina – Reimagining Intelligence in Future Cities with Urban Experts},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517502},
doi = {10.1145/3491102.3517502},
abstract = {The current mechanisms that drive the development of AI technologies are widely criticized for being tech-oriented and market-led instead of stemming from societal challenges. In Human-Centered AI discourses, and more broadly in Human-Computer Interaction research, initiatives have been proposed to engage experts from various domains of social science in determining how AI should reach our societies, predominantly through informing the adoption policies. Our contribution, however, seeks a more essential role for social sciences, namely to introduce discursive standpoints around what we need AI to be. With a focus on the domain of urbanism, the specific goal has been to elicit – from interviews with 16 urban experts – the imaginaries of how AI can and should impact future cities. Drawing on the social science literature, we present how the notion of “imaginary” has essentially framed this research and how it could reveal an alternative vision of non-human intelligent actors in future cities.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {370},
numpages = {13},
keywords = {Urban Sciences, Sociology, Smart City, Artificial Intelligence},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517493,
author = {Janzen, Izabelle F and McGrenere, Joanna},
title = {Reflective Spring Cleaning: Using Personal Informatics to Support Infrequent Notification Personalization},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517493},
doi = {10.1145/3491102.3517493},
abstract = {Distracting mobile notifications are a high-profile problem but previous research suggests notification management tools are underused because of the barriers users face in relation to the perceived benefits. We posit that users might be more motivated to personalize if they could view contextual data for how personalizations would have impacted their recent notifications. We propose the ‘Reflective Spring Cleaning’ approach to support notification management through infrequent personalization with visualization of collected notification data. To simplify and contextualize key trends in a user’s notifications, we framed these visualizations within a novel who-what-when data abstraction. We evaluated it through a four-week longitudinal study: 21 participants logged their notifications before and after a personalization session that included suggestions for notification management contextualized against visualizations of their recent notifications. A debriefing interview described their new experience after two more weeks of logging. Our approach encouraged users to critically reflect on their notifications, which frequently inspired them to personalize and improved the experience of the majority.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {179},
numpages = {16},
keywords = {visualization, interruption, personalization, personal informatics, notifications},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517475,
author = {Chen, Janet X. and McDonald, Allison and Zou, Yixin and Tseng, Emily and Roundy, Kevin A and Tamersoy, Acar and Schaub, Florian and Ristenpart, Thomas and Dell, Nicola},
title = {Trauma-Informed Computing: Towards&nbsp;Safer&nbsp;Technology&nbsp;Experiences&nbsp;for&nbsp;All},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517475},
doi = {10.1145/3491102.3517475},
abstract = {Trauma is the physical, emotional, or psychological harm caused by deeply distressing experiences. Research with communities that may experience high rates of trauma has shown that digital technologies can create or exacerbate traumatic experiences. Via three vignettes, we discuss how considering the possible effects of trauma and traumatic stress reactions provides an explanatory lens with new insights into people’s technology experiences. Then, we present a framework—trauma-informed computing—in which we adapt and show how to apply six key principles of trauma-informed approaches to computing: safety, trust, peer support, collaboration, enablement, and intersectionality. Through specific examples, we describe how to apply trauma-informed computing in four areas of computing research and practice: user experience research &amp; design, security &amp; privacy, artificial intelligence &amp; machine learning, and organizational culture in tech companies. We conclude by discussing how adopting trauma-informed computing will lead to benefits for all users, not only those experiencing trauma.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {544},
numpages = {20},
keywords = {gender-based violence, computer security and privacy, transgender, trauma-informed computing, intimate partner violence, trauma},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517471,
author = {Cai, Wanling and Jin, Yucheng and Chen, Li},
title = {Impacts of Personal Characteristics on User Trust in Conversational Recommender Systems},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517471},
doi = {10.1145/3491102.3517471},
abstract = {Conversational recommender systems (CRSs) imitate human advisors to assist users in finding items through conversations and have recently gained increasing attention in domains such as media and e-commerce. Like in human communication, building trust in human-agent communication is essential given its significant influence on user behavior. However, inspiring user trust in CRSs with a “one-size-fits-all” design is difficult, as individual users may have their own expectations for conversational interactions (e.g., who, user or system, takes the initiative), which are potentially related to their personal characteristics. In this study, we investigated the impacts of three personal characteristics, namely personality traits, trust propensity, and domain knowledge, on user trust in two types of text-based CRSs, i.e., user-initiative and mixed-initiative. Our between-subjects user study (N=148) revealed that users’ trust propensity and domain knowledge positively influenced their trust in CRSs, and that users with high conscientiousness tended to trust the mixed-initiative system.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {489},
numpages = {14},
keywords = {trust, Conversational recommender systems, personal characteristics, mixed-initiative interaction},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517465,
author = {Holloway, Leona M and Goncu, Cagatay and Ilsar, Alon and Butler, Matthew and Marriott, Kim},
title = {Infosonics: Accessible Infographics for People Who Are Blind Using Sonification and Voice},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517465},
doi = {10.1145/3491102.3517465},
abstract = {Data visualisations are increasingly used online to engage readers and enable independent analysis of the data underlying news stories. However, access to such infographics is problematic for readers who are blind or have low vision (BLV). Equitable access to information is a basic human right and essential for independence and inclusion. We introduce infosonics, the audio equivalent of infographics, as a new style of interactive sonification that uses a spoken introduction and annotation, non-speech audio and sound design elements to present data in an understandable and engaging way. A controlled user evaluation with 18 BLV adults found a COVID-19 infosonic enabled a clearer mental image than a traditional sonification. Further, infosonics prove complementary to text descriptions and facilitate independent understanding of the data. Based on our findings, we provide preliminary suggestions for infosonics design, which we hope will enable BLV people to gain equitable access to online news and information.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {480},
numpages = {13},
keywords = {low vision, sonification, information access, Blind, accessible graphics},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517457,
author = {Kim, Young-Ho and Chou, Diana and Lee, Bongshin and Danilovich, Margaret and Lazar, Amanda and Conroy, David E. and Kacorri, Hernisa and Choe, Eun Kyoung},
title = {MyMove: Facilitating Older Adults to Collect In-Situ Activity Labels on a Smartwatch with Speech},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517457},
doi = {10.1145/3491102.3517457},
abstract = {Current activity tracking technologies are largely trained on younger adults’ data, which can lead to solutions that are not well-suited for older adults. To build activity trackers for older adults, it is crucial to collect training data with them. To this end, we examine the feasibility and challenges with older adults in collecting activity labels by leveraging speech. Specifically, we built MyMove, a speech-based smartwatch app to facilitate the in-situ labeling with a low capture burden. We conducted a 7-day deployment study, where 13 older adults collected their activity labels and smartwatch sensor data, while wearing a thigh-worn activity monitor. Participants were highly engaged, capturing 1,224 verbal reports in total. We extracted 1,885 activities with corresponding effort level and timespan, and examined the usefulness of these reports as activity labels. We discuss the implications of our approach and the collected dataset in supporting older adults through personalized activity tracking technologies.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {416},
numpages = {21},
keywords = {older adults, speech interaction, smartwatch, activity labeling, experience sampling method},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517456,
author = {Choi, Youjin and Kim, JooYeong and Park, Chan Woo and Kim, Jeongyoun and Yi, Ji Hyun and Hong, Jin-Hyuk},
title = {We Play and Learn Rhythmically: Gesture-Based Rhythm Game for Children with Intellectual Developmental Disabilities to Learn Manual Sign},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517456},
doi = {10.1145/3491102.3517456},
abstract = {Manual sign systems have been introduced to improve the communication of children with intellectual developmental disabilities (IDD). Due to the lack of learning support tools, teachers face many practical challenges in teaching manual sign to children, such as low attention span and the need for persistent intervention. To address these issues, we collaborated with teachers to develop the Sondam Rhythm Game, a gesture-based rhythm game that assists in teaching manual sign language, and ran a four-week empirical study with five teachers and eight children with IDD. Based on video annotation and post-hoc interviews, our game-based learning approach has the potential to be effective at teaching manual sign to children with IDD. Our approach improved children attention span and motivation while also increasing the number of voluntary gestures made without the need for prompting. Other practical issues and learning challenges were also uncovered to improve teaching paradigms for children with IDD.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {539},
numpages = {13},
keywords = {Rhythm game, Gamification, Manual sign learning, Children with intellectual and developmental disabilities},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

