@inproceedings{10.1145/3491102.3517431,
author = {Sharif, Ather and Wang, Olivia H. and Muongchan, Alida T. and Reinecke, Katharina and Wobbrock, Jacob O.},
title = {VoxLens: Making Online Data Visualizations Accessible with an Interactive JavaScript Plug-In},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517431},
doi = {10.1145/3491102.3517431},
abstract = {JavaScript visualization libraries are widely used to create online data visualizations but provide limited access to their information for screen-reader users. Building on prior findings about the experiences of screen-reader users with online data visualizations, we present VoxLens, an open-source JavaScript plug-in that—with a single line of code—improves the accessibility of online data visualizations for screen-reader users using a multi-modal approach. Specifically, VoxLens enables screen-reader users to obtain a holistic summary of presented information, play sonified versions of the data, and interact with visualizations in a “drill-down” manner using voice-activated commands. Through task-based experiments with 21 screen-reader users, we show that VoxLens improves the accuracy of information extraction and interaction time by 122% and 36%, respectively, over existing conventional interaction with online data visualizations. Our interviews with screen-reader users suggest that VoxLens is a “game-changer” in making online data visualizations accessible to screen-reader users, saving them time and effort.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {478},
numpages = {19},
keywords = {accessibility, Visualizations, screen readers, blind, voice-based interaction, low-vision.},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502207,
author = {Sundar, S. Shyam and Jia, Haiyan and Bellur, Saraswathi and Oh, Jeeyun and Kim, Hyang-Sook},
title = {News Informatics: Engaging Individuals with Data-Rich News Content through Interactivity in Source, Medium, and Message},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502207},
doi = {10.1145/3491102.3502207},
abstract = {This paper introduces the concept of “news informatics” to refer to journalistic presentation of big data in online sites. For users to be engaged with such data-driven public information, it is important to incorporate interactive tools so that each person can extract personally relevant information. Drawing upon a communication model of interactivity, we designed a data-rich site with three different types of interactive features—namely, modality interactivity, message interactivity, and source interactivity—and empirically tested their relative and combined effects on user engagement and user experience with a 2 (modality) \texttimes{} 3 (source) \texttimes{} 2 (message) field experiment (N =166). Findings shed light on how interface designers, online news editors and journalists can maximize user engagement with data-rich news content. Certain interactivity combinations are found to be better than others, with a structural equation model (SEM) revealing the underlying theoretical mechanisms and providing implications for the design of news informatics.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {317},
numpages = {17},
keywords = {Website Interactivity, News Informatics, User Engagement},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502121,
author = {Wang, Ding and Prabhat, Shantanu and Sambasivan, Nithya},
title = {Whose AI Dream? In Search of the Aspiration in Data Annotation.},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502121},
doi = {10.1145/3491102.3502121},
abstract = {Data is fundamental to AI/ML models. This paper investigates the work practices concerning data annotation as performed in the industry, in India. Previous human-centred investigations have largely focused on annotators’ subjectivity, bias and efficiency. We present a wider perspective of the data annotation: following a grounded approach, we conducted three sets of interviews with 25 annotators, 10 industry experts and 12 ML/AI practitioners. Our results show that the work of annotators is dictated by the interests, priorities and values of others above their station. More than technical, we contend that data annotation is a systematic exercise of power through organizational structure and practice. We propose a set of implications for how we can cultivate and encourage better practice to balance the tension between the need for high quality data at low cost and the annotators’ aspiration for well-being, career perspective, and active participation in building the AI dream.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {582},
numpages = {16},
keywords = {AI labour, future of work, qualitative study, data annotation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502106,
author = {McKay, Dana and Zhang, Huiwen and Buchanan, George},
title = {Who Am I, and Who Are You, and Who Are We? A Scientometric Analysis of Gender and Geography in HCI},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502106},
doi = {10.1145/3491102.3502106},
abstract = {Conference authorship, attendance and presentation is a key measure of quality in the HCI academic, yet we know conferences are not equally accessible for reasons that have nothing to do with quality. In this paper we examine two axes of diversity: gender, and geographic location (of both authors and conferences) and examine how they affect participation at major HCI conferences. Diversity in a group is associated with better outcomes from its work, and HCI has made numerous contributions to increasing representation in other communities. Reflecting on our own situation can produce recommendations for the planning of future HCI conferences, and identify challenges of representation that the HCI community should endeavor to address.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {396},
numpages = {19},
keywords = {Equity, authorship in HCI, diversity, gender, geography},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502098,
author = {Schankin, Andrea and Budde, Matthias and Riedel, Till and Beigl, Michael},
title = {Psychometric Properties of the User Experience Questionnaire (UEQ)},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502098},
doi = {10.1145/3491102.3502098},
abstract = {User experience (UX) summarizes user perceptions and responses resulting from the interaction with a product, system, or service. The User Experience Questionnaire (UEQ) is one standardized instrument for measuring UX. With six scales, it identifies areas in which product improvements will have the highest impact. In this paper, we evaluate the reliability and validity of this questionnaire. The data of N = 1, 121 participants who interacted with one of 23 products indicated an acceptable to good reliability of all scales. The results show, however, that the scales were not independent of each other. Combining perspicuity, efficiency, and dependability to pragmatic aspects as well as novelty and stimulation to hedonic aspects of UX improved the model fit significantly. The systematic variations of product properties and correlations with the System Usability Scale (SUS) in a second experiment with N=499 participants supported the validity of these two factors. Practical implications of the results are discussed.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {466},
numpages = {11},
keywords = {psychometric properties, UEQ, user experience},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502089,
author = {Mohaddesi, Omid and Griffin, Jacqueline and Ergun, Ozlem and Kaeli, David and Marsella, Stacy and Harteveld, Casper},
title = {To Trust or to Stockpile: Modeling Human-Simulation Interaction in Supply Chain Shortages},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502089},
doi = {10.1145/3491102.3502089},
abstract = {Understanding decision-making in dynamic and complex settings is a challenge yet essential for preventing, mitigating, and responding to adverse events (e.g., disasters, financial crises). Simulation games have shown promise to advance our understanding of decision-making in such settings. However, an open question remains on how we extract useful information from these games. We contribute an approach to model human-simulation interaction by leveraging existing methods to characterize: (1) system states of dynamic simulation environments (with Principal Component Analysis), (2) behavioral responses from human interaction with simulation (with Hidden Markov Models), and (3) behavioral responses across system states (with Sequence Analysis). We demonstrate this approach with our game simulating drug shortages in a supply chain context. Results from our experimental study with 135 participants show different player types (hoarders, reactors, followers), how behavior changes in different system states, and how sharing information impacts behavior. We discuss how our findings challenge existing literature.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {363},
numpages = {18},
keywords = {human-simulation interaction, supply chain, hidden markov models, principal component analysis, sequence analysis, gamette},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502063,
author = {Lei, Wentao and Fan, Mingming and Thang, Juliann},
title = {“I Shake The Package To Check If It’s Mine”: A Study of Package Fetching Practices and Challenges of Blind and Low Vision People in China},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502063},
doi = {10.1145/3491102.3502063},
abstract = {With about 230 million packages delivered per day in 2020, fetching packages has become a routine for many city dwellers in China. When fetching packages, people usually need to go to collection sites of their apartment complexes or a KuaiDiGui, an increasingly popular type of self-service package pickup machine. However, little is known whether such processes are accessible to blind and low vision (BLV) city dwellers. We interviewed BLV people (N=20) living in a large metropolitan area in China to understand their practices and challenges of fetching packages. Our findings show that participants encountered difficulties in finding the collection site and localizing and recognizing their packages. When fetching packages from KuaiDiGuis, they had difficulty in identifying the correct KuaiDiGui, interacting with its touch screen, navigating the complex on-screen workflow, and opening the target compartment. We discuss design considerations to make the package fetching process more accessible to the BLV community.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {268},
numpages = {15},
keywords = {Package delivery, People with vision impairments, Accessibility, China, Qualitative study, KuaiDiGui, Blind and low vision, Interview},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502057,
author = {Wang, Ge and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
title = {Informing Age-Appropriate AI: Examining Principles and Practices of AI for Children},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502057},
doi = {10.1145/3491102.3502057},
abstract = {AI systems are becoming increasingly pervasive within children’s devices, apps, and services. However, it is not yet well-understood how risks and ethical considerations of AI relate to children. This paper makes three contributions to this area: first, it identifies ten areas of alignment between general AI frameworks and codes for age-appropriate design for children. Then, to understand how such principles relate to real application contexts, we conducted a landscape analysis of children’s AI systems, via a systematic literature review including 188 papers. This analysis revealed a wide assortment of applications, and that most systems’ designs addressed only a small subset of principles among those we identified. Finally, we synthesised our findings in a framework to inform a new “Code for Age-Appropriate AI”, which aims to provide timely input to emerging policies and standards, and inspire increased interactions between the AI and child-computer interaction communities.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {536},
numpages = {29},
keywords = {AI for children, systematic literature review, age appropriate design},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502040,
author = {Allen, Jennifer and Martel, Cameron and Rand, David G},
title = {Birds of a Feather Don’t Fact-Check Each Other: Partisanship and the Evaluation of News in Twitter’s Birdwatch Crowdsourced Fact-Checking Program},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502040},
doi = {10.1145/3491102.3502040},
abstract = {There is a great deal of interest in the role that partisanship, and cross-party animosity in particular, plays in interactions on social media. Most prior research, however, must infer users’ judgments of others’ posts from engagement data. Here, we leverage data from Birdwatch, Twitter’s crowdsourced fact-checking pilot program, to directly measure judgments of whether other users’ tweets are misleading, and whether other users’ free-text evaluations of third-party tweets are helpful. For both sets of judgments, we find that contextual features – in particular, the partisanship of the users – are far more predictive of judgments than the content of the tweets and evaluations themselves. Specifically, users are more likely to write negative evaluations of tweets from counter-partisans; and are more likely to rate evaluations from counter-partisans as unhelpful. Our findings provide clear evidence that Birdwatch users preferentially challenge content from those with whom they disagree politically. While not necessarily indicating that Birdwatch is ineffective for identifying misleading content, these results demonstrate the important role that partisanship can play in content evaluation. Platform designers must consider the ramifications of partisanship when implementing crowdsourcing programs.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {245},
numpages = {19},
keywords = {crowdsourcing, fact-checking, misinformation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502037,
author = {Das Swain, Vedant and Chen, Victor and Mishra, Shrija and Mattingly, Stephen M. and Abowd, Gregory D. and De Choudhury, Munmun},
title = {Semantic Gap in Predicting Mental Wellbeing through Passive Sensing},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502037},
doi = {10.1145/3491102.3502037},
abstract = {When modeling passive data to infer individual mental wellbeing, a common source of ground truth is self-reports. But these tend to represent the psychological facet of mental states, which might not align with the physiological facet of that state. Our paper demonstrates that when what people “feel” differs from what people “say they feel”, we witness a semantic gap that limits predictions. We show that predicting mental wellbeing with passive data (offline sensors or online social media) is related to how the ground-truth is measured (objective arousal or self-report). Features with psycho-social signals (e.g., language) were better at predicting self-reported anxiety and stress. Conversely, features with behavioral signals (e.g., sleep), were better at predicting stressful arousal. Regardless of the source of ground truth, integrating both signals boosted prediction. To reduce the semantic gap, we provide recommendations to evaluate ground truth measures and adopt parsimonious sensing.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {374},
numpages = {16},
keywords = {Social Media, Activity Patterns, Passive Sensing, Mental Wellbeing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502008,
author = {Sykownik, Philipp and Maloney, Divine and Freeman, Guo and Masuch, Maic},
title = {Something Personal from the Metaverse: Goals, Topics, and Contextual Factors of Self-Disclosure in Commercial Social VR},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502008},
doi = {10.1145/3491102.3502008},
abstract = {Current Social VR literature provides limited insight on one of the most critical behaviors for developing and maintaining interpersonal relationships: self-disclosure. Therefore, we present an online survey (N = 126) investigating how users disclose personal information to each other in Social VR. Our results indicate that many participants see in Social VR access to authentic connections with others despite tending towards skepticism and privacy concerns. Most users disclose sexuality-related information, lifestyle preferences, and personal goals. In contrast, information that breaks anonymity, such as real names and more intimate aspects of oneself, are shared less commonly. Thereby, self-disclosure decisions depend on factors like the relationship to or age of disclosure recipients, the privacy of a virtual environment, the group size, or the activity context, and is driven by different goals, i.a., relational development or exploration of oneself. These insights advance the understanding of current Social VR users and their behavior by directing future research on self-disclosure-based relationship building in Social VR and outlying broader design implications for the future metaverse.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {632},
numpages = {17},
keywords = {online social interaction, social virtual reality, self-disclosure},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501994,
author = {Popova, Kristina and Garrett, Rachael and N\'{u}\~{n}ez-Pacheco, Claudia and Lampinen, Airi and H\"{o}\"{o}k, Kristina},
title = {Vulnerability as an Ethical Stance in Soma Design Processes},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501994},
doi = {10.1145/3491102.3501994},
abstract = {We articulate vulnerability as an ethical stance in soma design processes and discuss the conditions of its emergence. We argue that purposeful vulnerability – an act of taking risk, exposing oneself, and resigning part of one’s autonomy – is a necessary although often neglected part of design, and specifically soma design, which builds on felt experience and stimulates designers to engage with the non-habitual by challenging norms, habitual movements, and social interactions. With the help of ethnography, video analysis, and micro-phenomenological interviews, we document an early design exploration around drones, describing how vulnerability is accomplished in collaboration between members of the design team and the design materials. We (1) define vulnerability as an active ethical stance; (2) make vulnerability visible as a necessary but often neglected part of an exploratory design process; and (3) discuss the conditions of its emergence, demonstrating the importance of deliberating ethics within the design process.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {178},
numpages = {13},
keywords = {ethics, soma design, drones, vulnerability},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501978,
author = {N\'{u}\~{n}ez-Pacheco, Claudia and Loke, Lian},
title = {Focusing for Interaction Design: An Introspective Somatic Method},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501978},
doi = {10.1145/3491102.3501978},
abstract = {Attending to the challenges of describing first-person experience, this article illustrates different uses of the Focusing method in interaction design and HCI, offering a systematic way of accessing the subtle qualities of lived experiences for design use. In this approach, the implicit bodily knowledge -or felt sense- becomes the material capture of aesthetic experiences used to inform data collection, ideation and prototyping. We offer a high-level, yet systematic coverage of Focusing applied to two case studies, informing both a set of instructions to use the method and a series of design considerations to adopt this understudied tool of introspection in interaction design research and practice.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {177},
numpages = {18},
keywords = {Design Methods, Interaction Design, Soma Design, HCI, Focusing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501967,
author = {Rechkemmer, Amy and Yin, Ming},
title = {When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501967},
doi = {10.1145/3491102.3501967},
abstract = {Previous research shows that laypeople’s trust in a machine learning model can be affected by both performance measurements of the model on the aggregate level and performance estimates on individual predictions. However, it is unclear how people would trust the model when multiple performance indicators are presented at the same time. We conduct an exploratory human-subject experiment to answer this question. We find that while the level of model confidence significantly affects people’s belief in model accuracy, both the model’s stated and observed accuracy generally have a larger impact on people’s willingness to follow the model’s predictions as well as their self-reported levels of trust in the model, especially after observing the model’s performance in practice. We hope the empirical evidence reported in this work could open doors to further studies to advance understanding of how people perceive, process, and react to performance-related information of machine learning.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {535},
numpages = {14},
keywords = {trust, accuracy, human-subject experiments, Machine learning, confidence},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501960,
author = {Shen, Vivian and Shultz, Craig and Harrison, Chris},
title = {Mouth Haptics in VR Using a Headset Ultrasound Phased Array},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501960},
doi = {10.1145/3491102.3501960},
abstract = {Today’s consumer virtual reality (VR) systems offer limited haptic feedback via vibration motors in handheld controllers. Rendering haptics to other parts of the body is an open challenge, especially in a practical and consumer-friendly manner. The mouth is of particular interest, as it is a close second in tactile sensitivity to the fingertips, offering a unique opportunity to add fine-grained haptic effects. In this research, we developed a thin, compact, beamforming array of ultrasonic transducers, which can render haptic effects onto the mouth. Importantly, all components are integrated into the headset, meaning the user does not need to wear an additional accessory, or place any external infrastructure in their room. We explored several effects, including point impulses, swipes, and persistent vibrations. Our haptic sensations can be felt on the lips, teeth and tongue, which can be incorporated into new and interesting VR experiences.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {275},
numpages = {14},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501956,
author = {Waycott, Jenny and Kelly, Ryan M. and Baker, Steven and Barbosa Neves, Barbara and Thach, Kong Saoane and Lederman, Reeva},
title = {The Role of Staff in Facilitating Immersive Virtual Reality for Enrichment in Aged Care: An Ethic of Care Perspective},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501956},
doi = {10.1145/3491102.3501956},
abstract = {Immersive virtual reality (VR) is being used as an enriching experience for people living in residential aged care, or nursing homes, where care staff play a critical role supporting clients to use VR. In HCI research concerned with technology use in aged care, however, the role of formal caregivers has received limited attention. We conducted interviews with 11 caregivers working in care homes that have implemented VR as part of the social program offered to residents. Our findings highlight tensions between the opportunities created by the immersive VR experience and the risks and challenges full immersion presents for people in aged care. In this paper, we draw on an ethics of care framework to make visible the care practices involved in facilitating VR in aged care homes, highlighting the care required to ensure that older adults experience benefits when using immersive VR, while risks and challenges are carefully managed.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {414},
numpages = {17},
keywords = {Aging, Ethics of Care, Aged Care, Virtual Reality},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501946,
author = {Luo, Weizhou and Lehmann, Anke and Widengren, Hjalmar and Dachselt, Raimund},
title = {Where Should We Put It? Layout and Placement Strategies of Documents in Augmented Reality for Collaborative Sensemaking},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501946},
doi = {10.1145/3491102.3501946},
abstract = {Future offices are likely reshaped by Augmented Reality (AR) extending the display space while maintaining awareness of surroundings, and thus promise to support collaborative tasks such as brainstorming or sensemaking. However, it is unclear how physical surroundings and co-located collaboration influence the spatial organization of virtual content for sensemaking. Therefore, we conducted a study (N=28) to investigate the effect of office environments and work styles during a document classification task using AR with regard to content placement, layout strategies, and sensemaking workflows. Results show that participants require furniture, especially tables and whiteboards, to assist sensemaking and collaboration regardless of room settings, while generous free spaces (e.g., walls) are likely used when available. Moreover, collaborating participants tend to use furniture despite personal layout preferences. We identified different placement and layout strategies, as well as the transitions in-between. Finally, we propose design implications for future immersive sensemaking applications and beyond.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {627},
numpages = {16},
keywords = {affordance, collaborative sensemaking, sensemaking, spatiality, spatial layout, Augmented Reality, content organization, Mixed Reality, qualitative user study},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501941,
author = {Yeh, Su-Fang and Wu, Meng-Hsin and Chen, Tze-Yu and Lin, Yen-Chun and Chang, XiJing and Chiang, You-Hsuan and Chang, Yung-Ju},
title = {How to Guide Task-Oriented Chatbot Users, and When: A Mixed-Methods Study of Combinations of Chatbot Guidance Types and Timings},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501941},
doi = {10.1145/3491102.3501941},
abstract = {The popularity of task-oriented chatbots is constantly growing, but smooth conversational progress with them remains profoundly challenging. In recent years, researchers have argued that chatbot systems should include guidance for users on how to converse with them. Nevertheless, empirical evidence about what to place in such guidance, and when to deliver it, has been lacking. Using a mixed-methods approach that integrates results from a between-subjects experiment and a reflection session, this paper compares the effectiveness of eight combinations of two guidance types (example-based and rule-based) at four guidance timings (service-onboarding, task-intro, after-failure, and upon-request), as measured by users’ task performance, improvement on subsequent tasks, and subjective experience. It establishes that each guidance type and timing has particular strengths and weaknesses, thus that each type/timing combination has a unique impact on performance metrics, learning outcomes, and user experience. On that basis, it presents guidance-design recommendations for future task-oriented chatbots.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {488},
numpages = {16},
keywords = {non-progress, lab study, guidance, chatbot},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501940,
author = {An, Pengcheng and Zhou, Ziqi and Liu, Qing and Yin, Yifei and Du, Linghao and Huang, Da-Yuan and Zhao, Jian},
title = {VibEmoji: Exploring User-Authoring Multi-Modal Emoticons in Social Communication},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501940},
doi = {10.1145/3491102.3501940},
abstract = {Emoticons are indispensable in online communications. With users’ growing needs for more customized and expressive emoticons, recent messaging applications begin to support (limited) multi-modal emoticons:, enhancing emoticons with animations or vibrotactile feedback. However, little empirical knowledge has been accumulated concerning how people create, share and experience multi-modal emoticons in everyday communication, and how to better support them through design. To tackle this, we developed VibEmoji, a user-authoring multi-modal emoticon interface for mobile messaging. Extending existing designs, VibEmoji grants users greater flexibility to combine various emoticons, vibrations, and animations on-the-fly, and offers non-aggressive recommendations based on these components’ emotional relevance. Using VibEmoji as a probe, we conducted a four-week field study with 20 participants, to gain new understandings from in-the-wild usage and experience, and extract implications for design. We thereby contribute to both a novel system and various insights for supporting users’ creation and communication of multi-modal emoticons.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {493},
numpages = {17},
keywords = {Social communication, emotional expression, animation, mobile interfaces., haptic feedback, emoticons, multi-modal interaction},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501932,
author = {Head, Andrew and Xie, Amber and Hearst, Marti A.},
title = {Math Augmentation: How Authors Enhance the Readability of Formulas Using Novel Visual Design Practices},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501932},
doi = {10.1145/3491102.3501932},
abstract = {With the increasing growth and impact of machine learning and other math-intensive fields, it is more important than ever to broaden access to mathematical notation. Can new visual and interactive displays help a wider readership successfully engage with notation? This paper provides the first detailed qualitative analysis of math augmentation—the practice of embellishing notation with novel visual design patterns to improve its readability. We present two qualitative studies of the practice of math augmentation. First is an analysis of 1.1k augmentations to 281 formulas in 47 blogs, textbooks, and other documents containing mathematical expressions. Second is an interview study with 12 authors who had previously designed custom math augmentations (“maugs”). This paper contributes a comprehensive inventory of the kinds of maugs that appear in math documents, and a detailed account of how authors’ tools ought to be redesigned to support efficient creation of math augmentations. These studies open a critical new design space for HCI researchers and interface designers.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {18},
keywords = {mathematical notation, authoring, visual links, details-on-demand},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501915,
author = {Papenmeier, Andrea and Kern, Dagmar and Hienert, Daniel and Kammerer, Yvonne and Seifert, Christin},
title = {How Accurate Does It Feel? – Human Perception of Different Types of Classification Mistakes},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501915},
doi = {10.1145/3491102.3501915},
abstract = {Supervised machine learning utilizes large datasets, often with ground truth labels annotated by humans. While some data points are easy to classify, others are hard to classify, which reduces the inter-annotator agreement. This causes noise for the classifier and might affect the user’s perception of the classifier’s performance. In our research, we investigated whether the classification difficulty of a data point influences how strongly a prediction mistake reduces the “perceived accuracy”. In an experimental online study, 225 participants interacted with three fictive classifiers with equal accuracy (73%). The classifiers made prediction mistakes on three different types of data points (easy, difficult, impossible). After the interaction, participants judged the classifier’s accuracy. We found that not all prediction mistakes reduced the perceived accuracy equally. Furthermore, the perceived accuracy differed significantly from the calculated accuracy. To conclude, accuracy and related measures seem unsuitable to represent how users perceive the performance of classifiers.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {180},
numpages = {13},
keywords = {Accuracy, Ground Truth, Perception, Annotations},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501903,
author = {Liu, Zhe and Chen, Chunyang and Wang, Junjie and Huang, Yuekai and Hu, Jun and Wang, Qing},
title = {Guided Bug Crush: Assist Manual GUI Testing of Android Apps via Hint Moves},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501903},
doi = {10.1145/3491102.3501903},
abstract = {Mobile apps are indispensable for people’s daily life. Complementing with automated GUI testing, manual testing is the last line of defence for app quality. However, the repeated actions and easily missing of functionalities make manual testing time-consuming and inefficient. Inspired by the game candy crush with flashy candies as hint moves for players, we propose an approach named NaviDroid for navigating testers via highlighted next operations for more effective and efficient testing. Within NaviDroid, we construct an enriched state transition graph with the triggering actions as the edges for two involved states. Based on it, we utilize the dynamic programming algorithm to plan the exploration path, and augment the GUI with visualized hints for testers to quickly explore untested activities and avoid duplicate explorations. The automated experiments demonstrate the high coverage and efficient path planning of NaviDroid and a user study further confirms its usefulness. The NaviDroid can help us develop more robust software that works in more mission-critical settings, not only by performing more thorough testing with the same effort that has been put in before, but also by integrating these techniques into different parts of development pipeline.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {557},
numpages = {14},
keywords = {Software Engineering, Quality Assurance, GUI testing, Android App},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501891,
author = {Bao, Calvin S. and Li, Siyao and Flores, Sarah G and Correll, Michael and Battle, Leilani},
title = {Recommendations for Visualization Recommendations: Exploring Preferences and Priorities in Public Health},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501891},
doi = {10.1145/3491102.3501891},
abstract = {The promise of visualization recommendation systems is that analysts will be automatically provided with relevant and high-quality visualizations that will reduce the work of manual exploration or chart creation. However, little research to date has focused on what analysts value in the design of visualization recommendations. We interviewed 18 analysts in the public health sector and explored how they made sense of a popular in-domain dataset1 in service of generating visualizations to recommend to others. We also explored how they interacted with a corpus of both automatically- and manually-generated visualization recommendations, with the goal of uncovering how the design values of these analysts are reflected in current visualization recommendation systems. We find that analysts champion simple charts with clear takeaways that are nonetheless connected with existing semantic information or domain hypotheses. We conclude by recommending that visualization recommendation designers explore ways of integrating context and expectation into their systems.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {411},
numpages = {17},
keywords = {automation, Visualization recommendation systems, recommendation source, algorithmic trust},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501875,
author = {Rogers, Katja and Karaosmanoglu, Sukran and Altmeyer, Maximilian and Suarez, Ally and Nacke, Lennart E.},
title = {Much Realistic, Such Wow! A Systematic Literature Review of Realism in Digital Games},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501875},
doi = {10.1145/3491102.3501875},
abstract = {Researchers reference realism in digital games without sufficient specificity. Without clarity about the dimensions of realism, we cannot assess how and when to aim for a higher degree of realism, when lower realism suffices, or when purposeful unrealism is ideal for a game and can benefit player experience (PX). To address this conceptual gap, we conducted a systematic review using thematic synthesis to distinguish between types of realism currently found in the digital games literature. We contribute qualitative themes that showcase contradictory design goals of realism/unrealism. From these themes, we created a framework (i.e., a hierarchical taxonomy and mapping) of realism dimensions in digital games as a conceptual foundation. Our themes and framework enable a workable specificity for designing or analyzing types of realism, equip future work to explore effects of specific realism types on PX, and offer a starting point for similar efforts in non-game applications.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {190},
numpages = {21},
keywords = {thematic synthesis, fidelity, systematic literature review, realism},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501853,
author = {Vandenberghe, Bert and Gerling, Kathrin and Geurts, Luc and Vanden Abeele, Vero},
title = {Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501853},
doi = {10.1145/3491102.3501853},
abstract = {Maker culture encourages do-it-yourself practices to create, repair, and repurpose technology. In Human-Computer Interaction (HCI) research, it is seen as a means of empowering people, providing affordable and customisable technology with potential to enrich areas such as education or assistive technology. To investigate this alleged potential, we performed an anthropological inquiry at an elementary school for disabled children that lasted one year, participating in everyday activities with students, teachers, and therapists. We observed ‘heterogeneity in a fluid environment’ and ‘creativity in the moment’ in an ‘endemically underfunded’ setting. We saw how technology is ‘injecting dependencies’, ‘reinforcing disability’, and ‘occupying time and space’, changing our view on the role that making can have. Leveraging Empowerment Theory, we highlight how (making) technology risks ignoring the intertwined dynamics between the individual, the organisational, and the community, and articulate points for reflection for technology in schools for disabled children for the HCI research community.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {546},
numpages = {18},
keywords = {school for disabled children, occupational therapy, anthropology, physical therapy, empowerment, disability, ethnography, making technology, non-use},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501847,
author = {Park, Su Han and Han, Bin and Kim, Gerard Jounghyun},
title = {Mixing in Reverse Optical Flow to Mitigate Vection and Simulation Sickness in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501847},
doi = {10.1145/3491102.3501847},
abstract = {Simulator sickness has been one of the major obstacles toward making virtual reality (VR) widely accepted and used. For example, virtual navigation produces vection, which is the illusion of self-motion as one perceives bodily motion despite no movement actually occurs. This, in turn, causes a sensory conflict between visual and actual (or vestibular) motion and sickness. In this study, we explore a method to reduce simulator sickness by visually mixing the optical flow patterns that are in the reverse direction of the virtual visual motion. As visual motion is mainly detected and perceived by the optical flow, artificial mixing in the reverse flow is hypothesized to induce a cancellation effect, thereby reducing the degree of the conflict with the vestibular sense and sickness. To validate our hypothesis, we developed a real-time algorithm to visualize the reverse optical flow and conducted experiments by comparing the before and after sickness levels in seven virtual navigation conditions. The experimental results confirmed the proposed method was effective for reducing the simulator sickness in a statistically significant manner. However, no dependency to the motion type or degrees of freedom were found. Significant distraction and negative influence to the sense of presence and immersion were observed only when the the artificially added reverse optical flow patterns were rather visually marked with high contrast to the background content.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {189},
numpages = {11},
keywords = {Virtual Reality, Vection, Optical Flow, Simulator Sickness},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501835,
author = {Wampfler, Rafael and Klingler, Severin and Solenthaler, Barbara and Schinazi, Victor R. and Gross, Markus and Holz, Christian},
title = {Affective State Prediction from Smartphone Touch and Sensor Data in the Wild},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501835},
doi = {10.1145/3491102.3501835},
abstract = {Knowledge of users’ affective states can improve their interaction with smartphones by providing more personalized experiences (e.g., search results and news articles). We present an affective state classification model based on data gathered on smartphones in real-world environments. From touch events during keystrokes and the signals from the inertial sensors, we extracted two-dimensional heat maps as input into a convolutional neural network to predict the affective states of smartphone users. For evaluation, we conducted a data collection in the wild with 82 participants over 10&nbsp;weeks. Our model accurately predicts three levels (low, medium, high) of valence (AUC up to 0.83), arousal (AUC up to 0.85), and dominance (AUC up to 0.84). We also show that using the inertial sensor data alone, our model achieves a similar performance (AUC up to 0.83), making our approach less privacy-invasive. By personalizing our model to the user, we show that performance increases by an additional 0.07&nbsp;AUC.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {403},
numpages = {14},
keywords = {Deep Learning, Smartphone, Affective Computing, Classification},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501828,
author = {Piitulainen, Roosa and H\"{a}m\"{a}l\"{a}inen, Perttu and Mekler, Elisa D},
title = {Vibing Together: Dance Experiences in Social Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501828},
doi = {10.1145/3491102.3501828},
abstract = {Dancing is a universal human activity, and also a domain of enduring significance in Human-Computer Interaction (HCI) research. However, there has been limited investigation into how computing supports the experiences of recreational dancers. Concurrently, a diverse and sizeable dance community has been emerging in VRChat. Little is known about these dancers’ experiences, motivations, and practices. Yet shedding light into these could inform both VR technology development and the design of systems that better support embodied and complex social interactions. To bridge this gap, we interviewed participants active in the VRChat dance scene. Through thematic analysis, we identified six central facets of their experiences related to freedom, community, dance as an individual experience, dance as a shared experience, dance as a performance, and self-expression and -exploration. Based on these findings, we discuss emerging tensions and highlight beneficial impacts of dancing in VR as well as problems that still await resolving.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {188},
numpages = {18},
keywords = {dancing, social VR, VRChat},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501825,
author = {Liu, Vivian and Chilton, Lydia B},
title = {Design Guidelines for Prompt Engineering Text-to-Image Generative Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501825},
doi = {10.1145/3491102.3501825},
abstract = {Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {384},
numpages = {23},
keywords = {multimodal generative models, AI co-creation, computational creativity, prompt engineering., text-to-image, design guidelines},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501819,
author = {Chung, John Joon Young and Kim, Wooseok and Yoo, Kang Min and Lee, Hwaran and Adar, Eytan and Chang, Minsuk},
title = {TaleBrush: Sketching Stories with Generative Pretrained Language Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501819},
doi = {10.1145/3491102.3501819},
abstract = {While advanced text generation algorithms (e.g., GPT-3) have enabled writers to co-create stories with an AI, guiding the narrative remains a challenge. Existing systems often leverage simple turn-taking between the writer and the AI in story development. However, writers remain unsupported in intuitively understanding the AI’s actions or steering the iterative generation. We introduce TaleBrush, a generative story ideation tool that uses line sketching interactions with a GPT-based language model for control and sensemaking of a protagonist’s fortune in co-created stories. Our empirical evaluation found our pipeline reliably controls story generation while maintaining the novelty of generated sentences. In a user study with 14 participants with diverse writing experiences, we found participants successfully leveraged sketching to iteratively explore and write stories according to their intentions about the character’s fortune while taking inspiration from generated stories. We conclude with a reflection on how sketching interactions can facilitate the iterative human-AI co-creation process.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {209},
numpages = {19},
keywords = {story generation, story writing, controlled generation, sketching, creativity support tool},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517717,
author = {Heuer, Hendrik and Glassman, Elena Leah},
title = {A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517717},
doi = {10.1145/3491102.3517717},
abstract = {During the COVID-19 pandemic, the World Health Organization provided a checklist to help people distinguish between accurate and misinformation. In controlled experiments in the United States and Germany, we investigated the utility of this ordered checklist and designed an interactive version to lower the cost of acting on checklist items. Across interventions, we observe non-trivial differences in participants’ performance in distinguishing accurate and misinformation between the two countries and discuss some possible reasons that may predict the future helpfulness of the checklist in different environments. The checklist item that provides source labels was most frequently followed and was considered most helpful. Based on our empirical findings, we recommend practitioners focus on providing source labels rather than interventions that support readers performing their own fact-checks, even though this recommendation may be influenced by the WHO’s chosen order. We discuss the complexity of providing such source labels and provide design recommendations.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {241},
numpages = {21},
keywords = {Misinformation, World Health Organization, Fact-check, Fake News, Propaganda, COVID-19, Disinformation, Social Media},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517693,
author = {Biehl, Jacob T. and Farzan, Rosta and Zhou, Yingfan},
title = {Can Anybody Help Me?: Using Community Help Desk Call Records to Examine the Impact of Digital Divides During a Global Pandemic},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517693},
doi = {10.1145/3491102.3517693},
abstract = {The COVID-19 global pandemic has ignited lightning-fast adoption of digital tools in our communities, organizations, and systems of governance. It also inspired an unprecedented level of providing access to digital devices to communities and individuals lacking prior access. The situation and circumstances provide a unique opportunity to understand digital divides through a new lens. In this work, we contribute a contemporaneous understanding of digital divides beyond access by qualitatively analyzing over 300 calls made to a volunteer-based community IT help desk. We highlight the intertwined network of challenges leading to ecosystem digital divides and contribute new insights into how the complex socio-technical systems of practice, and the tools to support them, must adapt to bridge digital divides more effectively.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {314},
numpages = {13},
keywords = {ICT use, pandemic response, digital divides},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517671,
author = {Feick, Martin and Regitz, Kora Persephone and Tang, Anthony and Kr\"{u}ger, Antonio},
title = {Designing Visuo-Haptic Illusions with Proxies in Virtual Reality: Exploration of Grasp, Movement Trajectory and Object Mass},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517671},
doi = {10.1145/3491102.3517671},
abstract = {Visuo-haptic illusions are a method to expand proxy-based interactions in VR by introducing unnoticeable discrepancies between the virtual and real world. Yet how different design variables affect the illusions with proxies is still unclear. To unpack a subset of variables, we conducted two user studies with 48 participants to explore the impact of (1) different grasping types and movement trajectories, and (2) different grasping types and object masses on the discrepancy which may be introduced. Our Bayes analysis suggests that grasping types and object masses (≤ 500 g) did not noticeably affect the discrepancy, but for movement trajectory, results were inconclusive. Further, we identified a significant difference between (un)restricted movement trajectories. Our data shows considerable differences in participants’ proprioceptive accuracy, which seem to correlate with their prior VR experience. Finally, we illustrate the impact of our key findings on the visuo-haptic illusion design process by showcasing a new design workflow.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {635},
numpages = {15},
keywords = {Grasp, Visuo-Haptic Illusions, Object Mass, Movement Trajectory},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517635,
author = {Lee, Cheuk Yin Phipson and Zhang, Zhuohao and Herskovitz, Jaylin and Seo, JooYoung and Guo, Anhong},
title = {CollabAlly: Accessible Collaboration Awareness in Document Editing},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517635},
doi = {10.1145/3491102.3517635},
abstract = {Collaborative document editing tools are widely used in professional and academic workplaces. While these tools provide basic accessibility support, it is challenging for blind users to gain collaboration awareness that sighted people can easily obtain using visual cues (e.g., who is editing where and what). Through a series of co-design sessions with a blind coauthor, we identified the current practices and challenges in collaborative editing, and iteratively designed CollabAlly, a system that makes collaboration awareness in document editing accessible to blind users. CollabAlly extracts collaborator, comment, and text-change information and their context from a document and presents them in a dialog box to provide easy access and navigation. CollabAlly uses earcons to communicate background events unobtrusively, voice fonts to differentiate collaborators, and spatial audio to convey the location of document activity. In a study with 11 blind participants, we demonstrate that CollabAlly provides improved access to collaboration awareness by centralizing scattered information, sonifying visual information, and simplifying complex operations.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {596},
numpages = {17},
keywords = {Blind, accessibility, visual impairment, spatial audio, voice font, collaboration awareness, screen reader, earcon, Collaborative writing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517633,
author = {Ku, Pin-Sung and Huang, Kunpeng and Kao, Cindy Hsin-Liu},
title = {Patch-O: Deformable Woven Patches for On-Body Actuation},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517633},
doi = {10.1145/3491102.3517633},
abstract = {We present Patch-O, a novel deformable interface devised as a woven patch that enables diverse movement-based interactions adaptive to garments or on-skin wearing. Patch-O interfaces are uniquely detachable and relocatable soft actuation units that can be sewn or attached to clothing or skin at various locations. To optimize the morphing effect while preserving a slim form factor, we introduce a construction approach that integrates actuators at a structural level and varies the texture and stiffness of the woven substrate locally. We implement three basic actuation primitives, including bending, expanding, and shrinking, and experiment with aggregation parameters to exhaustively extend the design space. A final workshop study inviting textile practitioners to create personalized designs of Patch-O provides insights into the expressiveness of the approach for wearable interactions. We conclude with three applications inspired by users’ designs and showcase the aesthetic and functional usages enabled by the deformable woven patches.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {615},
numpages = {12},
keywords = {Fabrication, Wearable Computers, Fashion/Clothing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517620,
author = {Tang, Kymeng and Gerling, Kathrin and Geurts, Luc},
title = {Virtual Feed: Design and Evaluation of a Virtual Reality Simulation Addressing the Lived Experience of Breastfeeding},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517620},
doi = {10.1145/3491102.3517620},
abstract = {Breastfeeding can be challenging, but it is difficult for antenatal education to convey issues associated with the lived experience of breastfeeding. In our work, we explore the potential of interactive simulations to support antenatal education, and present Virtual Feed, a Virtual Reality breastfeeding simulation for parents-to-be developed following a three-step process. (1) We created an experience prototype that features basic VR scenarios and a tangible baby, (2) we engaged in design sessions with 19 parents and parents-to-be to derive design implications to further refine the simulation, and (3) we evaluated the system through case studies to examine the perspectives of parents and parents-to-be on the simulation. Our results show that the simulation successfully engaged users and sparked curiosity, while also encouraging reflection about the challenges of breastfeeding. On this basis, we discuss challenges for the design of simulations with the purpose of supplementing antenatal education.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {438},
numpages = {17},
keywords = {breastfeeding, co-design, virtual reality, qualitative research},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517600,
author = {Das, Dipto and Semaan, Bryan},
title = {Collaborative Identity Decolonization as Reclaiming Narrative Agency: Identity Work of Bengali Communities on Quora},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517600},
doi = {10.1145/3491102.3517600},
abstract = {While people’s identities can be marginalized through various forces, colonialism is one of the primary ways that continues to influence people’s lives and identities. Colonialism refers to the policies and practices where foreign powers migrate to other lands and alter the social structures, and thus identities, of local populations. What is less understood is how online spaces can support people in the aftermath of colonization in revising, repairing, and strengthening their identities—the process of identity decolonization work. Using trace ethnography beginning on 15 May, 2020 and ending on 15 July, 2020 and drawing on Poka Laenui’s framework of decolonization, we explore how South Asian Bengalis on the platform Bengali Quora (BnQuora) engage in collaborative identity decolonization work to reclaim narrative agency. We discuss how narratives serve to help people bounce back from threat or vulnerability—a concept we dub narrative resilience. We also describe potential implications for future scholarship focused on decolonization that extends multiple ongoing conversations around ICT for development, social justice, decolonial HCI, and identity research within the CHI community.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {236},
numpages = {23},
keywords = {Decolonization, Bengali Quora, Colonial, Identity, Bengali},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517599,
author = {Ceha, Jessy and Law, Edith},
title = {Expressive Auditory Gestures in a Voice-Based Pedagogical Agent},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517599},
doi = {10.1145/3491102.3517599},
abstract = {In this paper, we explore how expressive auditory gestures added to the speech of a pedagogical agent influence the human-agent relationship and learning outcomes. In a between-subjects experiment, 41 participants assumed the role of a tutor to teach a voice-based agent. The agent used either: expressive interjections (e.g.,“yay”, “hmm”, “oh”), brief expressive musical executions, or no auditory gestures at all (control condition), throughout the interaction. Overall, the results indicate that both gestures can positively affect the interaction, but in particular, interjections can significantly increase feelings of emotional rapport with the agent and enhance motivation in learners. The implications of our findings are discussed as our work adds to the understanding of conversational agent design and can be useful for education as well as other domains in which dialogue systems are used.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {163},
numpages = {13},
keywords = {motivation, interjections, voice, agent, rapport, music, education},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517597,
author = {Hasselqvist, Hanna and Renstr\"{o}m, Sara and H\r{a}kansson, Maria and Str\"{o}mberg, Helena},
title = {Exploring Renewable Energy Futures through Household Energy Resilience},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517597},
doi = {10.1145/3491102.3517597},
abstract = {A transition to renewable energy increases the risks of disruptions when electricity supply does not meet demand.&nbsp;HCI&nbsp;has explored how digital technologies can mitigate such problems in households through support for reducing or shifting electricity use. However, faster transitions may be possible if some disturbances can be&nbsp;acceptable&nbsp;and households are supported in adapting to them. In this paper, we present a study of 21 Swedish households and their experiences of and ideas on how to manage disruptions in electricity supply. We call this perspective&nbsp;household energy resilience&nbsp;and identify three strategies for resilience: (1)&nbsp;response diversity, i.e., diversity in ways of carrying out normally electricity-dependent practices, (2) creating&nbsp;opportunities to develop resilience, and (3) building&nbsp;community energy resilience. Furthermore, we suggest how&nbsp;HCI&nbsp;can support these strategies, both by providing tools to increase resilience and by carefully designing technology and services to be more resilient in themselves.&nbsp;},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {333},
numpages = {18},
keywords = {Energy resilience, Sustainable HCI, Energy futures, Households, Renewable energy},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517594,
author = {Williamson, Julie R. and O'Hagan, Joseph and Guerra-Gomez, John Alexis and Williamson, John H and Cesar, Pablo and Shamma, David A.},
title = {Digital Proxemics: Designing Social and Collaborative Interaction in Virtual Environments},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517594},
doi = {10.1145/3491102.3517594},
abstract = {Behaviour in virtual environments might be informed by our experiences in physical environments, but virtual environments are not constrained by the same physical, perceptual, or social cues. Instead of replicating the properties of physical spaces, one can create virtual experiences that diverge from reality by dynamically manipulating environmental, aural, and social properties. This paper explores digital proxemics, which describe how we use space in virtual environments and how the presence of others influences our behaviours, interactions, and movements. First, we frame the open challenges of digital proxemics in terms of activity, social signals, audio design, and environment. We explore a subset of these challenges through an evaluation that compares two audio designs and two displays with different social signal affordances: head-mounted display (HMD) versus desktop PC. We use quantitative methods using instrumented tracking to analyse behaviour, demonstrating how personal space, proximity, and attention compare between desktop PC and HMDs.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {423},
numpages = {12},
keywords = {Social Signal Processing, Virtual Environments, Digital Proxemics, Quantitative Methods.},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517588,
author = {Varanasi, Rama Adithya and Pal, Joyojeet and Vashistha, Aditya},
title = {Accost, Accede, or Amplify: Attitudes towards COVID-19 Misinformation on WhatsApp in India},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517588},
doi = {10.1145/3491102.3517588},
abstract = {Social media has witnessed an unprecedented growth in users based in low-income communities in the Global South. However, much remains unknown about the drivers of misinformation in such communities. To fill this gap, we conducted an interview-based study to examine how rural and urban communities in India engage with misinformation on WhatsApp. We found that misinformation led to bitterness and conflict – rural users who had higher social status heavily influenced the perceptions and engagement of marginalized members. While urban users relied on the expertise of gatekeepers for verification, rural users engaged in collective deliberations in offline spaces. Both rural and urban users knowingly forwarded misinformation. However, rural users propagated hyperlocal misinformation, whereas urban users forwarded misinformation to reduce their efforts to assess information credibility. Using a public sphere lens, we propose that the reactions to misinformation provide a view of Indian society and its schisms around class, urbanity, and social interactions.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {17},
keywords = {public sphere, encrypted platforms, Misinformation, disinformation, WhatsApp, rural},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517575,
author = {Yadav, Deepika and Dabas, Kirti and Malik, Prerna and Bhandari, Anushka and Singh, Pushpendra},
title = {“Should I Visit the Clinic”: Analyzing WhatsApp-Mediated Online Health Support for Expectant and New Mothers in Rural India},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517575},
doi = {10.1145/3491102.3517575},
abstract = {Limited interaction with professionals, infrastructural, and social constraints put barriers in providing holistic support to expectant and new mothers in low-resource settings. We examine the use of digital support groups facilitated through WhatsApp by a non-government organization in India. Complementing prior research, these digital peer support groups inform about an open public space created over a chat platform where rural communities and health professionals can engage. By qualitatively analyzing six months of interaction among 588 group members and collecting the experiences of the group moderators, we inform about how the support groups acted as an important source for compensating the gaps in the existing healthcare, providing reassurance support on routine health, explanation on test reports, validation and counseling support in ongoing treatments. We also derive implications for the future of digital support groups and the need for further research on the use of unplatformed design models in resource-constrained settings.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {296},
numpages = {20},
keywords = {Maternal health, Digital support group, Social support, WhatsApp},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517568,
author = {Garcia, J\'{e}r\'{e}mie and Brock, Anke M.},
title = {CandyFly: Bringing Fun to Drone Pilots with Disabilities through Adapted and Adaptable Interactions},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517568},
doi = {10.1145/3491102.3517568},
abstract = {Flying drones is an increasingly popular activity. However, it is challenging due to the required perceptual and motor skills for following and stabilizing the drone, especially for people with special needs. This paper describes CandyFly, an application supporting people with diverse sensory, cognitive and motor impairments to pilot drones. We observed an existing accessible piloting workshop and evaluated CandyFly during eight additional workshops over three and a half years using a research-through-design process and ability-based design methods. We identified users’ needs, formulated requirements and explored adaptive interactions such as using pressure-sensitive keys, adjusting controls to the pilots’ range of motion, or limiting the drone’s degrees of freedom to cope with a broad range of disabilities. Our results show that the pilots and their caregivers enjoyed flying and emphasized CandyFly’s ability to be tailored to specific needs. Our findings offer a framework for designing adaptable systems and can support the design of future assistive and recreational systems.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {605},
numpages = {13},
keywords = {Automation, Human-Drone Interaction, Piloting, Accessibility, Unmanned Aerial Vehicles, Drones},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517564,
author = {Do, Tiffany D. and McMahan, Ryan P. and Wisniewski, Pamela J.},
title = {A New Uncanny Valley? The Effects of Speech Fidelity and Human Listener Gender on Social Perceptions of a Virtual-Human Speaker},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517564},
doi = {10.1145/3491102.3517564},
abstract = {Virtual humans can be used to deliver persuasive arguments; yet, those with synthetic text-to-speech (TTS) have been perceived less favorably than those with recorded human speech. In this paper, we investigate standard concatenative TTS and more advanced neural TTS. We conducted a 3x2 between-subjects experiment (n=79) to evaluate the effect of a virtual human’s speech fidelity at three levels (Standard TTS, Neural TTS, and Human speech) and the listener’s gender (male or female) on perceptions and persuasion. We found that the virtual human was perceived as significantly less trustworthy by both genders, if they used neural TTS compared to human speech, while male listeners (but not females) also perceived standard TTS as less trustworthy than human speech. Our findings indicate that neural TTS may not be an effective choice for persuasive virtual humans and that gender of the listener plays a role in how virtual humans are perceived.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {424},
numpages = {11},
keywords = {social perception, virtual humans, text-to-speech, speech fidelity},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517556,
author = {Michaelis, Joseph E and Di Canio, Daniela},
title = {Embodied Geometric Reasoning with a Robot: The Impact of Robot Gestures on Student Reasoning about Geometrical Conjectures},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517556},
doi = {10.1145/3491102.3517556},
abstract = {In this paper, we explore how the physically embodied nature of robots can influence learning through non-verbal communication, such as gesturing. We take an embodied cognition perspective to examine student interactions with a NAO robot that uses gestures while reasoning about geometry conjectures. College aged students (N = 30) were randomly assigned to either a dynamic condition, where the robot uses dynamic gestures that represent and manipulate geometric shapes in the conjectures, or control condition, where the robot uses beat gestures that match the rhythm of speech. Students in the dynamic condition: (1) use more gestures when they reason about geometry conjectures, (2) look more at the robot as it speaks, (3) feel the robot is a better study partner and uses effective gestures, but (4) were not more successful in correctly reasoning about geometry conjectures. We discuss implications for socially supported and embodied learning with a physically present robot.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {224},
numpages = {14},
keywords = {mathematics learning, human-robot interaction, embodied cognition, gesture},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517548,
author = {Masnadi, Sina and Pfeil, Kevin and Sera-Josef, Jose-Valentin T and LaViola, Joseph},
title = {Effects of Field of View on Egocentric Distance Perception in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517548},
doi = {10.1145/3491102.3517548},
abstract = {We performed a mixed-design study with 56 participants to compare the effect of horizontal FOV (hfov) and vertical FOV (vfov) on egocentric distance perception in four different realistic virtual environments (VEs). We also compared VE attributes of indoor/outdoor and cluttered/uncluttered. The participants blind-walked towards four different targets at 3m, 4m, 5m, and 6m distance while wearing a backpack computer and a wide FOV head-mounted display (HMD). The combinations of 165°, 110° and 45° hfovs, and 110° and 35° vfovs was simulated in the same HMD. The results indicated more accurate distance judgement with larger hfov with no significant effect of vfov. More accurate distance judgement in indoor VEs compared to outdoor VEs was observed. Also, participants judged distances more accurately in cluttered environments versus uncluttered environments. These results highlight that the environment is important in distance-critical VR applications and wider hfov should be considered for an improved distance judgment.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {613},
numpages = {10},
keywords = {virtual reality, outdoor, field of view, vertical FOV, clutter, FOV, horizontal FOV, distance perception, virtual environment, indoor, VR},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517547,
author = {Gaver, William and Boucher, Andy and Brown, Dean and Chatting, David and Matsuda, Naho and Ovalle, Liliana and Sheen, Andy and Vanis, Michail},
title = {Yo–Yo Machines: Self-Build Devices That Support Social Connections During the Pandemic},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517547},
doi = {10.1145/3491102.3517547},
abstract = {Yo–Yo Machines are playful communication devices designed to help people feel socially connected while physically separated. We designed them to reach as many people as possible, both to make a positive impact during the COVID-19 pandemic and to assess a self-build approach to circulating research products and the appeal of peripheral and expressive communication devices. A portfolio of four distinct designs, based on over 30 years of research, were made available for people to make by following simple online instructions (yoyomachines.io). Each involves connecting a pair of identical devices over the internet to allow simple communication at a distance. This paper describes our motivation for the project, previous work in the area, the design of the devices, supporting website and publicity, and how users have made and used Yo-Yo Machines. Finally, we reflect on what we learned about peripheral and expressive communication devices and implications for the self-build approach.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {458},
numpages = {17},
keywords = {design research, open source, peripheral and expressive communication, research through design, self-build, IoT},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517510,
author = {Sabir, Aafaq and Lafontaine, Evan and Das, Anupam},
title = {Hey Alexa, Who Am I Talking to?: Analyzing Users’ Perception and Awareness Regarding Third-Party Alexa Skills},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517510},
doi = {10.1145/3491102.3517510},
abstract = {The Amazon Alexa voice assistant provides convenience through automation and control of smart home appliances using voice commands. Amazon allows third-party applications known as skills to run on top of Alexa to further extend Alexa’s capability. However, as multiple skills can share the same invocation phrase and request access to sensitive user data, growing security and privacy concerns surround third-party skills. In this paper, we study the availability and effectiveness of existing security indicators or a lack thereof to help users properly comprehend the risk of interacting with different types of skills. We conduct an interactive user study (inviting active users of Amazon Alexa) where participants listen to and interact with real-world skills using the official Alexa app. We find that most participants fail to identify the skill developer correctly (i.e., they assume Amazon also develops the third-party skills) and cannot correctly determine which skills will be automatically activated through the voice interface. We also propose and evaluate a few voice-based skill type indicators, showcasing how users would benefit from such voice-based indicators.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {447},
numpages = {15},
keywords = {Third-party skills, Voice assistant, Security indicators},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517509,
author = {Ding, Xianghua(Sharon) and Kou, Yubo and Xu, Yiwen and Zhang, Peng},
title = {“As Uploaders, We Have the Responsibility”: Individualized Professionalization of Bilibili Uploaders},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517509},
doi = {10.1145/3491102.3517509},
abstract = {The prevalence of social media blurs the boundaries between consumer and producer, work and play, and leads to new social roles, professions, and identities (e.g. blogger, YouTuber, micro-celebrity). However, we still lack a clear understanding of how people come to identify with these new roles and how individual professional development is digitally mediated. This paper presents a study based on Bilibili, a popular Chinese social media platform featuring user-generated videos, and highlights a professionalization process through which individuals consciously distinguish between the roles of uploaders and consumers, develop a shared work ethos around the role of the uploader, and, as uploaders, improve their technical-professional expertise. We conclude by discussing individualized professionalization as a concept that describes the bottom-up and community-based process of professional development for User Generated Content (UGC) taking place in contemporary digital media environments.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {509},
numpages = {14},
keywords = {Online Creative Media, User Generated Content (UGC), Profession, Professionalization},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3517508,
author = {Thoravi Kumaravel, Balasaravanan and Wilson, Andrew D},
title = {DreamStream: Immersive and Interactive Spectating in VR},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517508},
doi = {10.1145/3491102.3517508},
abstract = {Today spectating and streaming virtual reality (VR) activities typically involves spectators viewing a 2D stream of the VR user’s view. Streaming 2D videos of the game play is popular and well-supported by platforms such as Twitch. However, the generic streaming of full 3D representations is less explored. Thus, while the VR player’s experience may be fully immersive, spectators are limited to 2D videos. This asymmetry lessens the overall experience for spectators, who themselves may be eager to spectate in VR. DreamStream puts viewers in the virtual environment of the VR application, allowing them to look “over the shoulder” of the VR player. Spectators can view streamed VR content immersively in 3D, independently explore the VR scene beyond what the VR player sees and ultimately cohabit the virtual environment alongside the VR player. For the VR player, DreamStream provides a spatial awareness of all their spectators. DreamStream retrofits and works with existing VR applications. We discuss the design and implementation of DreamStream, and carry out three qualitative informal evaluations. These evaluations shed light on the strengths and weakness of using DreamStream for the purpose of interactive spectating. Our participants found that DreamStream’s VR viewer interface offered increased immersion, and made it easier to communicate and interact with the VR player.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {636},
numpages = {17},
keywords = {Collaborative Interactions, Virtual Reality, Streaming},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

