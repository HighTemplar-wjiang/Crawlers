@inproceedings{10.1145/3313831.3376552,
author = {Yasu, Kentaro},
title = {MagneLayer: Force Field Fabrication by Layered Magnetic Sheets},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376552},
doi = {10.1145/3313831.3376552},
abstract = {Magnets are very useful for the rapid prototyping of haptic interactions. However, it is difficult to arrange fine and complex magnetic fields rapidly. Therefore, we invented a method for fabricating complex geometric magnetic patterns by overlaying multiple magnetic rubber sheets. This method resolves the tradeoff between magnetized pattern complexity and the time required for magnetization. By layering multiple magnetic sheets that have simple magnetic patterns, various types of geometric magnetic patterns, such as checkered and diamond ones, can be generated on the top surface. By applying superposed magnetic fields, various types of tactile stimuli and haptic interaction can be created rapidly. Furthermore, the superposed magnetic fields can be changed dynamically by rotating the layered magnetic sheets. In this paper, we clarify the material requirements and describe the design method for creating these geometric magnetic patterns. We also demonstrate several of their applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {haptic, fabrication, tactile, rapid prototyping, diy, magnet},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376547,
author = {Michaelis, Joseph E. and Siebert-Evenstone, Amanda and Shaffer, David Williamson and Mutlu, Bilge},
title = {Collaborative or Simply Uncaged? Understanding Human-Cobot Interactions in Automation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376547},
doi = {10.1145/3313831.3376547},
abstract = {Collaborative robots, or cobots, represent a breakthrough technology designed for high-level (e.g. collaborative) interactions between workers and robots with capabilities for flexible deployment in industries such as manufacturing. Understanding how workers and companies use and integrate cobots is important to inform the future design of cobot systems and educational technologies that facilitate effective worker-cobot interaction. Yet, little is known about typical training for collaboration and the application of cobots in manufacturing. To close this gap, we interviewed nine experts in manufacturing about their experience with cobots. Our thematic analysis revealed that, contrary to the envisioned use, experts described most cobot applications as only low-level (e.g. pressing start/stop buttons) interactions with little flexible deployment, and experts felt traditional robotics skills were needed for collaborative and flexible interaction with cobots. We conclude with design recommendations for improved future robots, including programming and interface designs, and educational technologies to support collaborative use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human-robot collaboration, technology adoption, educational technology, end-user programming, collaborative robots, human-robot interaction (hri)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376542,
author = {Rho, Eugenia Ha Rim and Mazmanian, Melissa},
title = {Political Hashtags &amp; the Lost Art of Democratic Discourse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376542},
doi = {10.1145/3313831.3376542},
abstract = {In this work, we investigate whether and how the presence of political hashtags in social media news articles influences the way people discuss news content. Specifically, we examine how political hashtags in news posts act as a design characteristic that affects the quality of online discourse. We use a randomized control experiment to assess how the presence versus absence of political hashtags (particularly the most prevalently used #MeToo and #BlackLivesMatter) in social media news posts shapes discourse across a general audience (n=3205). Key findings show differences in topical focus, emotional tone of discourse, and rhetorical styles between commenters who were shown news posts with political hashtags versus those shown news posts without the hashtags. Compared to the control group, those shown hashtagged news posts heavily focus on the politics of the hashtag, use more words associated with fear, anger, and disgust in their comments, and exhibit black-and-white rhetoric and less emotionally temperate expressions in their arguments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {civil discourse, social media news, political hashtags, control experiment, digital journalism, online social movements},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376527,
author = {Carstensdottir, Elin and Partlan, Nathan and Sutherland, Steven and Duke, Tyler and Ferris, Erika and Richter, Robin M. and Valladares, Maria and Seif El-Nasr, Magy},
title = {Progression Maps: Conceptualizing Narrative Structure for Interaction Design Support},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376527},
doi = {10.1145/3313831.3376527},
abstract = {Interactive narratives are frequently designed for learning and training applications, such as social training. In these contexts, designers may be inexperienced in storytelling and interaction design, and it may be difficult to quickly build an effective experience, even for experienced designers. Designers often approach this problem through iterative design. To augment and reduce iteration, we argue for the utility of employing models to reason about, evaluate, and improve designs. While there has been much previous work on interactive narrative models, none of them capture aspects of the interaction design necessary for testing and evaluation. In this paper we propose a new computational model called Progression Maps, which abstracts interaction design elements of the narrative's structure and visualizes its interaction properties. We report on the model, its implementation, and two studies evaluating its use. Our results demonstrate Progression Maps' effectiveness in communicating the underlying design through an easily understandable visualization.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {graph-based models, interaction design, interactive narrative, interactive narrative model, visualization, design assistance tools, game design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376524,
author = {August, Tal and Card, Dallas and Hsieh, Gary and Smith, Noah A. and Reinecke, Katharina},
title = {Explain like I Am a Scientist: The Linguistic Barriers of Entry to r/Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376524},
doi = {10.1145/3313831.3376524},
abstract = {As an online community for discussing research findings, r/science has the potential to contribute to science outreach and communication with a broad audience. Yet previous work suggests that most of the active contributors on r/science are science-educated people rather than a lay general public. One potential reason is that r/science contributors might use a different, more specialized language than used in other subreddits. To investigate this possibility, we analyzed the language used in more than 68 million posts and comments from 12 subreddits from 2018. We show that r/science uses a specialized language that is distinct from other subreddits. Transient (newer) authors of posts and comments on r/science use less specialized language than more frequent authors, and those that leave the community use less specialized language than those that stay, even when comparing their first comments. These findings suggest that the specialized language used in r/science has a gatekeeping effect, preventing participation by people whose language does not align with that used in r/science. By characterizing r/science's specialized language, we contribute guidelines and tools for increasing the number of contributors in r/science.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {science communication, social computing, reddit},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376523,
author = {Suzuki, Ryo and Hedayati, Hooman and Zheng, Clement and Bohn, James L. and Szafir, Daniel and Do, Ellen Yi-Luen and Gross, Mark D. and Leithinger, Daniel},
title = {RoomShift: Room-Scale Dynamic Haptics for VR with Furniture-Moving Swarm Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376523},
doi = {10.1145/3313831.3376523},
abstract = {RoomShift is a room-scale dynamic haptic environment for virtual reality, using a small swarm of robots that can move furniture. RoomShift consists of nine shape-changing robots: Roombas with mechanical scissor lifts. These robots drive beneath a piece of furniture to lift, move and place it. By augmenting virtual scenes with physical objects, users can sit on, lean against, place and otherwise interact with furniture with their whole body; just as in the real world. When the virtual scene changes or users navigate within it, the swarm of robots dynamically reconfigures the physical environment to match the virtual content. We describe the hardware and software implementation, applications in virtual tours and architectural design and interaction techniques.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {haptic interfaces, virtual reality, swarm robots, room-scale haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376522,
author = {Murad, Christine and Munteanu, Cosmin},
title = {Designing Voice Interfaces: Back to the (Curriculum) Basics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376522},
doi = {10.1145/3313831.3376522},
abstract = {Voice user interfaces (VUIs) are rapidly increasing in popularity in the consumer space. This leads to a concurrent explosion of available applications for such devices, with many industries rushing to offer voice interactions for their products. This pressure is then transferred to interface designers; however, a large majority of designers have been only trained to handle the usability challenges specific to Graphical User Interfaces (GUIs). Since VUIs differ significantly in design and usability from GUIs, we investigate in this paper the extent to which current educational resources prepare designers to handle the specific challenges of VUI design. For this, we conducted a preliminary scoping scan and syllabi meta review of HCI curricula at more than twenty top international HCI departments, revealing that the current offering of VUI design training within HCI education is rather limited. Based on this, we advocate for the updating of HCI curricula to incorporate VUI design, and for the development of VUI-specific pedagogical artifacts to be included in new curricula.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {conversational interface, hci curriculum, voice user interface, vui design, hci education, speech},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376509,
author = {Kj\ae{}rup, Maria and Skov, Mikael B. and Agerholm, Niels},
title = {Digital-Enabled Last Mile: A Study of Passenger Trips in Rural, Low-Density Populated Areas},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376509},
doi = {10.1145/3313831.3376509},
abstract = {Public transportation in rural areas is difficult due to low numbers of passengers and diverse needs, also reflected in the last mile problem that points to the distance to access transportation hubs in order to connect with core networks of transportation. In this paper, we study public transportation in rural areas using a digital-enabled, demand-responsive service called Plustur. This service was recently introduced as an effort to increase mobility in underserved rural areas by creating routes ad-hoc to answer to the last mile(s). We study how passengers and drivers understand Plustur, as well as experience the role of passenger. Our findings show that Plustur is viewed as a benefit for autonomy of mobility in rural areas, however is lacking in addressing integration of modes of mobilities, flexibility and spontaneous trips. We contribute with design implications for digital multimodal mobility services.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mobility as a service, mobility on demand, demand-responsive transit, digital-enabled passenger trips},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376508,
author = {Melfi, Giuseppe and M\"{u}ller, Karin and Schwarz, Thorsten and Jaworek, Gerhard and Stiefelhagen, Rainer},
title = {Understanding What You Feel: A Mobile Audio-Tactile System for Graphics Used at Schools with Students with Visual Impairment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376508},
doi = {10.1145/3313831.3376508},
abstract = {A lot of information is nowadays presented graphically. However, students with blindness do not have access to visual information. Providing an alternative text is not always the appropriate solution as exploring graphics to discover information independently is a fundamental part of the learning process. In this work, we introduce a mobile audio-tactile learning environment, which facilitates the incorporation of real educational material. We evaluate our system by comparing three methods of interaction with tactile graphics: A tactile graphic augmented by (1) a document with key index information in Braille, (2) a digital document with key index information and (3) the TPad system, an audio-tactile solution meeting the specific needs within the school context. Our study shows that the TPad system is suitable for educational environments. Moreover, compared to the other methods TPad is faster to explore tactile graphics and it suggests a promising effect on the memorization of information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {blind, access technology, touch screen devices, visually impaired, tactile graphics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376507,
author = {D\"{o}rrenb\"{a}cher, Judith and L\"{o}ffler, Diana and Hassenzahl, Marc},
title = {Becoming a Robot - Overcoming Anthropomorphism with Techno-Mimesis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376507},
doi = {10.1145/3313831.3376507},
abstract = {Employing anthropomorphism in physical appearance and behavior is the most widespread strategy for designing social robots. In the present paper, we argue that imitating humans impedes the full exploration of robots' social abilities. In fact, their very 'thingness' (e.g., sensors, rationality) is able to create 'superpowers' that go beyond human abilities, such as endless patience. To better identify these special abilities, we develop a performative method called 'Techno-Mimesis' and explore it in a series of workshops with robot designers. Specifically, we create 'prostheses' to allow designers to transform themselves into their future robot to experience use cases from the robot's perspective, e.g., 'seeing' with a distance sensor rather than with eyes. This imperfect imitation helps designers to experience being human and being robot at the same time, making differences apparent and facilitating the discovery of a number of potential physical, cognitive, and communicational robotic superpowers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {service robots, anthropomorphism, social robots, new animism, performative design method},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376505,
author = {Huang, Kai-Chieh and Sun, Chen-Kuo and Huang, Da-Yuan and Chen, Yu-Chun and Chang, Ruei-Che and Hsu, Shuo-wen and Yang, Chih-Yun and Chen, Bing-Yu},
title = {Glissade: Generating Balance Shifting Feedback to Facilitate Auxiliary Digital Pen Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376505},
doi = {10.1145/3313831.3376505},
abstract = {This paper introduces Glissade, a digital pen that generates balance shifting feedback by changing the weight distribution of the pen. A pulley system shifts a brass mass inside the pen to change the pen's center of mass and moment of inertia. When the mass is stationary, the pen delivers a constant yet natural sensation of weight, which can be used to convey a status. The pen can also generate a variety of haptic clues by actuating the mass according to the tilt or rotation of the pen, two commonly-used auxiliary pen input channels. Glissade demonstrates new possibilities that balance shifting feedback can bring to digital pen interactions. We validated the usability of this feedback by determining the recognizability of six balance patterns – a mix of static and dynamic patterns chosen based on our design considerations – in two controlled experiments. The results show that, on average, the participants could distinguish between the patterns with a 94.25% accuracy. At the end, we demonstrate a set of novel interactions enabled by Glissade and discuss the directions for future research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {haptics, sensation of weight, balance shifting feedback, digital pen},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376501,
author = {Chiang, Yi-Shyuan and Chang, Ruei-Che and Chuang, Yi-Lin and Chou, Shih-Ya and Lee, Hao-Ping and Lin, I-Ju and Jiang Chen, Jian-Hua and Chang, Yung-Ju},
title = {Exploring the Design Space of User-System Communication for Smart-Home Routine Assistants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376501},
doi = {10.1145/3313831.3376501},
abstract = {AI-enabled smart-home agents that automate household routines are increasingly viable, but the design space of how and what such systems should communicate with their users remains underexplored. Through a user-enactment study, we identified various interpretations of and feelings toward such a system's confidence in its automated acts. That confidence and their own mental models influenced what and how the participants wanted the system to communicate, as well as how they would assess, diagnose, and subsequently improve it. Automated acts resulted from false predictions were not generally considered improper, provided that they were perceived as reasonable or potentially useful. The participants' improvement strategies were of four general types, all of which will be discussed. Factors affecting their preferred levels of involvement in automated acts and their interest in system confidence were also identified. We conclude by making practical design recommendations for the user-system communication design spaces of smart-home routine assistants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {intelligent agent, smart-home, routine assistant, user enactment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376500,
author = {Chidziwisano, George Hope and Wyche, Susan and Oduor, Erick},
title = {GridAlert: Using a Sensor-Based Technology to Monitor Power Blackouts in Kenyan Homes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376500},
doi = {10.1145/3313831.3376500},
abstract = {Power blackouts (outages) are a common occurrence in Kenyan households. They affect people's livelihoods, and damage their property (household electrical items). We explore the role of GridAlert-a sensor-based technology we designed-in monitoring power blackouts. We worked with local technicians to design GridAlert's housing and integrate GridAlert with Kenya's electricity infrastructure. Then, we used interview, observation, diary, and data logging methods to understand 18 households' experiences using the system. Our findings provide insights for using sensor-based technology to monitor power usage and blackouts in Kenyan households. We also present participants' thoughts about GridAlert's housing, and about how it influenced their actions when using the system. We use these findings to discuss design insights for power monitoring systems, and to offer new perspectives on the role of technology in monitoring blackouts in Kenyan households.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hardware, blackouts, sensors, kenya, electricity, domestic technology, monitoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376495,
author = {Bourdeau, Simon and Lesage, Annemarie and Couturier Caron, B\'{e}atrice and L\'{e}ger, Pierre-Majorique},
title = {When Design Novices and LEGO® Meet: Stimulating Creative Thinking for Interface Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376495},
doi = {10.1145/3313831.3376495},
abstract = {Design thinking is an iterative, human-centered approach to innovation. Its success rests on collaboration within a multidisciplinary project team going through cycles of divergent and convergent ideations. In these teams, nondesigners risk diminishing the divergent reach because they are generally reluctant to sketch, thus missing out on theambiguous, imprecise early conceptual divergent phases. We hypothesized that LEGO® could advantageously be a substitute to sketching. In this comparative study, 44 nondesigners randomly paired in 22 dyads did two conceptual ideations of healthcare landing pages, one using pen/paper (spontaneously writing words on sticky notes) and the other using LEGO, assessed through Torrance and Guilford frameworks for divergent thinking. Results show that LEGO interfaces gathered significantly higher divergent thinking scores because their concepts were significantly more elaborated. Furthermore, when using LEGO, teams who generated more elements were likely to also generate more ideas, more categories of ideas and more original ideas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design methods, user experience design, tangibles, creativity support},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376484,
author = {Faas, Stefanie M. and Kao, Andrea C. and Baumann, Martin},
title = {A Longitudinal Video Study on Communicating Status and Intent for Self-Driving Vehicle  Pedestrian Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376484},
doi = {10.1145/3313831.3376484},
abstract = {With self-driving vehicles (SDVs), pedestrians cannot rely on communication with the driver anymore. Industry experts and policymakers are proposing an external Human-Machine Interface (eHMI) communicating the automated status. We investigated whether additionally communicating SDVs' intent to give right of way further improves pedestrians' street crossing. To evaluate the stability of these eHMI effects, we conducted a three-session video study with N=34 pedestrians where we assessed subjective evaluations and crossing onset times. This is the first work capturing long-term effects of eHMIs. Our findings add credibility to prior studies by showing that eHMI effects last (acceptance, user experience) or even increase (crossing onset, perceived safety, trust, learnability, reliance) with time. We found that pedestrians benefit from an eHMI communicating SDVs' status, and that additionally communicating SDVs' intent adds further value. We conclude that SDVs should be equipped with an eHMI communicating both status and intent.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {external human-machine interface, self-driving vehicles, intent, status, pedestrians, information need},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376472,
author = {Colley, Mark and Walch, Marcel and Gugenheimer, Jan and Askari, Ali and Rukzio, Enrico},
title = {Towards Inclusive External Communication of Autonomous Vehicles for Pedestrians with Vision Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376472},
doi = {10.1145/3313831.3376472},
abstract = {People with vision impairments (VIP) are among the most vulnerable road users in traffic. Autonomous vehicles are believed to reduce accidents but still demand some form of external communication signaling relevant information to pedestrians. Recent research on the design of vehicle-pedestrian communication (VPC) focuses strongly on concepts for a non-disabled population. Our work presents an inclusive user-centered design for VPC, beneficial for both vision impaired and seeing pedestrians. We conducted a workshop with VIP (N=6), discussing current issues in road traffic and comparing communication concepts proposed by literature. A thematic analysis unveiled two important themes: number of communicating vehicles and content (affecting duration). Subsequently, we investigated these in a second user study in virtual reality (N=33, 8 VIP) comparing the VPC between groups of abilities. We found that trust and understanding is enhanced and cognitive load reduced when all relevant vehicles communicate; high content messages also reduce cognitive load.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {autonomous vehicles, external communication, accessibility, vulnerable road users, inclusive design research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376461,
author = {Chin, Hyojin and Molefi, Lebogang Wame and Yi, Mun Yong},
title = {Empathy Is All You Need: How a Conversational Agent Should Respond to Verbal Abuse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376461},
doi = {10.1145/3313831.3376461},
abstract = {With the popularity of AI-infused systems, conversational agents (CAs) are becoming essential in diverse areas, offering new functionality and convenience, but simultaneously, suffering misuse and verbal abuse. We examine whether conversational agents' response styles under varying abuse types influence those emotions found to mitigate peoples' aggressive behaviors, involving three verbal abuse types (Insult, Threat, Swearing) and three response styles (Avoidance, Empathy, Counterattacking). Ninety-eight participants were assigned to one of the abuse type conditions, interacted with the three spoken (voice-based) CAs in turn, and reported their feelings about guiltiness, anger, and shame after each session. The results show that the agent's response style has a significant effect on user emotions. Participants were less angry and more guilty with the empathy agent than the other two agents. Furthermore, we investigated the current status of commercial CAs' responses to verbal abuse. Our study findings have direct implications for the design of conversational agents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {intelligent personal assistant, verbal abuse, smart speaker, agent abuse, virtual assistant, conversational agent},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inbook{10.1145/3313831.3376434,
author = {Browne, Kieran and Swift, Ben and Nurmikko-Fuller, Terhi},
title = {Camera Adversaria},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376434},
abstract = {In this paper we introduce Camera Adversaria; a mobile app designed to disrupt the automatic surveillance of personal photographs by technology companies. The app leverages the brittleness of deep neural networks with respect to high-frequency signals, adding generative adversarial perturbations to users' photographs. These perturbations confound image classification systems but are virtually imperceptible to human viewers. Camera Adversaria builds on methods developed by machine learning researchers as well as a growing body of work, primarily from art and design, which transgresses contemporary surveillance systems. We map the design space of responses to surveillance and identify an under-explored region where our project is situated. Finally we show that the language typically used in the adversarial perturbation literature serves to affirm corporate surveillance practices and malign resistance. This raises significant questions about the function of the research community in countenancing systems of surveillance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inproceedings{10.1145/3313831.3376432,
author = {Dixon, Emma and Lazar, Amanda},
title = {Approach Matters: Linking Practitioner Approaches to Technology Design for People with Dementia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376432},
doi = {10.1145/3313831.3376432},
abstract = {Technology design for dementia is an active and growing area. Though work to date has largely addressed functional needs, there is a growing recognition of the importance of supporting meaningful activities. However, technology for active, rather than passive, engagement is relatively novel beyond specific applications (e.g., music or reminiscence therapy). To better understand how to support active engagement of people with dementia in activities, we interviewed nineteen practitioners. Our findings reveal differing approaches to making sense of the actions of people with dementia, as well as to engaging them in activities. We discuss the importance of tracing epistemological understandings of dementia to different configurations of technology for people living with dementia and provide a practical guide to support designers to do so. Finally, we discuss considerations for the design of dementia technologies around facilitating self-actualization and managing emotional exposure for care-providers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {practitioners, design, dementia, meaningful activities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376424,
author = {Xiao, Sijia and Metaxa, Dana\"{e} and Park, Joon Sung and Karahalios, Karrie and Salehi, Niloufar},
title = {Random, Messy, Funny, Raw: Finstas as Intimate Reconfigurations of Social Media},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376424},
doi = {10.1145/3313831.3376424},
abstract = {Among many young people, the creation of a finsta-a portmanteau of "fake" and "Instagram" which describes secondary Instagram accounts-provides an outlet to share emotional, low-quality, or indecorous content with their close friends. To study why people create and maintain finstas, we conducted a qualitative study through interviews with finsta users and content analysis of video bloggers exposing their finsta on YouTube. We found that one way that young people deal with mounting social pressures is by reconfiguring online platforms and changing their purposes, norms, expectations, and currencies. Carving out smaller spaces accessible only to close friends allows users the opportunity for a more unguarded, vulnerable, and unserious performance. Drawing on feminist theory, we term this process intimate reconfiguration. Through this reconfiguration finsta users repurpose an existing and widely-used social platform to create opportunities for more meaningful and reciprocal forms of social support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {reconfiguration, feminist hci, finsta, performance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376422,
author = {Larsen-Ledet, Ida and Korsgaard, Henrik and B\o{}dker, Susanne},
title = {Collaborative Writing Across Multiple Artifact Ecologies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376422},
doi = {10.1145/3313831.3376422},
abstract = {Research focusing on how collaborative writing takes place across multiple applications and devices and over longer projects is sparse. We respond to this gap by presenting the results of a qualitative study of longer-term academic writing projects, showing how co-writers employ multiple tools when working on a common text. We identify three patterns of multi-application collaboration as well as four common types of motivations for transitions between applications. We also extend existing taxonomies of collaborative writing by proposing a categorization of the functions served by the text as object and backbone of the collaboration. Together, these contributions offer a framing for understanding transitions within and across artifact ecologies in work around a common object. Our findings highlight ways in which features like concurrent editing may in fact challenge the collaborative writing process, and we point to opportunities for alternative application models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sharelatex, potential artifact ecology, collaboration, github, overleaf, computer-supported cooperative work, google docs, personal artifact ecology, cscw, aligned artifact ecology, academic writing, text function, latex, collaborative academic writing, artifact ecology, collaborative writing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376417,
author = {Taranta, Eugene M. and Pittman, Corey R. and Oakley, Jack P. and Maslych, Mykola and Maghoumi, Mehran and LaViola, Joseph J.},
title = {Moving Toward an Ecologically Valid Data Collection Protocol for 2D Gestures In Video Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376417},
doi = {10.1145/3313831.3376417},
abstract = {Those who design gesture recognizers and user interfaces often use data collection applications that enable users to comfortably produce gesture training samples. In contrast, games present unique contexts that impact cognitive load and have the potential to elicit rapid gesticulations as players react to dynamic conditions, which can result in high gesture form variability. However, the extent to which these gestures differ is presently unknown. To this end, we developed two games with unique mechanics, Follow the Leader (FTL) and Sleepy Town, as well as a standard data collection application. We collected gesture samples from 18 participants across all conditions for gestures of varying complexity, and through an analysis using relative, global, and distribution coverage measures, we confirm significant differences between conditions. We discuss the implications of our findings, and show that our FTL design is closer to being an ecologically valid data collection protocol with low implementation complexity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {follow the leader, ecologically validity, gestures, games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376416,
author = {Xu, Ying and Warschauer, Mark},
title = {What Are You Talking To?: Understanding Children's Perceptions of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376416},
doi = {10.1145/3313831.3376416},
abstract = {Conversational agents (CAs) available in smart phones or smart speakers play an increasingly important role in young children's technological landscapes and life worlds. While a handful of studies have documented children's natural interactions with CAs, little is known about children's perceptions of CAs. To fill this gap, we examined three- to six-year-olds' perceptions of CAs' animate/artifact domain membership and properties, as well as their justifications for these perceptions. We found that children sometimes take a more nuanced position and spontaneously attribute both artifact and animate properties to CAs or view them as neither artifacts nor animate objects. This study extends current research on children's perceptions of intelligent artifacts by adding CAs as a new genre of study and provides some underlying knowledge that may guide the development of CAs to support young children's cognitive and social development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {children, conversational agents, perceptions, animacy, child-agent interactions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376412,
author = {Burnell, Edward and Damen, Nicole B. and Hoburg, Warren},
title = {GPkit: A Human-Centered Approach to Convex Optimization in Engineering Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376412},
doi = {10.1145/3313831.3376412},
abstract = {We present GPkit, a Python toolkit for Geometric and Signomial Programming that prioritizes explainability and incremental complexity. GPkit was designed through an ethnographic approach in the firms, classrooms, and research labs where it became part of the fabric of daily engineering work. Organizations have approached GPkit both in ways which centralize and in ways which distribute design work, usecases which emerged from and inspired new toolkit features. This two-way flow between mathematical structure and practitioner knowledge resulted in several novel contributions to the formulation and interpretation of convex programs and to our understanding of early-stage engineering design. For example, dual solutions (often considered incidental) can be more valuable to a design process than the "optimal design" itself, and we present novel algorithms and design methods based on this insight.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {modeling languages, convex optimization, toolkits, design models, geometric programming, human-centered design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376409,
author = {Paneva, Viktorija and Bachynskyi, Myroslav and M\"{u}ller, J\"{o}rg},
title = {Levitation Simulator: Prototyping Ultrasonic Levitation Interfaces in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376409},
doi = {10.1145/3313831.3376409},
abstract = {We present the Levitation Simulator, a system that enables researchers and designers to iteratively develop and prototype levitation interface ideas in Virtual Reality. This includes user tests and formal experiments. We derive a model of the movement of a levitating particle in such an interface. Based on this, we develop an interactive simulation of the levitation interface in VR, which exhibits the dynamical properties of the real interface. The results of a Fitts' Law pointing study show that the Levitation Simulator enables performance, comparable to the real prototype. We developed the first two interactive games, dedicated for levitation interfaces: LeviShooter and BeadBounce, in the Levitation Simulator, and then implemented them on the real interface. Our results indicate that participants experienced similar levels of user engagement when playing the games, in the two environments. We share our Levitation Simulator as Open Source, thereby democratizing levitation research, without the need for a levitation apparatus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {modeling, ultrasonic levitation, vr, virtual prototyping, simulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376407,
author = {Superti Pantoja, Luiza and Diederich, Kyle and Crawford, Liam and Corbett, Megan and Klemm, Samantha and Peterman, Kerry and Currin, Flannery and Hourcade, Juan Pablo},
title = {Play-Based Design: Giving 3- to 4-Year-Old Children a Voice in the Design Process},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376407},
doi = {10.1145/3313831.3376407},
abstract = {There has been a dramatic growth in interactive technology use by children under the age of 5 during the past decade. Despite this growth, children under the age of 5 typically participate only as users or testers in the design process in the overwhelming majority of projects targeting this population presented in key child-computer interaction venues. In this paper we introduce play-based design, an age-appropriate design method to give 3-4-year-old children a voice in the design process. More specifically, we contribute a thorough analysis of the use of existing methods to design technologies for children under the age of 5, a summary of the process that resulted in the development of play-based design, a detailed description of play-based design, a qualitative analysis of our experience implementing play-based design with two groups of children, and a discussion of play-based design's place among other methods, its advantages, and limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {children, preschool, play, design methods},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376402,
author = {Carros, Felix and Meurer, Johanna and L\"{o}ffler, Diana and Unbehaun, David and Matthies, Sarah and Koch, Inga and Wieching, Rainer and Randall, Dave and Hassenzahl, Marc and Wulf, Volker},
title = {Exploring Human-Robot Interaction with the Elderly: Results from a Ten-Week Case Study in a Care Home},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376402},
doi = {10.1145/3313831.3376402},
abstract = {Ageing societies and the associated pressure on the care systems are major drivers for new developments in socially assistive robotics. To understand better the real-world potential of robot-based assistance, we undertook a 10-week case study in a care home involving groups of residents, caregivers and managers as stakeholders. We identified both, enablers and barriers to the potential implementation of robot systems. The study employed the robot platform Pepper, which was deployed with a view to understanding better multi-domain interventions with a robot supporting physical activation, cognitive training and social facilitation. We employed the robot in a group setting in a care facility over the course of 10 weeks and 20 sessions, observing how stakeholders, including residents and caregivers, appropriated, adapted to, and perceived the robot. We also conducted interviews with 11 residents and caregivers. Our results indicate that the residents were positively engaged in the training sessions that were moderated by the robot. The study revealed that such humanoid robots can work in a care home but that there is a moderating person needed, that is in control of the robot.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {elderly care, user studies, ethics, social robots},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376400,
author = {Razi, Afsaneh and Badillo-Urquiola, Karla and Wisniewski, Pamela J.},
title = {Let's Talk about Sext: How Adolescents Seek Support and Advice about Their Online Sexual Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376400},
doi = {10.1145/3313831.3376400},
abstract = {We conducted a thematic content analysis of 4,180 posts by adolescents (ages 12-17) on an online peer support mental health forum to understand what and how adolescents talk about their online sexual interactions. Youth used the platform to seek support (83%), connect with others (15%), and give advice (5%) about sexting, their sexual orientation, sexual abuse, and explicit content. Females often received unwanted nudes from strangers and struggled with how to turn down sexting requests from people they knew. Meanwhile, others who sought support complained that they received unwanted sexual solicitations while doing so-to the point that adolescents gave advice to one another on which users to stay away from. Our research provides insight into the online sexual experiences of adolescents and how they seek support around these issues. We discuss how to design peer-based social media platforms to support the well-being and safety of youth.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sexual risks, online sexual experiences, sexting, adolescent online safety, peer support, social support seeking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376398,
author = {Lee, Kyungjun and Sato, Daisuke and Asakawa, Saki and Kacorri, Hernisa and Asakawa, Chieko},
title = {Pedestrian Detection with Wearable Cameras for the Blind: A Two-Way Perspective},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376398},
doi = {10.1145/3313831.3376398},
abstract = {Blind people have limited access to information about their surroundings, which is important for ensuring one's safety, managing social interactions, and identifying approaching pedestrians. With advances in computer vision, wearable cameras can provide equitable access to such information. However, the always-on nature of these assistive technologies poses privacy concerns for parties that may get recorded. We explore this tension from both perspectives, those of sighted passersby and blind users, taking into account camera visibility, in-person versus remote experience, and extracted visual information. We conduct two studies: an online survey with MTurkers (N=206) and an in-person experience study between pairs of blind (N=10) and sighted (N=40) participants, where blind participants wear a working prototype for pedestrian detection and pass by sighted participants. Our results suggest that both of the perspectives of users and bystanders and the several factors mentioned above need to be carefully considered to mitigate potential social tensions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {wearable camera, pedestrian detection, social acceptance, face recognition, crowdsourcing, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376389,
author = {Colnago, Jessica and Feng, Yuanyuan and Palanivel, Tharangini and Pearman, Sarah and Ung, Megan and Acquisti, Alessandro and Cranor, Lorrie Faith and Sadeh, Norman},
title = {Informing the Design of a Personalized Privacy Assistant for the Internet of Things},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376389},
doi = {10.1145/3313831.3376389},
abstract = {Internet of Things (IoT) devices create new ways through which personal data is collected and processed by service providers. Frequently, end users have little awareness of, and even less control over, these devices' data collection. IoT Personalized Privacy Assistants (PPAs) can help overcome this issue by helping users discover and, when available, control the data collection practices of nearby IoT resources. We use semi-structured interviews with 17 participants to explore user perceptions of three increasingly more autonomous potential implementations of PPAs, identifying benefits and issues associated with each implementation. We find that participants weigh the desire for control against the fear of cognitive overload. We recommend solutions that address users' differing automation preferences and reduce notification overload. We discuss open issues related to opting out from public data collections, automated consent, the phenomenon of user resignation, and designing PPAs with at-risk communities in mind.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {inteviews, internet of things, personalized privacy assistants},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376378,
author = {Lam, Amy T. and Griffin, Jonathan and Loeun, Matthew Austin and Cira, Nate J. and Lee, Seung Ah and Riedel-Kruse, Ingmar H.},
title = {Pac-Euglena: A Living Cellular Pac-Man Meets Virtual Ghosts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376378},
doi = {10.1145/3313831.3376378},
abstract = {The advancement of biotechnology enabled the development of "biotic video games", where human players manipulate real biological samples for fun and educational human-biology interactions. However, new design principles are needed to both leverage and mitigate biological properties (e.g., variability and stochasticity), and create unique play experiences that transcend traditional video games. This paper describes the implementation of Pac-Euglena, a biotic Pac-Man analog, where players guide live microscopic Euglena cells with light stimuli through a physical microfluidic maze. Through use of multi-modal stimuli, a mixed biology-digital-human reality is achieved, enabling cell interactions with virtual ghosts and collectibles. Through an iterative design process, we illustrate challenges and strategies for designing games with living organisms. A user study (n=18, conducted at a university event) showed that Pac-Euglena was fun, stimulated curiosity, and taught users about Euglena. We conclude with five general guidelines for the design and development of biotic games and HBI interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {biological user interfaces, human-biology interaction (hbi), augmented reality, euglena gracilis, mixed reality, biotic games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376374,
author = {Jiang, Xinlong and Chen, Yiqiang and Huang, Wuliang and Zhang, Teng and Gao, Chenlong and Xing, Yunbing and Zheng, Yi},
title = {WeDA: Designing and Evaluating A Scale-Driven Wearable Diagnostic Assessment System for Children with ADHD},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376374},
doi = {10.1145/3313831.3376374},
abstract = {Attention Deficit Hyperactivity Disorder (ADHD) is one of the most common mental disorders affecting children. Because the etiology of ADHD is complex and its symptoms are not specific, there is a lack of feasible quantitative diagnostic methods. Pursuing objective and non-invasive detection methods and standards is of great practical significance to prevent the development of the disease. In this study, we aim to address one specific concern about the objectivity and quantification of ADHD diagnosis. Over a year, we iteratively designed and tested WeDA, a scale-driven wearable diagnostic assessment system. This system contains an Android computer machine with a large touchscreen, a suite of 3D printed interactive devices, and six wearable motion sensors. We implement ten diagnostic tasks drawing on the symptoms of ADHD based on DSM-5. The experimental results of classifying children with ADHD and typically developing children and subjective evaluations from doctors, parents, and children validate the effectiveness and acceptability of WeDA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {neurodevelopmental disorder, diagnostic assessment, attention deficit hyperactivity disorder (adhd), wearable computing, scale-driven},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376371,
author = {Yoo, Soojeong and Gough, Phillip and Kay, Judy},
title = {Embedding a VR Game Studio in a Sedentary Workplace: Use, Experience and Exercise Benefits},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376371},
doi = {10.1145/3313831.3376371},
abstract = {Many people, especially those in sedentary occupations, fail to achieve the recommended levels of physical activity. Virtual reality (VR) games have the potential to overcome this because they are fun and also can be physically demanding. This paper explores whether a VR game studio can help workers in sedentary jobs to get valuable levels of exercise. We studied how 11 participants used our VR game studio in a sedentary workplace over 8-weeks and their perceptions of the experience. We analysed the physical exertion in the VR game studio, comparing this to their step counts from a smartwatch. All participants achieved valuable levels of physical activity and mood benefits. Importantly, for 6 participants, only with the VR game studio did they meet recommended activity levels. Our key contributions are insights about the use of a workplace VR game studio and its health benefits.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality game, exercise, sedentary workplace, head-mounted display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376359,
author = {Jo, Eunkyung and Toombs, Austin L. and Gray, Colin M. and Hong, Hwajung},
title = {Understanding Parenting Stress through Co-Designed Self-Trackers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376359},
doi = {10.1145/3313831.3376359},
abstract = {New parents often experience significant stress as they take on new roles and responsibilities. Stress management and mental wellbeing are two areas in which personal informatics (PI) research has gained attention, and there is an opportunity to investigate how parenting stress can be mitigated through PI practices. In this paper, we present the results of a co-designed technology probe study through which we deployed individualized self-trackers with new parents. We investigate the stress management topics new parents are interested in tracking and how — and with what goals---they engage in self-directed PI practices. Our findings indicate that PI practices can potentially enable parents to: re-discover positive aspects of their everyday lives; identify better-suited stress management strategies; and facilitate spousal communication about shared responsibilities. We discuss how self-tracking experiences for the mental wellness of parents can be better designed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personal informatics, co-design, stress management, parenting, new parents, self-tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376358,
author = {Yoshida, Shigeo and Sun, Yuqian and Kuzuoka, Hideaki},
title = {PoCoPo: Handheld Pin-Based Shape Display for Haptic Rendering in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376358},
doi = {10.1145/3313831.3376358},
abstract = {We introduce PoCoPo, the first handheld pin-based shape display that can render various 2.5D shapes in hand in realtime. We designed the display small enough for a user to hold it in hand and carry it around, thereby enhancing the haptic experiences in a virtual environment. PoCoPo has 18 motor-driven pins on both sides of a cuboid, providing the sensation of skin contact on the user's palm and fingers. We conducted two user studies to understand the capability of PoCoPo. The first study showed that the participants were generally successful in distinguishing the shapes rendered by PoCoPo with an average success rate of 88.5%. In the second study, we investigated the acceptable visual size of a virtual object when PoCoPo rendered a physical object of a certain size. The result led to a better understanding of the acceptable differences between the perceptions of visual size and haptic size.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, haptic device, shape display, handheld device},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376347,
author = {Pierce, James and Wong, Richmond Y. and Merrill, Nick},
title = {Sensor Illumination: Exploring Design Qualities and Ethical Implications of Smart Cameras and Image/Video Analytics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376347},
doi = {10.1145/3313831.3376347},
abstract = {Drawing analogies between smart cameras and electric lighting, we highlight and extrapolate design trends towards always-on sensing in intimate contexts, and the functional expansion of smart cameras as general-purpose and multi-functional devices. Employing a research through design (RtD) approach, we extrapolate these trends using speculative scenarios, materialize the scenarios by designing and constructing lighting-inspired smart camera fixtures, and self-experiment with these fixtures to introduce and exacerbate privacy and security issues, and inspire creative workarounds and design opportunities for sensor-level regulation. We synthesize our insights by presenting 8 smart camera sensing design qualities for addressing privacy, security, and related social and ethical issues.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–19},
numpages = {19},
keywords = {privacy, research through design, iot, security, smart home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376326,
author = {Tomlinson, Bill and Silberman, M. Six and Torrance, Andrew W. and Squire, Kurt and Atwal, Paramdeep S. and Mandalik, Ameya N. and Railkar, Sahil and Black, Rebecca W.},
title = {A Participatory Simulation of the Accountable Capitalism Act},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376326},
doi = {10.1145/3313831.3376326},
abstract = {Interactive computing systems increasingly allow for experimental evaluations of fundamental issues in law, government, and society. In this paper, we describe a participatory simulation of the Accountable Capitalism Act, a bill proposed in 2018 by US Senator Elizabeth Warren. We present findings from an empirical study conducted using this system, relating to the impact of 1) interactive visualization and 2) the Accountable Capitalism Act legal framework on the behavior of participants acting as corporate directors. From this study, we draw lessons about research possibilities at the juncture of HCI and legal and policy studies. This study contributes an analysis and evaluation of a design probe used to investigate potential impacts of the Accountable Capitalism Act, experimental evidence from a study conducted using the design probe, and guidance for future participatory simulations that seek to inform the design of social institutions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {business, law, corporations, participatory simulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376324,
author = {Wu, Ziming and Jiang, Yulun and Liu, Yiding and Ma, Xiaojuan},
title = {Predicting and Diagnosing User Engagement with Mobile UI Animation via a Data-Driven Approach},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376324},
doi = {10.1145/3313831.3376324},
abstract = {Animation, a common design element in user interfaces (UI), can impact user engagement (UE) with mobile applications. To avoid impairing UE due to improper design of animation, designers rely on resource-intensive evaluation methods like user studies or expert reviews. To alleviate this burden, we propose a data-driven approach to assisting designers in examining UE issues with their animation designs. We first crowdsource UE assessments of mobile UI animations. Based on the collected data, we then build a novel deep learning model that captures both spatial and temporal features of animations to predict their UE levels. Evaluations show that our model achieves a reasonable accuracy. We further leverage the animation feature encoded by our model and a sample set of expert reviews to derive potential UE issues of a particular animation. Finally, we develop a proof-of-concept tool and evaluate its potential usage in actual design practices with experts},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user engagement, mobile ui animation, data-driven approach},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376298,
author = {Reynolds, Joshua and Kumar, Deepak and Ma, Zane and Subramanian, Rohan and Wu, Meishan and Shelton, Martin and Mason, Joshua and Stark, Emily and Bailey, Michael},
title = {Measuring Identity Confusion with Uniform Resource Locators},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376298},
doi = {10.1145/3313831.3376298},
abstract = {Uniform Resource Locators (URLs) unambiguously specify host identity on the web. URLs are syntactically complex, and although software can accurately parse identity from URLs, users are frequently exposed to URLs and expected to do the same. Unfortunately, incorrect assessment of identity from a URL can expose users to attacks, such as typosquatting and phishing. Our work studies how well users can correctly determine the host identity of real URLs from common services and obfuscated "look-alike" URLs. We observe that participants employ a wide range of URL parsing strategies, and can identify real URLs 93% of time. However, only 40% of obfuscated URLs were identified correctly. These mistakes highlighted several ways in which URLs were confusing to users and why their existing URL parsing strategies fall short. We conclude with future research directions for reliably conveying website identity to users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {usable security, phishing, server identity, url, authentication, url readability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376286,
author = {Wang, Yuntao and Chen, Zichao (Tyson) and Li, Hanchuan and Cao, Zhengyi and Luo, Huiyi and Zhang, Tengxiang and Ou, Ke and Raiti, John and Yu, Chun and Patel, Shwetak and Shi, Yuanchun},
title = {MoveVR: Enabling Multiform Force Feedback in Virtual Reality Using Household Cleaning Robot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376286},
doi = {10.1145/3313831.3376286},
abstract = {Haptic feedback can significantly enhance the realism and immersiveness of virtual reality (VR) systems. In this paper, we propose MoveVR, a technique that enables realistic, multiform force feedback in VR leveraging commonplace cleaning robots. MoveVR can generate tension, resistance, impact and material rigidity force feedback with multiple levels of force intensity and directions. This is achieved by changing the robot's moving speed, rotation, position as well as the carried proxies. We demonstrated the feasibility and effectiveness of MoveVR through interactive VR gaming. In our quantitative and qualitative evaluation studies, participants found that MoveVR provides more realistic and enjoyable user experience when compared to commercially available haptic solutions such as vibrotactile haptic systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {haptic feedback, cleaning robot, robotics, vr, force feedback, human-robot interaction, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376285,
author = {Pilzer, Jan and Rosenast, Raphael and Meyer, Andr\'{e} N. and Huang, Elaine M. and Fritz, Thomas},
title = {Supporting Software Developers' Focused Work on Window-Based Desktops},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376285},
doi = {10.1145/3313831.3376285},
abstract = {Software developers, like other information workers, continuously switch tasks and applications to complete their work on their computer. Given the high fragmentation and complexity of their work, staying focused on the relevant pieces of information can become quite challenging in today's window-based environments, especially with the ever increasing monitor screen-size. To support developers in staying focused, we conducted a formative study with 18 professionals in which we examined their computer based and eye-gaze interaction with the window environment and devised a relevance model of open windows. Based on the results, we developed a prototype to dim irrelevant windows and reduce distractions, and evaluated it in a user study. Our results indicate that our model was able to predict relevant open windows with high accuracy and participants felt that integrating visual prominence into the desktop environment reduces clutter and distraction, which results in reduced window switching and an increase in focus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user interfaces, window relevance, window management, focus, productivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376280,
author = {Kim, Erin and Schneider, Oliver},
title = {Defining Haptic Experience: Foundations for Understanding, Communicating, and Evaluating HX},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376280},
doi = {10.1145/3313831.3376280},
abstract = {Haptic technology is maturing, with expectations and evidence that it will contribute to user experience (UX). However, we have very little understanding about how haptic technology can influence people's experience. Researchers and designers need a way to understand, communicate, and evaluate haptic technology's effect on UX. From a literature review and two studies - one with haptics novices, the other with expert hapticians - we developed a theoretical model of the factors that constitute a good haptic experience (HX). We define HX and propose its constituent factors: design parameters of Timeliness, Density, Intensity, and Timbre; the cross-cutting concern of Personalization; usability requirements of Utility, Causality, Consistency, and Saliency; and experiential factors of Harmony, Expressivity, Autotelics, Immersion, and Realism as guiding constructs important for haptic experience. This model will help guide design and research of haptic systems, inform language around haptics, and provide the basis for evaluative instruments, such as checklists, heuristics, or questionnaires.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design, user experience, scale development, haptics, vibrotactile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376279,
author = {Stewart, Angela E.B. and Amon, Mary Jean and Duran, Nicholas D. and D'Mello, Sidney K.},
title = {Beyond Team Makeup: Diversity in Teams Predicts Valued Outcomes in Computer-Mediated Collaborations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376279},
doi = {10.1145/3313831.3376279},
abstract = {In an increasingly globalized and service-oriented economy, people need to engage in computer-mediated collaborative problem solving (CPS) with diverse teams. However, teams routinely fail to live up to expectations, showcasing the need for technologies that help develop effective collaboration skills. We take a step in this direction by investigating how different dimensions of team diversity (demographic, personality, attitudes towards teamwork, prior domain experience) predict objective (e.g. effective solutions) and subjective (e.g. positive perceptions) collaborative outcomes. We collected data from 96 triads who engaged in a 30-minute CPS task via videoconferencing. We found that demographic diversity and differing attitudes towards teamwork predicted impressions of positive engagement, while personality diversity predicted learning outcomes. Importantly, these relationships were maintained after accounting for team makeup. None of the diversity measures predicted task performance. We discuss how our findings can be incorporated into technologies that aim to help diverse teams develop CPS skills.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {collaborative problem solving, diversity, learning technologies, team makeup},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376273,
author = {Kurze, Albrecht and Bischof, Andreas and Totzauer, S\"{o}ren and Storz, Michael and Eibl, Maximilian and Brereton, Margot and Berger, Arne},
title = {Guess the Data: Data Work to Understand How People Make Sense of and Use Simple Sensor Data from Homes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376273},
doi = {10.1145/3313831.3376273},
abstract = {Simple smart home sensors, e.g. for temperature or light, increasingly collect seemingly inconspicuous data. Prior work has shown that human sensemaking of such sensor data can reveal domestic activities. Such sensemaking presents an opportunity to empower people to understand the implications of simple smart home sensors. To investigate, we developed and field-tested the Guess the Data method, which enabled people to use and make sense of live data from their homes and to collectively interpret and reflect on anonymized data from the homes in our study. Our findings show how participants reconstruct behavior, both individually and collectively, expose the sensitive personal data of others, and use sensor data as evidence and for lateral surveillance within the household. We discuss the potential of our method as a participatory HCI method for investigating design of the IoT and implications created by doing data work on home sensors.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {smart home, iot, privacy, networked sensing systems, data work, sensor data, personal data, internet of things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376269,
author = {Shahmiri, Fereshteh and Dietz, Paul H.},
title = {ShArc: A Geometric Technique for Multi-Bend/Shape Sensing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376269},
doi = {10.1145/3313831.3376269},
abstract = {We present ShArc, a precision, geometric measurement technique for building multi-bend/shape sensors. ShArc sensors are made from flexible strips that can be dynamically formed into complex curves in a plane. They measure local curvature by noting the relative shift between the inner and outer layers of the sensor at many points and model shape as a series of connected arcs. Unlike jointed systems where angular errors sum with each joint measured, ShArc sensors do not accumulate angular error as more measurement points are added. This allows for inexpensive, robust sensors that can accurately model curves with multiple bends. To demonstrate the efficacy of this technique, we developed a capacitive ShArc sensor and evaluated its performance. We conclude with examples of how ShArc sensors can be employed in applications like gesture input devices, user interface controllers, human motion tracking and angular measurement of free-form objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {capacitive, bend, sensor, multi-bend, sharc, shape},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376263,
author = {Lu, Min and Wang, Chufeng and Lanir, Joel and Zhao, Nanxuan and Pfister, Hanspeter and Cohen-Or, Daniel and Huang, Hui},
title = {Exploring Visual Information Flows in Infographics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376263},
doi = {10.1145/3313831.3376263},
abstract = {Infographics are engaging visual representations that tell an informative story using a fusion of data and graphical elements. The large variety of infographic design poses a challenge for their high-level analysis. We use the concept of Visual Information Flow (VIF), which is the underlying semantic structure that links graphical elements to convey the information and story to the user. To explore VIF, we collected a repository of over 13K infographics. We use a deep neural network to identify visual elements related to information, agnostic to their various artistic appearances. We construct the VIF by automatically chaining these visual elements together based on Gestalt principles. Using this analysis, we characterize the VIF design space by a taxonomy of 12 different design patterns. Exploring in a real-world infographic dataset, we discuss the design space and potentials of VIF in light of this taxonomy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {infographics, visual information flow, design analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376262,
author = {Liao, Yi-Chi and Kim, Sunjun and Lee, Byungjoo and Oulasvirta, Antti},
title = {Button Simulation and Design via FDVV Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376262},
doi = {10.1145/3313831.3376262},
abstract = {Designing a push-button with desired sensation and performance is challenging because the mechanical construction must have the right response characteristics. Physical simulation of a button's force-displacement (FD) response has been studied to facilitate prototyping; however, the simulations' scope and realism have been limited. In this paper, we extend FD modeling to include vibration (V) and velocity-dependence characteristics (V). The resulting FDVV models better capture tactility characteristics of buttons, including snap. They increase the range of simulated buttons and the perceived realism relative to FD models. The paper also demonstrates methods for obtaining these models, editing them, and simulating accordingly. This end-to-end approach enables the analysis, prototyping, and optimization of buttons, and supports exploring designs that would be hard to implement mechanically.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {modeling, input device, haptic, haptic rendering, vibration, fdvv model, force feedback, button, simulation, tactility, fd model},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376257,
author = {Mallari, Keri and Inkpen, Kori and Johns, Paul and Tan, Sarah and Ramesh, Divya and Kamar, Ece},
title = {Do I Look Like a Criminal? Examining How Race Presentation Impacts Human Judgement of Recidivism},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376257},
doi = {10.1145/3313831.3376257},
abstract = {Understanding how racial information impacts human decision making in online systems is critical in today's world. Prior work revealed that race information of criminal defendants, when presented as a text field, had no significant impact on users' judgements of recidivism. We replicated and extended this work to explore how and when race information influences users' judgements, with respect to the saliency of presentation. Our results showed that adding photos to the race labels had a significant impact on recidivism predictions for users who identified as female, but not for those who identified as male. The race of the defendant also impacted these results, with black defendants being less likely to be predicted to recidivate compared to white defendants. These results have strong implications for how system-designers choose to display race information, and cautions researchers to be aware of gender and race effects when using Amazon Mechanical Turk workers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-ai collaboration, legal, race, crowd work, gender, bias, recidivism, mechanical turk},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376242,
author = {Mueller, Florian Floyd and Lopes, Pedro and Strohmeier, Paul and Ju, Wendy and Seim, Caitlyn and Weigel, Martin and Nanayakkara, Suranga and Obrist, Marianna and Li, Zhuying and Delfa, Joseph and Nishida, Jun and Gerber, Elizabeth M. and Svanaes, Dag and Grudin, Jonathan and Greuter, Stefan and Kunze, Kai and Erickson, Thomas and Greenspan, Steven and Inami, Masahiko and Marshall, Joe and Reiterer, Harald and Wolf, Katrin and Meyer, Jochen and Schiphorst, Thecla and Wang, Dakuo and Maes, Pattie},
title = {Next Steps for Human-Computer Integration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376242},
doi = {10.1145/3313831.3376242},
abstract = {Human-Computer Integration (HInt) is an emerging paradigm in which computational and human systems are closely interwoven. Integrating computers with the human body is not new. however, we believe that with rapid technological advancements, increasing real-world deployments, and growing ethical and societal implications, it is critical to identify an agenda for future research. We present a set of challenges for HInt research, formulated over the course of a five-day workshop consisting of 29 experts who have designed, deployed and studied HInt systems. This agenda aims to guide researchers in a structured way towards a more coordinated and conscientious future of human-computer integration.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {symbiosis, cyborg, implants, fusion, integration, augmentation, bodily extension},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376231,
author = {Jung, Heekyoung},
title = {In Search of Forms for Evocative and Generative Reflection: Exploratory Studies and a Design Proposal},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376231},
doi = {10.1145/3313831.3376231},
abstract = {Today an increasing number of personal informatics tools and platforms support intended behavior change and goal achievement through data-based self-reflection. The scope of self-reflection expands with emerging sources, goals, and challenges of human well-being, demanding for reframing recent computer-mediated reflective practice. This study investigates a broader range of contexts and forms of self-reflection that support navigating one's mind and goals beyond achieving preset goals. This paper describes contemporary issues on human well-being and two exploratory studies-one conducted in a traveling artists' residency and the other in a design studio class-which surveyed various triggers, contexts, and forms of self-reflection. By connecting the insights from the two studies, I propose evocative and generative reflection as an alternative perspective to tracking-based, goal-oriented reflection and discuss implications for the design for reflection with a focus on the creative dimension of human well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {well-being, reflective forms, reflection, creativity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

