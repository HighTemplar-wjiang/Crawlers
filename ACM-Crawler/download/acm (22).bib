@inproceedings{10.1145/3491102.3502056,
author = {Petrovskaya, Elena and Deterding, Sebastian and Zendle, David I},
title = {Prevalence and Salience of Problematic Microtransactions in Top-Grossing Mobile and PC Games: A Content Analysis of User Reviews},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502056},
doi = {10.1145/3491102.3502056},
abstract = {Microtransactions have become a major monetisation model in digital games, shaping their design, impacting player experience, and raising ethical concerns. Research in this area has chiefly focused on loot boxes. This begs the question whether other microtransactions might actually be more relevant and problematic for players. We therefore conducted a content analysis of negative player reviews (n=801) of top-grossing mobile and desktop games to determine which problematic microtransactions are most prevalent and salient for players. We found that problematic microtransactions with mobile games featuring more frequent and different techniques compared to desktop games. Across both, players minded issues related to fairness, transparency, and degraded user experience, supporting prior theoretical work, and importantly take issue with monetisation-driven design as such. We identify future research needs on why microtransactions in particular spark this critique, and which player communities it may be more or less representative of.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {560},
numpages = {12},
keywords = {player experience, mobile games, dark patterns, microtransactions, ethics},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502051,
author = {Katharina Willamowski, Jutta and Gonzalez-Jimenez, Shreepriya and Legras, Christophe and Gallo, Danilo},
title = {FlexNav: Flexible Navigation and Exploration through Connected Runnable Zones},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502051},
doi = {10.1145/3491102.3502051},
abstract = {Runners want to actively explore unknown environments without the fear of getting lost. We conducted a survey to better understand runners’ needs and practices in this context. The survey results emphasized the interest in flexible exploration. To address this interest, we designed FlexNav, a system that supports exploratory running through flexible tours that link the best runnable zones in a neighbourhood. FlexNav provides adaptive navigation support enabling runners to follow such tours without continually getting disruptive directions. We tested it with runners to assess its usability. The results confirm the usefulness of the system and the users' preference for flexible tours over fully specified tours with turn-by-turn guidance. Our study highlights the subjective nature of runnable zones and the subtle balance between guidance and exploration.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {368},
numpages = {17},
keywords = {Running, Pedestrian Navigation, Sports, Route Recommendation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502050,
author = {Xu, Ying and Vigil, Valery and Bustamante, Andres S. and Warschauer, Mark},
title = {“Elinor’s Talking to Me!”:Integrating Conversational AI into Children’s Narrative Science Programming},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502050},
doi = {10.1145/3491102.3502050},
abstract = {Video programs are important, accessible educational resources for young children, especially those from an under-resourced backgrounds. These programs’ potential can be amplified if children are allowed to socially interact with media characters during their video watching. This paper presents the design and empirical investigation of interactive science-focused videos in which the main character, powered by a conversational agent, engaged in contingent conversation with children by asking children questions and providing responsive feedback. We found that children actively interacted with the media character in the conversational videos and their parents spontaneously provided support in the process. We also found that the children who watched the conversational video performed better in the immediate, episode-specific science assessment compared to their peers who watched the broadcast, non-interactive version of the same episode. Several design implications are discussed for using conversational technologies to better support child active learning and parent involvement in video watching.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {166},
numpages = {16},
keywords = {Conversational AI, children, conversational agents, educational media, science learning},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502035,
author = {Feinberg, Rachel R. and Lakshmi, Udaya and Golino, Matthew J. and Arriaga, Rosa I.},
title = {ZenVR: Design Evaluation of a Virtual Reality Learning System for Meditation},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502035},
doi = {10.1145/3491102.3502035},
abstract = {Meditation has become a popular option to manage stress. Though studies examine technologies to assist in meditation, few explore how technology supports development of such skills for independent practice. From a two-phase mixed-methods study, we contribute learner-centered insights from 36 participants in a virtual reality environment designed to teach meditation skills to novices. In Phase I, we gathered affective and behavioral learner needs from 21 meditation novices, experts, and instructors to synthesize insights for learning. We then designed ZenVR: an interactive system to deliver an eight-lesson meditation curriculum to support learners’ progress. In Phase II, we conducted a 6-week longitudinal lab-based evaluation with 15 novice meditation learners. We found statistically significant improvements in mindfulness and self-reported meditation ability. Their insights from a self-managed practice, two weeks after the study ended, offered opportunities to understand how technology can be designed to offer progressive support without creating dependence in technology-mediated meditation practice.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {15},
keywords = {wellness, Virtual reality, interaction design, self-guided learning, meditation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502031,
author = {Druga, Stefania and Christoph, Fee Lia and Ko, Amy J},
title = {Family as a Third Space for AI Literacies: How Do Children and Parents Learn about AI Together?},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502031},
doi = {10.1145/3491102.3502031},
abstract = {Many families engage daily with artificial intelligence (AI) applications, from conversations with a voice assistant to mobile navigation searches. While there are known ways for youth to learn about AI, we do not yet understand how to engage parents in this process. To explore parents’ roles in helping their children develop AI literacies, we designed 11 learning activities organized into four topics: image classification, object recognition, interaction with voice assistants, and unplugged AI co-design. We conducted a 5-week online in-home study with 18 children (5 to 11 years old) and 16 parents. We identify parents’ most common roles in supporting their children and consider the benefits of parent-child partnerships when learning AI literacies. Finally, we discuss how our different activities supported parents’ roles and present design recommendations for future family-centered AI literacies resources.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {225},
numpages = {17},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502030,
author = {Lee, Mina and Liang, Percy and Yang, Qian},
title = {CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502030},
doi = {10.1145/3491102.3502030},
abstract = {Large language models (LMs) offer unprecedented language generation capabilities and exciting opportunities for interaction design. However, their highly context-dependent capabilities are difficult to grasp and are often subjectively interpreted. In this paper, we argue that by curating and analyzing large interaction datasets, the HCI community can foster more incisive examinations of LMs’ generative capabilities. Exemplifying this approach, we present CoAuthor, a dataset designed for revealing GPT-3’s capabilities in assisting creative and argumentative writing. CoAuthor captures rich interactions between 63 writers and four instances of GPT-3 across 1445 writing sessions. We demonstrate that CoAuthor can address questions about GPT-3’s language, ideation, and collaboration capabilities, and reveal its contribution as a writing “collaborator” under various definitions of good collaboration. Finally, we discuss how this work may facilitate a more principled discussion around LMs’ promises and pitfalls in relation to interaction design. The dataset and an interface for replaying the writing sessions are publicly available at https://coauthor.stanford.edu.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {388},
numpages = {19},
keywords = {writing assistants., Human-AI collaborative writing, dataset, GPT-3, natural language generation, crowdsourcing, language models},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502006,
author = {Rifat, Mohammad Rashidujjaman and Prottoy, Hasan Mahmud and Ahmed, Syed Ishtiaque},
title = {Putting the Waz on Social Media: Infrastructuring Online Islamic Counterpublic through Digital Sermons in Bangladesh},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502006},
doi = {10.1145/3491102.3502006},
abstract = {While the presence of religious content is rapidly increasing over digital media, the HCI literature on digital media production has remained mostly limited by its focus on secular contents and analyses. Hence, the production, politics, and impact of such religious videos from the Global South have remained understudied in HCI. In this paper, we shed light on this topic through our nine-month-long ethnographic study on the production, sharing, and consumption of Islamic sermon videos (locally known as Waz) in Bangladesh. We report how faith, informal learning, local collaboration, creativity, and care play crucial roles in creating Islamic sermon videos and their proliferation online. We discuss how the sermon videos create a religious counterpublic in Bangladesh. We further discuss how such faith-based media production makes important lessons pertinent to the national grassroots politics in the Global South, politics of social media platforms, and HCI4D scholarship.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {576},
numpages = {19},
keywords = {grassroots, infrastructuring, counterpublic, content creation, politics, waz, Islamic media},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501988,
author = {Romat, Hugo and Marquardt, Nicolai and Hinckley, Ken and Henry Riche, Nathalie},
title = {Style Blink: Exploring Digital Inking of Structured Information via Handcrafted Styling as a First-Class Object},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501988},
doi = {10.1145/3491102.3501988},
abstract = {Structured note-taking forms such as sketchnoting, self-tracking journals, and bullet journaling go beyond immediate capture of information scraps. Instead, hand-drawn pride-in-craftmanship increases perceived value for sharing and display. But hand-crafting lists, tables, and calendars is tedious and repetitive. To support these practices digitally, Style Blink (“Style-Blocks+Ink”) explores handcrafted styling as a first-class object. Style-blocks encapsulate digital ink, enabling people to craft, modify, and reuse embellishments and decorations for larger structures, and apply custom layouts. For example, we provide interaction instruments that style ink for personal expression, inking palettes that afford creative experimentation, fillable pens that can be “loaded” with commands and actions to replace menu selections, techniques to customize inked structures post-creation by modifying the underlying handcrafted style-blocks and to re-layout the overall structure to match users’ preferred template. In effect, any ink stroke, notation, or sketch can be encapsulated as a style-object and re-purposed as a tool. Feedback from 13 users show the potential of style adaptation and re-use in individual sketching practices.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {336},
numpages = {14},
keywords = {note-taking, bullet journaling, pen+touch},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501984,
author = {McNaney, Roisin and Morgan, Catherine and Kulkarni, Pranav and Vega, Julio and Heidarivincheh, Farnoosh and McConville, Ryan and Whone, Alan and Kim, Mickey and Kirkham, Reuben and Craddock, Ian},
title = {Exploring Perceptions of Cross-Sectoral Data Sharing with People with Parkinson’s},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501984},
doi = {10.1145/3491102.3501984},
abstract = {In interdisciplinary spaces such as digital health, datasets that are complex to collect, require specialist facilities, and/or are collected with specific populations have value in a range of different sectors. In this study we collected a simulated free-living dataset, in a smart home, with 12 participants (six people with Parkinson’s, six carers). We explored their initial perceptions of the sensors through interviews and then conducted two data exploration workshops, wherein we showed participants the collected data and discussed their views on how this data, and other data relating to their Parkinson’s symptoms, might be shared across different sectors. We provide recommendations around how participants might be better engaged in considering data sharing in the early stages of research, and guidance for how research might be configured to allow for more informed data sharing practices in the future.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {280},
numpages = {14},
keywords = {Smart home, IoT, Parkinson’s, Data sharing, Privacy and security},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501983,
author = {Matviienko, Andrii and M\"{u}ller, Florian and Schmitz, Martin and Fendrich, Marco and M\"{u}hlh\"{a}user, Max},
title = {SkyPort: Investigating 3D Teleportation Methods in Virtual Environments},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501983},
doi = {10.1145/3491102.3501983},
abstract = {Teleportation has become the de facto standard of locomotion in Virtual Reality (VR) environments. However, teleportation with parabolic and linear target aiming methods is restricted to horizontal 2D planes and it is unknown how they transfer to the 3D space. In this paper, we propose six 3D teleportation methods in virtual environments based on the combination of two existing aiming methods (linear and parabolic) and three types of transitioning to a target (instant, interpolated and continuous). To investigate the performance of the proposed teleportation methods, we conducted a controlled lab experiment (N = 24) with a mid-air coin collection task to assess accuracy, efficiency and VR sickness. We discovered that the linear aiming method leads to faster and more accurate target selection. Moreover, a combination of linear aiming and instant transitioning leads to the highest efficiency and accuracy without increasing VR sickness.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {516},
numpages = {11},
keywords = {virtual environments, locomotion, virtual reality, teleportation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501977,
author = {Kim, Taejun and Ham, Auejin and Ahn, Sunggeun and Lee, Geehyuk},
title = {Lattice Menu: A Low-Error Gaze-Based Marking Menu Utilizing Target-Assisted Gaze Gestures on a Lattice of Visual Anchors},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501977},
doi = {10.1145/3491102.3501977},
abstract = {We present Lattice Menu, a gaze-based marking menu utilizing a lattice of visual anchors that helps perform accurate gaze pointing for menu item selection. Users who know the location of the desired item can leverage target-assisted gaze gestures for multilevel item selection by looking at visual anchors over the gaze trajectories. Our evaluation showed that Lattice Menu exhibits a considerably low error rate (~1%) and a quick menu selection time (1.3-1.6 s) for expert usage across various menu structures (4 \texttimes{} 4 \texttimes{} 4 and 6 \texttimes{} 6 \texttimes{} 6) and sizes (8, 10 and 12°). In comparison with a traditional gaze-based marking menu that does not utilize visual targets, Lattice Menu showed remarkably (~5 times) fewer menu selection errors for expert usage. In a post-interview, all 12 subjects preferred Lattice Menu, and most subjects (8 out of 12) commented that the provisioning of visual targets facilitated more stable menu selections with reduced eye fatigue.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {277},
numpages = {12},
keywords = {Eye Tracking, AR/VR, Marking Menu, Gaze-Based Interaction},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501961,
author = {Heath, Claude P. R. and Coles-Kemp, Lizzie},
title = {Drawing Out the Everyday Hyper-[In]Securities of Digital Identity},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501961},
doi = {10.1145/3491102.3501961},
abstract = {In a study of everyday digital identity, a set of primary drawings were made by researchers in online focus group settings as a way to capture our participants’ spoken narratives of hyper-[in]security in the usages of digital identity. In a second stage of work, key extracts from the drawings were collaged using the method described in the paper, allowing an exploratory qualitative cartography of hyper-[in]security to be constructed. These secondary collages group the [in]securities thematically without losing essential contextual information. Samples of our data are given, to illustrate the contribution of the method to experience-centred design, with special reference to security from the perspective of marginalised and underserved communities. We discuss our method as a step towards multidimensional cognitive mapping of the salient features of our participants’ narratives about hyper-[in]security, potentially paving the way for further world building explorations of digital identity futures.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {254},
numpages = {18},
keywords = {digital inclusion, drawing, security technologies, world building},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501953,
author = {Muender, Thomas and Bonfert, Michael and Reinschluessel, Anke Verena and Malaka, Rainer and D\"{o}ring, Tanja},
title = {Haptic Fidelity Framework: Defining the Factors of Realistic Haptic Feedback for Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501953},
doi = {10.1145/3491102.3501953},
abstract = {Providing haptic feedback in virtual reality to make the experience more realistic has become a strong focus of research in recent years. The resulting haptic feedback systems differ greatly in their technologies, feedback possibilities, and overall realism making it challenging to compare different systems. We propose the Haptic Fidelity Framework providing the means to describe, understand and compare haptic feedback systems. The framework locates a system in the spectrum of providing realistic or abstract haptic feedback using the Haptic Fidelity dimension. It comprises 14 criteria that either describe foundational or limiting factors. A second Versatility dimension captures the current trade-off between highly realistic but application-specific and more abstract but widely applicable feedback. To validate the framework, we compared the Haptic Fidelity score to the perceived feedback realism of evaluations from 38 papers and found a strong correlation suggesting the framework accurately describes the realism of haptic feedback.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {431},
numpages = {17},
keywords = {feedback, fidelity, framework, realism, versatility, user experience, virtual environment, haptic feedback, haptics, immersion},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501948,
author = {Kim, Jeongyeon and Choi, Yubin and Kahng, Minsuk and Kim, Juho},
title = {FitVid: Responsive and Flexible Video Content Adaptation},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501948},
doi = {10.1145/3491102.3501948},
abstract = {Mobile video-based learning attracts many learners with its mobility and ease of access. However, most lectures are designed for desktops. Our formative study reveals mobile learners’ two major needs: more readable content and customizable video design. To support mobile-optimized learning, we present FitVid, a system that provides responsive and customizable video content. Our system consists of (1) an adaptation pipeline that reverse-engineers pixels to retrieve design elements (e.g., text, images) from videos, leveraging deep learning with a custom dataset, which powers (2) a UI that enables resizing, repositioning, and toggling in-video elements. The content adaptation improves the guideline compliance rate by 24% and 8% for word count and font size. The content evaluation study (n=198) shows that the adaptation significantly increases readability and user satisfaction. The user study (n=31) indicates that FitVid significantly improves learning experience, interactivity, and concentration. We discuss design implications for responsive and customizable video adaptation.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {501},
numpages = {16},
keywords = {Responsive Design, Mobile Learning, Video-Based Learning, Content Adaptation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501944,
author = {Kang, Soowon and Park, Cheul Young and Kim, Auk and Cha, Narae and Lee, Uichin},
title = {Understanding Emotion Changes in Mobile Experience Sampling},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501944},
doi = {10.1145/3491102.3501944},
abstract = {Mobile experience sampling methods&nbsp;(ESMs) are widely used to measure users’ affective states by randomly sending self-report requests. However, this random probing can interrupt users and adversely influence users’ emotional states by inducing disturbance and stress. This work aims to understand how ESMs themselves may compromise the validity of ESM responses and what contextual factors contribute to changes in emotions when users respond to ESMs. Towards this goal, we analyze 2,227 samples of the mobile ESM data collected from 78 participants. Our results show ESM interruptions positively or negatively affected users’ emotional states in at least 38% of ESMs, and the changes in emotions are closely related to the contexts users were in prior to ESMs. Finally, we discuss the implications of using the ESM and possible considerations for mitigating the variability in emotional responses in the context of mobile data collection for affective computing.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {198},
numpages = {14},
keywords = {Emotion / Affective Computing, Mobile Devices: Phones/Tablets, Experience Sampling, Empirical study that tells us about people},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501917,
author = {Choi, Kabdo and Shin, Hyungyu and Xia, Meng and Kim, Juho},
title = {AlgoSolve: Supporting Subgoal Learning in Algorithmic Problem-Solving with Learnersourced Microtasks},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501917},
doi = {10.1145/3491102.3501917},
abstract = {Designing solution plans before writing code is critical for successful algorithmic problem-solving. Novices, however, often plan on-the-fly during implementation, resulting in unsuccessful problem-solving due to lack of mental organization of the solution. Research shows that subgoal learning helps learners develop more complete solution plans by enhancing their understanding of the high-level solution structure. However, expert-created materials such as subgoal labels are necessary to provide learning benefits from subgoal learning, which are a scarce resource in self-learning due to limited availability and high cost. We propose a learnersourcing workflow that collects high-quality subgoal labels from learners by helping them improve their label quality. We implemented the workflow into AlgoSolve, a prototype interface that supports subgoal learning for algorithmic problems. A between-subjects study with 63 problem-solving novices revealed that AlgoSolve helped learners create higher-quality labels and more complete solution plans, compared to a baseline method known to be effective in subgoal learning.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {229},
numpages = {16},
keywords = {Algorithmic problem-solving, Subgoal learning, Learnersourcing},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501914,
author = {Zhang, Chao and Yao, Cheng and Wu, Jiayi and Lin, Weijia and Liu, Lijuan and Yan, Ge and Ying, Fangtian},
title = {StoryDrawer: A Child–AI Collaborative Drawing System to Support Children's Creative Visual Storytelling},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501914},
doi = {10.1145/3491102.3501914},
abstract = {Visual storytelling is a new approach to creative expression based on verbal and figural creativity. The keys to visual storytelling are narrating and drawing over a period of time, which can be beneficial but also demanding on creativity for children. Informed by need-finding investigations, we developed StoryDrawer, a co-creative system that supports visual storytelling for children aged 6–10 years through collaborative drawing between children and artificial intelligence (AI). The system includes a context-based voice agent and two AI-driven collaborative strategies: the real-time transformation of children's telling into drawings, and the generation of abstract sketches with semantic similarity to existing story content. We conducted a 2 \texttimes{} 2 study with 64 children to evaluate the efficacy of StoryDrawer by varying the two strategies in four conditions. The results suggest that StoryDrawer provoked participants’ creative and elaborate ideas and contributed to their creative outcomes during an engaging visual storytelling experience.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {311},
numpages = {15},
keywords = {Visual storytelling, Child–AI collaboration, Co-creative system, Children, Drawing, Creativity support tool},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501890,
author = {Tseng, Chun-Miao and Chen, Po-Yu and Lin, Shih Chin and Wang, Yu-Wei and Lin, Yu-Hsin and Kuo, Mu-An and Yu, Neng-Hao and Chen, Mike Y.},
title = {HeadWind: Enhancing Teleportation Experience in VR by Simulating Air Drag during Rapid Motion},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501890},
doi = {10.1145/3491102.3501890},
abstract = {Teleportation, which instantly moves users from their current location to the target location, has become the most popular locomotion technique in VR games. It enables fast navigation with reduced VR sickness but results in significantly reduced immersion. We present HeadWind, a novel approach to improve the experience of teleportation by simulating the haptic sensation of air drag when rapidly moving through the air in real life. Specifically, HeadWind modulates bursts of compressed air to the face and uses multiple nozzles to provide directional cues. To design the wearable device and to model airflow speed and duration for teleportation, we conducted three formative studies and a design session. User experience evaluation with 24 participants showed that HeadWind significantly improved realism, immersion, and enjoyment of teleportation in VR (p&lt;.01) with large effect sizes (r&gt;0.5), and was preferred by 96% of participants.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {518},
numpages = {11},
keywords = {VR Haptics, Air drag, Motion perception, Teleportation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501878,
author = {Streli, Paul and Jiang, Jiaxi and Fender, Andreas Rene and Meier, Manuel and Romat, Hugo and Holz, Christian},
title = {TapType: Ten-Finger Text Entry on Everyday Surfaces via Bayesian Inference},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501878},
doi = {10.1145/3491102.3501878},
abstract = {Despite the advent of touchscreens, typing on physical keyboards remains most efficient for entering text, because users can leverage all fingers across a full-size keyboard for convenient typing. As users increasingly type on the go, text input on mobile and wearable devices has had to compromise on full-size typing. In this paper, we present TapType, a mobile text entry system for full-size typing on passive surfaces—without an actual keyboard. From the inertial sensors inside a band on either wrist, TapType decodes and relates surface taps to a traditional QWERTY keyboard layout. The key novelty of our method is to predict the most likely character sequences by fusing the finger probabilities from our Bayesian neural network classifier with the characters’ prior probabilities from an n-gram language model. In our online evaluation, participants on average typed 19 words per minute with a character error rate of 0.6% after 30 minutes of training. Expert typists thereby consistently achieved more than 25&nbsp;WPM at a similar error rate. We demonstrate applications of TapType in mobile use around smartphones and tablets, as a complement to interaction in situated Mixed Reality outside visual control, and as an eyes-free mobile text input method using an audio feedback-only interface.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {497},
numpages = {16},
keywords = {n-gram language model, invisible interfaces, Bayesian inference, virtual reality, mobile text entry, Bayesian neural network},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501877,
author = {Renom, Miguel A. and Caramiaux, Baptiste and Beaudouin-Lafon, Michel},
title = {Exploring Technical Reasoning in Digital Tool Use},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501877},
doi = {10.1145/3491102.3501877},
abstract = {The Technical Reasoning hypothesis in cognitive neuroscience posits that humans engage in physical tool use by reasoning about mechanical interactions among objects. By modeling the use of objects as tools based on their abstract properties, this theory explains how tools can be re-purposed beyond their assigned function. This paper assesses the relevance of Technical Reasoning to digital tool use. We conducted an experiment with 16 participants that forced them to re-purpose commands to complete a text layout task. We analyzed self-reported scores of creative personality and experience with text editing, and found a significant association between re-purposing performance and creativity, but not with experience. Our results suggest that while most participants engaged in Technical Reasoning to re-purpose digital tools, some experienced “functional fixedness.” This work contributes Technical Reasoning as a theoretical model for the design of digital tools.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {579},
numpages = {17},
keywords = {technical reasoning, tool re-purposing, human tool use},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501876,
author = {Dutta, Senjuti and Linder, Rhema and Lowe, Doug and Rosenbalm, Richard and Kuzminykh, Anastasia and Williams, Alex C},
title = {Mobilizing Crowdwork:A Systematic Assessment of the Mobile Usability of HITs},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501876},
doi = {10.1145/3491102.3501876},
abstract = {There is a growing interest in extending crowdwork beyond traditional desktop-centric design to include mobile devices (e.g., smartphones). However, mobilizing crowdwork remains significantly tedious due to a lack of understanding about the mobile usability requirements of human intelligence tasks (HITs). We present a taxonomy of characteristics that defines the mobile usability of HITs for smartphone devices. The taxonomy is developed based on findings from a study of three consecutive steps. In Step 1, we establish an initial design of our taxonomy through a targeted literature analysis. In Step 2, we verify and extend the taxonomy through an online survey with Amazon Mechanical Turk crowdworkers. Finally, in Step 3 we demonstrate the taxonomy’s utility by applying it to analyze the mobile usability of a dataset of scraped HITs. In this paper, we present the iterative development of the taxonomy, highlighting the observed practices and preferences around mobile crowdwork. We conclude with the implications of our taxonomy for accessibly and ethically mobilizing crowdwork not only within the context of smartphone devices, but beyond them.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {465},
numpages = {20},
keywords = {Crowdwork, Mobile Usability, Human Intelligence Tasks., Taxonomy},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501871,
author = {Lee, Hyejin and Jiang, Ruixi and Yoo, Yongjae and Henry, Max and Cooperstock, Jeremy R.},
title = {The Sound of Hallucinations: Toward a More Convincing Emulation of Internalized Voices},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501871},
doi = {10.1145/3491102.3501871},
abstract = {The need to generate convincing simulation of voices often arises in the context of avatar therapy, a treatment approach for disorders such as schizophrenia. This treatment involves patients interacting with simulations of the entity they imagine to be responsible for the voices they hear, for which there is often no external reference available. However, in such scenarios, there is little knowledge of how to design and reproduce these voices in a convincing manner. Existing voice manipulation interfaces are often complex to use, and highly limited in their ability to modify vocal characteristics beyond small adjustments. To address these challenges, we designed a framework that allows users to explore and select from a large set of voices, and thereafter manipulate the voice(s) to converge towards an effective match for one they have in mind. We demonstrated both the usability and superior performance of this system compared to existing voice manipulation interfaces.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {340},
numpages = {11},
keywords = {Avatar Therapy, Speech Synthesis, Voice Transformation Interface},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501858,
author = {Ballou, Nick and Deterding, Sebastian and Iacovides, Ioanna and Helsby, Laura},
title = {Do People Use Games to Compensate for Psychological Needs During Crises? A Mixed-Methods Study of Gaming During COVID-19 Lockdowns},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501858},
doi = {10.1145/3491102.3501858},
abstract = {Do people use games to cope with adverse life events and crises? Research informed by self-determination theory proposes that people might compensate for thwarted basic psychological needs in daily life by seeking out games that satisfy those lacking needs. To test this, we conducted a preregistered mixed-method survey study (n = 285) on people’s gaming behaviours and need states during early stages of the COVID-19 pandemic (May 2020). We found qualitative evidence that gaming was an often actively sought out and successful means of replenishing particular needs, but one that could ‘backfire’ for some through an appraisal process discounting gaming as ‘unreal’. Meanwhile, contrary to our predictions, the quantitative data showed a “rich get richer, poor get poorer” pattern: need satisfaction in daily life positively correlated with need satisfaction in games. We derive methodological considerations and propose three potential explanations for this contradictory data pattern to pursue in future research.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {471},
numpages = {15},
keywords = {video games, mixed methods, coping, compensation, Covid-19, basic needs},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501852,
author = {Nguyen, Huy Anh and Hofman, Jake M and Goldstein, Daniel G},
title = {Round Numbers Can Sharpen Cognition},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501852},
doi = {10.1145/3491102.3501852},
abstract = {Scientists and journalists strive to report numbers with high precision to keep readers well-informed. Our work investigates whether this practice can backfire due to the cognitive costs of processing multi-digit precise numbers. In a pre-registered randomized experiment, we presented readers with several news stories containing numbers in either precise or round versions. We then measured their ability to approximately recall these numbers and make estimates based on what they read. Our results revealed a counter-intuitive effect where reading round numbers helped people better approximate the precise values, while seeing precise numbers made them worse. We also conducted two surveys to elicit individual preferences for the ideal degree of rounding for numbers spanning seven orders of magnitude in various contexts. From the surveys, we found that people tended to prefer more precision when the rounding options contained only digits (e.g., ”2,500,000”) than when they contained modifier terms (e.g., ”2.5 million”). We conclude with a discussion of how these findings can be leveraged to enhance numeracy in digital content consumption.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {375},
numpages = {15},
keywords = {number representation, estimation, experimentation, cognitive effect, recall, round numbers, measurement},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501849,
author = {Park, Chaeyong and Kim, Jeongwoo and Kim, Dong-Geun and Oh, Seungjae and Choi, Seungmoon},
title = {Vibration-Augmented Buttons: Information Transmission Capacity and Application to Interaction Design},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501849},
doi = {10.1145/3491102.3501849},
abstract = {One can embed a vibration actuator to a physical button and augment the physical button’s original kinesthetic response with a programmable vibration generated by the actuator. Such vibration-augmented buttons inherit the advantages of both physical and virtual buttons. This paper reports the information transmission capacity of vibration-augmented buttons. It was obtained by conducting a series of absolute identification experiments while increasing the number of augmented buttons. The information transmission capacity found was 2.6 bits, and vibration-augmented and physical buttons showed similar abilities in rendering easily recognizable haptic responses. In addition, we showcase a VR text entry application that utilizes vibration-augmented buttons. Our method provides several error messages to the user during text entry using a VR controller that includes an augmented button. We validate that the variable haptic feedback improves task performance, cognitive workload, and user experience for a transcription task.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {435},
numpages = {13},
keywords = {Button, Vibrotactile, Information Theory, Augmentation, Haptics},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501840,
author = {Ankenbauer, Sam Addison and Lu, Alex Jiahong},
title = {Making Space for Cultural Infrastructure: The Breakdown and Maintenance Work of Independent Movie Theaters During Crisis},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501840},
doi = {10.1145/3491102.3501840},
abstract = {Independent movie theaters (IMTs) are a part of the cultural infrastructure that offers shared spaces for patron communities to access, share, and engage with cultural artifacts. In light of the COVID-19 pandemic, IMTs were mandated to shut down, resulting in unanticipated infrastructural breakdown. Drawing insights from a preliminary survey and interviews with staff members from 18 IMTs in the U.S., this paper attends to how this breakdown disrupted art and community engagement within patron communities. We investigate the sociotechnical practices of maintaining cultural infrastructure through 1) collaborating with community partners and external stakeholders, 2) screening films through online virtual cinema platforms, and 3) retaining community members through online platforms. Our work highlights the tensions and invisible human labor in this maintenance work. Together, this work intends to foreground cultural infrastructure and discuss how HCI can support and contribute to the design and oft-invisible maintenance of cultural infrastructure.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {508},
numpages = {13},
keywords = {infrastructuring work, materiality, cultural infrastructure, symbolic meaning, cultural spaces, COVID-19, Infrastructure},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501833,
author = {Chalhoub, George and Sarkar, Advait},
title = {“It’s Freedom to Put Things Where My Mind Wants”: Understanding and Improving the User Experience of Structuring Data in Spreadsheets},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501833},
doi = {10.1145/3491102.3501833},
abstract = {Despite efforts to augment or replace the 2-dimensional spreadsheet grid with formal data structures such as arrays and tables to ease formula authoring and reduce errors, the flexible grid remains overwhelmingly successful. Why? We interviewed a diverse sample of 21 spreadsheet users about their use of structure in spreadsheets. It emerges that data structuring is subject to a complex network of incentives and constraints, including factors extrinsic to spreadsheets such as the user’s expertise, auxiliary tools, and collaborator needs. Moreover, we find that table columns are an important abstraction, and that operations such as conditional formatting, data validation, and formula authoring can be implemented on table columns, rather than cell ranges. To probe this, we designed 4 click-through prototypes for a follow-up study with 20 participants. We found that although column operations improved the value proposition of structured tables, they are unlikely to supplant the advantages of the flexible grid.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {585},
numpages = {24},
keywords = {user experience, structure, spreadsheets, data},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501826,
author = {Zhang, Wencan and Lim, Brian Y},
title = {Towards Relatable Explainable AI with the Perceptual Process},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501826},
doi = {10.1145/3491102.3501826},
abstract = {Machine learning models need to provide contrastive explanations, since people often seek to understand why a puzzling prediction occurred instead of some expected outcome. Current contrastive explanations are rudimentary comparisons between examples or raw features, which remain difficult to interpret, since they lack semantic meaning. We argue that explanations must be more relatable to other concepts, hypotheticals, and associations. Inspired by the perceptual process from cognitive psychology, we propose the XAI Perceptual Processing Framework and RexNet model for relatable explainable AI with Contrastive Saliency, Counterfactual Synthetic, and Contrastive Cues explanations. We investigated the application of vocal emotion recognition, and implemented a modular multi-task deep neural network to predict and explain emotions from speech. From think-aloud and controlled studies, we found that counterfactual explanations were useful and further enhanced with semantic cues, but not saliency explanations. This work provides insights into providing and evaluating relatable contrastive explainable AI for perception applications.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {181},
numpages = {24},
keywords = {contrastive explanations, Explainable AI, vocal emotion, audio},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501821,
author = {Gruenefeld, Uwe and Auda, Jonas and Mathis, Florian and Schneegass, Stefan and Khamis, Mohamed and Gugenheimer, Jan and Mayer, Sven},
title = {VRception: Rapid Prototyping of Cross-Reality Systems in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501821},
doi = {10.1145/3491102.3501821},
abstract = {Cross-reality systems empower users to transition along the reality-virtuality continuum or collaborate with others experiencing different manifestations of it. However, prototyping these systems is challenging, as it requires sophisticated technical skills, time, and often expensive hardware. We present VRception, a concept and toolkit for quick and easy prototyping of cross-reality systems. By simulating all levels of the reality-virtuality continuum entirely in Virtual Reality, our concept overcomes the asynchronicity of realities, eliminating technical obstacles. Our VRception Toolkit leverages this concept to allow rapid prototyping of cross-reality systems and easy remixing of elements from all continuum levels. We replicated six cross-reality papers using our toolkit and presented them to their authors. Interviews with them revealed that our toolkit sufficiently replicates their core functionalities and allows quick iterations. Additionally, remote participants used our toolkit in pairs to collaboratively implement prototypes in about eight minutes that they would have otherwise expected to take days.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {611},
numpages = {15},
keywords = {Prototyping, Cross-Reality Systems, Augmented Reality, Virtual Reality, Transitional Interfaces},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@proceedings{10.1145/3491102,
title = {CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {New Orleans, LA, USA}
}

