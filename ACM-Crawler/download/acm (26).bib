@inproceedings{10.1145/3334480.3375028,
author = {Arora, Rahul},
title = {Creative Expression with Immersive 3D Interactions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375028},
doi = {10.1145/3334480.3375028},
abstract = {Virtual and augmented realities (VR/AR) allow artists to create 3D content in a three-dimensional space — both display and inputs are 3D. Getting rid of 2D proxies such as screens and graphic tablets removes a significant barrier from 3D creation and allows artists to create more intuitively, and potentially more efficiently. However, creating in VR/AR introduces new control, precision, and ergonomic challenges. Designing interactive tools for 3D creation is therefore non-trivial. A deep understanding of human factors, user preferences, as well as biases stemming from users' experience with 2D tools is essential to develop effective creative tools for VR/AR. My research combines exploratory user studies and technical advancements to build novel tools for creating 3D content in immersive spaces. I present two computer graphics applications which utilize 3D interactions to improve existing creative workflows and devise novel ones for visual creative expression in three-dimensions. The first studies concept sketching, while the second explores animation of dynamic physical phenomena. I then describe my ongoing work and planned future work on other creative applications.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {immersive reality, creative tools, virtual and augmented realities, 3d interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383155,
author = {Piantella, Benedetta and Nathanson, Alex and Brain, Tega and Ohshiro, Keita},
title = {Solar-Powered Server: Designing for a More Energy Positive Internet},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383155},
doi = {10.1145/3334480.3383155},
abstract = {User Experience designers, software engineers and computer scientists alike are rarely tasked with thinking about the environmental impact and resource consumption of their design decisions, both when creating online platforms and experiences and when publishing multimedia content. Furthermore, free or low-cost web and hosting services encourage designers and users alike to overlook the substantial energy footprint of their online behaviors and interactions. The Solar-Powered Server is as a system designed to more deeply investigate the power consumption of our online actions and compare different design elements and choices, while experimenting with the intrinsic qualities of renewable energy sources in order to create more resource-efficient content, to make information storage more accessible under low resource conditions and foster more energy positive behaviors.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {sustainability, climate, design, multimedia server, solar, renewable energy sources, green computing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383153,
author = {Han, Yoon Chung and Nguyen, Nhat},
title = {The Roads of Your Veins: Visualizing Map and Vein Data Matching},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383153},
doi = {10.1145/3334480.3383153},
abstract = {The roads of your veins is an interactive biometric-data artwork that allows participants to scan their veins and find the roads that match their vein lines. The vein data as one of the fascinating forms of biometric data contain uniquely complicated lines that resemble the roads and paths surrounding us. The roads resemble how our vein lines are interconnected and how the blood circulates in our bodies in various directions, at various speeds, and in different conditions. This new artwork explores the line segmentation and the structure of veins and compares them to roads in the real world. Through this project, users can explore the correlation between individuals and environments using the hidden patterns under the skin and the vein recognition techniques and image processing. This project also has the potential to lead the way in the interpretation of complicated datasets while providing aesthetically beautiful and mesmerizing visualizations.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {interactive biometric data art, digital art, roads, template matching, biometric data, vein, environments, interactive art, map data visualization},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383138,
author = {Reipschl\"{a}ger, Patrick and Engert, Severin and Dachselt, Raimund},
title = {Augmented Displays: Seamlessly Extending Interactive Surfaces With Head-Mounted Augmented Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383138},
doi = {10.1145/3334480.3383138},
abstract = {We present Augmented Displays, a new class of display systems combining high-resolution interactive surfaces with head-coupled Augmented Reality. This extends the screen estate beyond the display and enables placing AR content directly at the display's borders or within the real environment. Furthermore, it enables people to interact with AR objects with natural pen and touch input in high precision on the surface. This combination allows a variety of interesting applications. To illustrate them, we present two use cases: An immersive 3D modeling tool and an architectural design tool. Our goal is to demonstrate the potential of Augmented Displays as a foundation for future work in the design space of this exciting new class of systems.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {touch+pen interaction, augmented reality, 3D modeling, interactive surfaces, augmented displays, design, designar, architecture},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383096,
author = {Narain, Jaya and Ananthabhotla, Ishwarya and Mendez, Samuel and Taylor, Cameron and Siu, Hosea and Brugnaro, Lora and Mallozzi, Adriana},
title = {ATHack: Co-Design and Education in Assistive Technology Development},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383096},
doi = {10.1145/3334480.3383096},
abstract = {ATHack, an annual assistive technologies hackathon at MIT, is unique in that community members living with disabilities (co-designers) propose projects and work with hackers to create prototypes over a two-week period. Since 2014, over 75 co-designers and 400 students have participated in ATHack. We present an overview of the program goals and implementation and share our reflections on the strengths and challenges surrounding the event as organizers, participants, and co-designers. Our reflections include that open communication between co-designers and participants is crucial, and that working on well-scoped, feasible projects is motivating for participants. From a survey (n=48) of ATHack participants from 2014-2019, 89% of respondents would recommend the event and 75% reported that they learned about disability and user-centered design. Our reflections suggest that the collaborative hackathon model can engage students spark innovations in accessible interfaces. We hope this report will inspire and guide others in implementing similar educational and design initiatives.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {co-design, assistive technology, accessibility education, design methodology, education},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383080,
author = {Kuzminykh, Anastasia and Rintel, Sean},
title = {Low Engagement As a Deliberate Practice of Remote Participants in Video Meetings},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383080},
doi = {10.1145/3334480.3383080},
abstract = {Many employees who join work video meetings remotely are frustrated by technological constraints on their engagement. While we should seek to deepen engagement for those who want it, in this paper we explore how low engagement by remote employees in video meetings can also be a social choice. Employees don't always need to engage fully in all or part of a meeting, and they use the technology to help communicate that choice. We argue that video meeting systems should expand the spectrum of engagement levels for remote meeting participants.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {attention, video, meeting, teleconferencing, engagement},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383066,
author = {Chang, Hsiu-Chi and Chang, Yung-Ju and Newman, Mark W. and Lin, Chih-Hsin},
title = {Combining Participatory and ESM: A Hybrid Approach to Collecting Annotated Mobility Data},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383066},
doi = {10.1145/3334480.3383066},
abstract = {Collecting continual labeled activity data entails considerable effort from users to label a series of activity data. We propose Checkpoint-and-Remind (CAR), a hybrid approach that combines participatory (PART) and context-trigger ESM labeling (ESM). Checkpoint-and-Remind has the advantage of user control but reduces users' burden in recording activities. Meanwhile, it features a context-trigger mechanism of ESM as a backup to remind users of labeling. Our preliminary evaluation of CAR with nine participants, who collected and labeled their mobility activity data for 15 weekdays, showed that compared with PART and ESM, participants collected a larger amount of annotated mobility data using CAR. In addition, participants had a higher annotation rate when using CAR than when using ESM. Our results show that the hybrid approach that combines manual and automated recording is promising. Our future work is validating these results and measure more metrics related to compliance with more participants.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {label, field experiment, activity collection, transportation, annotation, wearable camera, ground truth},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383053,
author = {Sun, Lingyun and Li, Jiaji and Chen, Yu and Yang, Yue and Tao, Ye and Wang, Guanyun and Yao, Lining},
title = {4DTexture: A Shape-Changing Fabrication Method for 3D Surfaces with Texture},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383053},
doi = {10.1145/3334480.3383053},
abstract = {4D printing with a hobbyist FDM printer has enabled a rapid fabrication and self-assembly process for 3D shapes. Researchers have leveraged novel structure design and material techniques to create a wide range of 4D shapes. Meanwhile, 4D printing texture (i.e., shape-changing texture) on objects which could easily augment the haptic sensation, has drawn more attention to this field. In this paper, we introduce 4DTexture, a novel design and fabrication approach that integrates texture design through the 4D printing process. Compared to conventional 3D printing surfaces with texture, which usually requires support structures, 4DTexture can effectively reduce production material, time and the post-process effort after printing. Specifically, 4DTexture prints flat substrates with a customized texture design on its top surfaces, which can easily be triggered and can self-morph to target 3D shapes. Overall, our approach enables the design and fabrication of 3D surfaces with texture and can be leveraged by designers and researchers in the field of personal fabrication.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {texture, 3D printing, 4D printing, haptic design, shape-changing interfaces},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383052,
author = {Park, Sangmin and Kim, Hyeonkyu and Kim, Jimoon and Jang, Yoonho and Han, Sangsun and Aan, Hojun and Kim, Kibum},
title = {L-Visor: Visor Input Device for Labo Head-Mounted Display},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383052},
doi = {10.1145/3334480.3383052},
abstract = {Among VR devices on the market, 'Nintendo Labo VR Kit (Labo VR)' has various pieces of DIY (Do-It-Yourself) hardware which are constructed from corrugated cardboard blueprints. While using the Labo VR, the user must hold the Labo HMD with both hands and this prevents the simultaneous use of other input devices. To overcome this limitation, we developed L-Visor which mimics Labo VR HMD but frees the hands to widen the virtual reality experience. In addition, we developed four prototype games for use with L-Visor. The results of our pilot user study showed that participants had positive impressions of L-Visor, because they felt L-Visor was intuitively consistent with the game content. This paper shows how to expand DIY's value in VR by creating a new cardboard visor input device for the Labo head-mounted display and by customizing game contents which allow users to interact with virtual environments in their own way.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {do-it-yourself, virtual reality, Labo, visor},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383051,
author = {Hind, Michael and Houde, Stephanie and Martino, Jacquelyn and Mojsilovic, Aleksandra and Piorkowski, David and Richards, John and Varshney, Kush R.},
title = {Experiences with Improving the Transparency of AI Models and Services},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383051},
doi = {10.1145/3334480.3383051},
abstract = {AI models and services are used in a growing number of high-stakes areas, resulting in a need for increased transparency. Consistent with this, several proposals for higher quality and more consistent documentation of AI data, models, and systems have emerged. Little is known, however, about the needs of those who would produce or consume these new forms of documentation. Through semi-structured developer interviews, and two document-creation exercises, we have assembled a clearer picture of these needs and the various challenges faced in creating accurate and useful AI documentation. Based on the observations from this work, supplemented by feedback received during multiple design explorations and stakeholder conversations, we make recommendations for easing the collection and flexible presentation of AI facts to promote transparency.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {AI governance, AI transparency, documentation, factsheets},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383042,
author = {Georges, Vanessa and Courtemanche, Fran\c{c}ois and Fredette, Marc and Doyon-Poulin, Philippe},
title = {Emotional Maps for User Experience Research in the Wild},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383042},
doi = {10.1145/3334480.3383042},
abstract = {While most traditional user experience (UX) evaluation methods (e.g., questionnaires) have made the transition to the "wild", physiological measurements still strongly rely upon controlled lab settings. As part of an ongoing research agenda, this paper presents a novel approach for UX research which contributes to this transition. The proposed method triangulates GPS and physiological data to create emotional maps, which outline geographical areas where users experienced specific emotional states in outdoor environments. The method is implemented as a small portable recording device, and a data visualization software. A field study was conducted in an amusement park to test the proposed approach. Emotional maps highlighting the areas where users experienced varying levels of arousal are presented. We also discuss insights uncovered, and how UX practitioners could use the approach to bring their own research into the wild.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {user experience, in the wild methods, data visualization, emotion evaluation, heat maps, physiological measures},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383013,
author = {Tsai, Wenn-Chieh and Chung, David and Liu, MengChi and Kong, Bowen and Huang, Chun-Cheng and Liang, Rung-Huei},
title = {Designing a Speculative Kit for Technology Imagination with Makers},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383013},
doi = {10.1145/3334480.3383013},
abstract = {Recent studies have articulated that DIY and the maker culture enrich practice-led HCI communities. Drawing on the specialties, intrinsical playfulness, and tangibility of the maker culture, we took a participatory and design fiction approach to technology imagination with a local maker community. We made a Speculative Kit composed of four series of catalogs and props of fictional products to embody the knowledge produced by an IoT research center. The tool kit will be used in situated making activities for technology practitioners to create alternatives for emerging technologies.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {speculation, maker culture, technology imagination, design fiction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383009,
author = {Yu, Bingjie and Seering, Joseph and Spiel, Katta and Watts, Leon},
title = {"Taking Care of a Fruit Tree": Nurturing as a Layer of Concern in Online Community Moderation},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383009},
doi = {10.1145/3334480.3383009},
abstract = {Care in communities has a powerful influence on potentially disruptive social encounters. Practising care in moderation means exposing a group's core values, which, in turn, has the potential to strengthen identity and relationships in communities. Dissent is as inevitable in online communities as it is in their offline counterparts. However, dissent can be productive by sparking discussions that drive the evolution of community norms and boundaries, and there is value in understanding the role of moderation in this process. Our work draws on an exploratory analysis of moderation practices in the MetaFilter community, focusing on cases of intervention and response. We identify and analyse MetaFilter moderation with the metaphor: "taking care of a fruit tree", which is quoted from an interview with moderators on MetaFilter. We address the relevance of care as it is evidenced in these MetaFilter exchanges, and discuss what it might mean to approach an analysis of online moderation practices with a focus on nurturing care. We consider how HCI researchers might make use of care-as-nurture as a frame to identify multi-faceted and nuanced concepts characterising dissent and to develop tools for the sustainable support of online communities and their moderators.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {care, online communities, moderation, wmpathy, community norms},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383000,
author = {Xu, Ying and Warschauer, Mark},
title = {"Elinor Is Talking to Me on the Screen!" Integrating Conversational Agents into Children's Television Programming},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383000},
doi = {10.1145/3334480.3383000},
abstract = {Science-oriented television and video programming can be an important source of science learning for young children. However, the educational benefits of television have long been limited by children not being able to interact with the content in a contingent way. This project leverages an intelligent conversational agent -an on-screen character capable of verbal interaction-to add social contingency into children's experience watching science videos. This conversational agent has been developed in an iterative process and embedded in a new PBS KIDS science show "Elinor Wonders Why." This Late Breaking Work presents the design of the conversational agent and reports findings from a field study that has proven feasibility of this approach. We also discuss our planned future work to examine the agent's effectiveness in enhancing children's engagement and learning.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {social learning, screen media, children, science learning, conversational agents},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382979,
author = {Mubin, Omar and Kharub, Isha and Khan, Aila},
title = {Pepper in the Library" Students' First Impressions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382979},
doi = {10.1145/3334480.3382979},
abstract = {Humanoid robots through their embodied features and range of interactivity are proving to be effective as service or information disseminating agents. However in the Australian context, the deployment and evaluation of robots in public spaces is limited. In this study, we report on an observation based exploratory study of university students interaction with the Pepper humanoid robot over 8 days in the library of an Australian university. The students' first impressions of Pepper using the top-of-mind association showed that they were in general wary and scared of service robots. Many considered Pepper as creepy. Their positive remarks were related to the novelty of Pepper's features and technology. In conclusion, we speculate on the results obtained and what they mean for the integration of humanoid robots in mainstream Australian society.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {public spaces, pepper, social robots, library},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382978,
author = {Jeon, Youngseung and Jin, Seungwan and Kim, Bogoan and Han, Kyungsik},
title = {FashionQ: An Interactive Tool for Analyzing Fashion Style Trend with Quantitative Criteria},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382978},
doi = {10.1145/3334480.3382978},
abstract = {Fashion is one of the areas in which decision-making relies on the subjective experiences of fashion professionals. Fashion style trend analysis is an important process in fashion; however, due to a lack of quantitative style criteria, analysis results tend to vary by fashion professionals, often making it difficult to apply the analysis results to other fashion cases. In this paper, we propose an interface that provides fashion professionals with objective support which can aid in making more generalizable decisions on fashion analysis. Through interviews and interactions with fashion professionals, we identified quantitative-style classification criteria and analysis requirements in decision making. Based on such design guidelines, we introduce FashionQ (Fashion Quant), which provides three main features: A quantitative-based style clustering (FashionQStyle), style trend analysis (FashionQTrend), and style comparison analysis (FashionQMap). Professionals positively evaluated FashionQ, showing its usefulness and feasibility of fashion analysis in the future.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {interactive interface, user-centered design, quantitative fashion style analysis},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382934,
author = {Jin, Sheng and Fan, Min and Wang, Yongchao and Liu, Qi},
title = {Reconstructing Traditional Chinese Paintings with Immersive Virtual Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382934},
doi = {10.1145/3334480.3382934},
abstract = {This paper describes the design of a virtual reality learning environment that reconstructs a traditional Chinese painting, Spring Morning in the Han Palace, using a head-mounted platform. The issues of art styles, enhanced interpretation and interaction design strategies that may impact learning experience are considered. We discuss the future plan for conducting user studies with young undergraduate students.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {design strategies, immersive virtual reality, art and cultural learning, reconstruction, Chinese ancient paintings, cultural heritage},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382928,
author = {Dagan, Ella and Fey, James and Kikkeri, Sanoja and Hoang, Charlene and Hsiao, Rachel and Isbister, Katherine},
title = {Flippo the Robo-Shoe-Fly: A Foot Dwelling Social Wearable Companion},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382928},
doi = {10.1145/3334480.3382928},
abstract = {Here we present Flippo: A social wearable creature prototype. This design is meant to support people to take breaks away from their desks and move, as well as to socialize with others by caring for their creatures. Flippo takes the shape of a soft and fuzzy bug-like creature. It lives on people's shoes and occasionally nudges them when it needs to move and have social interaction with another creature from its species. It does this by making sounds and visual effects and requires that the wearers coordinate shaking their feet and helping the creatures face each other. If Flippo is satisfied with the interaction it displays a light animation and plays 'happy' tunes, and if not it nudges the wearer again. We ran a field study with 13 participants, preliminary results show the potential of the design to encourage and facilitate co-located social interaction.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {social interaction, social wearables, RTD, breaks, co-located, robotic companion, shoe-accessory, foot interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382917,
author = {Ahmetoglu, Yoana and Brumby, Duncan P. and Cox, Anna L.},
title = {Time Estimation Bias in Knowledge Work: Tasks With Fewer Time Constraints Are More Error-Prone},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382917},
doi = {10.1145/3334480.3382917},
abstract = {Previous research has found that people often make time estimation errors in their daily planning at work. However, there is limited insight on the types of estimation errors found in different knowledge work tasks. This one-day diary study with 20 academics compared the tasks people aimed to achieve in the morning with what they actually did during the day. Results showed that participants were good at estimating the duration of time-constrained tasks, such as meetings, however they were biased when estimating the time they would spend on less time-constrained tasks. Particularly, the time needed for email and coding tasks was underestimated, whereas the time needed for writing research and planning activities was overestimated. The findings extend previous research by measuring in situ whether some tasks are more prone to time estimation errors than others. Planning and scheduling (AI) tools could incorporate this knowledge to help people overcome these time estimation biases in their work.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {daily planning, time management, time estimation bias, knowledge work, productivity},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382900,
author = {Dey, Rajib and Sultana, Sayma and Razi, Afsaneh and Wisniewski, Pamela J.},
title = {Exploring Smart Home Device Use by Airbnb Hosts},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382900},
doi = {10.1145/3334480.3382900},
abstract = {An increasing number of Airbnb hosts are using smart home devices to manage their properties; as a result, Airbnb guests are expressing concerns about their privacy. To reconcile the tensions between hosts and guests, we interviewed 10 Airbnb hosts to understand what smart home devices they use, for what purposes, their concerns, and their unmet needs regarding smart home device usage. Overall, hosts used smart home devices to give remote access to their home to guests and safeguard their investment properties against misuse. They were less concerned about guest privacy and felt that smart home devices provided unique value to guests and, thus, a competitive advantage over other Airbnb properties.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {sharing economy, internet of things, security and privacy, smart home device, Airbnb},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382879,
author = {Schoop, Eldon and Huang, Forrest and Hartmann, Bj\"{o}rn},
title = {SCRAM: Simple Checks for Realtime Analysis of Model Training for Non-Expert ML Programmers},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382879},
doi = {10.1145/3334480.3382879},
abstract = {Many non-expert Machine Learning users wish to apply powerful deep learning models to their own domains but encounter hurdles in the opaque model tuning process. We introduce SCRAM, a tool which uses heuristics to detect potential error conditions in model output and suggests actionable steps and best practices to help such users tune their models. Inspired by metaphors from software engineering, SCRAM extends high-level deep learning development tools to interpret model metrics during training and produce human-readable error messages. We validate SCRAM through three author-created example scenarios with image and text datasets, and by collecting informal feedback from ML researchers with teaching experience. We finally reflect upon our feedback for the design of future ML debugging tools.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {debugging, interactive visualization, tutorial systems, machine learning},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382863,
author = {Cuerdo, Marjorie Ann M. and Melcer, Edward F.},
title = {"I'll Be Back": A Taxonomy of Death and Rebirth in Platformer Video Games},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382863},
doi = {10.1145/3334480.3382863},
abstract = {Failure, often represented through death, is a central aspect of almost every video game. In-game death can drive player perceptions of difficulty and greatly impact the core player experience; however, there is surprisingly limited amounts of research examining how games actually handle this occurrence. We posit that this is a rich, underexplored space with significant implications for player experience and the design of many games. This paper presents our initial exploration into the space of player death and rebirth through the creation of a generalized taxonomy developed from 62 recent platformer games. Our taxonomy consists of five key dimensions: 1) obstacles, 2) death conditions, 3) aesthetics, 4) changes to player progress, and 5) respawn locations.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {in-game death, taxonomy, grounded theory, player experience, games, platformers},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382860,
author = {Degraen, Donald and Schubhan, Marc and Mushkina, Kamila and Makhsadov, Akhmajon and Kosmalla, Felix and Zenner, Andr\'{e} and Kr\"{u}ger, Antonio},
title = {AmbiPlant - Ambient Feedback for Digital Media through Actuated Plants},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382860},
doi = {10.1145/3334480.3382860},
abstract = {To enhance viewing experiences during digital media consumption, both research and industry have considered ambient feedback effects to visually and physically extend the content presented. In this paper, we present AmbiPlant, a system using support structures for plants as interfaces for providing ambient effects during digital media consumption. In our concept, the media content presented to the viewer is augmented with visual actuation of the plant structures in order to enhance the viewing experience. We report on the results of a user study comparing our AmbiPlant condition to a condition with ambient lighting and a condition without ambient effects. Our system outperformed the no ambient effects condition in terms of engagement, entertainment, excitement and innovation and the ambient lighting condition in terms of excitement and innovation.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {ambient effects, user study, ambient interfaces, empathic living media},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382845,
author = {Barczewski, Antoine and Bezerianos, Anastasia and Boukhelifa, Nadia},
title = {How Domain Experts Structure Their Exploratory Data Analysis: Towards a Machine-Learned Storyline},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382845},
doi = {10.1145/3334480.3382845},
abstract = {Exploratory data analysis is an open-ended iterative process, where the goal is to discover new insights. Much of the work to characterise this exploration stems from qualitative research resulting in rich findings, task taxonomies, and conceptual models. In this work, we propose a machine-learning approach where the structure of an exploratory analysis session is automatically learned. Our method, based on Hidden-Markov Models, automatically builds a storyline of past exploration from log data events, that shows key analysis scenarios and the transitions between analysts' hypotheses and research questions. Compared to a clustering method, this approach yields higher accuracy for detecting transitions between analysis scenarios. We argue for incorporating provenance views in exploratory data analysis systems that show, at minimum, the structure and intermediate results of past exploration. Besides helping the reproducibility of the different analyses and their results, this can encourage analysts to reflect upon and ultimately adapt their exploration strategies.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {provenance, storytelling, machine learning, visualization, sensemaking, log analysis, exploratory data analysis},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382792,
author = {Peng, Zhenhui and Mo, Kaixiang and Zhu, Xiaogang and Chen, Junlin and Chen, Zhijun and Xu, Qian and Ma, Xiaojuan},
title = {Understanding User Perceptions of Robot's Delay, Voice Quality-Speed Trade-off and GUI during Conversation},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382792},
doi = {10.1145/3334480.3382792},
abstract = {Conversational robots face the practical challenge of providing timely responses to ensure smooth interactions with users. Thus, those who design and implement robots will need to understand how different levels of delay in response may affect users' satisfaction with the conversation, how to balance the trade-off between a robot's quality of voice and response time, and how to design strategies to mitigate possible negative effects of a long delay. Via an online video-prototype study on a service robot with 94 Chinese participants, we find that users could tolerate up to 4s delay but their satisfaction drops at the 8s delay during both information-retrieval conversations and chitchats. We gain an in-depth understanding of users' preference for the trade-off between the voice quality and the response speed, as well as their opinions on possible robot graphic user interface (GUI) design to alleviate negative user experience with response latency.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {speech synthesis, graphic user interface, voice, delay, human-robot interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3381812,
author = {Tomlinson, Bill},
title = {Suffering-Centered Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381812},
doi = {10.1145/3334480.3381812},
abstract = {Humans are skilled at closing their minds to the suffering of others. This paper argues that, over the past several decades, human computer interaction tools and techniques have both exacerbated and ameliorated this human tendency. It contributes a theoretical framework for thinking about the relationship between HCI and various forms of suffering, and a set of principles to support suffering-centered design — design activities that foreground the suffering of others rather than obscure it. This paper proposes that there is a need for further exploration of ways that HCI can improve the collective human experience by supporting ways to open people's minds to the suffering of others.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–19},
numpages = {19},
keywords = {design, suffering, wellbeing},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375055,
author = {schraefel, m.c. and Tabor, Aaron and Andres, Josh},
title = {Inbodied Interaction 102: Understanding the Selection and Application of Non-Invasive Neuro-Physio Measurements for Inbodied Interaction Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375055},
doi = {10.1145/3334480.3375055},
abstract = {As a means to validate the effects of interaction designs, particularly those involving physiological processes, like: breathing in mindfulness; heartrate in exertion games, and blood flow to the brain for cognitive load assessments, HCI researchers are increasingly turning to body-based signals as signals to quantify effects and guide design decisions. These design decisions can be informed by Inbodied Interaction principles of aligning knowledge of how the body performs optimally (physiologically, neurologically) with our designs. The purpose of this course is to present new-to-HCI neuro-physiological measures including peripheral awareness, deep HRV, and new pre-cortical assessments to open new design opportunities. Students will leave the course with this set of new assessments, as well as practical worked examples of how to choose and apply which measures as best suited for a particular design and evaluation context.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–5},
numpages = {5},
keywords = {inbodied interaction, neurology, physiology, midbrain, cerebellum, measurement, performance},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3375046,
author = {Lewis, Makayla and Sturdee, Miriam},
title = {So You Think You Can't Draw? A Hands-on Introductory Course on Sketching in HCI Techniques},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375046},
doi = {10.1145/3334480.3375046},
abstract = {Hand-drawn sketching is a practice as old as our ancestors. From cave painting to picture-books, we have explored the world with our visual senses. Within Human-Computer Interaction, sketches can be used to document, ideate, and describe concepts between researcher, user, or client. Attendees will leave the course with the confidence to engage actively with sketching on an everyday basis in their research practice.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {sketching, hci, drawing, visual thinking},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3386152,
author = {Strohmeier, Paul},
title = {SIGCHI Outstanding Dissertation Award: Shaping Material Experiences},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3386152},
doi = {10.1145/3334480.3386152},
abstract = {When interacting with materials, we infer many of their properties through tactile stimuli. These stimuli are caused by our manual interaction with the material, they are therefore closely coupled to our actions. Similarly, if we are subjected to a vibrotactile stimulus with a frequency directly coupled to our actions, we do not experience vibration - instead we experience this as a material property. My thesis explores this phenomenon of 'material experience' in three parts. Part I contributes two novel devices, a flexible phone which provides haptic feedback as it is being deformed, and a system which can track a finger and simultaniously provide haptic feedback. Part II investigates how vibration is perceived, when coupled to motion: what are the effects of varying feedback parameters and what are the effects of different types of motion? Part III reflects and contextualizes the findings presented in the previous sections. In this extended abstract I briefly outline the most important aspects of my thesis and questions I've left unanswered, while also reflecting on the writing process.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383152,
author = {Morales Gonz\'{a}lez, Rafael and Freeman, Euan and Georgiou, Orestis},
title = {Levi-Loop: A Mid-Air Gesture Controlled Levitating Particle Game},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383152},
doi = {10.1145/3334480.3383152},
abstract = {Acoustic levitation offers a novel alternative to traditional volumetric displays. With state-of-the-art hand-tracking technology, direct interaction and manipulation of levitating objects in 3D is now possible. Further, adding game-elements like completing simple tasks can encourage participant exploration of new technologies. We have therefore developed a gesture controlled levitating particle game, akin to the classic wire-loop game, that combines all these elements (levitation, hand-tracking, and gameplay) together with physical obstacles. Further, we have designed a gesture input set that constrains false triggering gestures and dropping of the levitating particle.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {game, gesture input, acoustic levitation, ultrasound, wire-loop},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383136,
author = {Huang, Hsin-Yu and Ning, Chih-Wei and Wang, Po-Yao (Cosmos) and Cheng, Jen-Hao and Cheng, Lung-Pan},
title = {Haptic-Go-Round: A Surrounding Platform for Encounter-Type Haptic in Virtual Reality Experiences},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383136},
doi = {10.1145/3334480.3383136},
abstract = {We present Haptic-go-round, a surrounding platform that allows deploying props and devices to provide haptic feedbacks in any direction in virtual reality experiences. The key component of Haptic-go-round is a motorized turntable that rotates the correct haptic device to the right direction at the right time to match what users are about to touch. We implemented a working platform including plug-and-play prop cartridges and a software interface that allow experience designers to agilely add their haptic components and use the platform for their applications.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {virtual reality, props, encounter-type haptic feedback},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383105,
author = {Nilsen, Erik and Safran, Elizabeth and Drake, Peter and Sebok, Bryan},
title = {Playing a Serious Game for Earthquake Preparedness: Effects of Resource Richness and Avatar Choice},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383105},
doi = {10.1145/3334480.3383105},
abstract = {This study investigates the potential for learning about and motivating earthquake preparedness through video game play. 112 participants played a custom-built video game for between 5 and 30 minutes in an experiment involving two avatar selection conditions (choice vs. random assignment) and two avatar power conditions (more resources vs. fewer resources). We assessed pre- and post-test changes in levels of self-efficacy, outcome expectation, and intent to act relating to various preparedness and response actions. We found that playing the game increases these scores significantly in all game conditions immediately after play. Where avatar characteristics were significant, more resources led to higher scores. However, contrary to our predictions, randomly assigned avatars led to higher increases in scores than when players chose and named their avatar. Future studies are planned to explore a variety of other game features designed to maximize motivation and behavior change in young adults.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {social cognition, earthquake preparedness, avatar, self efficacy, serious game},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383091,
author = {Claudino Daffara, Stephanie and Brewer, Anna and Thoravi Kumaravel, Balasaravanan and Hartmann, Bjoern},
title = {Living Paper: Authoring AR Narratives Across Digital and Tangible Media},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383091},
doi = {10.1145/3334480.3383091},
abstract = {Storytelling is an important means for children to build literacy while sharing beliefs, values, and cultural norms. Our work investigates how augmented reality (AR) can fit into creative storytelling practices. We introduce Living Paper, a system for authoring AR narratives that span both digital and tangible media. Our augmented storybook prototype integrates animated AR characters from hand drawings with programmable LED lights that shine through the pages. Living Paper combines the flexibility of digital objects with the tangibility of physical cues to enable the creation of immersive and shareable stories.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {storytelling, tangible interfaces, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383089,
author = {Pomykalski, Patryk and Wo\'{z}niak, Miko\l{}aj P. and Wo\'{z}niak, Pawe\l{} W. and Grudzie\'{n}, Krzysztof and Zhao, Shengdong and Romanowski, Andrzej},
title = {Considering Wake Gestures for Smart Assistant Use},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383089},
doi = {10.1145/3334480.3383089},
abstract = {Smart speakers have become an almost ubiquitous technology as they enable users to access conversational agents easily. Yet, the agents can only be activated using specific voice commands, i.e. a wake word. This, in turn, requires the device to constantly listen to and process sound, which represents a privacy issue for some users. Further, using the trigger word for the agent in a conversation with another human may lead to accidental triggers. Here, we propose using gestural triggers for conversational agents. We conducted gesture elicitation to identify five candidate gestures. We then conducted a user study to investigate the acceptability and effort required to perform the gestures. Initial results indicate that the snap gesture shows the most potential. Our work contributes initial insights on using smart speakers with ubiquitous sensing.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {smart assistant, smart speaker, gestural input, gesture elicitation, gesture},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383079,
author = {Qian, Jing and Young-Ng, Meredith and Li, Xiangyu and Cheung, Angel and Yang, Fumeng and Huang, Jeff},
title = {Portalware: A Smartphone-Wearable Dual-Display System for Expanding the Free-Hand Interaction Region in Augmented Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383079},
doi = {10.1145/3334480.3383079},
abstract = {Free-hand manipulation in smartphone augmented reality (AR) enables users to directly interact with virtual contents using their hands. However, human hands can ergonomically move in a broader range than a smartphone's field of view (FOV) can capture, requiring users to be aware of the limited usable interaction and viewing regions at all times. We present Portalware, a smartphone-wearable dual-display system that expands the usable interaction region for free-hand manipulation and enables users to receive visual feedback outside the smartphone's view. The wearable is a lightweight, low-cost display that shares the same AR environment in real-time with the smartphone.This setup empowers AR applications such as mid-air drawing and object manipulation by providing a 180-degree horizontal interaction region in front of the user. Other potential applications include wearing the smartphone like a pendant while using Portalware to continue interacting with AR objects. Without having to hold their phone up with their hand, users can benefit from resting their arms as needed. Finally, we discuss usability explorations, potential interactions, and future plans for empirical studies.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {augmented reality, wearable, 3D manipulation, free-hand manipulation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383036,
author = {Eguchi, Soya and Yazaki, Yukako and Kato, Riku and Arita, Yusaku and Moriya, Takumi and Tanaka, Hiroya},
title = {Proto-Chair: Posture-Sensing Smart Furniture with 3D-Printed Auxetics},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383036},
doi = {10.1145/3334480.3383036},
abstract = {Public space/furniture are amongst the new domains to apply a data-driven approach of design intervention and improvements. Open space is essentially dynamic, livable and interactive. Various types of people spend time for various purposes. Therefore, the "Measure-Test-Refine" loop is applicable for improving open spaces gradually.In this research, we developed our original smart chair called "Proto-Chair" that can contribute to the new design method of public space. Our chair is made with 3D-printed soft auxetic patterns. It is morphable allowing users to sit in various ways. Also, our chair is equipped with two sensors, which collect data stream to distinguish four different states of the chair. Long-term sensor stream can be stored and used to refine the furniture.In this paper, we propose our concept, prototypes, sensing methods and results of experiments. We also introduce our future vision of a sensor-based public design platform.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {auxetic pattern, 3D printing, public furniture, morphing design, implicit interaction},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383025,
author = {Upadhyay, Pooja},
title = {Comparing Non-Visual and Visual Information Foraging on The Web},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383025},
doi = {10.1145/3334480.3383025},
abstract = {Graphical user web interfaces (GUIs) afford visual consumption and sensemaking of information, but present challenges for auditory, and often sequential, information seeking for people using screen readers. Information foraging theory illustrates that users' information behavior is guided by the use of information scent (mostly visual in GUIs) to assess value and cost of accessing information relevant to their goal, and rational decisions to maximize gain of information. Previous research about adaptive browsing behavior of screen reader users is associated with a lack of webpage usability. In this study, we observed and compared the information seeking behavior of ten sighted and ten screen reader users. Findings show that screen reader users demonstrate adapted mental models of the visual information search interface. Additionally, their adaptive search result exploration strategies in the context of query intent highlight key concern areas in specific parts of the search process.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {assistive technology, accessibility, adaptive browsing strategies, non-visual web access, non-visual search behavior, information retrieval, non-visual information foraging, information behavior},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383021,
author = {Zhang, Min and Bandara, Arosha K. and Price, Blaine and Pike, Graham and Walkington, Zoe and Elphick, Camilla and Frumkin, Lara and Philpot, Richard and Levine, Mark and Stuart, Avelie and Nuseibeh, Bashar},
title = {Designing Technologies for Community Policing},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383021},
doi = {10.1145/3334480.3383021},
abstract = {Community policing faces a combination of new challenges and opportunities due to both citizens and police adopting new digital technologies. However, there is limited scholarly work providing evidence for how technologies assist citizens' interactions with the police. This paper reports preliminary findings from interviews with 13 participants, both citizens and police officers, in England. We recognize four key types of actors in the current practice of community policing, alongside existing technologies and challenges faced by citizens and the police. We conclude with three design implications for improving citizen-police engagement.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {community policing, trust, crime, collective action},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383012,
author = {Mottelson, Aske and Djurslev, Anders Thrue},
title = {Disseminating Scientific Development Through Artistic Practice: The HCI History Poster},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383012},
doi = {10.1145/3334480.3383012},
abstract = {This paper presents two contributions: (i) an algorithm for generating visualizations of the historical interfield relations of a topic within a scientific corpus by parsing scientific literature and linking it using citation metrics, and (ii) a poster generated using aforementioned algorithm, that depicts the historical development of 'interaction' within the field of Human-Computer Interaction, based on all CHI papers and their citation data from Google Scholar. Furthermore, we discuss possibilities and limitations of disseminating scientific developments through artistic practice.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {scientometrics, poster, HCI, visualization, art history},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383008,
author = {Mechtley, Adam},
title = {API as Curriculum: Designing High-Level API Affordances as Instructional Scaffolds},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383008},
doi = {10.1145/3334480.3383008},
abstract = {APIs have been recognized in the CHI community and beyond as designed objects worthy of usability analysis. Some work in this vein has investigated the learnability of APIs in particular. Drawing on activity theory, we argue that APIs can also potentially have broader learning consequences for their users. By mediating interactions with code, APIs can shape their users' understanding of computing problems. We thus suggest that, by envisioning high-level API affordances as scaffolds, API designers can not only enhance users' productivity, but they can also help drive adoption of software components attempting to radically innovate on their past inheritance. We propose scaffold design recommendations that can augment existing API usability frameworks.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {application programming interface, API usability, data-oriented design, computing education},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3383003,
author = {Shin, Jaeeun and Cho, Jundong and Lee, Sangwon},
title = {Please Touch Color: Tactile-Color Texture Design for The Visually Impaired},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383003},
doi = {10.1145/3334480.3383003},
abstract = {This study aims at developing a 3D tactile system to help visually impaired people recognize colors via texture perception when they appreciate art paintings. The system is designed based on fundamentals of color perception, tactile acuity, and braille information. The scheme of tactile-color texture was designed to be intuitively learnable for the visually impaired, who has a lack of color perception. The result of focus interviews showed that visually impaired people could significantly distinguish and recognize the variation of color by grating textures. The study of color perception from grating texture indicates tactile efficiency of color recognition as a method for appreciating art painting. Regarding the practical approach not only can be used to improve accessibilities for blind people of art museums but can be references to develop 3D printed haptic devices.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {accessibility, 3D printed model, cross-modal association, universal design, the visually impaired, color recognition, haptic perception},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382996,
author = {Mohaddesi, Omid and Machado, Tiago and Harteveld, Casper},
title = {Learning from Gamettes: Imitating Human Behavior in Supply Chain Decisions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382996},
doi = {10.1145/3334480.3382996},
abstract = {Gamettes are playful tools for agent-based participatory simulation and have shown to be valid for collecting rich behavioral data from human decision-makers. However, there is still a question that how such data can be used to create or update agent-based and behavioral models. In this paper, we evaluate and compare the performance of different methods for imitating human behavior. We use extracted data from gamettes in an empirical study on supply chain decisions, and compare the performance of a nonlinear regression model with two imitation learning algorithms. Our results demonstrate that each method is capable of modeling and thus predicting human behavior by considering multiple trajectories from different players.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {gamette, decision-making, supply chain, imitation learning, human behavior},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382974,
author = {Olson, Danielle Marie and Soliman, Nouran and Wang, Angela and Price, Magdalena and Sahu, Rita and Harrell, D. Fox},
title = {Breakbeat Narratives: A Personalized, Conversational Interactive Storytelling System for Museum Education},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382974},
doi = {10.1145/3334480.3382974},
abstract = {We introduce a novel interactive narrative exhibit supporting general public learning about Hip Hop culture and history developed as a collaboration of the MIT Center for Advanced Virtuality, the Universal Hip Hop Museum, and Microsoft and supported by the TunesMap Educational Foundation and internationally known Afrofuturist artists Black Kirby. The exhibit's narrative system is personalized by categorizing users based on evaluating their input data light of a social psychology-based model based in musical identity theory. The system uses user input to determine which interactive narrative and customized music playlist to present to the user. The system has been deployed as the central interactive display within the [R]Evolution of Hip Hop for an exhibit of the Universal Hip Hop Museum. Future work will involve analysis of user feedback data from the thousands of local and international exhibit visitors to determine the impact of personalization on visitor engagement, satisfaction, and learning.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {personalization, educational technology, learning, museums, interactive narrative technologies},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382933,
author = {Ikematsu, Kaori and Tsubouchi, Kota and Yamanaka, Shota},
title = {PredicTaps: Latency Reduction Technique for Single-Taps Based on Recognition for Single-Tap or Double-Tap},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382933},
doi = {10.1145/3334480.3382933},
abstract = {In general, a system with touch input waits for a certain period of time (typically 350 -- 500 ms) for a subsequent tap to determine whether the initial tap was a single tap or the first tap of a double tap. This results in latency of hundreds of milliseconds for a single-tap event. To reduce the latency, we propose a novel machine-learning-based tap recognition method called "PredicTaps". In the PredicTaps method, by using touch-event data gathered from the capacitive touch surface, the system immediately predicts whether a detected tap is a single tap or the first tap of a double tap. Then, in accordance with the prediction, the system determines whether to execute a single-tap event immediately or wait for a subsequent second tap. This paper reports the feasibility study of PredicTaps.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {touch inputs, double-tap, latency, single-tap},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382923,
author = {Freeman, Guo and Zamanifard, Samaneh and Maloney, Divine and Adkins, Alexandra},
title = {My Body, My Avatar: How People Perceive Their Avatars in Social Virtual Reality},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382923},
doi = {10.1145/3334480.3382923},
abstract = {The perception and experience of avatars has been critical to understand the social dynamics in virtual environments, online gaming, and collaborative systems. How would emerging sociotechnical systems further complicate the role of avatars in our online social lives? In this paper we focus on how people perceive and understand their avatars in social virtual reality (VR) - 3D virtual spaces where multiple users can interact with one another through VR head-mounted displays (HMDs). Based on 30 interviews, we identified three key themes emerging in people's perceptions and experiences of their avatars across various social VR applications. Our study contributes to further improving social VR technologies and better understanding emerging social interaction dynamics and consequences within social VR.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {virtual worlds, avatar, social virtual reality},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382898,
author = {Dove, Graham and Seals, Ayanna and Nov, Oded},
title = {Socially-Informed Sorting for Guiding Personal Finance Choices},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382898},
doi = {10.1145/3334480.3382898},
abstract = {Planning for personal financial security is complex, and better-informed investors are likely to make better investment choices. However, the number of alternatives presented by most personal finance platforms pose novices a dual challenge of choice overload coupled with a lack of domain knowledge. We present a study investigating socially-informed sorting, in which users are offered subtle guidance in the form of visual and textual cues that aim to encourage information-seeking when choosing between large numbers of options. We evaluate this approach in an online experiment in which participants go through ten rounds of retirement saving budget allocation, making choices among 77 different funds. While we found that this technique increased novice investors' information-seeking, and offered significant benefit in terms of return performance, it may also be detrimental for more experienced investors. We discuss these findings in light of prior research.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {choice overload, social search, personal finance},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382877,
author = {DiCosola III, Blake M. and Neff, Gina},
title = {Using Social Comparisons to Facilitate Healthier Choices in Online Grocery Shopping Contexts},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382877},
doi = {10.1145/3334480.3382877},
abstract = {This exploratory research examines how we might nudge consumers towards making healthier food choices in online grocery shopping or other digitally mediated food consumption contexts. Our pilot study investigated how different forms of social comparisons could be used to encourage consumers to reduce the number of calories contained in their online grocery basket. Our findings show that participants who were less interested in trying new diets were more willing to reduce calories when presented with a comparison to people unlike them, an out-group member comparison, while those who were interested in trying new diets were more willing to reduce calories regardless of social comparison type. These findings imply that one size does not fit all when nudging. More research is needed to see how social comparisons influence the effectiveness of digital health behavior projects.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {health, diet, social influence, intervention, nutrition, digital, nudging, online, consumer behavior, choice, persuasive communication, shopping, decision making, food},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382867,
author = {Lee, Juyoung and Lee, Myungho and Kim, Gerard Jounghyun and Hwang, Jae-In},
title = {Effects of Virtual Gait Visualization in Walk-in-Place on Body Ownership and Presence},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382867},
doi = {10.1145/3334480.3382867},
abstract = {We investigate the effects of different ways of visualizing the virtual gait of the avatar in the context of Walk-in-Place (WIP) based navigation in a virtual environment (VE). In our study, participants navigated through a VE using the WIP method while inhabiting an avatar. We varied the leg motions of the avatar while performing the WIP gesture: (1) Fixed Body the legs stood still; (2) Prerecorded Animation the legs moved in a fixed predetermined pace (plausible but not in accordance to that of the user in general); (3) Synchronized Motion the legs moved according (synchronized) to the those of the users. Our results indicate that the sense of presence improved significantly by visualizing the leg movement, synchronized or not. This in turn further enhanced the sense of body ownership especially when the leg motion was synchronized to that of the user (Synchronized Motion). However, a significant level of simulation sickness was reported when the virtual leg motion did not match the user's (Fixed Body and Prerecorded Animation). We discuss the implications for representing the avatar locomotion in immersive virtual environments.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {virtual reality, body ownership, walk-in-place, presence},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382856,
author = {Kim, Jung-Hwa and Jeong, Jin-Woo},
title = {A Preliminary Study on Performance Evaluation of Multi-View Multi-Modal Gaze Estimation under Challenging Conditions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382856},
doi = {10.1145/3334480.3382856},
abstract = {In this paper, we address gaze estimation under practical and challenging conditions. Multi-view and multi-modal learning have been considered useful for various complex tasks; however, an in-depth analysis or a large-scale dataset on multi-view, multi-modal gaze estimation under a long-distance setup with a low illumination is still very limited. To address these limitations, first, we construct a dataset of images captured under challenging conditions. And we propose a simple deep learning architecture that can handle multi-view multi-modal data for gaze estimation. Finally, we conduct a performance evaluation of the proposed network with the constructed dataset to understand the effects of multiple views of a user and multi-modality (RGB, depth, and infrared). We report various findings from our preliminary experimental results and expect this would be helpful for gaze estimation studies to deal with challenging conditions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {deep neural networks, multi-modal interaction, gaze estimation, multi-view learning},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382834,
author = {Hoskin, Elizabeth and Singh, Aditi and Oddy, Nicola and Schneider, Adrian L. Jessup and Trepanier, Gabrielle and Trudel, Chantal and Girouard, Audrey},
title = {Assessing the Experience of People with Autism at the Canada Science and Technology Museum},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382834},
doi = {10.1145/3334480.3382834},
abstract = {To provide universal accessibility, public community spaces such as museums must be designed considering the experience of all patrons, including visitors living with Autism Spectrum Disorder. To develop a better understanding of the experience of visitors with autism at the Canada Science and Technology Museum, we invited four school children and one adult male for a visit, all of whom identified as being on the spectrum. They were joined by their support persons. We interviewed the adult, his caregiver and the teaching staff accompanying the school children. We analyzed our interviews and observation notes using thematic analysis to formulate key findings and suggestions to enhance the experience for autistic people. They include adding elements at a variety of developmental levels, offering options to reduce sensory stimulation, improving navigational resources and providing more resources for support persons.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {autism spectrum disorder, wayfinding, website efficacy, accessibility, museum experience},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

