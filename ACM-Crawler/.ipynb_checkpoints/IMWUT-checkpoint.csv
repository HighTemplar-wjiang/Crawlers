,doi,authors,title,abstract,issue
0,10.1145/3314388,"Sayma Akther, Nazir Saleheen, Shahin Alan Samiei, Vivek Shetty, Emre Ertin, Santosh Kumar",mORAL: An mHealth Model for Inferring Oral Hygiene Behaviors in-the-wild Using Wrist-worn Inertial Sensors,"We address the open problem of reliably detecting oral health behaviors passively from wrist-worn inertial sensors. We present our model named mORAL (pronounced em oral) for detecting brushing and flossing behaviors, without the use of instrumented toothbrushes so that the model is applicable to brushing with still prevalent manual toothbrushes. We show that for detecting rare daily events such as toothbrushing, adopting a model that is based on identifying candidate windows based on events, rather than fixed-length timeblocks, leads to significantly higher performance. Trained and tested on 2,797 hours of sensor data collected over 192 days on 25 participants (using video annotations for ground truth labels), our brushing model achieves 100% median recall with a false positive rate of one event in every nine days of sensor wearing. The average error in estimating the start/end times of the detected event is 4.1% of the interval of the actual toothbrushing event.","Volume 3 Issue 1, March 2019"
1,10.1145/3314389,"Ling Chen, Yifang Ding, Dandan Lyu, Xiaoze Liu, Hanyu Long",Deep Multi-Task Learning Based Urban Air Quality Index Modelling,"Obtaining comprehensive air quality information can help protect human health from air pollution. Existing spatially fine-grained estimation methods and forecasting methods have the following problems: 1) Only a part of data related to air quality is considered. 2) Features are defined and extracted artificially. 3) Due to the lack of training samples, they usually cannot achieve good generalization performance. Therefore, we propose a deep multi-task learning (MTL) based urban air quality index (AQI) modelling method (PANDA). On one hand, a variety of air quality-related urban big data (meteorology, traffic, factory air pollutant emission, point of interest (POI) distribution, road network distribution, etc.) are considered. Deep neural networks are used to learn the representations of these relevant spatial and sequential data, as well as to build the correlation between AQI and these representations. On the other hand, PANDA solves spatially fine-grained AQI level estimation task and AQI forecasting task jointly, which can leverage the commonalities and differences between these two tasks to improve generalization performance. We evaluate PANDA on the dataset of Hangzhou city. The experimental results show that our method can yield a better performance compared to the state-of-the-art methods.","Volume 3 Issue 1, March 2019"
2,10.1145/3314390,"Mingshi Chen, Panlong Yang, Jie Xiong, Maotian Zhang, Youngki Lee, Chaocan Xiang, Chang Tian",Your Table Can Be an Input Panel: Acoustic-based Device-Free Interaction Recognition,"This paper explores the possibility of extending the input and interactions beyond the small screen of the mobile device onto ad hoc adjacent surfaces, e.g., a wooden tabletop with acoustic signals. While the existing finger tracking approaches employ the active acoustic signal with a fixed frequency, our proposed system Ipanel employs the acoustic signals generated by sliding of fingers on the table for tracking. Different from active signal tracking, the frequency of the finger-table generated acoustic signals keeps changing, making accurate tracking much more challenging than the traditional approaches with fix frequency signal from the speaker. Unique features are extracted by exploiting the spatio-temporal and frequency domain properties of the generated acoustic signals. The features are transformed into images and then we employ the convolutional neural network (CNN) to recognize the finger movement on the table. Ipanel is able to support not only commonly used gesture (click, flip, scroll, zoom, etc.) recognition, but also handwriting (10 numbers and 26 alphabets) recognition at high accuracies. We implement Ipanel on smartphones, and conduct extensive real environment experiments to evaluate its performance. The results validate the robustness of Ipanel, and show that it maintains high accuracies across different users with varying input behaviours (e.g., input strength, speed and region). Further, Ipanel's performance is robust against different levels of ambient noise and varying surface materials.","Volume 3 Issue 1, March 2019"
3,10.1145/3314391,"Xinlei Chen, Yu Wang, Jiayou He, Shijia Pan, Yong Li, Pei Zhang",CAP: Context-aware App Usage Prediction with Heterogeneous Graph Embedding,"Context-aware mobile application (App) usage prediction benefits a variety of applications such as precise bandwidth allocation, App launch acceleration, etc. Prior works have explored this topic through individual data profiles and contextual information. However, it is still a challenging problem because of the following three aspects: i. App usage behavior is usually influenced by multiple factors, especially temporal and spatial factors. ii. It is difficult to describe individuals' preferences, which are usually time-variant. iii. A single user's data is sparse on the spatial domain and only covers a limited number of locations. Prediction becomes more difficult when the user appears at a new location.
This paper presents CAP, a context-aware App usage prediction algorithm that takes both contextual information (location &amp; time) and attribution (App with type information) into consideration. We find that the relationships between App-location, App-time, and App-App type are essential to prediction and propose a heterogeneous graph embedding algorithm to map them into the common comparable latent space. In addition, we create a user profile for each user with App usage and trajectory history to describe the individual dynamic preference for personalized prediction. We evaluate the performance of our proposed CAP with two large-scale real-world datasets. Extensive evaluations demonstrate that CAP achieves 30% higher accuracy than a state-of-the-art method Personalized Ranking Metric Embedding (PRME) in terms of Accuracy@5. In terms of mean reciprocal rank (MRR), CAP achieves 1.5× higher than the straightforward baseline Sta and 2× higher than PRME. Our investigation enables a range of applications to benefit from such timely predictions, including network operators, service providers, and etc.","Volume 3 Issue 1, March 2019"
4,10.1145/3314392,"Ying-Yu Chen, Ziyue Li, Daniela Rosner, Alexis Hiniker",Understanding Parents' Perspectives on Mealtime Technology,"For young children, family meals are an enjoyable and developmentally useful part of daily life. Although prior work has shown that ubiquitous computing solutions can enhance children's eating habits and mealtime experiences in valuable ways, other work demonstrates that many families are hesitant to use technology in this context. This paper examines adoption barriers for technology for family meals to understand with more nuance what parents value and resist in this space. Using mixed methods, we first observed family dinnertime experiences and then surveyed 122 parents with children from two to six years old. We found that parents prefer screen-based technology over voice interfaces and smart objects, because parents perceive the latter two systems to intrude on their relationship with children. The pervasiveness of smart objects embedded at meals led parents to worry about distraction and technology dependence, while the anthropomorphization of voice interfaces led parents to worry that this technology could displace parenting relationships or disrupt interpersonal interactions among family members. Parents mindlessly applied social scripts to voice interfaces, suggesting families may be more likely to apply concerns from interpersonal interactions to voice interfaces than to other technologies. We discuss the ways different form factors appeal to and worry parents, providing designers with insights about the likelihood of adoption and acceptance.","Volume 3 Issue 1, March 2019"
5,10.1145/3314393,"Yun Cheng, Xiaoxi He, Zimu Zhou, Lothar Thiele",ICT: In-field Calibration Transfer for Air Quality Sensor Deployments,"Recent years have witnessed a growing interest in urban air pollution monitoring, where hundreds of low-cost air quality sensors are deployed city-wide. To guarantee data accuracy and consistency, these sensors need periodic calibration after deployment. Since access to ground truth references is often limited in large-scale deployments, it is difficult to conduct city-wide post-deployment sensor calibration. In this work we propose In-field Calibration Transfer (ICT), a calibration scheme that transfers the calibration parameters of source sensors (with access to references) to target sensors (without access to references). On observing that (i) the distributions of ground truth in both source and target locations are similar and (ii) the transformation is approximately linear, ICT derives the transformation based on the similarity of distributions with a novel optimization formulation. The performance of ICT is further improved by exploiting spatial prediction of air quality levels and multi-source fusion. Experiments show that ICT is able to calibrate the target sensors as if they had direct access to the references.","Volume 3 Issue 1, March 2019"
6,10.1145/3314394,"Chia-Fang Chung, Qiaosi Wang, Jessica Schroeder, Allison Cole, Jasmine Zia, James Fogarty, Sean A. Munson",Identifying and Planning for Individualized Change: Patient-Provider Collaboration Using Lightweight Food Diaries in Healthy Eating and Irritable Bowel Syndrome,"Identifying and planning strategies that support a healthy lifestyle or manage a chronic disease often require patient-provider collaboration. For example, people with healthy eating goals often share everyday food, exercise, or sleep data with health coaches or nutritionists to find opportunities for change, and patients with irritable bowel syndrome (IBS) often gather food and symptom data as part of working with providers to diagnose and manage symptoms. However, a lack of effective support often prevents health experts from reviewing large amounts of data in time-constrained visits, prevents focusing on individual goals, and prevents generating correct, individualized, and actionable recommendations. To examine how to design photo-based diaries to help people and health experts exchange knowledge and focus on collaboration goals when reviewing the data together, we designed and developed Foodprint, a photo-based food diary. Foodprint includes three components: (1) A mobile app supporting lightweight data collection, (2) a web app with photo-based visualization and quantitative visualizations supporting collaborative reflection, and (3) a pre-visit note communicating an individual's expectations and questions to experts. We deployed Foodprint in two studies: (1) with 17 people with healthy eating goals and 7 health experts, and (2) with 16 IBS patients and 8 health experts. Building upon the lens of boundary negotiating artifacts and findings from two field studies, our research contributes design principles to (1) prepare individuals to collect data relevant to their health goals and for collaboration, (2) help health experts focus on an individual's eating context, experiences, and goals in collaborative review, and (3) support individuals and experts to develop individualized, actionable plans and strategies.","Volume 3 Issue 1, March 2019"
7,10.1145/3314395,"Afsaneh Doryab, Anind K. Dey, Grace Kao, Carissa Low",Modeling Biobehavioral Rhythms with Passive Sensing in the Wild: A Case Study to Predict Readmission Risk after Pancreatic Surgery,"Biobehavioral rhythms are associated with numerous health and life outcomes. We study the feasibility of detecting rhythms in data that is passively collected from Fitbit devices and using the obtained model parameters to predict readmission risk after pancreatic surgery. We analyze data from 49 patients who were tracked before surgery, in hospital, and after discharge. Our analysis produces a model of individual patients' rhythms for each stage of treatment that is predictive of readmission. All of the rhythm-based models outperform the traditional approaches to readmission risk stratification that uses administrative data.","Volume 3 Issue 1, March 2019"
8,10.1145/3314396,"Hendrik Engelbrecht, Stephan G. Lukosch, Dragos Datcu",Evaluating the Impact of Technology Assisted Hotspot Policing on Situational Awareness and Task-Load,"Everyday field work of a police officer requires the perception, filtering and understanding of large amounts of information in highly dynamic situations. This presents opportunities for ICT to alleviate strain on officers by providing adequate information provisioning. We evaluate the usage of a mobile location-based hotspot policing system, comprised of a smartphone, smartwatch and a web-application, during real field work with officers in high and low hotspot density locations. We use a repeated measures design to compare possible effects with our baseline measure, i.e. field work without using the system. Usability, task-load and situational awareness (SA), as well as possible mediators, are evaluated to gain insight into the differences between modes of transportation and the overall viability of the system itself. No significant difference was found between the two locations. Officers using the system scored high on usability measures and interview feedback was largely positive. Measures on SA remained stable throughout baseline and experimental shifts. Task-load was significantly higher with the use of the system. The contradiction in these findings can be explained by showing the differences in the nature of field work with and without the system.","Volume 3 Issue 1, March 2019"
9,10.1145/3314397,"Mikhail Fomichev, Max Maass, Lars Almon, Alejandro Molina, Matthias Hollick",Perils of Zero-Interaction Security in the Internet of Things,"The Internet of Things (IoT) demands authentication systems which can provide both security and usability. Recent research utilizes the rich sensing capabilities of smart devices to build security schemes operating without human interaction, such as zero-interaction pairing (ZIP) and zero-interaction authentication (ZIA). Prior work proposed a number of ZIP and ZIA schemes and reported promising results. However, those schemes were often evaluated under conditions which do not reflect realistic IoT scenarios. In addition, drawing any comparison among the existing schemes is impossible due to the lack of a common public dataset and unavailability of scheme implementations.
In this paper, we address these challenges by conducting the first large-scale comparative study of ZIP and ZIA schemes, carried out under realistic conditions. We collect and release the most comprehensive dataset in the domain to date, containing over 4250 hours of audio recordings and 1 billion sensor readings from three different scenarios, and evaluate five state-of-the-art schemes based on these data. Our study reveals that the effectiveness of the existing proposals is highly dependent on the scenario they are used in. In particular, we show that these schemes are subject to error rates between 0.6% and 52.8%.","Volume 3 Issue 1, March 2019"
10,10.1145/3314398,"Chen Gao, Chao Huang, Yue Yu, Huandong Wang, Yong Li, Depeng Jin",Privacy-preserving Cross-domain Location Recommendation,"Cross-domain recommendation is a typical solution for data sparsity and cold start issue in the field of location recommendation. Specifically, data of an auxiliary domain is leveraged to improve the recommendation of the target domain. There is a typical scenario that two interaction domains (location based check-in service, for example) combine data to perform the cross-domain location recommendation task. Existing approaches are based on the assumption that the interaction data from the auxiliary domain can be directly shared across domains. However, such an assumption is not reasonable, since in the real world those domains may be operated by different companies. Therefore, directly sharing raw data may violate business privacy policy and increase the risk of privacy leakage since the user-location interaction records are very sensitive.
In this paper, we propose a framework named privacy-preserving cross-domain location recommendation which works in two stages. First, for the interaction data from the auxiliary domain, we adopt a differential privacy based protection mechanism to hide the real locations of each user to meet the criterion of differential privacy. Then we share the protected user-location interaction to the target domain. Second, we develop a new method of Confidence-aware Collective Matrix Factorization (CCMF) to effectively exploit the transferred interaction data. To verify its efficacy, we collect two real-world datasets suitable for the task. Extensive experiments demonstrate that our proposed framework achieves the best performance compared with the state-of-the-art baseline methods. We further demonstrate that our method can alleviate the data sparsity issue significantly while protecting users' location privacy.","Volume 3 Issue 1, March 2019"
11,10.1145/3314399,"Yan Gao, Yang Long, Yu Guan, Anna Basu, Jessica Baggaley, Thomas Ploetz","Towards Reliable, Automated General Movement Assessment for Perinatal Stroke Screening in Infants Using Wearable Accelerometers","Perinatal stroke (PS) is a serious condition that, if undetected and thus untreated, often leads to life-long disability, in particular Cerebral Palsy (CP). In clinical settings, Prechtl's General Movement Assessment (GMA) can be used to classify infant movements using a Gestalt approach, identifying infants at high risk of developing PS. Training and maintenance of assessment skills are essential and expensive for the correct use of GMA, yet many practitioners lack these skills, preventing larger-scale screening and leading to significant risks of missing opportunities for early detection and intervention for affected infants. We present an automated approach to GMA, based on body-worn accelerometers and a novel sensor data analysis method--Discriminative Pattern Discovery (DPD)--that is designed to cope with scenarios where only coarse annotations of data are available for model training. We demonstrate the effectiveness of our approach in a study with 34 newborns (21 typically developing infants and 13 PS infants with abnormal movements). Our method is able to correctly recognise the trials with abnormal movements with at least the accuracy that is required by newly trained human annotators (75%), which is encouraging towards our ultimate goal of an automated PS screening system that can be used population-wide.","Volume 3 Issue 1, March 2019"
12,10.1145/3314400,"Shkurta Gashi, Elena Di Lascio, Silvia Santini",Using Unobtrusive Wearable Sensors to Measure the Physiological Synchrony Between Presenters and Audience Members,"The widespread adoption of mobile and wearable devices enables new approaches for the unobtrusive and continuous monitoring of humans' behavior, physiological state, interactions and more. Within this line of research, we focus on the physiological synchrony between a presenter and her audience and investigate whether it can be used to characterize the experience of presenters and audience members during presentations. To this end, we collect data from 17 presenters and six audience members during a two-days conference. For 40, unique presenter-audience pairs we gather electrodermal activity (EDA) signals and self-reports on different aspects of the experience: engagement, immersion and enjoyment/satisfaction. For 28 of these pairs, we also collect inter-beat interval (IBI) traces. We then apply seven approaches for measuring the synchrony of physiological signals and we contextualize these measures using metrics derived from the self-reports. We find that physiological synchrony -- measured using the Dynamic Time Warping algorithm -- can be used as a proxy to quantify participants' agreement on self-reported engagement. Our findings can be used to provide automated presenter-audience feedback in a conference setting and may be applicable in other scenarios, including education (teacher-student), arts (performer-audience), or meetings (presenter-audience).","Volume 3 Issue 1, March 2019"
13,10.1145/3314401,"Milan Jain, Mridula Gupta, Amarjeet Singh, Vikas Chandan",Beyond Control: Enabling Smart Thermostats for Leakage Detection,"Smart thermostats, with multiple sensory abilities, are becoming pervasive and ubiquitous, in both residential and commercial buildings. By analyzing occupants' behavior, adjusting set temperature automatically, and adapting to temporal and spatial changes in the atmosphere, smart thermostats can maximize both - energy savings and user comfort. In this paper, we study smart thermostats for refrigerant leakage detection. Retail outlets, such as milk-booths and quick service restaurants set up cold-rooms to store perishable items. In each room, a refrigeration unit (akin to air-conditioners) is used to maintain a suitable temperature for the stored products. Often, refrigerant leaks through the coils (or valves) of the refrigeration unit which slowly diminishes the cooling capacity of the refrigeration unit while allowing it to be functional. Such leaks waste significant energy, risk occupants' health, and impact the quality of stored perishable products. While store managers usually fail to sense the early symptoms of such leaks, current techniques to report refrigerant leakage are often not scalable. We propose Greina - to continuously monitor the readily available ambient information from the thermostat and timely report such leaks. We evaluate our approach on 74 outlets of a retail enterprise and results indicate that Greina can report the leakage a week in advance when compared to manual reporting.","Volume 3 Issue 1, March 2019"
14,10.1145/3314402,"Shenggong Ji, Yu Zheng, Zhaoyuan Wang, Tianrui Li",A Deep Reinforcement Learning-Enabled Dynamic Redeployment System for Mobile Ambulances,"Protecting citizens' lives from emergent accidents (e.g. traffic accidents) and diseases (e.g. heart attack) is of vital importance in urban computing. Every day many people are caught in emergent accidents or diseases and thus need ambulances to transport them to hospitals. In this paper, we propose a dynamic ambulance redeployment system to reduce the time needed for ambulances to pick up patients and to increase the probability of patients being saved in time. For patients in danger, every second counts. Specifically, whenever there is an ambulance becoming available (e.g. finishing transporting a patient to a hospital), our dynamic ambulance redeployment system will redeploy it to a proper ambulance station such that it can better pick up future patients. However, the dynamic ambulance redeployment is challenging, as when we redeploy an available ambulance we need to simultaneously consider each station's multiple dynamic factors. To trade off these multiple factors using handcrafted rules are almost impossible. To deal with this issue, we propose using a deep neural network, called deep score network, to balance each station's dynamic factors into one score, leveraging the excellent representation ability of deep neural networks. And then we propose a deep reinforcement learning framework to learn the deep score network. Finally, based on the learned deep score network, we provide an effective dynamic ambulance redeployment algorithm. Experiment results using data collected in real world show clear advantages of our method over baselines, e.g. comparing with baselines, our method can save ~100 seconds (~20%) of average pickup time of patients and improve the ratio of patients being picked up within 10 minutes from 0.786 to 0.838. With our method, people in danger can be better saved.","Volume 3 Issue 1, March 2019"
15,10.1145/3314403,"Jaejeung Kim, Hayoung Jung, Minsam Ko, Uichin Lee",GoalKeeper: Exploring Interaction Lockout Mechanisms for Regulating Smartphone Use,"Many people often experience difficulties in achieving behavioral goals related to smartphone use. Most of prior studies approached this problem with various behavior change strategies such as self-reflection and social support. However, little is known about the effectiveness and user experiences of restrictive and coercive interventions such as blocking. In this work, we developed ""GoalKeeper,"" a smartphone intervention app that locks the user into the self-defined daily use time limit with restrictive intervention mechanisms. We conducted a four-week field experiment with 36 participants to investigate the effects and user experiences of varying intensities of restrictive interventions. The results showed that restrictive mechanisms are more effective than non-restrictive mechanisms such as warning. However, we found that restrictive mechanisms caused more frustration and pressure to the users, mainly due to diversity of usage contexts and needs. Based on our study results, we extracted practical implications for designing restrictive mechanisms that balance the intervention effectiveness for behavioral changes and the flexibility for user acceptability.","Volume 3 Issue 1, March 2019"
16,10.1145/3314404,"Dawei Liang, Edison Thomaz",Audio-Based Activities of Daily Living (ADL) Recognition with Large-Scale Acoustic Embeddings from Online Videos,"Over the years, activity sensing and recognition has been shown to play a key enabling role in a wide range of applications, from sustainability and human-computer interaction to health care. While many recognition tasks have traditionally employed inertial sensors, acoustic-based methods offer the benefit of capturing rich contextual information, which can be useful when discriminating complex activities. Given the emergence of deep learning techniques and leveraging new, large-scale multimedia datasets, this paper revisits the opportunity of training audio-based classifiers without the onerous and time-consuming task of annotating audio data. We propose a framework for audio-based activity recognition that can make use of millions of embedding features from public online video sound clips. Based on the combination of oversampling and deep learning approaches, our framework does not require further feature processing or outliers filtering as in prior work. We evaluated our approach in the context of Activities of Daily Living (ADL) by recognizing 15 everyday activities with 14 participants in their own homes, achieving 64.2% and 83.6% averaged within-subject accuracy in terms of top-1 and top-3 classification respectively. Individual class performance was also examined in the paper to further study the co-occurrence characteristics of the activities and the robustness of the framework.","Volume 3 Issue 1, March 2019"
17,10.1145/3314405,"Fannie Liu, Mario Esparza, Maria Pavlovskaia, Geoff Kaufman, Laura Dabbish, Andrés Monroy-Hernández",Animo: Sharing Biosignals on a Smartwatch for Lightweight Social Connection,"We present Animo, a smartwatch app that enables people to share and view each other's biosignals. We designed and engineered Animo to explore new ground for smartwatch-based biosignals social computing systems: identifying opportunities where these systems can support lightweight and mood-centric interactions. In our work we develop, explore, and evaluate several innovative features designed for dyadic communication of heart rate. We discuss the results of a two-week study (N=34), including new communication patterns participants engaged in, and outline the design landscape for communicating with biosignals on smartwatches.","Volume 3 Issue 1, March 2019"
18,10.1145/3314406,"Ruibo Liu, Qijia Shao, Siqi Wang, Christina Ru, Devin Balkcom, Xia Zhou",Reconstructing Human Joint Motion with Computational Fabrics,"Accurate and continuous monitoring of joint rotational motion is crucial for a wide range of applications such as physical rehabilitation [6, 85] and motion training [22, 54, 68]. Existing motion capture systems, however, either need instrumentation of the environment, or fail to track arbitrary joint motion, or impose wearing discomfort by requiring rigid electrical sensors right around the joint area. This work studies the use of everyday fabrics as a flexible and soft sensing medium to monitor joint angular motion accurately and reliably. Specifically we focus on the primary use of conductive stretchable fabrics to sense the skin deformation during joint motion and infer the joint rotational angle. We tackle challenges of fabric sensing originated by the inherent properties of elastic materials by leveraging two types of sensing fabric and characterizing their properties based on models in material science. We apply models from bio-mechanics to infer joint angles and propose the use of dual strain sensing to enhance sensing robustness against user diversity and fabric position offsets. We fabricate prototypes using off-the-shelf fabrics and micro-controller. Experiments with ten participants show 9.69° median angular error in tracking joint angle and its sensing robustness across various users and activities.","Volume 3 Issue 1, March 2019"
19,10.1145/3314407,"Suraj Nair, Kiran Javkar, Jiahui Wu, Vanessa Frias-Martinez",Understanding Cycling Trip Purpose and Route Choice Using GPS Traces and Open Data,"Many mobile applications such as Strava or Mapmyride allow cyclists to collect detailed GPS traces of their trips for health or route sharing purposes. However, cycling GPS traces also have a lot of potential from an urban planning perspective. In this paper, we focus on two important issues to characterize urban cyclist behavior: trip purpose and route choice. Cycling trip purpose has been typically analyzed using survey data. Here, we present a method to automatically infer the purpose of a cycling trip using cyclists' personal data, GPS traces and a variety of built-in and social environment features extracted from open datasets characterizing the streets cycled. We evaluate the proposed method using GPS traces from over 7, 000 cycling routes in the city of Philadelphia and report F1 scores of up to 86% when four trip purposes are considered. On the other hand, we also present a novel statistical method to identify the role that certain variables characterizing the built-in and social environment play in the selection of a specific cycling route. Our results show that cyclists in Philadelphia tend to favor routes with green areas, safety and centrality.","Volume 3 Issue 1, March 2019"
20,10.1145/3314408,"Emirhan Poyraz, Gokhan Memik",Using Built-In Sensors to Predict and Utilize User Satisfaction for CPU Settings on Smartphones,"Understanding user experience/satisfaction with mobile systems in order to manage computational resources has become a popular approach in recent years. One of the key issues in this area is to gauge user satisfaction. In this paper, we propose and evaluate a system to save energy by altering CPU core count and frequency while keeping users satisfied. Specifically, the system uses the sensor data collected from two popular personal devices: a smartphone and a smartwatch. In the proposed architecture, we first develop prediction models by collecting sensor data along with user performance satisfaction inputs. Then, our system predicts users' current satisfaction and sets CPU core/frequency based on these predictions in real-time. We observe that sensor data gathered from these two devices are highly correlated with users' instantaneous satisfaction of the phone.
We evaluate the proposed system by developing and comparing two different models. First, we develop a user-independent (user-oblivious) model by using data gathered from 10 users. Second, we develop user-dependent (personal) models for 20 different users. We demonstrate that both models can predict satisfaction with over 97% accuracy on average when a binary satisfaction model is used (i.e., users indicating satisfied versus unsatisfied). The prediction accuracy is over 91% on average if a 3-level satisfaction model is used. Our results also show that when compared to default scheme, the user-independent and user-dependent models save 8.96% and 10.12% of the total system energy on average, respectively, without impacting user satisfaction.","Volume 3 Issue 1, March 2019"
21,10.1145/3314409,"Shriti Raj, Joyce M. Lee, Ashley Garrity, Mark W. Newman",Clinical Data in Context: Towards Sensemaking Tools for Interpreting Personal Health Data,"Clinical data augmented with contextual data can help patients with chronic conditions make sense of their disease. However, existing tools do not support interpretation of multiple data streams. To better understand how individuals make sense of clinical and contextual data, we interviewed patients with Type 1 diabetes and their caregivers using context-enhanced visualizations of patients' data as probes to facilitate interpretation activities. We observed that our participants performed four analytical activities when interpreting their data -- finding context-based trends and explaining them, triangulating multiple factors, suggesting context-specific actions, and hypothesizing about alternate contextual factors affecting outcomes. We also observed two challenges encountered during analysis -- the inability to identify clear trends challenged action planning and counterintuitive insights compromised trust in data. Situating our findings within the existing sensemaking frameworks, we demonstrate that sensemaking can not only inform action but can guide the discovery of information needs for exploration. We further argue that sensemaking is a valuable approach for exploring contextual data. Informed by our findings and our reflection on existing sensemaking frameworks, we provide design guidelines for sensemaking tools to improve awareness of contextual factors affecting patients and to support patients' agency in making sense of health data.","Volume 3 Issue 1, March 2019"
22,10.1145/3314410,"Soha Rostaminia, Alexander Lamson, Subhransu Maji, Tauhidur Rahman, Deepak Ganesan",W!NCE: Unobtrusive Sensing of Upper Facial Action Units with EOG-based Eyewear,"The ability to unobtrusively and continuously monitor one's facial expressions has implications for a variety of application domains ranging from affective computing to health-care and the entertainment industry. The standard Facial Action Coding System (FACS) along with camera based methods have been shown to provide objective indicators of facial expressions; however, these approaches can also be fairly limited for mobile applications due to privacy concerns and awkward positioning of the camera. To bridge this gap, W!NCE re-purposes a commercially available Electrooculography-based eyeglass (J!NS MEME) for continuously and unobtrusively sensing of upper facial action units with high fidelity. W!NCE detects facial gestures using a two-stage processing pipeline involving motion artifact removal and facial action detection. We validate our system's applicability through extensive evaluation on data from 17 users under stationary and ambulatory settings, a pilot study for continuous pain monitoring and several performance benchmarks. Our results are very encouraging, showing that we can detect five distinct facial action units with a mean F1 score of 0.88 in stationary and 0.82 in ambulatory settings, and that we can accurately detect facial gestures that due to pain.","Volume 3 Issue 1, March 2019"
23,10.1145/3314411,"Zhanna Sarsenbayeva, Niels van Berkel, Danula Hettiachchi, Weiwei Jiang, Tilman Dingler, Eduardo Velloso, Vassilis Kostakos, Jorge Goncalves",Measuring the Effects of Stress on Mobile Interaction,"Research shows that environmental factors such as ambient noise and cold ambience can render users situationally impaired, adversely affecting interaction with mobile devices. However, an internal factor which is known to negatively impact cognitive abilities -- stress -- has not been systematically investigated in terms of its impact on mobile interaction. In this paper, we report a study where we use the Trier Social Stress Test to induce stress on participants, and investigate its effect on three aspects of mobile interaction: target acquisition, visual search, and text entry. We find that stress reduces completion time and accuracy during target acquisition tasks, as well as completion time during visual search tasks. Finally, we are able to directly contrast the magnitude of these effects to previously published effects of environmentally-caused impairments. Our work contributes to the growing body of literature on situational impairments.","Volume 3 Issue 1, March 2019"
24,10.1145/3314412,"Xinyu Tong, Fengyuan Zhu, Yang Wan, Xiaohua Tian, Xinbing Wang",Batch Localization Based on OFDMA Backscatter,"OFDMA Wi-Fi backscatter can significantly improve the communication efficiency and meanwhile maintain ultra-low power consumption; however, the ground-up reworking on the core mechanism of traditional Wi-Fi system revolutionizes the basis of many existing Wi-Fi based mechanisms. In this paper, we explore how localization can be realized based on OFDMA backscatter, where a batch localization mechanism utilizing concurrent communication in the OFDMA backscatter system is proposed. We present a series of mechanisms to deal with the fundamental change of assumptions brought by the new paradigm. First, we process signals at the receiver in a finer granularity for signal classification. Then we remove phase offsets in real time without interrupting the communication. Finally, we propose an extended MUSIC algorithm to improve accuracy with limited localization information in OFDMA backscatter mechanism. We implement a prototype under the 802.11g framework in WARP, based on which we conduct comprehensive experiments to evaluate our propose mechanism. Results show that our system can localize 48 tags simultaneously, while achieving average localization errors within 0.49m. The tag's power consumption is about 55-81.3μW.","Volume 3 Issue 1, March 2019"
25,10.1145/3314413,"Zhen Tu, Yali Fan, Yong Li, Xiang Chen, Li Su, Depeng Jin",From Fingerprint to Footprint: Cold-start Location Recommendation by Learning User Interest from App Data,"With increasing diversity of user interest and preference, personalized location recommendation is essential and beneficial to our daily life. To achieve this, the most critical challenge is the cold-start recommendation problem, for we cannot learn preference from cold-start users without any historical records. In this paper, we demonstrate that it is feasible to make personalized location recommendation by learning user interest and location features from app usage data. By proposing a novel generative model to transfer user interests from app usage behavior to location preference, we achieve personalized location recommendation via learning the interest's correlation between locations and apps. Based on two real-world datasets, we evaluate our method's performance with a variety of scenarios and parameters. The results demonstrate that our method outperforms the state-of-the-art solutions in solving cold-start problem, i.e., when there are 60% cold-start users, we can still achieve a 77.0% hitrate in recommending the top five locations, which is at least 9.6% higher than the baselines. Our study is the first step forward for transferring user interests learning from online fingerprints to offline footprints, which paves the way for better personalized location recommendation services.","Volume 3 Issue 1, March 2019"
26,10.1145/3314414,"Huandong Wang, Yong Li, Sihan Zeng, Gang Wang, Pengyu Zhang, Pan Hui, Depeng Jin",Modeling Spatio-Temporal App Usage for a Large User Population,"With the wide adoption of mobile devices, it becomes increasingly important to understand how users use mobile apps. Knowing when and where certain apps are used is instrumental for app developers to improve app usability and for Internet service providers (ISPs) to optimize their network services. However, modeling spatio-temporal patterns of app usage has been a challenging problem due to the complicated usage behavior and the very limited personal data. In this paper, we propose a Bayesian mixture model to capture when, where and what apps are used and predict future app usage. To solve the challenge of data sparsity, we apply a hierarchical Dirichlet process to leverage the shared spatio-temporal patterns to accurately model users with insufficient data. We then evaluate our model using a large dataset of app usage traces involving 1.7 million users over 3503 apps. Our analysis shows a clear correlation between the user's location and the apps being used. Extensive evaluations show that our model can accurately predict users' future locations and app usage, outperforming the state-of-the-art algorithms by 11.7% and 11.1%, respectively. In addition, our model can be used to synthesize app usage traces that do not leak user privacy while preserving the key data statistical properties.","Volume 3 Issue 1, March 2019"
27,10.1145/3314415,"Xiaolei Wang, Andrea Continella, Yuexiang Yang, Yongzhong He, Sencun Zhu",LeakDoctor: Toward Automatically Diagnosing Privacy Leaks in Mobile Applications,"With the enormous popularity of smartphones, millions of mobile apps are developed to provide rich functionalities for users by accessing certain personal data, leading to great privacy concerns. To address this problem, many approaches have been proposed to detect privacy disclosures in mobile apps, but they largely fail to automatically determine whether the privacy disclosures are necessary for the functionality of apps. As a result, security analysts may easily face with a large number of false positives when directly adopting such approaches for app analysis. In this paper, we propose LeakDoctor, an analysis system seeking to automatically diagnose privacy leaks by judging if a privacy disclosure from an app is necessary for some functionality of the app. Functionality-irrelevant privacy disclosures are not justifiable, so considered as potential privacy leak cases. To achieve this goal, LeakDoctor integrates dynamic response differential analysis with static response taint analysis. In addition, it employs a novel technique to locate the program statements of each privacy disclosure. We implement a prototype of LeakDoctor and evaluate it against 1060 apps, which contain 2,095 known disclosure cases. Our experimental results show that LeakDoctor can automatically determine that 71.9% of the privacy disclosure cases indeed serve apps' functionalities and are justifiable. Hence, with the diagnosis results of LeakDoctor, analysts may avoid analyzing many justifiable privacy disclosures and only focus on the those unjustifiable cases.","Volume 3 Issue 1, March 2019"
28,10.1145/3314416,"Zhongqin Wang, Min Xu, Ning Ye, Ruchuan Wang, Haiping Huang",RF-Focus: Computer Vision-assisted Region-of-interest RFID Tag Recognition and Localization in Multipath-prevalent Environments,"Capturing RFID tags in the region of interest (ROI) is challenging. Many issues, such as multipath interference, frequency-dependent hardware characteristics and phase periodicity, make RF phase difficult to accurately indicate the tag-to-antenna distance for RFID tag localization. In this paper, we propose a comprehensive solution, called RF-Focus, which fuses RFID and computer vision (CV) techniques to recognize and locate moving RFID-tagged objects within ROI. Firstly, we build a multipath propagation model and propose a dual-antenna solution to minimize the impact of multipath interference on RF phase. Secondly, by extending the multipath model, we estimate phase shifts due to hardware characteristics at different operating frequencies. Thirdly, to minimize the tag position uncertainty due to RF phase periodicity, we leverage CV to extract image regions of being likely to contain ROI RFID-tagged objects, and then associate them with the processed RF phase after the removal of the phase shifts due to multipath interference and hardware characteristics for recognition and localization. Our experiments demonstrate the effectiveness of multipath modelling and hardware-related phase shift estimation. When five RFID-tagged objects are moving in the ROI, RF-Focus achieves the average recognition accuracy of 91.67% and localization accuracy of 94.26% given a false positive rate of 10%.","Volume 3 Issue 1, March 2019"
29,10.1145/3314417,"Tong Xia, Yong Li",Revealing Urban Dynamics by Learning Online and Offline Behaviours Together,"Urban problems and diseases accompanied by the pace of urbanization have drawn attention to the importance of understanding urban dynamics, while a deep and comprehensive understanding is challenging due to our diversified lifestyles in the modern city. In this paper, we propose an urban dynamics modeling system to characterize the regularity of urban activity dynamics as well as urban functions by learning residents' online and offline behaviours together. Built on a state-sharing hidden Markov model, our system utilizes online activities of App usage and offline activities of mobility in different urban regions and different time slots for learning. The learnt state sequence of each region reveals urban dynamics with the corresponding urban functions. We evaluate our system via a large-scale mobile network accessing dataset, which discovers ten hidden states characterizing different life modes and eight representative dynamic patterns corresponding to different urban functions. These discovered dynamic patterns and inferred functions are validated by social media check-ins and the land-use published by the government with 81% accuracy. Based on our model, we propose two applications, crowd flow prediction and popular App prediction, which outperforms the state-of-the-art approaches by 36.1% and 15.7%, respectively. This study paves the way for extensive city-related applications including urban demand analysis, land-use planning, and activity prediction.","Volume 3 Issue 1, March 2019"
30,10.1145/3314418,"Tuo Yu, Haiming Jin, Klara Nahrstedt",ShoesLoc: In-Shoe Force Sensor-Based Indoor Walking Path Tracking,"Currently, in-shoe force sensors have been widely used for step counting and gait analysis. However, it has not been realized that in-shoe force sensors are also capable of tracking walking paths. In this paper, we present ShoesLoc, an indoor walking path tracking method based on in-shoe force sensors. We show that, based on the force signals from a user's shoes, it is possible to estimate the walking direction change and the stride length of each step with machine learning techniques. We further apply a particle filter to combine this information with the constraint of barriers in floor maps, and thus can determine the walking path and the current position of the user. To solve the problem of the low accuracy caused by cumulative walking direction errors, we improve the particle filter by designing the direction correction algorithm. Moreover, we propose the weight normalization method to handle the impact of handbags and backpacks. Our experimental results show that, after a convergence phase, ShoesLoc achieves the average location error of 0.9-1.3 m. Compared with traditional indoor tracking technologies, ShoesLoc does not require the installation of wireless anchors, and has good robustness to environment changes such as the magnetic interference.","Volume 3 Issue 1, March 2019"
31,10.1145/3314419,"Mattia Zeni, Wanyi Zhang, Enrico Bignotti, Andrea Passerini, Fausto Giunchiglia",Fixing Mislabeling by Human Annotators Leveraging Conflict Resolution and Prior Knowledge,"According to the ""human in the loop"" paradigm, machine learning algorithms can improve when leveraging on human intelligence, usually in the form of labels or annotation from domain experts. However, in the case of research areas such as ubiquitous computing or lifelong learning, where the annotator is not an expert and is continuously asked for feedback, humans can provide significant fractions of incorrect labels. We propose to address this issue in a series of experiments where students are asked to provide information about their behavior via a dedicated mobile application. Their trustworthiness is tested by employing an architecture where the machine uses all its available knowledge to check the correctness of its own and the user labeling to build a uniform confidence measure for both of them to be used when a contradiction arises. The overarching system runs through a series of modes with progressively higher confidence and features a conflict resolution component to settle the inconsistencies. The results are very promising and show the pervasiveness of annotation mistakes, the extreme diversity of the users' behaviors which provides evidence of the impracticality of a uniform fits-it-all solution, and the substantially improved performance of a skeptical supervised learning strategy.","Volume 3 Issue 1, March 2019"
32,10.1145/3314420,"Fusang Zhang, Kai Niu, Jie Xiong, Beihong Jin, Tao Gu, Yuhang Jiang, Daqing Zhang",Towards a Diffraction-based Sensing Approach on Human Activity Recognition,"In recent years, wireless sensing has been exploited as a promising research direction for contactless human activity recognition. However, one major issue hindering the real deployment of these systems is that the signal variation patterns induced by the human activities with different devices and environmental settings are neither stable nor consistent, resulting in unstable system performance. The existing machine learning based methods usually take the ""black box"" approach and fails to achieve consistent performance. In this paper, we argue that a deep understanding of radio signal propagation in wireless sensing is needed, and it may be possible to develop a deterministic sensing model to make the signal variation patterns predictable.
With this intuition, in this paper we investigate: 1) how wireless signals are affected by human activities taking transceiver location and environment settings into consideration; 2) a new deterministic sensing approach to model the received signal variation patterns for different human activities; 3) a proof-of-concept prototype to demonstrate our approach and a case study to detect diverse activities. In particular, we propose a diffraction-based sensing model to quantitatively determine the signal change with respect to a target's motions, which eventually links signal variation patterns with motions, and hence can be used to recognize human activities. Through our case study, we demonstrate that the diffraction-based sensing model is effective and robust in recognizing exercises and daily activities. In addition, we demonstrate that the proposed model improves the recognition accuracy of existing machine learning systems by above 10%.","Volume 3 Issue 1, March 2019"
33,10.1145/3314421,"Jason Shuo Zhang, Mike Gartrell, Richard Han, Qin Lv, Shivakant Mishra",GEVR: An Event Venue Recommendation System for Groups of Mobile Users,"In this paper, we present GEVR, the first Group Event Venue Recommendation system that incorporates mobility via individual location traces and context information into a ""social-based"" group decision model to provide venue recommendations for groups of mobile users. Our study leverages a real-world dataset collected using the OutWithFriendz mobile app for group event planning, which contains 625 users and over 500 group events. We first develop a novel ""social-based"" group location prediction model, which adaptively applies different group decision strategies to groups with different social relationship strength to aggregate each group member's location preference, to predict where groups will meet. Evaluation results show that our prediction model not only outperforms commonly used and state-of-the-art group decision strategies with over 80% accuracy for predicting groups' final meeting location clusters, but also provides promising qualities in cold-start scenarios. We then integrate our prediction model with the Foursquare Venue Recommendation API to construct an event venue recommendation framework for groups of mobile users. Evaluation results show that GEVR outperforms the comparative models by a significant margin.","Volume 3 Issue 1, March 2019"
34,10.1145/3287031,"Nabil Alshurafa, Jayalakshmi Jain, Rawan Alharbi, Gleb Iakovlev, Bonnie Spring, Angela Pfammatter",Is More Always Better?: Discovering Incentivized mHealth Intervention Engagement Related to Health Behavior Trends,"Behavioral medicine is devoting increasing attention to the topic of participant engagement and its role in effective mobile health (mHealth) behavioral interventions. Several definitions of the term ""engagement"" have been proposed and discussed, especially in the context of digital health behavioral interventions. We consider that engagement refers to specific interaction and use patterns with the mHealth tools such as smartphone applications for intervention, whereas adherence refers to compliance with the directives of the health intervention, independent of the mHealth tools. Through our analysis of participant interaction and self-reported behavioral data in a college student health study with incentives, we demonstrate an example of measuring ""effective engagement"" as engagement behaviors that can be linked to the goals of the desired intervention. We demonstrate how clustering of one year of weekly health behavior self-reports generate four interpretable clusters related to participants' adherence to the desired health behaviors: healthy and steady, unhealthy and steady, decliners, and improvers. Based on the intervention goals of this study (health promotion and behavioral change), we show that not all app usage metrics are indicative of the desired outcomes that create effective engagement. As such, mHealth intervention design might consider eliciting not just more engagement or use overall, but rather, effective engagement defined by use patterns related to the desired behavioral outcome.","Volume 2 Issue 4, December 2018"
35,10.1145/3287032,"Ishwarya Ananthabhotla, Joseph A. Paradiso","SoundSignaling: Realtime, Stylistic Modification of a Personal Music Corpus for Information Delivery","Drawing inspiration from the notion of cognitive incongruence associated with Stroop's famous experiment, from musical principles, and from the observation that music consumption on an individual basis is becoming increasingly ubiquitous, we present the SoundSignaling system -- a software platform designed to make real-time, stylistically relevant modifications to a personal corpus of music as a means of conveying information or notifications. In this work, we discuss in detail the system's technical implementation and its motivation from a musical perspective, and validate these design choices through a crowd-sourced signal identification experiment consisting of 200 independent tasks performed by 50 online participants. We then qualitatively discuss the potential implications of such a system from the standpoint of switch cost, cognitive load, and listening behavior by considering the anecdotal outcomes of a small-scale, in-the-wild experiment consisting of over 180 hours of usage from 6 participants. Through this work, we suggest a re-evaluation of the age-old paradigm of binary audio notifications in favor of a system designed to operate upon the relatively unexplored medium of a user's musical preferences.","Volume 2 Issue 4, December 2018"
36,10.1145/3287033,"Chu Cao, Zhenjiang Li, Pengfei Zhou, Mo Li",Amateur: Augmented Reality Based Vehicle Navigation System,"This paper presents Amateur, an augmented reality based vehicle navigation system using commodity smart phones. Amateur reads the navigation information from a digital map, matches it into live road condition video captured by smart phone, and directly annotates the navigation instructions on the video stream. The Amateur design entails two major challenges, including the lane identification and the intersection inference so as to correctly annotate navigation instructions for lane-changing and intersection-turning. In this paper, we propose a particle filter based design, assisted by inertial motion sensors and lane markers, to tolerate incomplete and even erroneous detection of road conditions. We further leverage traffic lights as land markers to estimate the position of each intersection to accurately annotate the navigation instructions. We develop a prototype system on Android mobile phones and test our system in a total number of more than 300km travel distance on different taxi cabs in a city. The evaluation results suggest that our system can timely provide correct instructions to navigate drivers. Our system can identify lanes in 2s with 92.7% accuracy and detect traffic lights with 95.29% accuracy. Overall, the accuracy of the navigation signs placement is less than 105 pixels on the screen throughout the experiments. The feedback from 50 taxi drivers indicates that Amateur provides an improved experience compared to traditional navigation systems.","Volume 2 Issue 4, December 2018"
37,10.1145/3287034,"Hancheng Cao, Zhilong Chen, Fengli Xu, Yong Li, Vassilis Kostakos","Revisitation in Urban Space vs. Online: A Comparison across POIs, Websites, and Smartphone Apps","We present the first large-scale analysis of POI revisitation patterns, which aims to model the periodic behavior in human mobility. We apply the revisitation analysis technique, which has previously been used to understand website revisitation, and smartphone app revisitations. We analyze a 1.5-year-long Foursquare check-in dataset with 266,909 users in 415 cities around the globe, as well as a Chinese social networking dataset on continuous localization of 15,000 users in Beijing. Our analysis identifies four major POI revisitation patterns and four user revisitation patterns of distinct characteristics, and demonstrates the role of POI functions and geographic constraints in shaping these patterns. We compare our results to previous analysis on website and app revisitation, and highlight the similarities and differences between physical and cyber revisitation activities. These point to fundamental characteristics of human behavior.","Volume 2 Issue 4, December 2018"
38,10.1145/3287035,"Simone Centellegher, Giovanna Miritello, Daniel Villatoro, Devyani Parameshwar, Bruno Lepri, Nuria Oliver",Mobile Money: Understanding and Predicting its Adoption and Use in a Developing Economy,"Access to financial institutions is difficult in developing economies and especially for the poor. However, the widespread adoption of mobile phones has enabled the development of mobile money systems that deliver financial services through the mobile phone network. Despite the success of mobile money, there is a lack of quantitative studies that unveil which factors contribute to the adoption and sustained usage of such services. In this paper, we describe the results of a quantitative study that analyzes data from the world's leading mobile money service, M-Pesa. We analyzed millions of anonymized mobile phone communications and M-Pesa transactions in an African country. Our contributions are threefold: (1) we analyze the customers' usage of M-Pesa and report large-scale patterns of behavior; (2) we present the results of applying machine learning models to predict mobile money adoption (AUC=0.691), and mobile money spending (AUC=0.619) using multiple data sources: mobile phone data, M-Pesa agent information, the number of M-Pesa friends in the user's social network, and the characterization of the user's geographic location; (3) we discuss the most predictive features in both models and draw key implications for the design of mobile money services in a developing country. We find that the most predictive features are related to mobile phone activity, to the presence of M-Pesa users in a customer's ego-network and to mobility. We believe that our work will contribute to the understanding of the factors playing a role in the adoption and sustained usage of mobile money services in developing economies.","Volume 2 Issue 4, December 2018"
39,10.1145/3287036,"Jagmohan Chauhan, Jathushan Rajasegaran, Suranga Seneviratne, Archan Misra, Aruna Seneviratne, Youngki Lee",Performance Characterization of Deep Learning Models for Breathing-based Authentication on Resource-Constrained Devices,"Providing secure access to smart devices such as smartphones, wearables and various other IoT devices is becoming increasingly important, especially as these devices store a range of sensitive personal information. Breathing acoustics-based authentication offers a highly usable and possibly a secondary authentication mechanism for secure access. Executing sophisticated machine learning pipelines for such authentication on such devices remains an open problem, given their resource limitations in terms of storage, memory and computational power. To investigate this challenge, we compare the performance of an end-to-end system for both user identification and user verification tasks based on breathing acoustics on three type of smart devices: smartphone, smartwatch and Raspberry Pi using both shallow classifiers (i.e., SVM, GMM, Logistic Regression) and deep learning based classifiers (e.g., LSTM, MLP). Via detailed analysis, we conclude that LSTM models for acoustic classification are the smallest in size, have the lowest inference time and are more accurate than all other compared classifiers. An uncompressed LSTM model provides an average f-score of 80%-94% while requiring only 50--180 KB of storage (depending on the breathing gesture). The resulting inference can be done on smartphones and smartwatches within approximately 7--10 ms and 18--66 ms respectively, thereby making them suitable for resource-constrained devices. Further memory and computational savings can be achieved using model compression methods such as weight quantization and fully connected layer factorization: in particular, a combination of quantization and factorization achieves 25%--55% reduction in LSTM model size, with almost no loss in performance. We also compare the performance on GPUs and show that the use of GPU can reduce the inference time of LSTM models by a factor of 300%. These results provide a practical way to deploy breathing based biometrics, and more broadly LSTM-based classifiers, in future ubiquitous computing applications.","Volume 2 Issue 4, December 2018"
40,10.1145/3287037,"Huijie Chen, Fan Li, Xiaojun Hei, Yu Wang",CrowdX: Enhancing Automatic Construction of Indoor Floorplan with Opportunistic Encounters,"The lack of floorplan limits the spread of pervasive indoor location-based services. Existing crowdsourcing based approaches mostly rely on identifying, locating landmarks in the environment and utilizing the spatial relationship between the landmarks and traces for efficiently constructing fine-grained floorplan. However, these methods are always restricted by the sparse landmark distribution or may cause privacy leakage. In this paper, we propose CrowdX, a crowdsourcing system for accurate, low-cost indoor floorplan construction enhanced with opportunistic encounters among mobile users. The key insight is that the spatial relation (i.e., the displacement of each user and the distance between each other during the encounter) will be extracted from the audio and inertia data, which are aligned by the proposed vibration event-based method. Such information can be used to calibrate the drift of encounter position. The calibrated encounter position is beneficial to most of the floorplan generation steps, such as trace drift elimination, landmark positioning, hallway assembling, and room area estimation. Our experiments in three shopping malls show that CrowdX achieves an average F-measure around 89.4%. In addition, the average estimated room area error within about 20%. The evaluation results demonstrate a significant improvement of accuracy enhanced with opportunistic encounters.","Volume 2 Issue 4, December 2018"
41,10.1145/3287038,"Thilina Dissanayake, Takuya Maekawa, Daichi Amagata, Takahiro Hara",Detecting Door Events Using a Smartphone via Active Sound Sensing,"Event detection of indoor objects, including doors, has a wide variety of applications, including intruder detection, HVAC control, and surveillance of independently living elderly people. Hence, this has been the focus of multiple research projects in the UbiComp research community. Herein, we propose a method to accurately detect door events in an indoor environment, without the installation and maintenance costs of using distributed ubiquitous sensors. In particular, we recognize the events of multiple doors existing in the environment via active sound probing using a disused smartphone installed in the environment. We perform event recognition by fusing the analysis of the Doppler shift caused by the moving doors with the acoustic characteristics describing the open/close states of the doors acquired via impulse response. To accurately distinguish between the events of different doors via sound probing, our method employs the time-series analysis of the Doppler shift as well as the active sound probing using directional high-frequency sine waves and stereo sound recording. In addition, by incorporating prior knowledge about the state transitions of a door object into a recognition model, we attempt to improve the accuracy of event recognition. Moreover, our method is capable of recognizing walking activities of a person related to door events in the environment, which are necessary information for applications such as HVAC control that require information about both door events and human presence.","Volume 2 Issue 4, December 2018"
42,10.1145/3287039,"Junjun Fan, Xiangmin Fan, Feng Tian, Yang Li, Zitao Liu, Wei Sun, Hongan Wang",What is That in Your Hand?: Recognizing Grasped Objects via Forearm Electromyography Sensing,"Knowing the object in hand can offer essential contextual information revealing a user's fine-grained activities. In this paper, we investigate the feasibility, accuracy, and robustness of recognizing the uninstrumented object in a user's hand by sensing and decoding her forearm muscular activities via off-the-shelf electromyography (EMG) sensors. We present results from three studies to advance our fundamental understanding of the opportunities that EMG brings in object interaction recognition. In the first study, we investigated the influence of physical properties of objects such as shape, size, and weight on EMG signals. We also conducted a thorough exploration of the feature spaces and sensor positions which can provide a solid base to rely on for future designers and practitioners for such interactive technique. In the second study, we assessed the feasibility and accuracy of inferring the types of grasped objects via using forearm muscular activity as a cue. Our results indicate that the types of objects can be recognized with up to 94.2% accuracy by employing user-dependent training. In the third study, we investigated the robustness of this approach in a realistic office setting where users were allowed to interact with objects as they would naturally. Our approach achieved up to 82.5% accuracy in discriminating 15 types of objects, even when training and testing phrases were purposefully performed on different days to incorporate changes in EMG patterns over time. Overall, this work contributes a set of fundamental findings and guidelines on using EMG technologies for object-based activity tracking.","Volume 2 Issue 4, December 2018"
43,10.1145/3287040,"Kaori Fujinami, Mami Kosaka, Bipin Indurkhya",Painting an Apple with an Apple: A Tangible Tabletop Interface for Painting with Physical Objects,"We introduce UnicrePaint, a digital painting system that allows the user to paint with physical objects by acquiring three parameters from the interacting object: the form, the color pattern and the contact pressure. The design of the system is motivated by a hypothesis that integrating direct input from physical objects with digital painting offers unique creative experiences to the user. A major technical challenge in implementing UnicrePaint is to resolve the conflict between input and output, i.e., to be able to capture the form and color pattern of contacting objects from a camera, while at the same time be able to present the captured data using a projector. We present a solution for this problem. We implemented a prototype and carried out a user study with fifteen novice users. Additionally, five professional users with art-related backgrounds participated in a user study to obtain insights into how professionals might view our system. The results show that UnicrePaint offers unique experiences with painting in a creative manner. Also, its potentials beyond mere artwork are suggested.","Volume 2 Issue 4, December 2018"
44,10.1145/3287041,"Ekin Gedik, Hayley Hung",Detecting Conversing Groups Using Social Dynamics from Wearable Acceleration: Group Size Awareness,"In this paper, we propose a method for detecting conversing groups. More specifically, we detect pairwise F-formation membership using a single worn accelerometer. We focus on crowded real life scenarios, specifically mingling events, where groups of different sizes naturally occur and evolve over time. Our method uses the dynamics of interaction, derived from people's coordinated social actions and movements. The social actions, speaking, head and hand gesturing, are inferred from wearable acceleration with a transfer learning approach. These automatically labeled actions, together with the raw acceleration, are used to define joint representations of interaction between people through the extraction of pairwise features. We present a new feature set based on the overlap patterns of social actions and utilize some others that were previously proposed in other domains. Our approach considers various interaction patterns of different sized groups by training multiple classifiers with respect to cardinality. The final estimation is then dynamically performed by meta-classifier learning using the local neighborhood of the current test sample. We experimentally show that the proposed method outperforms state of the art approaches. Finally, we show how the accuracy of the social action detection affects group detection performance, analyze the effectiveness of features for different group sizes in detail, discuss how different types of features contribute to the final performance and evaluate the effects of using the local neighborhood for meta-classifier learning.","Volume 2 Issue 4, December 2018"
45,10.1145/3287042,"Hyunjae Gil, Hongmin Kim, Ian Oakley",Fingers and Angles: Exploring the Comfort of Touch Input on Smartwatches,"Smartwatches present a unique touch input context: small, fixed to one wrist and approachable from a limited range of angles by the touching hand. Techniques to expand their input expressivity often involve variations in how a watch must be touched, such as with different fingers, poses or from specific angles. While objective performance with such systems is commonly reported, subjective qualities such as comfort remain overlooked. We argue that techniques that involve uncomfortable input will be of limited value and contribute the first data on the comfort of input on smartwatches via two studies that combine subjective ratings of comfort with objective performance data. We examine both static and dynamic touches and three finger poses. Based on the study results, we contribute a set of design recommendations for comfortable, effective smartwatch input. We close by instantiating the recommendations in interface prototypes that we evaluate in a final qualitative study.","Volume 2 Issue 4, December 2018"
46,10.1145/3287043,"Xiaonan Guo, Jian Liu, Cong Shi, Hongbo Liu, Yingying Chen, Mooi Choo Chuah",Device-free Personalized Fitness Assistant Using WiFi,"There is a growing trend for people to perform regular workouts in home/office environments because work-at-home people or office workers can barely squeeze in time to go to dedicated exercise places (e.g., gym). To provide personalized fitness assistance in home/office environments, traditional solutions, e.g., hiring personal coaches incur extra cost and are not always available, while new trends requiring wearing smart devices around the clock are cumbersome. In order to overcome these limitations, we develop a device-free fitness assistant system in home/office environments using existing WiFi infrastructure. Our system aims to provide personalized fitness assistance by differentiating individuals, automatically recording fine-grained workout statistics, and assessing workout dynamics. In particular, our system performs individual identification via deep learning techniques on top of workout interpretation. It further assesses the workout by analyzing both short and long-term workout quality, and provides workout reviews for users to improve their daily exercises. Additionally, our system adopts a spectrogram-based workout detection algorithm along with a Cumulative Short Time Energy (CSTE)-based workout segmentation method to ensure its robustness. Extensive experiments involving 20 participants demonstrate that our system can achieve a 93% accuracy on workout recognition and a 97% accuracy for individual identification.","Volume 2 Issue 4, December 2018"
47,10.1145/3287044,"Jinsong Han, Chen Qian, Yuqin Yang, Ge Wang, Han Ding, Xin Li, Kui Ren",Butterfly: Environment-Independent Physical-Layer Authentication for Passive RFID,"RFID tag authentication is challenging because most commodity tags cannot run cryptographic algorithms. Prior research demonstrates that physical layer information based authentication is a promising solution, which uses special features from the physical backscatter signals from tags as their fingerprints. However, our recent studies show that existing physical-layer authentication may fail if feature collection and authentication are conducted in different locations, due to location-dependent noises, environmental factors, or reader hardware differences.
This paper presents a new physical layer authentication scheme, called Butterfly, which is resilient to environment and location changes. Butterfly utilizes a pair of adjacent tags as an identifier of each object. By using the difference between the RF signals of the two tags as their fingerprint, the environmental factors can be effectively canceled. Butterfly is fully compatible with commodity RFID systems and standards. We set up a prototype Butterfly using commodity readers, tags, and RF devices. Extensive experiments show that Butterfly achieves high authentication accuracy for substantially different environments and device changes.","Volume 2 Issue 4, December 2018"
48,10.1145/3287045,"Tanzima Hashem, Rubaba Hasan, Flora Salim, Mehnaz Tabassum Mahin","Crowd-enabled Processing of Trustworthy, Privacy-Enhanced and Personalised Location Based Services with Quality Guarantee","We propose a novel approach for enabling trustworthy, privacy-enhanced and personalised location based services (LBSs) that find nearby points of interests (POIs) such as restaurants, ATM booths, and hospitals in a crowdsourced manner. In our crowdsourced approach, a user forms a group from the crowd and processes the LBS using the POI knowledge of the group members without involving an external service provider. We use personalised rating in addition to the distance of a POI for finding the answers of the location based queries. The personalised rating of a POI is computed using individual POI ratings given by the group members and the query requestor's trust and similarity scores for the group members. The major challenges for the crowdsourced data are incompleteness and inaccuracy, which may result in lower quality answer for the LBS. In this paper, we first present techniques to select knowledgeable group members for processing LBSs and thereby increase the accuracy and the confidence level of the query answers. We then develop efficient algorithms to process LBSs in real time and enhance privacy by reducing the number of the group members' POIs shared with the query requestor. Finally, we run extensive experiments using real datasets to show the efficiency and effectiveness of our approach.","Volume 2 Issue 4, December 2018"
49,10.1145/3287046,"Zhiyuan He, Su Yang",Multi-view Commercial Hotness Prediction Using Context-aware Neural Network Ensemble,"Prediction over heterogeneous data attracts much attention in urban computing. Recently, satellite imagery provides a new chance for urban perception but raises the problem of how to fuse visual and non-visual features. So far, the practice is to concatenate the multimodal features into a vector, which may suppress important features. Therefore, we propose a new ensemble learning framework: (1) An estimator is developed for each predictor to score its confidence, which is input adaptive. (2) By applying the output of each predictor to the input of the corresponding estimator as feedback, the estimator learns the performance of the predictor in the input-output space. When a new input is applied to produce a prediction, the similar situations will be recalled by the estimator to score the confidence of the prediction. (3) Using end-to-end training, the estimator learns the weights automatically to minimize the total loss of the neural networks. With the proposed method, data mining based urban computing and computer vision rendered urban perception can be bridged at the task of commercial activeness prediction, where the prediction based on satellite images and social context data are fused to yield better prediction than those based on single view data in the experiments.","Volume 2 Issue 4, December 2018"
50,10.1145/3287047,"Eiichi Iwamoto, Masaki Matsubara, Chihiro Ota, Satoshi Nakamura, Tsutomu Terada, Hiroyuki Kitagawa, Atsuyuki Morishima",Passerby Crowdsourcing: Workers' Behavior and Data Quality Management,"Worker recruitment is one of the important problems in crowdsourcing, and many proposals have been presented for placing equipment in physical spaces for recruiting workers. One of the essential challenges of the approach is how to keep people attracted because those who perform tasks at first gradually lose interest and do not access the equipment. This study uses a different approach to the worker recruitment problem. In our approach, we dive into people's personal spaces by projecting task images on the floor, thereby allowing the passersby to effortlessly access tasks while walking. The problem then changes from how to keep people engaged to how to manage data quality because many passersby unconsciously or intentionally walk through the task screen on the floor without doing the task, which produces unintended results. We explore a machine-learning approach to select only the intended results and manage the data quality. The system assesses the workers' intention from their behavior. We identify the features for classifiers based on our observations of the passersby. We then conduct extensive evaluations with real data. The results show that the features are effective in practice, and the classifiers improve the data quality.","Volume 2 Issue 4, December 2018"
51,10.1145/3287048,"Mohit Jain, Pratyush Kumar, Ishita Bhansali, Q. Vera Liao, Khai Truong, Shwetak Patel",FarmChat: A Conversational Agent to Answer Farmer Queries,"Farmers constitute 54.6% of the Indian population, but earn only 13.9% of the national GDP. This gross mismatch can be alleviated by improving farmers' access to information and expert advice (e.g., knowing which seeds to sow and how to treat pests can significantly impact yield). In this paper, we report our experience of designing a conversational agent, called FarmChat, to meet the information needs of farmers in rural India. We conducted an evaluative study with 34 farmers near Ranchi in India, focusing on assessing the usability of the system, acceptability of the information provided, and understanding the user population's unique preferences, needs, and challenges in using the technology. We performed a comparative study with two different modalities: audio-only and audio+text. Our results provide a detailed understanding on how literacy level, digital literacy, and other factors impact users' preferences for the interaction modality. We found that a conversational agent has the potential to effectively meet the information needs of farmers at scale. More broadly, our results could inform future work on designing conversational agents for user populations with limited literacy and technology experience.","Volume 2 Issue 4, December 2018"
52,10.1145/3287049,"Timo Jakobi, Gunnar Stevens, Nico Castelli, Corinna Ogonowski, Florian Schaub, Nils Vindice, Dave Randall, Peter Tolmie, Volker Wulf",Evolving Needs in IoT Control and Accountability: A Longitudinal Study on Smart Home Intelligibility,"A key issue for smart home systems is supporting non-expert users in their management. Whereas feedback design on use cases (such as energy feedback) have gained attention, current approaches to providing awareness on the system state typically provide a rather technical view. Long-term investigations of the practices and resources needed for maintaining Do-It-Yourself smart home systems, are particularly scarce. We report on a design case study in which we equipped 12 households with DIY smart home systems for two years and studied participants' strategies for maintaining system awareness, from learning about its workings to monitoring its behavior. We find that people's needs regarding system accountability changed over time. Their privacy needs were also affected over the same period. We found that participants initially looked for in-depth awareness information from the dedicated web-based dashboard. In the later phases of appropriation, however, their interaction and information needs shifted towards management by exception on mobile or ambient displays -- only focusing on the system when things were 'going wrong'. In terms of system accountability, we find that a system's self-declaration should focus on being socially meaningful rather than technically complete, for instance by relating itself to people's activities and the home routines.","Volume 2 Issue 4, December 2018"
53,10.1145/3287050,"Kasthuri Jayarajah, Archan Misra",Predicting Episodes of Non-Conformant Mobility in Indoor Environments,"Traditional mobility prediction literature focuses primarily on improved methods to extract latent patterns from individual-specific movement data. When such predictions are incorrect, we ascribe it to 'random' or 'unpredictable' changes in a user's movement behavior. Our hypothesis, however, is that such apparently-random deviations from daily movement patterns can, in fact, of ten be anticipated. In particular, we develop a methodology for predicting Likelihood of Future Non-Conformance (LFNC), based on two central hypotheses: (a) the likelihood of future deviations in movement behavior is positively correlated to the intensity of such trajectory deviations observed in the user's recent past, and (b) the likelihood of such future deviations increases if the user's strong-ties have also recently exhibited such non-conformant movement behavior. We use extensive longitudinal indoor location data (spanning 4+ months) from an urban university campus to validate these hypotheses, and then show that these features can be used to build an accurate non-conformance predictor: it can predict non-conformant mobility behavior two hours in advance with an AUC ≥ 0.85, significantly outperforming the baseline. We also show that this prediction methodology holds for a representative outdoor public-transport based mobility dataset. Finally, we use a real-world mobile crowd-sourcing application to show the practical impact of such non-conformance: failure to identify such likely anomalous movement behavior causes workers to suffer a noticeable drop in task completion rates and reduces the spatial spread of successfully completed tasks.","Volume 2 Issue 4, December 2018"
54,10.1145/3287051,"Haojian Jin, Minyi Liu, Kevan Dodhia, Yuanchun Li, Gaurav Srivastava, Matthew Fredrikson, Yuvraj Agarwal, Jason I. Hong",Why Are They Collecting My Data?: Inferring the Purposes of Network Traffic in Mobile Apps,"Many smartphone apps collect potentially sensitive personal data and send it to cloud servers. However, most mobile users have a poor understanding of why their data is being collected. We present MobiPurpose, a novel technique that can take a network request made by an Android app and then classify the data collection purposes, as one step towards making it possible to explain to non-experts the data disclosure contexts. Our purpose inference works by leveraging two observations: 1) developer naming conventions (e.g., URL paths) of ten offer hints as to data collection purposes, and 2) external knowledge, such as app metadata and information about the domain name, are meaningful cues that can be used to infer the behavior of different traffic requests. MobiPurpose parses each traffic request body into key-value pairs, and infers the data type and data collection purpose of each key-value pair using a combination of supervised learning and text pattern bootstrapping. We evaluated MobiPurpose's effectiveness using a dataset cross-labeled by ten human experts. Our results show that MobiPurpose can predict the data collection purpose with an average precision of 84% (among 19 unique categories).","Volume 2 Issue 4, December 2018"
55,10.1145/3287052,"Mohamed Khamis, Ludwig Trotter, Ville Mäkelä, Emanuel von Zezschwitz, Jens Le, Andreas Bulling, Florian Alt","CueAuth: Comparing Touch, Mid-Air Gestures, and Gaze for Cue-based Authentication on Situated Displays","Secure authentication on situated displays (e.g., to access sensitive information or to make purchases) is becoming increasingly important. A promising approach to resist shoulder surfing attacks is to employ cues that users respond to while authenticating; this overwhelms observers by requiring them to observe both the cue itself as well as users' response to the cue. Although previous work proposed a variety of modalities, such as gaze and mid-air gestures, to further improve security, an understanding of how they compare with regard to usability and security is still missing as of today. In this paper, we rigorously compare modalities for cue-based authentication on situated displays. In particular, we provide the first comparison between touch, mid-air gestures, and calibration-free gaze using a state-of-the-art authentication concept. In two in-depth user studies (N=20, N=17) we found that the choice of touch or gaze presents a clear tradeoff between usability and security. For example, while gaze input is more secure, it is also more demanding and requires longer authentication times. Mid-air gestures are slightly slower and more secure than touch but users hesitate to use them in public. We conclude with three significant design implications for authentication using touch, mid-air gestures, and gaze and discuss how the choice of modality creates opportunities and challenges for improved authentication in public.","Volume 2 Issue 4, December 2018"
56,10.1145/3287053,"Auk Kim, Woohyeok Choi, Jungmi Park, Kyeyoon Kim, Uichin Lee",Interrupting Drivers for Interactions: Predicting Opportune Moments for In-vehicle Proactive Auditory-verbal Tasks,"Auditory-verbal interactions with in-vehicle information systems have become increasingly popular for improving driver safety because they obviate the need for distractive visual-manual operations. This opens up new possibilities for enabling proactive auditory-verbal services where intelligent agents proactively provide contextualized recommendations and interactive decision-making. However, prior studies have warned that such interactions may consume considerable attentional resources, thus negatively affecting driving performance. This work aims to develop a machine learning model that can find opportune moments for the driver to engage in proactive auditory-verbal tasks by using the vehicle and environment sensor data. Given that there is a lack of definition about what constitutes interruptibility for auditory-verbal tasks, we first define interruptible moments by considering multiple dimensions and then iteratively develop the experimental framework through an extensive literature review and four pilot studies. We integrate our framework into OsmAnd, an open-source navigation service, and perform a real-road field study with 29 drivers to collect sensor data and user responses. Our machine learning analysis shows that opportune moments for interruption can be conservatively inferred with an accuracy of 0.74. We discuss how our experimental framework and machine learning models can be used to design intelligent auditory-verbal services in practical deployment contexts.","Volume 2 Issue 4, December 2018"
57,10.1145/3287054,"Hyosun Kwon, Joel E. Fischer, Martin Flintham, James Colley",The Connected Shower: Studying Intimate Data in Everyday Life,"This paper presents the design and field study of the Connected Shower, a bespoke IoT device that captures water flow, temperature, shower-head movement, and shower product weight. We deployed the device in six UK homes for a week to understand the use of 'intimate data' as captured by IoT systems. Findings from our contextual interviews unpack a) how such intimate data is collaboratively made sense of by accounting for the social order of showering practices as part and parcel of everyday routines; b) how the data makes details of showering accountable to their partners; c) how people reason about sharing intimate data both with third parties and their partners. Our study shows that intimate data is not intimate per se, nor is intimacy a property of the data, but is an interactional outcome arising from the articulation of shower practices to their co-present partners. Thus, judgments as to whether the data is too sensitive, private, or intimate to share are contingent on situated sense-making and therefore subject to change; however, there was a general consensus that sharing intimate data with service providers was acceptable if the data was sufficiently abstract and anonymised. We discuss challenges in the design of trustworthy data-driven IoT systems, and how they need to be warranted to be both acceptable and adopted into our intimate practices.","Volume 2 Issue 4, December 2018"
58,10.1145/3287055,"Zeshui Li, Haipeng Dai, Wei Wang, Alex X. Liu, Guihai Chen",PCIAS: Precise and Contactless Measurement of Instantaneous Angular Speed Using a Smartphone,"Measuring Instantaneous Angular Speed (IAS) of rotating objects is ubiquitous in industry and our daily life. Engineers diagnose the operation condition of engines with IAS. Anemometers obtain instantaneous wind speed with the IAS of rotating cups. Traditional IAS measurement systems have their limitations in the aspects of installation, accuracy, and cost. In this paper, we propose PCIAS, a system that uses acoustic signals of a smartphone to measure IAS of rotating objects in a contactless manner. PCIAS covers a pretty large IAS measurement range (the numerical interval of IAS) from 10 Revolutions Per Minute (RPM) to 10000 RPM, which outperforms almost all existing Commercial-Off-The-Shelf (COTS) IAS meters. In PCIAS, we first choose an appropriate measurement range according to applications. We then use the smartphone to collect acoustic signals backscattered or generated by the object. Next, we extract acoustic features of the object to eliminate interferences from the environment. After that, we propose a robust tracking algorithm to estimate IAS by matching cycle time length of acoustic features adaptively. We build two testbeds to evaluate the accuracy and the robustness of our system in different IAS ranges. Our experiments show that PCIAS achieves a relative accuracy of more than 92% in the low IAS range, more than 94% in the middle IAS range, and more than 96% in the high IAS range. Finally, We exhibit two typical cases to demonstrate the practical use of our system.","Volume 2 Issue 4, December 2018"
59,10.1145/3287056,"Tianshi Li, Yuvraj Agarwal, Jason I. Hong",Coconut: An IDE Plugin for Developing Privacy-Friendly Apps,"Although app developers are responsible for protecting users' privacy, this task can be very challenging. In this paper, we present Coconut, an Android Studio plugin that helps developers handle privacy requirements by engaging developers to think about privacy during the development process and providing real-time feedback on potential privacy issues. We start by presenting new findings based on a series of semi-structured interviews with Android developers, probing into the difficulties with privacy that developers face when building apps. Based on these findings, we implemented a proof-of-concept prototype of Coconut and evaluated it in a controlled lab study with 18 Android developers (including eight professional developers). Our study results suggest that apps developed with Coconut handled privacy concerns better, and the developers that used Coconut had a better understanding of their code's behavior and wrote a better privacy policy for their app. We also found that requiring developers to do a small amount of annotating work regarding their apps' personal data practices during the development process may result in a significant improvement in app privacy.","Volume 2 Issue 4, December 2018"
60,10.1145/3287057,"Peng Liao, Walter Dempsey, Hillol Sarker, Syed Monowar Hossain, Mustafa al'Absi, Predrag Klasnja, Susan Murphy",Just-in-Time but Not Too Much: Determining Treatment Timing in Mobile Health,"There is a growing scientific interest in the use and development of just-in-time adaptive interventions in mobile health. These mobile interventions typically involve treatments, such as reminders, activity suggestions and motivational messages, delivered via notifications on a smartphone or a wearable to help users make healthy decisions in the moment. To be effective in influencing health, the combination of the right treatment and right delivery time is likely critical. A variety of prediction/detection algorithms have been developed with the goal of pinpointing the best delivery times. The best delivery times might be times of greatest risk and/or times at which the user might be most receptive to the treatment notifications. In addition, to avoid over burdening users, there is of ten a constraint on the number of treatments that should be provided per time interval (e.g., day or week). Yet there may be many more times at which the user is predicted or detected to be at risk and/or receptive. The goal then is to spread treatment uniformly across all of these times. In this paper, we introduce a method that spreads the treatment uniformly across the delivery times. This method can also be used to provide data for learning whether the treatments are effective at the delivery times. This work is motivated by our work on two mobile health studies, a smoking cessation study and a physical activity study.","Volume 2 Issue 4, December 2018"
61,10.1145/3287058,"Héctor A. Cordourier Maruri, Paulo Lopez-Meyer, Jonathan Huang, Willem Marco Beltman, Lama Nachman, Hong Lu",V-Speech: Noise-Robust Speech Capturing Glasses Using Vibration Sensors,"Smart glasses are often used in public environments or industrial scenarios that are relatively noisy. Background noise and sound from competing speakers deteriorate voice communication or performance of automatic speech recognition (ASR). Typically, signal processing techniques are used to reduce noise and enhance voice quality, but they have limitations in performance, hardware and/or computing resources. Voice capturing techniques using bone conducting on the head have been proposed in some experimental and commercial devices, with good robustness against environmental noise, but limited by signal distortions inherent to the capturing method. We present V-Speech, a novel sensing and signal processing solution that enables speech recognition and human-to-human communication in very noisy environments. It captures the voice signal with a vibration sensor located in the nasal pads of smart glasses and performs a transformation to the sensor signal in order to mimic that of a regular microphone in low noise conditions. The signal transformation is key, as it eliminates the ""nasal distortion"" that is introduced for nasal phonemes in the speech induced vibrations of the nasal bone. The output of V-Speech has low noise, sounds natural, and can be used in voice communication or as input to an off-the-shelf ASR service. We evaluated V-Speech in noise-free and noisy conditions with 30 volunteer speakers uttering 145 phrases and validated its performance on ASR engines and with assessments of voice quality using the Perceptual Evaluation of Speech Quality (PESQ) metric. The results show in extreme noise conditions a mean improvement of 50% for Word Error Rate (WER), and 1.0 on a scale of 5.0 for PESQ. In addition, real life recordings were made under various representative noise conditions, some with sound pressure levels of 93 dBA, which require hearing protection. Subjective listening tests were conducted according to a modified ITU P.835 approach to determine intelligibility, naturalness and overall quality. Under these extreme conditions, where V-Speech achieved 30 dB SNR, subjective results show the speech is intelligible, and the naturalness of the speech is rated as fair to good. This enables clear voice communication in challenging work environments, for example in places with industrial, factory, mining and construction noise. With our proposed smart switching technique between a regular microphone signal and V-Speech, the optimal quality can be maintained from low to high noise conditions.","Volume 2 Issue 4, December 2018"
62,10.1145/3287059,"Akshay Uttama Nambi, Adtiya Virmani, Venkata N. Padmanabhan",FarSight: A Smartphone-based Vehicle Ranging System,"Maintaining an adequate separation from the vehicle in front is key to safe driving. While LIDAR and RADAR sensors could be used for ranging, cost considerations and the huge installed base of vehicles that lack these sensors, especially in developing regions, call for a low-cost yet robust alternative. To this end, we present FarSight, a system that performs vehicle ranging using a smartphone mounted on the windshield or the dashboard. FarSight uses the smartphone's camera to identify and draw a bounding box around vehicles in front, based on which ranging is performed. Unlike prior smartphone-based work, FarSight does not depend on any infrastructure support such as standard-width lane markers and works with a heterogeneous mix of vehicles, both of which are characteristics of developing regions. We develop a novel hybrid approach for vehicle detection and tracking, which balances accuracy and speed by combining deep neural network based vehicle detection with vision-based object tracking in a pipelined manner. We also devise data augmentation techniques to improve the effectiveness of vehicle detection, thereby increasing the ranging distance.
We show that FarSight can range accurately in both daytime and nighttime conditions and up to distances of 90 m. We have implemented FarSight as an Android-app and tested it across various phones. Further, we present two ranging-based applications built on FarSight.","Volume 2 Issue 4, December 2018"
63,10.1145/3287060,"Yi Ouyang, Bin Guo, Tong Guo, Longbing Cao, Zhiwen Yu",Modeling and Forecasting the Popularity Evolution of Mobile Apps: A Multivariate Hawkes Process Approach,"In recent years, with the rapid development of mobile app ecosystem, the number and categories of mobile apps have grown tremendously. However, the global prevalence of mobile apps also leads to fierce competition. As a result, many apps will disappear. To thrive in this competitive app market, it is vital for app developers to understand the popularity evolution of their mobile apps, and inform strategic decision-making for better mobile app development. Therefore, it is significant and necessary to model and forecast the future popularity evolution of mobile apps. The popularity evolution of mobile apps is usually a long-term process, affected by various complex factors. However, existing works lack the capabilities to model such complex factors. To better understand the popularity evolution, in this paper, we aim to forecast the popularity evolution of mobile apps by incorporating complex factors, i.e., exogenous stimulis and endogenous excitations. Specifically, we propose a model based on the Multivariate Hawkes Process (MHP), which is an exogenous stimulis-driven self-exciting point process, to model the exogenous stimulis and endogenous excitations simultaneously. Extensive experimental studies on a real-world dataset from app store demonstrate that MHP outperforms the state-of-the-art methods regarding popularity evolution forecasting.","Volume 2 Issue 4, December 2018"
64,10.1145/3287061,"Xinru Page, Paritosh Bahirat, Muhammad I. Safi, Bart P. Knijnenburg, Pamela Wisniewski",The Internet of What?: Understanding Differences in Perceptions and Adoption for the Internet of Things,"This study explores people's perceptions of and attitudes towards Internet of Things (IoT) devices and their resulting (non)adoption behaviors. Based on 38 interviews (19 pairs each consisting of a Millennial and their parent), we found that few had a clear understanding of IoT, even among those who had already adopted it. Rather, they relied on two distinct conceptual models of IoT that shaped their beliefs, concerns, and adoption decisions: Many approached IoT with an ""user-centric"" technology mentality, viewing IoT devices as tools to be controlled by the end-user, and focusing on their tangible aspects (e.g. breakability). Others drew on an ""agentic"" technology perspective, where IoT behaviors were device-driven and, at times, negotiated between the user, other people, and/or the IoT devices. Our study revealed that consumer-oriented IoT currently cater towards the agentic view and raise concerns for those coming from a user-centric perspective. We also found that generational differences in attitudes towards IoT were rather explained by these differing perspectives. Instead of following the trend towards greater automation and agentic modes of interaction, we advocate for a hybrid and personalized approach that supports a spectrum of agentic and user-centric perspectives and provide design recommendations to work towards this end.","Volume 2 Issue 4, December 2018"
65,10.1145/3287062,"Pablo E. Paredes, Stephanie Balters, Kyle Qian, Elizabeth L. Murnane, Francisco Ordóñez, Wendy Ju, James A. Landay",Driving with the Fishes: Towards Calming and Mindful Virtual Reality Experiences for the Car,"We present the use of in-car virtual reality (VR) as a way to create calm, mindful experiences for passengers and, someday, autonomous vehicle occupants. Specifically, we describe a series of studies aimed at exploring appropriate VR content, understanding the influence of car movement, and determining the length and other parameters of the simulation to avoid physical discomfort. Overall, our quantitative and qualitative insights suggest calm VR applications are well suited to an automotive context. Testing combinations of VR content designed to provide the participant with a static or dynamic experience versus stationary and moving vehicle modes, we find that a simulated experience of diving in the ocean while in a moving car elicited significantly lower levels of autonomic arousal as compared with a static VR plus stationary car condition. No significant motion sickness effects were subjectively reported by participants nor observable in the data, though a crossover interaction effect reveals how incongruence between the movement of the car and movement in VR could affect nausea. We conclude with recommendations for the design of calming and mindful VR experiences in moving vehicles.","Volume 2 Issue 4, December 2018"
66,10.1145/3287063,"Rushil Khurana, Karan Ahuja, Zac Yu, Jennifer Mankoff, Chris Harrison, Mayank Goel","GymCam: Detecting, Recognizing and Tracking Simultaneous Exercises in Unconstrained Scenes","Worn sensors are popular for automatically tracking exercises. However, a wearable is usually attached to one part of the body, tracks only that location, and thus is inadequate for capturing a wide range of exercises, especially when other limbs are involved. Cameras, on the other hand, can fully track a user's body, but suffer from noise and occlusion. We present GymCam, a camera-based system for automatically detecting, recognizing and tracking multiple people and exercises simultaneously in unconstrained environments without any user intervention. We collected data in a varsity gym, correctly segmenting exercises from other activities with an accuracy of 84.6%, recognizing the type of exercise at 93.6% accuracy, and counting the number of repetitions to within ± 1.7 on average. GymCam advances the field of real-time exercise tracking by filling some crucial gaps, such as tracking whole body motion, handling occlusion, and enabling single-point sensing for a multitude of users.","Volume 2 Issue 4, December 2018"
67,10.1145/3287064,"Amin Sadri, Flora D. Salim, Yongli Ren, Wei Shao, John C. Krumm, Cecilia Mascolo",What Will You Do for the Rest of the Day?: An Approach to Continuous Trajectory Prediction,"Understanding and predicting human mobility is vital to a large number of applications, ranging from recommendations to safety and urban service planning. In some travel applications, the ability to accurately predict the user's future trajectory is vital for delivering high quality of service. The accurate prediction of detailed trajectories would empower location-based service providers with the ability to deliver more precise recommendations to users. Existing work on human mobility prediction has mainly focused on the prediction of the next location (or the set of locations) visited by the user, rather than on the prediction of the continuous trajectory (sequences of further locations and the corresponding arrival and departure times). Furthermore, existing approaches often return predicted locations as regions with coarse granularity rather than geographical coordinates, which limits the practicality of the prediction.
In this paper, we introduce a novel trajectory prediction problem: given historical data and a user's initial trajectory in the morning, can we predict the user's full trajectory later in the day (e.g. the afternoon trajectory)? The predicted continuous trajectory includes the sequence of future locations, the stay times, and the departure times. We first conduct a comprehensive analysis about the relationship between morning trajectories and the corresponding afternoon trajectories, and found there is a positive correlation between them. Our proposed method combines similarity metrics over the extracted temporal sequences of locations to estimate similar informative segments across user trajectories.
Our evaluation shows results on both labeled and geographical trajectories with a prediction error reduced by 10-35% in comparison to the baselines. This improvement has the potential to enable precise location services, raising usefulness to users to unprecedented levels. We also present empirical evaluations with Markov model and Long Short Term Memory (LSTM), a state-of-the-art Recurrent Neural Network model. Our proposed method is shown to be more effective when smaller number of samples are used and is exponentially more efficient than LSTM.","Volume 2 Issue 4, December 2018"
68,10.1145/3287065,"Ankur Sarker, Haiying Shen",A Data-Driven Misbehavior Detection System for Connected Autonomous Vehicles,"In a Connected and Autonomous Vehicle (CAV) system, some malicious CAVs may send out false information in vehicle-to-vehicle communication to gain benefits or cause safety-related accidents. Previous false data detection methods are not sufficient to meet the accuracy and real-time requirements. In this paper, we propose a data-driven misbehavior detection system (MDS) (running by each CAV) that checks the consistency between the estimated and actually reported driving state (i.e., velocity, acceleration, brake status, steering angle) of an alerting CAV. First, MDS predicts the driving state using Gaussian mixture model based Mixture Density Network incorporating Recurrent Neural Network that can catch the driving behavior patterns of a CAV. Second, MDS extends the existing Krauss traffic flow model and uses it to consider the overall traffic flow of the road to make the predicted driving state more accurate. Finally, for a given received alert, a CAV validates the alert by checking the consistency between the predicted and actually reported driving states of the alerting CAV. We conduct extensive simulation studies based on a real driving dataset we collected from 29 participants and the Simulator for Urban MObility (SUMO) traffic simulator. The experimental results show that the false information detection rate of the proposed MDS is higher than other existing systems in different alert scenarios.","Volume 2 Issue 4, December 2018"
69,10.1145/3287066,"Takuya Sasatani, Chouchang Jack Yang, Matthew J. Chabalko, Yoshihiro Kawahara, Alanson P. Sample",Room-Wide Wireless Charging and Load-Modulation Communication via Quasistatic Cavity Resonance,"The rise of the Internet of Things (IoT) has led to a significant increase in the number of connected devices that stream data in our homes, offices and industrial spaces. However, as the number of these devices increases, the costs of actively maintaining and replacing batteries becomes prohibitive at scale. Recent work on Quasistatic Cavity Resonance (QSCR), offers the possibility of seamless wireless power transfer (WPT) to receivers placed anywhere inside large indoor spaces. This work aims to solve two unexplored and critical missing pieces needed to realize this vision of ubiquitous WPT. First, we demonstrate a full end-to-end QSCR-based WPT system that is capable of simultaneously charging multiple custom designed nodes nearly anywhere in the 4.9 m x 4.9 m x 2.3 m test room. Second, this work utilizes the WPT mechanism as a communication channel, where nodes communicate with a centralized reader and to each other via load modulation. Through analysis and experiments, the proposed system shows that 10 receiver nodes can be safely and efficiently wirelessly charged and the end node to end node communication rate can achieve from 1 kbps without occurring any errors, up to 5 kbps with 6% BER while the end node to central unit can achieve 10 kbps without occurring any errors.","Volume 2 Issue 4, December 2018"
70,10.1145/3287067,"Namrata Srivastava, Joshua Newn, Eduardo Velloso",Combining Low and Mid-Level Gaze Features for Desktop Activity Recognition,"Human activity recognition (HAR) is an important research area due to its potential for building context-aware interactive systems. Though movement-based activity recognition is an established area of research, recognising sedentary activities remains an open research question. Previous works have explored eye-based activity recognition as a potential approach for this challenge, focusing on statistical measures derived from eye movement properties---low-level gaze features---or some knowledge of the Areas-of-Interest (AOI) of the stimulus---high-level gaze features. In this paper, we extend this body of work by employing the addition of mid-level gaze features; features that add a level of abstraction over low-level features with some knowledge of the activity, but not of the stimulus. We evaluated our approach on a dataset collected from 24 participants performing eight desktop computing activities. We trained a classifier extending 26 low-level features derived from existing literature with the addition of 24 novel candidate mid-level gaze features. Our results show an overall classification performance of 0.72 (F1-Score), with up to 4% increase in accuracy when adding our mid-level gaze features. Finally, we discuss the implications of combining low- and mid-level gaze features, as well as the future directions for eye-based activity recognition.","Volume 2 Issue 4, December 2018"
71,10.1145/3287068,"Ryo Takahashi, Takuya Sasatani, Fuminori Okuya, Yoshiaki Narusue, Yoshihiro Kawahara",A Cuttable Wireless Power Transfer Sheet,"We propose a cuttable wireless power transfer sheet which allows users to modify its size and shape. This intuitive manipulation allows users to easily add wireless power transmission capabilities to everyday objects. The properties of the sheet such as thinness, flexibility, and lightness make our sheet highly compatible with various configurations. We contribute a set of technical principles for the design of circuitry, which integrates H-tree wiring and time division power supply techniques. H-tree wiring allows the sheet to remain functional even when cut from the outside of the sheet, whereas time division power supply avoids the reduction in power transfer efficiency caused by the magnetic interference between adjacent transmitter coils. Through the evaluations, we found that our time division power supply scheme mitigates the degradation of power transfer efficiency and successfully improves the average efficiency. Furthermore, we present four applications which integrates our sheet into daily objects: wireless charging furniture, bag, jacket, and craft; these applications confirmed the feasibility of our prototype.","Volume 2 Issue 4, December 2018"
72,10.1145/3287069,"Neille-Ann H. Tan, Han Sha, Eda Celen, Phucanh Tran, Kelly Wang, Gifford Cheung, Philip Hinch, Jeff Huang",Rewind: Automatically Reconstructing Everyday Memories with First-Person Perspectives,"Snapping photos or videos on a smartphone makes recording visual memories convenient, but what isn't captured may still be meaningful in retrospect. In this paper, digital mementos are automatically generated for participants using the Rewind system, which assists the recall of location-based minutiae. Rewind is a video-like medium describing people's daily excursions using a sequence of street-level images determined by self-tracked location data. The Rewinds are color-processed to reflect seasonal, time-of-day and weather characteristics. Through two user studies with a combined 40 users, Rewinds were shown to be used as memory artifacts, and are especially meaningful in the many situations when photos or videos are not available. The small cues in Rewinds evoke longer fragments of memory tied to nostalgic routines or significant events, and the sequence of images provide a first-person perspective of remembrance for users. While they are more generic and can possess inaccuracies, Rewinds give people anchors for memories that feel like their own that are used to craft a narrative for that day. Rewind strikes a balance between automatic logging and manually-curated memories by personalizing it in meaningful visuals and consolidating an otherwise overwhelming amount of data.","Volume 2 Issue 4, December 2018"
73,10.1145/3287070,"Nic Volanschi, Bernard Serpette, Adrien Carteron, Charles Consel","A Language for Online State Processing of Binary Sensors, Applied to Ambient Assisted Living","There is a large variety of binary sensors in use today, and useful context-aware services can be defined using such binary sensors. However, the currently available approaches for programming context-aware services do not conveniently support binary sensors. Indeed, no existing approach simultaneously supports a notion of state, central to binary sensors, offers a complete set of operators to compose states, allows to define reusable abstractions by means of such compositions, and implements efficient online processing of these operators.
This paper proposes a new language for event processing specifically targeted to binary sensors. The central contributions of this language are a native notion of state and semi-causal operators for temporal state composition including: Allen's interval relations generalized for handling multiple intervals, and temporal filters for handling delays. Compared to other approaches such as CEP (complex event processing), our language provides less discontinued information, allows less restricted compositions, and supports reusable abstractions. We implemented an interpreter for our language and applied it to successfully rewrite a full set of real Ambient Assisted Living services. The performance of our prototype interpreter is shown to compete well with a commercial CEP engine when expressing the same services.","Volume 2 Issue 4, December 2018"
74,10.1145/3287071,"Yanwen Wang, Yuanqing Zheng",Modeling RFID Signal Reflection for Contact-free Activity Recognition,"Wireless sensing techniques for tracking human activities have been vigorously developed in recent years. Yet current RFID based human activity recognition techniques need either direct contact to human body (e.g., attaching RFIDs to users) or specialized hardware (e.g., software defined radios, antenna array). How to wirelessly track human activities using commodity RFID systems without attaching tags to users (i.e., a contact-free scenario) still faces lots of technical challenges. In this paper, we quantify the correlation between RF phase values and human activities by modeling intrinsic characteristics of signal reflection in contact-free scenarios. Based on the signal reflection model, we introduce TACT that can recognize human activities using commodity RFIDs without attaching any RFID tags to users. TACT first reliably detects the presence of human activities and segments phase values. Then, candidate phase segments are classified according to their coarse-grained features (e.g., moving speed, moving distance, activity duration) as well as their fine-grained feature of phase waveform. We deploy and leverage multiple tags to increase the coverage and enhance the robustness of the system. We implement TACT with commodity RFID systems. We invite 12 participants to evaluate our system in various scenarios. The experiment results show that TACT can recognize eight types of human activities with 93.5% precision under different and challenging experiment settings.","Volume 2 Issue 4, December 2018"
75,10.1145/3287072,"Zi Wang, Sheng Tan, Linghan Zhang, Jie Yang",ObstacleWatch: Acoustic-based Obstacle Collision Detection for Pedestrian Using Smartphone,"Walking while using a smartphone is becoming a major pedestrian safety concern as people may unknowingly bump into various obstacles that could lead to severe injuries. In this paper, we propose ObstacleWatch, an acoustic-based obstacle collision detection system to improve the safety of pedestrians who are engaged in smartphone usage while walking. ObstacleWatch leverages the advanced audio hardware of the smartphone to sense the surrounding obstacles and infers fine-grained information about the frontal obstacle for collision detection. In particular, our system emits well-designed inaudible beep signals from the smartphone built-in speaker and listens to the reflections with the stereo recording of the smartphone. By analyzing the reflected signals received at two microphones, ObstacleWatch is able to extract fine-grained information of the frontal obstacle including the distance, angle and size for detecting the possible collisions and to alert users. Our experimental evaluation under two real-world environments with different types of phones and obstacles shows that ObstacleWatch achieves over 92% accuracy in predicting obstacle collisions with distance estimation errors at about 2 cm. Results also show that ObstacleWatch is robust to different sizes of objects and is compatible to different phone models with low energy consumption.","Volume 2 Issue 4, December 2018"
76,10.1145/3287073,"Shweta Ware, Chaoqun Yue, Reynaldo Morillo, Jin Lu, Chao Shang, Jayesh Kamath, Athanasios Bamis, Jinbo Bi, Alexander Russell, Bing Wang",Large-scale Automatic Depression Screening Using Meta-data from WiFi Infrastructure,"Depression is a serious public health problem. Current diagnosis techniques rely on physician-administered or patient self-administered interview tools, which are burdensome and suffer from recall bias. Recent studies have proposed new approaches that use sensing data collected on smartphones to serve as ""human sensors"" for automatic depression screening. These approaches, however, require running an app on the phones for continuous data collection. We explore a novel approach that uses data collected from WiFi infrastructure for large-scale automatic depression screening. Specifically, when smartphones connect to a WiFi network, their locations (and hence the locations of the users) can be determined by the access points that they associate with; the location information over time provides important insights into the behavior of the users, which can be used for depression screening. To investigate the feasibility of this approach, we have analyzed two datasets, each collected over several months, involving tens of participants recruited from a university. Our results demonstrate that WiFi meta-data is effective for passive depression screening: the F1 scores are as high as 0.85 for predicting depression, comparable to those obtained by using sensing data collected directly from smartphones.","Volume 2 Issue 4, December 2018"
77,10.1145/3287074,"Xiaoyang Xie, Yu Yang, Zhihan Fang, Guang Wang, Fan Zhang, Fan Zhang, Yunhuai Liu, Desheng Zhang",coSense: Collaborative Urban-Scale Vehicle Sensing Based on Heterogeneous Fleets,"The real-time vehicle sensing at urban scale is essential to various urban services. To date, most existing approaches rely on static infrastructures (e.g., traffic cameras) or mobile services (e.g., smartphone apps). However, these approaches are often inadequate for urban scale vehicle sensing at the individual level because of their static natures or low penetration rates. In this paper, we design a sensing system called coSense to utilize commercial vehicular fleets (e.g., taxis, buses, and trucks) for real-time vehicle sensing at urban scale, given (i) the availability of well-equipped commercial fleets sensing other vehicles by onboard cameras or peer-to-peer communication, and (ii) an increasing trend of connected vehicles and autonomous vehicles with periodical status broadcasts for safety applications. Compared to existing solutions based on cameras and smartphones, the key features of coSense are in its high penetration rates and transparent sensing for participating drivers. The key technical challenge we addressed is how to recover spatiotemporal sensing gaps by considering various mobility patterns of commercial vehicles with deep learning. We evaluate coSense with a preliminary road test and a large-scale trace-driven evaluation based on vehicular fleets in the Chinese city Shenzhen, including 14 thousand taxis, 13 thousand buses, 13 thousand trucks, and 10 thousand regular vehicles. We compare coSense to infrastructure and cellphone-based approaches, and the results show that we increase the sensing accuracy by 10.1% and 16.6% on average.","Volume 2 Issue 4, December 2018"
78,10.1145/3287075,"Mengwei Xu, Feng Qian, Qiaozhu Mei, Kang Huang, Xuanzhe Liu",DeepType: On-Device Deep Learning for Input Personalization Service with Minimal Privacy Concern,"Mobile users spend an extensive amount of time on typing. A more efficient text input instrument brings a significant enhancement of user experience. Deep learning techniques have been recently applied to suggesting the next words of input, but to achieve more accurate predictions, these models should be customized for individual users. Personalization is often at the expense of privacy concerns. Existing solutions require users to upload the historical logs of their input text to the cloud so that a deep learning predictor can be trained. In this work, we propose a novel approach, called DeepType, to personalize text input with better privacy. The basic idea is intuitive: training deep learning predictors on the device instead of on the cloud, so that the model makes personalized and private data never leaves the device to externals. With DeepType, a global model is first trained on the cloud using massive public corpora, and our personalization is done by incrementally customizing the global model with data on individual devices. We further propose a set of techniques that effectively reduce the computation cost of training deep learning models on mobile devices at the cost of negligible accuracy loss. Experiments using real-world text input from millions of users demonstrate that DeepType significantly improves the input efficiency for individual users, and its incurred computation and energy costs are within the performance and battery restrictions of typical COTS mobile devices.","Volume 2 Issue 4, December 2018"
79,10.1145/3287076,"Yukang Yan, Chun Yu, Xin Yi, Yuanchun Shi",HeadGesture: Hands-Free Input Approach Leveraging Head Movements for HMD Devices,"We propose HeadGesture, a hands-free input approach to interact with Head Mounted Display (HMD) devices. Using HeadGesture, users do not need to raise their arms to perform gestures or operate remote controllers in the air. Instead, they perform simple gestures with head movement to interact with the devices. In this way, users' hands are free to perform other tasks, e.g., taking notes or manipulating tools. This approach also reduces the hand occlusion of the field of view [11] and alleviates arm fatigue [7]. However, one main challenge for HeadGesture is to distinguish the defined gestures from unintentional movements. To generate intuitive gestures and address the issue of gesture recognition, we proceed through a process of Exploration - Design - Implementation - Evaluation. We first design the gesture set through experiments on gesture space exploration and gesture elicitation with users. Then, we implement algorithms to recognize the gestures, including gesture segmentation, data reformation and unification, feature extraction, and machine learning based classification. Finally, we evaluate user performance of HeadGesture in the target selection experiment and application tests. The results demonstrate that the performance of HeadGesture is comparable to mid-air hand gestures, measured by completion time. Additionally, users feel significantly less fatigue than when using hand gestures and can learn and remember the gestures easily. Based on these findings, we expect HeadGesture to be an efficient supplementary input approach for HMD devices.","Volume 2 Issue 4, December 2018"
80,10.1145/3287077,"Lin Yang, Zeyu Wang, Wei Wang, Qian Zhang",NALoc: Nonlinear Ambient-Light-Sensor-based Localization System,"Visible light position (VLP) is a revolutionary technique which enables many promising applications. As the human eye is sensitive to low-rate changes, VLP systems often convey location information through light flickering over 1 KHz, which induces a heavy burden on the VLP receiver. Existing solutions either rely on the high-resolution cameras or a dedicated photodiode to capture the location information, but the high power consumption and extraction deployment cost hinder their wide adoption. In this paper, we present a light-weight VLP system, NALoc, which leverages the ambient light sensor (ALS) readily on many mobile devices to sense high-frequency-modulation location information. To overcome the insufficient sampling ability of ALS, we exploit the nonlinearity of ALS to sense the leaked energy from high frequency(≥ 1 KHz) at a low sampling rate(100 Hz). Extensive evaluations demonstrate that our system can achieve a decimeter-level localization accuracy with about 1 mW power consumption, which is 2000 times less than existing camera-based VLP solutions.","Volume 2 Issue 4, December 2018"
81,10.1145/3287078,"Hui-Shyong Yeo, Ryosuke Minami, Kirill Rodriguez, George Shaker, Aaron Quigley",Exploring Tangible Interactions with Radar Sensing,"Research has explored miniature radar as a promising sensing technique for the recognition of gestures, objects, users' presence and activity. However, within Human-Computer Interaction (HCI), its use remains underexplored, in particular in Tangible User Interface (TUI). In this paper, we explore two research questions with radar as a platform for sensing tangible interaction with the counting, ordering, identification of objects and tracking the orientation, movement and distance of these objects. We detail the design space and practical use-cases for such interaction which allows us to identify a series of design patterns, beyond static interaction, which are continuous and dynamic. With a focus on planar objects, we report on a series of studies which demonstrate the suitability of this approach. This exploration is grounded in both a characterization of the radar sensing and our rigorous experiments which show that such sensing is accurate with minimal training. With these techniques, we envision both realistic and future applications and scenarios. The motivation for what we refer to as Solinteraction, is to demonstrate the potential for radar-based interaction with objects in HCI and TUI.","Volume 2 Issue 4, December 2018"
82,10.1145/3287079,"Tengxiang Zhang, Xin Yi, Ruolin Wang, Yuntao Wang, Chun Yu, Yiqin Lu, Yuanchun Shi",Tap-to-Pair: Associating Wireless Devices with Synchronous Tapping,"Ad-hoc wireless device pairing enables impromptu interactions in smart spaces, such as resource sharing and remote control. The pairing experience is mainly determined by the device association process, during which users express their pairing intentions between the advertising device and the scanning device. Currently, most wireless devices are associated by selecting the advertiser's name from a list displayed on the scanner's screen, which becomes less efficient and often misplaced as the number of wireless devices increases. In this paper, we propose Tap-to-Pair, a spontaneous device association mechanism that initiates pairing from advertising devices without hardware or firmware modifications. Tapping an area near the advertising device's antenna can change its signal strength. Users can then associate two devices by synchronizing taps on the advertising device with the blinking pattern displayed by the scanning device. By leveraging the wireless transceiver for sensing, Tap-to-Pair does not require additional resources from advertising devices and needs only a binary display (e.g. LED) on scanning devices. We conducted a user study to test users' synchronous tapping ability and demonstrated that Tap-to-Pair can reliably detect users' taps. We ran simulations to optimize parameters for the synchronization recognition algorithm and provide pattern design guidelines. We used a second user study to evaluate the on-chip performance of Tap-to-Pair. The results show that Tap-to-Pair can achieve an overall successful pairing rate of 93.7% with three scanning devices at different distances.","Volume 2 Issue 4, December 2018"
83,10.1145/3287080,"Zijie Zhu, Xuewei Wang, Aakaash Kapoor, Zhichao Zhang, Tingrui Pan, Zhou Yu",EIS: A Wearable Device for Epidermal American Sign Language Recognition,"American Sign Language (ASL) is widely used among hearing impaired individuals in English-speaking countries. Various technologies have been developed to perform ASL recognition, including optical signal sensing, electrical signal sensing, and mechanical signal sensing. However, wearable devices using those methods have bulky and complex sensing modules that lead to long-term discomfort as well as poor accuracy. In this paper, we present an epidermal-iontronic sensing (EIS)-based wearable device that wears on finger joints for 35 fingerspelling ASL recognitions (i.e., 26 alphabets from A to Z and 9 digits from one to nine). Compared to current on-market devices, such design is lighter, comfortable to wear and has better appearance according to user comments. When bending the finger, a physical contact forms between the ionic material and the epidermis of skin, leading to an electric double layer (EDL) established at the interface. Therefore, a significant capacitive change can be achieved with various finger gestures. By using Nafion as the ionic sensing material, we developed a sensing device to provide excellent flexibility and optical transparency. We used machine learning methods, such as neural networks to track and perform ASL recognition using the signals obtained from the designed device. The algorithm achieved a within-user accuracy of 99.6% and a cross-user accuracy of 76.1% when adapted the model to different users. This wearable device is low-cost and has broad potential to be integrated in future application of human-machine interactions (HMI), smart home controls, and nonverbal communications.","Volume 2 Issue 4, December 2018"
84,10.1145/3264899,"Tousif Ahmed, Apu Kapadia, Venkatesh Potluri, Manohar Swaminathan",Up to a Limit?: Privacy Concerns of Bystanders and Their Willingness to Share Additional Information with Visually Impaired Users of Assistive Technologies,"The emergence of augmented reality and computer vision based tools offer new opportunities to visually impaired persons (VIPs). Solutions that help VIPs in social interactions by providing information (age, gender, attire, expressions etc.) about people in the vicinity are becoming available. Although such assistive technologies are already collecting and sharing such information with VIPs, the views, perceptions, and preferences of sighted bystanders about such information sharing remain unexplored. Although bystanders may be willing to share more information for assistive uses it remains to be explored to what degree bystanders are willing to share various kinds of information and what might encourage additional sharing of information based on the contextual needs of VIPs. In this paper we describe the first empirical study of information sharing preferences of sighted bystanders of assistive devices. We conducted a survey based study using a contextual method of inquiry with 62 participants followed by nine semi-structured interviews to shed more insight on our key quantitative findings. We find that bystanders are more willing to share some kinds of personal information with VIPs and are willing to share additional information if higher security assurances can be made by improving their control over how their information is shared.","Volume 2 Issue 3, September 2018"
85,10.1145/3264900,"Rawan Alharbi, Tammy Stump, Nilofar Vafaie, Angela Pfammatter, Bonnie Spring, Nabil Alshurafa",I Can't Be Myself: Effects of Wearable Cameras on the Capture of Authentic Behavior in the Wild,"Wearable sensors can provide reliable, automated measures of health behaviors in free-living populations. However, validation of these measures is impossible without observable confirmation of behaviors. Participants have expressed discomfort during the use of ego-centric wearable cameras with first-person view. We argue that mounting the camera on different body locations with a different lens orientation, gives a device recording affordance that has the effect of reducing surveillance and social discomfort compared to ego-centric cameras. We call these types of cameras ""activity-oriented"" because they are designed to capture a particular activity, rather than the field of view of the wearer. We conducted an experiment of three camera designs with 24 participants, collecting qualitative data on participants' experience while wearing these devices in the wild. We provide a model explaining factors that lead to an increase in social presence and social stigma, which, therefore, create social and surveillance discomfort for the wearer. Wearers' attempts to reduce this discomfort by modifying their behavior or abandoning the device threatens the validity of observations of authentic behaviors. We discuss design implications and provide recommendations to help reduce social presence and stigma in order to improve the validity of observations with cameras in the wild.","Volume 2 Issue 3, September 2018"
86,10.1145/3264901,"Frank Bentley, Chris Luvogt, Max Silverman, Rushani Wirasinghe, Brooke White, Danielle Lottridge",Understanding the Long-Term Use of Smart Speaker Assistants,"Over the past two years the Ubicomp vision of ambient voice assistants, in the form of smart speakers such as the Amazon Echo and Google Home, has been integrated into tens of millions of homes. However, the use of these systems over time in the home has not been studied in depth. We set out to understand exactly what users are doing with these devices over time through analyzing voice history logs of 65,499 interactions with existing Google Home devices from 88 diverse homes over an average of 110 days. We found that specific types of commands were made more often at particular times of day and that commands in some domains increased in length over time as participants tried out new ways to interact with their devices, yet exploration of new topics was low. Four distinct user groups also emerged based on using the device more or less during the day vs. in the evening or using particular categories. We conclude by comparing smart speaker use to a similar study of smartphone use and offer implications for the design of new smart speaker assistants and skills, highlighting specific areas where both manufacturers and skill providers can focus in this domain.","Volume 2 Issue 3, September 2018"
87,10.1145/3264902,"Shengjie Bi, Tao Wang, Nicole Tobias, Josephine Nordrum, Shang Wang, George Halvorsen, Sougata Sen, Ronald Peterson, Kofi Odame, Kelly Caine, Ryan Halter, Jacob Sorber, David Kotz",Auracle: Detecting Eating Episodes with an Ear-mounted Sensor,"In this paper, we propose Auracle, a wearable earpiece that can automatically recognize eating behavior. More specifically, in free-living conditions, we can recognize when and for how long a person is eating. Using an off-the-shelf contact microphone placed behind the ear, Auracle captures the sound of a person chewing as it passes through the bone and tissue of the head. This audio data is then processed by a custom analog/digital circuit board. To ensure reliable (yet comfortable) contact between microphone and skin, all hardware components are incorporated into a 3D-printed behind-the-head framework. We collected field data with 14 participants for 32 hours in free-living conditions and additional eating data with 10 participants for 2 hours in a laboratory setting. We achieved accuracy exceeding 92.8% and F1 score exceeding 77.5% for eating detection. Moreover, Auracle successfully detected 20-24 eating episodes (depending on the metrics) out of 26 in free-living conditions. We demonstrate that our custom device could sense, process, and classify audio data in real time. Additionally, we estimate Auracle can last 28.1 hours with a 110 mAh battery while communicating its observations of eating behavior to a smartphone over Bluetooth.","Volume 2 Issue 3, September 2018"
88,10.1145/3264903,"Davis Blalock, Samuel Madden, John Guttag",Sprintz: Time Series Compression for the Internet of Things,"Thanks to the rapid proliferation of connected devices, sensor-generated time series constitute a large and growing portion of the world's data. Often, this data is collected from distributed, resource-constrained devices and centralized at one or more servers. A key challenge in this setup is reducing the size of the transmitted data without sacrificing its quality. Lower quality reduces the data's utility, but smaller size enables both reduced network and storage costs at the servers and reduced power consumption in sensing devices. A natural solution is to compress the data at the sensing devices. Unfortunately, existing compression algorithms either violate the memory and latency constraints common for these devices or, as we show experimentally, perform poorly on sensor-generated time series.
We introduce a time series compression algorithm that achieves state-of-the-art compression ratios while requiring less than 1KB of memory and adding virtually no latency. This method is suitable not only for low-power devices collecting data, but also for servers storing and querying data; in the latter context, it can decompress at over 3GB/s in a single thread, even faster than many algorithms with much lower compression ratios. A key component of our method is a high-speed forecasting algorithm that can be trained online and significantly outperforms alternatives such as delta coding.
Extensive experiments on datasets from many domains show that these results hold not only for sensor data but also across a wide array of other time series.","Volume 2 Issue 3, September 2018"
89,10.1145/3264904,"Roger Boldu, Alexandru Dancu, Denys J.C. Matthies, Thisum Buddhika, Shamane Siriwardhana, Suranga Nanayakkara",FingerReader2.0: Designing and Evaluating a Wearable Finger-Worn Camera to Assist People with Visual Impairments while Shopping,"People with Visual Impairments (PVI) experience greater difficulties with daily tasks, such as supermarket shopping. Identifying and purchasing an item proves challenging for PVI. Using a user-centered design process, we understand the difficulties PVI encounter in their daily routines. Consequently, the previous FingerReader model was elevated to a new level. In contrast, FingerReader2.0 incorporates a highly integrated hardware design, as it is standalone, wearable, and not tethered to a computer. Software-wise, the prototype utilizes a deep learning system, relying on a hybrid, an on-board and a cloud-based model. The advanced design significantly extends the range of mobile assistive technology, particularly for shopping purposes. This paper presents the findings from interviews, several iterative studies, and a field study in supermarkets to demonstrate the FingerReader2.0's enhanced capabilities for those with varied levels of visual impairment.","Volume 2 Issue 3, September 2018"
90,10.1145/3264905,"Giovanni Campagna, Silei Xu, Rakesh Ramesh, Michael Fischer, Monica S. Lam",Controlling Fine-Grain Sharing in Natural Language with a Virtual Assistant,"This paper proposes a novel approach to let consumers share data from their existing web accounts and devices easily, securely, and with fine granularity of control. Our proposal is to have our personal virtual assistant be responsible for sharing our digital assets. The owner can specify fine-grain access control in natural language; the virtual assistant executes access requests on behalf of the requesters and returns the results, if the requests conform to the owner's access control policies.
Specifically, we allow a virtual assistant to share any ThingTalk command--an event-driven task composed of skills drawn from Thingpedia, a crowdsourced repository with over 200 functions currently. Access control in natural language is translated into TACL, a formal language we introduce to let users express for whom, what, when, where, and how ThingTalk commands can be executed. TACL policies are in turn translated into SMT (Satisfiability Modulo Theories) formulas and enforced using a provably correct algorithm. Our Distributed ThingTalk Protocol lets users access their own and others' data through their own virtual assistant, while enabling sharing without disclosing information to a third party.
The proposed ideas have been incorporated and released in the open-source Almond virtual assistant. 18 of the 20 users in a study say that they like the concept proposed, and 14 like the prototype. We show that users are more willing to share their data given the ability to impose TACL constraints, that 90% of enforceable use cases suggested by 60 users are supported by TACL, and that static and dynamic conformance of policies can be enforced efficiently.","Volume 2 Issue 3, September 2018"
91,10.1145/3264906,"Andrew Carek, Christian Holz",Naptics: Convenient and Continuous Blood Pressure Monitoring during Sleep,"Normal circadian rhythm mediates blood pressure during sleep, decreasing in value in healthy subjects. Current methods to monitor nocturnal blood pressure use an active blood pressure cuff that repeatedly auto-inflates while the subject sleeps. Since these inflations happen in intervals of thirty minutes to one hour, they cause considerable sleep disturbances that lead to false measurements and impact the person's quality of sleep. These blood pressure samples are also just spot checks and rarely exceed 10-15 values per night.
We present Naptics, a wearable device woven into shorts. Naptics passively monitors the wearer's blood pressure throughout the night---continuously and unobtrusively---without disturbing the user during sleep. Naptics detects the micro-vibrations of the wearer's body that stem from the heartbeat and senses the optical reflections from the pulse wave as it propagates down the wearer's leg. From the timing between these two events, Naptics computes the pulse transit time, which correlates strongly with the user's blood pressure.
Naptics' key novelty is its unobtrusive approach in tracking blood pressure during the night. Our controlled evaluation of six subjects showed a high correlation (r = 0.89) between Naptics' calibrated mean arterial pressure and cuff-based blood pressure. Our in-the-wild evaluation validates Naptics in tracking five participants' blood pressure patterns throughout four nights and compares them to before and after cuff measurements. In a majority of the nights, Naptics correctly followed the trend of the cuff measurements while providing insights into the behavior and the patterns of participants' nocturnal blood pressure. Participants reported high sleep quality in sleep diaries after each night, validating Naptics as a convenient monitoring apparatus.","Volume 2 Issue 3, September 2018"
92,10.1145/3264907,"Perumal Varun Chadalavada, Goutham Palaniappan, Vimal Kumar Chandran, Khai Truong, Daniel Wigdor",ID'em: Inductive Sensing for Embedding and Extracting Information in Robust Materials,"We present ID'em, a novel tagging and localization method that employs an array of Inductive Sensors to 'image' patterns of electrically conductive dots that are embedded underneath the surfaces of materials that cover the environments that we inhabit. ID'em addresses drawbacks found with existing tagging/localization technologies, while drawing on some of their attributes and strengths, thus creating a cost-effective, scalable system that is robust enough to be deployed pervasively. We present a detailed description of the system, applications that leverage ID'em's unique affordances, and address ID'em's strengths and limitations. With ID'em, we envision a future where the materials that we use to cover and build our everyday environments come imbued with information that can provide valuable context for rich, diverse interactions and capabilities.","Volume 2 Issue 3, September 2018"
93,10.1145/3264908,"Liqiong Chang, Jiaqi Lu, Ju Wang, Xiaojiang Chen, Dingyi Fang, Zhanyong Tang, Petteri Nurmi, Zheng Wang",SleepGuard: Capturing Rich Sleep Information Using Smartwatch Sensing Data,"Sleep is an important part of our daily routine -- we spend about one-third of our time doing it. By tracking sleep-related events and activities, sleep monitoring provides decision support to help us understand sleep quality and causes of poor sleep. Wearable devices provide a new way for sleep monitoring, allowing us to monitor sleep from the comfort of our own home. However, existing solutions do not take full advantage of the rich sensor data provided by these devices. In this paper, we present the design and development of SleepGuard, a novel approach to track a wide range of sleep-related events using smartwatches. We show that using merely a single smartwatch, it is possible to capture a rich amount of information about sleep events and sleeping context, including body posture and movements, acoustic events, and illumination conditions. We demonstrate that through these events it is possible to estimate sleep quality and identify factors affecting it most. We evaluate our approach by conducting extensive experiments involved fifteen users across a 2-week period. Our experimental results show that our approach can track a richer set of sleep events, provide better decision support for evaluating sleep quality, and help to identify causes for sleep problems compared to prior work.","Volume 2 Issue 3, September 2018"
94,10.1145/3264909,"Jim Cherian, Jun Luo, Shen-Shyang Ho",ParkLoc: Light-weight Graph-based Vehicular Localization in Parking Garages,"Locating a vehicle indoors (e.g., underground parking garages) has been a difficult problem to tackle, due to the unavailability of GPS and/or Wi-Fi signals. Current GPS-free indoor localization efforts often rely on infrastructure supports such as Wi-Fi or BLE beacons, whereas the smartphone-only proposals mostly require significant data collection and training efforts per garage. In this context, we propose ParkLoc, a novel lightweight smartphone-only solution for vehicular localization in GPS/Wi-Fi-deprived environments such as indoor parking garages. ParkLoc exploits the inherent planar graph structure of the navigable paths in parking facilities, in order to match a vehicle trajectory onto a sub-section of the map, by modeling these as sparse directed graphs. Exploiting an approximate graph matching method, ParkLoc is able to track a vehicle in real-time with a median error of 4.8m and localize a parked vehicle with a median error of 2m from the nearest parking space. Furthermore, ParkLoc adopts the popular GraphSLAM algorithm from robotics research; it learns the map graph from the observed trajectory graphs and a given set of bootstrap (seed) landmark nodes, in a semi-supervised manner. A key benefit of our approach is that ParkLoc works off-the-shelf without any expensive on-site training or sensor data collection per garage. A comprehensive evaluation of ParkLoc through extensive experiments performed in 4 different parking facilities reveals the promising performance of our graph-based approach for both localization and mapping.","Volume 2 Issue 3, September 2018"
95,10.1145/3264910,"Krittika D'Silva, Kasthuri Jayarajah, Anastasios Noulas, Cecilia Mascolo, Archan Misra",The Role of Urban Mobility in Retail Business Survival,"Economic and urban planning agencies have strong interest in tackling the hard problem of predicting the odds of survival of individual retail businesses. In this work, we tap urban mobility data available both from a location-based intelligence platform, Foursquare, and from public transportation agencies, and investigate whether mobility-derived features can help foretell the failure of such retail businesses, over a 6 month horizon, across 10 distinct cities spanning the globe. We hypothesise that the survival of such a retail outlet is correlated with not only venue-specific characteristics but also broader neighbourhood-level effects. Through careful statistical analysis of Foursquare and taxi mobility data, we uncover a set of discriminative features, belonging to the neighbourhood's static characteristics, the venue-specific customer visit dynamics, and the neighbourhood's mobility dynamics. We demonstrate that classifiers trained on such features can predict such survival with high accuracy, achieving approximately 80% precision and recall across the cities. We also show that the impact of such features varies across new and established venues and across different cities. Besides achieving a significant improvement over past work on business vitality prediction, our work demonstrates the vital role that mobility dynamics plays in the economic evolution of a city.","Volume 2 Issue 3, September 2018"
96,10.1145/3264911,"Nediyana Daskalova, Bongshin Lee, Jeff Huang, Chester Ni, Jessica Lundin",Investigating the Effectiveness of Cohort-Based Sleep Recommendations,"Existing sleep-tracking apps and devices provide simple descriptive statistics or generic recommendations for everyone. In this work, we aim to leverage cohort-based sleep data to provide recommendations to improve an individual's sleep. We report a 4-week study (N = 39) conducted to compare three alternatives: 1) no recommendation, 2) general recommendation, and 3) cohort-based recommendation, using six sleep quality metrics. For the cohort-based recommendation, recommendations were generated based on ""similar users"" using about 40 million sleep events from Microsoft Band users. Our results indicate that cohort-based systems for health recommendations can prompt a desire for behavior change inspired by social comparison and increased awareness about sleep habits. However, in order to be effective, such systems need to establish their credibility and to be able to generate cohorts based on features that are important to users. Finally, we provide further suggestions and design implications for future cohort-based recommendation systems for healthy sleep.","Volume 2 Issue 3, September 2018"
97,10.1145/3264912,"Artem Dementyev, Javier Hernandez, Inrak Choi, Sean Follmer, Joseph Paradiso",Epidermal Robots: Wearable Sensors That Climb on the Skin,"Epidermal sensing has enabled significant advancements towards the measurement and understanding of health. Most of the existing medical instruments require direct expert manipulation of a doctor, measure a single parameter, and/or have limited sensing coverage. In contrast, this work demonstrates the first epidermal robot with the ability to move over the surface of the skin and capture a large range of body parameters. In particular, we developed SkinBot, a 2x4x2 centimeter-size robot that moves over the skin surface with a two-legged suction-based locomotion. We demonstrate three of the potential medical sensing applications which include the measurement of body biopotentials (e.g., electrodermal activity, electrocardiography) through modified suction cups that serve as electrodes, skin imaging through a skin-facing camera that can capture skin anomalies, and inertial body motions through a 6-axis accelerometer and gyroscope that can capture changes of body posture and subtle cardiorespiratory vibrations.","Volume 2 Issue 3, September 2018"
98,10.1145/3264913,"Elena Di Lascio, Shkurta Gashi, Silvia Santini",Unobtrusive Assessment of Students' Emotional Engagement during Lectures Using Electrodermal Activity Sensors,"Modern wearable devices enable the continuous and unobtrusive monitoring of human physiological parameters, including heart rate and electrodermal activity. Through the definition of adequate models these parameters allow to infer the wellbeing, empathy, or engagement of humans in different contexts. In this paper, we show that off-the-shelf wearable devices can be used to unobtrusively monitor the emotional engagement of students during lectures. We propose the use of several novel features to capture students' momentary engagement and use existing methods to characterize the general arousal of students and their physiological synchrony with the teacher. To evaluate our method we collect a data set that -- after data cleaning -- contains data from 24 students, 9 teachers, and 41 lectures. Our results show that non-engaged students can be identified with high reliability. Using a Support Vector Machine, for instance, we achieve a recall of 81% -- which is a 25 percentage points improvement with respect to a Biased Random classifier. Overall, our findings may inform the design of systems that allow students to self-monitor their engagement and act upon the obtained feedback. Teachers could profit of information about non-engaged students too to perform self-reflection and to devise and evaluate methods to (re-)engage students.","Volume 2 Issue 3, September 2018"
99,10.1145/3264914,"Rizanne Elbakly, Moustafa Elhamshary, Moustafa Youssef",HyRise: A Robust and Ubiquitous Multi-Sensor Fusion-based Floor Localization System,"Floor localization is an integral part of indoor localization systems that are deployed in any typical high-rise building. Nevertheless, while many efforts have been made to detect floor change events leveraging phone-embedded sensors, there are still a number of pitfalls that need to be overcome to provide robust and accurate localization in the 3D space.
In this paper, we present HyRise: a robust and ubiquitous probabilistic crowdsourcing-based floor determination system. HyRise is a hybrid system that combines the barometer sensor and the ubiquitous Wi-Fi access points installed in the building into a probabilistic framework to identify the user's floor. In particular, HyRise incorporates a discrete Markov localization algorithm where the motion model is based on the vertical transitions detected from the sampled pressure readings and the observation model is based on the overheard Wi-Fi access points (APs) to find the most probable floor of the user. HyRise also has provisions to handle practical deployment issues including handling the inherent drift in the barometer readings, the noisy wireless environment, heterogeneous devices, among others.
HyRise is implemented on Android phones and evaluated using three different testbeds: a campus building, a shopping mall, and a residential building with different floorplan layouts and APs densities. The results show that HyRise can identify the exact user's floor correctly in 93%, 92% and 77% of the cases for the campus building, the shopping mall, and the more challenging residential building; respectively. In addition, it can identify the floor with at most 1-floor error in 100% of the cases for all three testbeds. Moreover, the floor localization accuracy outperforms that achieved by other state-of-the-art techniques by at least 79% and up to 278%. This accuracy is achieved with no training overhead, is robust to the different user devices, and is consistent in buildings with different structures and APs densities.","Volume 2 Issue 3, September 2018"
100,10.1145/3264915,"Zipei Fan, Xuan Song, Tianqi Xia, Renhe Jiang, Ryosuke Shibasaki, Ritsu Sakuramachi",Online Deep Ensemble Learning for Predicting Citywide Human Mobility,"Predicting citywide human mobility is critical to an effective management and regulation of city governance, especially during a rare event (e.g. large event such as New Year's celebration or Comiket). Classical models can effectively predict routine human mobility, but irregular mobility during a rare event (precedented or unprecedented), which is much more difficult to model, has not drawn sufficient attention. Moreover, the complexity and non-linearity of human mobility hinders a simple model from making an accurate prediction. Bearing these facts in mind, we propose a novel online gating neural network framework with two phases. In the offline training phase, we train a gated recurrent unit-based human mobility predictor for each day in our training set, while in the online predicting phase, we construct an online adaptive human mobility predictor as well as a gating neural network that switches among the pre-trained predictors and the online adaptive human predictor. Our approach was evaluated using a real-world GPS-log dataset from Tokyo and Osaka and achieved a higher prediction accuracy than baseline models.","Volume 2 Issue 3, September 2018"
101,10.1145/3264916,"Zhihan Fang, Fan Zhang, Ling Yin, Desheng Zhang",MultiCell: Urban Population Modeling Based on Multiple Cellphone Networks,"Exploring cellphone network data has been proved to be a very effective way to understand urban populations because of the high penetration rate of cellphones. However, the state-of-the-art population models driven by cellphone data are typically built upon single cellphone networks, assuming the users in a particular cellphone network used are representative of all residents in the studied city with multiple cellphone networks. This assumption usually does not hold in the real world due to strategic spatial coverages and business concentrations of cellphone companies, which lead to data biases, and thus overfitting of resultant population models. To address this issue, we design a model called MultiCell to model real-time urban populations from multiple cellphone networks with two novel techniques: (i) a network realignment technique to integrate individual cell-tower spatial distributions from multiple cellphone networks for finer granular population modeling; (ii) a data fusion technique based on cross-network training to design a population model based on multiple network data. We implement MultiCell in the Chinese city Shenzhen based on three cellphone networks with 10 million active users and their daily data records at 11 thousand cell towers. We evaluate MultiCell by comparing it to the state-of-the-art models driven by single cellphone networks, and the evaluation results show that MultiCell outperforms them by 27% in terms of accuracy. Finally, we cross-validate MultiCell with three transportation systems with more than 8 million passengers to investigate its performances.","Volume 2 Issue 3, September 2018"
102,10.1145/3264917,"Clayton Feustel, Shyamak Aggarwal, Bongshin Lee, Lauren Wilcox",People Like Me: Designing for Reflection on Aggregate Cohort Data in Personal Informatics Systems,"Increases in data complexity in personal informatics systems require new ways of contextualizing personal data to facilitate meaningful reflection. An emerging approach for providing such context includes augmenting one's personal data with the data of others ""like them"" to help individuals make sense of their data. However, we do not yet understand how an individual's self-reflection process is affected when the data of others is made available. In this paper, we investigate how people reflect on three types of personal data when presented alongside a large set of aggregated data of multiple cohorts. We conducted personal and cohort data reviews using a subset of participants from a mobile-sensing study that collected physical activity, digital social activity, and perceived stress, from 47 students over three weeks. Participants preferred to use characteristics of the data (e.g., maxima, minima) and graphical presentation (e.g., appearance of trends) along with demographic identities (e.g., age, gender) when relating to cohorts. We further characterize how participants incorporated cohort data into their self-reflection process, and conclude with discussion of the implications for personal informatics systems that leverage the data of ""people like me"" to enable meaningful reflection.","Volume 2 Issue 3, September 2018"
103,10.1145/3264918,"Yang Gao, Borui Li, Wei Wang, Wenyao Xu, Chi Zhou, Zhanpeng Jin",Watching and Safeguarding Your 3D Printer: Online Process Monitoring Against Cyber-Physical Attacks,"The increasing adoption of 3D printing in many safety and mission critical applications exposes 3D printers to a variety of cyber attacks that may result in catastrophic consequences if the printing process is compromised. For example, the mechanical properties (e.g., physical strength, thermal resistance, dimensional stability) of 3D printed objects could be significantly affected and degraded if a simple printing setting is maliciously changed. To address this challenge, this study proposes a model-free real-time online process monitoring approach that is capable of detecting and defending against the cyber-physical attacks on the firmwares of 3D printers. Specifically, we explore the potential attacks and consequences of four key printing attributes (including infill path, printing speed, layer thickness, and fan speed) and then formulate the attack models. Based on the intrinsic relation between the printing attributes and the physical observations, our defense model is established by systematically analyzing the multi-faceted, real-time measurement collected from the accelerometer, magnetometer and camera. The Kalman filter and Canny filter are used to map and estimate three aforementioned critical toolpath information that might affect the printing quality. Mel-frequency Cepstrum Coefficients are used to extract features for fan speed estimation. Experimental results show that, for a complex 3D printed design, our method can achieve 4% Hausdorff distance compared with the model dimension for infill path estimate, 6.07% Mean Absolute Percentage Error (MAPE) for speed estimate, 9.57% MAPE for layer thickness estimate, and 96.8% accuracy for fan speed identification. Our study demonstrates that, this new approach can effectively defend against the cyber-physical attacks on 3D printers and 3D printing process.","Volume 2 Issue 3, September 2018"
104,10.1145/3264919,"Cole Gleason, Alexander J. Fiannaca, Melanie Kneisel, Edward Cutrell, Meredith Ringel Morris",FootNotes: Geo-referenced Audio Annotations for Nonvisual Exploration,"The majority of information in the physical environment is conveyed visually, meaning that people with vision impairments often lack access to the shared cultural, historical, and practical features that define a city. How can someone who is blind find out about the sleek skyscrapers that dot a modern city's skyline, historic cannons that have been remade into traffic pillars, or ancient trees that uproot a neighborhood's sidewalks? We present FootNotes, a system that embeds rich textual descriptions of objects and locations in OpenStreetMap, a popular geowiki. Both sighted and blind users can annotate the physical environment with functional, visual, historical, and social descriptions. We report on the experience of ten participants with vision impairments who used a spatialized audio application to interact with these annotations while exploring a city. By sharing rich annotations of physical objects and areas, FootNotes helps people thoroughly explore a new location or serendipitously discover previously unknown features of familiar environments.","Volume 2 Issue 3, September 2018"
105,10.1145/3264920,"Manoj Gulati, Farshid Salemi Parizi, Eric Whitmire, Sidhant Gupta, Shobha Sundar Ram, Amarjeet Singh, Shwetak N. Patel",CapHarvester: A Stick-on Capacitive Energy Harvester Using Stray Electric Field from AC Power Lines,"Internet of Things (IoT) applications and platforms are becoming increasingly prevalent. Alongside this growth of smart devices comes added costs for deployment, maintenance, and the need to manage power consumption so as to reduce recurrent costs of replacing batteries. To alleviate recurrent battery replacement and maintenance, we propose a novel battery-free, stick-on capacitive energy harvester that harvests the stray electric field generated around AC power lines (110 V/230 V) without an ohmic connection to earth ground reference, thereby obviating the need for cumbersome scraping of paint on concrete walls or digging a earth ground plate. Furthermore, our harvester does not require any appliance or load to be operating on the power line and can continuously harvest power after deployment. In effect, end-users are expected to simply stick the proposed harvester onto any existing power-line cord in order to power a sensing platform. Our controlled lab measurements and real-world deployments demonstrate that our device can harvest 270.6 μJ of energy from a 14 cm long interface in 12 min. We also demonstrate several applications, such as distributed temperature monitoring, appliance state monitoring, and environmental parameter logging for indoor farming.","Volume 2 Issue 3, September 2018"
106,10.1145/3264921,"Anhong Guo, Anuraag Jain, Shomiron Ghose, Gierad Laput, Chris Harrison, Jeffrey P. Bigham",Crowd-AI Camera Sensing in the Real World,"Smart appliances with built-in cameras, such as the Nest Cam and Amazon Echo Look, are becoming pervasive. They hold the promise of bringing high fidelity, contextually rich sensing into our homes, workplaces and other environments. Despite recent and impressive advances, computer vision systems are still limited in the types of sensing questions they can answer, and more importantly, do not easily generalize across diverse human environments. In response, researchers have investigated hybrid crowd- and AI-powered methods that collect human labels to bootstrap automatic processes. However, deployments have been small and mostly confined to institutional settings, leaving open questions about the scalability and generality of the approach. In this work, we describe our iterative development of Zensors++, a full-stack crowd-AI camera-based sensing system that moves significantly beyond prior work in terms of scale, question diversity, accuracy, latency, and economic feasibility. We deployed Zensors++ in the wild, with real users, over many months and environments, generating 1.6 million answers for nearly 200 questions created by our participants, costing roughly 6/10ths of a cent per answer delivered. We share lessons learned, insights gleaned, and implications for future crowd-AI vision systems.","Volume 2 Issue 3, September 2018"
107,10.1145/3264922,"Suiming Guo, Chao Chen, Jingyuan Wang, Yaxiao Liu, Ke Xu, Daqing Zhang, Dah Ming Chiu",A Simple but Quantifiable Approach to Dynamic Price Prediction in Ride-on-demand Services Leveraging Multi-source Urban Data,"Ride-on-demand (RoD) services such as Uber and Didi are becoming increasingly popular, and in these services dynamic prices play an important role in balancing the supply and demand to benefit both drivers and passengers. However, dynamic prices also create concerns. For passengers, the ""unpredictable"" prices sometimes prevent them from making quick decisions: one may wonder if it is possible to get a lower price if s/he chooses to wait a while. It is necessary to provide more information to them, and predicting the dynamic prices is a possible solution. For the transportation industry and policy makers, there are also concerns about the relationship between RoD services and their more traditional counterparts such as metro, bus, and taxi: whether they affect each other and how.
In this paper we tackle these two concerns by predicting the dynamic prices using multi-source urban data. Price prediction could help passengers understand whether they could get a lower price in neighboring locations or within a short time, thus alleviating their concerns. The prediction is based on urban data from multiple sources, including the RoD service itself, taxi service, public transportation, weather, the map of a city, etc. We train a simple linear regression model with high-dimensional composite features to perform the prediction. By combining simple basic features into composite features, we compensate for the loss of expressiveness in a linear model due to the lack of non-linearity. Additionally, the use of multi-source data and a linear model enables us to quantify and explain the relationship between multiple means of transportation by examining the weights of different features in the model. Our hope is that the study not only serves as an accurate prediction to make passengers more satisfied, but also sheds light on the concern about the relationship between different means of transportation for either the industry or policy makers.","Volume 2 Issue 3, September 2018"
108,10.1145/3264923,"Takashi Hamatani, Moustafa Elhamshary, Akira Uchiyama, Teruo Higashino",FluidMeter: Gauging the Human Daily Fluid Intake Using Smartwatches,"Water is the most vital nutrient in the human body accounting for about 60% of the body weight. To maintain optimal health, it is important for humans to consume a sufficient amount of fluids daily. Therefore, tracking the amount of human daily fluid intake has a myriad of health applications like dehydration prevention.
In this paper, we present FluidMeter: a ubiquitous and unobtrusive system to track the amount of fluid intake leveraging the inertial sensors embedded in smartwatches. To achieve this, FluidMeter first separates the drinking activities from other human activities (playing, running, eating, etc.). Thereafter, it analyzes the sampled sensors data during the extracted drinking episodes to recognize the sequence of micro-activities (lift the bottle, sip, release the bottle) that constitute the drinking activity. Finally, it applies some machine learning algorithms on some features extracted from sampled sensor data during the sipping period to gauge the amount of fluid intake in the designated drinking episode.
FluidMeter is evaluated by collecting more than 260 hours of different human activities by 70 different participants using different smartwatch models. The results show that FluidMeter can recognize the drinking activity and its micro-activities accurately which is comparable to that achieved by the state-of-the-art techniques. Finally, FluidMeter can estimate the overall amount of fluid intake in grams accurately with a estimation error limited to 15%, highlighting its promise as a ubiquitous health service.","Volume 2 Issue 3, September 2018"
109,10.1145/3264924,"Victoria Hollis, Alon Pekurovsky, Eunika Wu, Steve Whittaker",On Being Told How We Feel: How Algorithmic Sensor Feedback Influences Emotion Perception,"Algorithms and sensors are increasingly deployed for highly personal aspects of our everyday lives. Recent work suggests people have imperfect understanding of system outputs, often assuming sophisticated capabilities and deferring to feedback. We explore how people construe algorithmic interpretations of emotional data in personal informatics systems. A survey (n=188) showed strong interest in automatic stress and emotion tracking, but many respondents expected these systems to provide objective measurements for their emotional experiences. A second study examined how algorithmic sensor feedback influences emotional self-judgments, by comparing three system framings of physiological ElectroDermal Activity data (EDA): Positive (""alert and engaged""), Negative (""stressed""), and Control (no frame) in a mixed-methods study with 64 participants. Despite users reporting strategies to test system outputs, users still deferred to feedback and their perceived emotions were significantly influenced by feedback frames. Some users overrode personal judgments, believing the system had access to privileged information about their emotions. Based on these findings, we explore design implications for personal informatics including risks of users trusting systems that seemingly ""unlock"" hidden aspects of the self. We propose design approaches that provide opportunities for future emotion-monitoring systems to exploit these framing effects, and for users to more actively construe emotional states.","Volume 2 Issue 3, September 2018"
110,10.1145/3264925,"Hande Hong, Girisha Durrel De Silva, Mun Choon Chan",CrowdProbe: Non-invasive Crowd Monitoring with Wi-Fi Probe,"Devices with integrated Wi-Fi chips broadcast beacons for network connection management purposes. Such information can be captured with inexpensive monitors and used to extract user behavior. To understand the behavior of visitors, we deployed our passive monitoring system---CrowdProbe, in a multi-floor museum for six months. We used a Hidden Markov Models (HMM) based trajectory inference algorithm to infer crowd movement using more than 1.7 million opportunistically obtained probe request frames.
However, as more devices adopt schemes to randomize their MAC addresses in the passive probe session to protect user privacy, it becomes more difficult to track crowd and understand their behavior. In this paper, we try to make use of historical transition probability to reason about the movement of those randomized devices with spatial and temporal constraints. With CrowdProbe, we are able to achieve sufficient accuracy to understand the movement of visitors carrying devices with randomized MAC addresses.","Volume 2 Issue 3, September 2018"
111,10.1145/3264926,"Hsin-Liu Cindy Kao, Abdelkareem Bedri, Kent Lyons",SkinWire: Fabricating a Self-Contained On-Skin PCB for the Hand,"Current wearable form factors often house electronics using an enclosure that is attached to the body. This form factor, while wearable, tends to protrude from the body and therefore can limit wearability. While emerging research in on-skin interfaces from the HCI and wearable communities have generated form factors with lower profiles, they often still require support by conventional electronics and associated form factors for the microprocessor, wireless communication, and battery units. In this work, we introduce SkinWire, a fabrication approach that extends the early work in on-skin interfaces to shift wearable devices from their traditional box-like forms to a fully self-contained on-skin form factor.
The Skin Wire approach starts with the placement of electronic components into individual PCB islands, which are then distributed over the body surface. The islands are connected through a novel skin-wiring approach that deposits conformal multi-stranded metallic wires on thin silicon substrates through a sewing-based technique. The process affords on-skin interfaces with the needed wiring in limited surface areas. We exemplify the capacity of this approach by shifting an IMU-based hand gesture system - which traditionally come in bulky glove-based form factors - directly onto the skin. Inspired by the emerging body art trend of body wiring, the Skin Wire approach uses readily accessible materials and affords aesthetic customization. We evaluate fabrication parameters, and conduct a user study to uncover wearability concerns.","Volume 2 Issue 3, September 2018"
112,10.1145/3264927,"Ravi Karkar, Rafal Kocielnik, Xiaoyi Zhang, Jasmine Zia, George N. Ioannou, Sean A. Munson, James Fogarty",Beacon: Designing a Portable Device for Self-Administering a Measure of Critical Flicker Frequency,"Critical flicker frequency (CFF) is the minimum frequency at which a flickering light source appears fused to an observer. Measuring CFF can support early diagnosis of minimal hepatic encephalopathy (MHE), a condition affecting up to 80% of people with cirrhosis of the liver. However, adoption of CFF measurement in clinical practice has been hampered by the cost of a device for measuring CFF and the need for specialized training to administer the test. This paper presents Beacon, a portable, inexpensive device that enables people to measure their own critical flicker frequency. We adopt a mixed-methods approach to informing and evaluating the design of and potential opportunities for Beacon. We first report on a two-part formative study with 10 participants to evaluate the choice of certain parameters in the design of Beacon. We then report on a study of 41 healthy adults ranging from 18 to 99 years of age, finding that Beacon performs on par with Lafayette Flicker Fusion System, an established medical device, achieving a pearson correlation coefficient of 0.88. We finally report on a focus group with five hepatoligists who work with patients with cirrhosis of the liver, using our initial prototype development to examine their perspectives on potential opportunities and challenges in adoption of a device like Beacon. We discuss Beacon as an exploration of reframing critical flicker frequency measurement from a clinical screening tool into a self-administered self-tracking measure, thereby drawing upon and contributing to research in the health and personal informatics.","Volume 2 Issue 3, September 2018"
113,10.1145/3264928,"J. Knibbe, A. Alsmith, K. Hornbæk",Experiencing Electrical Muscle Stimulation,"Electrical Muscle Stimulation (EMS) offers rich opportunities for interaction. By varying stimulation parameters (amplitudes, pulse widths and frequencies), EMS can be used to either trigger muscle contractions, and so convey object affordances or guide user movements, or provide rich haptic feedback. However, the way users' experience changes with these parameters, and EMS in general, is poorly understood. Using a phenomenologically inspired interview technique, the explicitation interview, we study fifteen users' experience of EMS across 48 combinations of stimulation parameters. We synthesize the descriptions of EMS and relate stimulation parameters to categories of experience, such as 'temperature', 'motion', and 'sensitivity'. From the interviews, we explore more general topics in body-based interfaces, including the experience of control, metaphors for having your body actuated, and the relation between EMS parameters and perceived depth and location of sensations. These findings provide a vocabulary of EMS experience, and an insight into the relationship between specific parameters and associated sensations. In turn, this can help designers consider the user experience of EMS when developing interfaces.","Volume 2 Issue 3, September 2018"
114,10.1145/3264929,"Alona Levy, Ben Nassi, Yuval Elovici, Erez Shmueli",Handwritten Signature Verification Using Wrist-Worn Devices,"This paper suggests a novel verification system for handwritten signatures. The proposed system is based on capturing motion signals from the sensors of wrist-worn devices, such as smartwatches and fitness trackers, during the signing process, to train a machine learning classifier to determine whether a given signature is genuine or forged. Our system can be used to: (1) Verify signatures written on paper documents, such as checks, credit card receipts and vote by mail ballots. Unlike existing systems for signature verification, our system obtains a high degree of accuracy, without requiring an ad hoc digital signing device. (2) Authenticate a user of a secure system based on ""who you are"" traits. Unlike existing ""motion-based"" authentication methods that commonly rely on long-term user behavior, writing a signature is a relatively short-term process. In order to evaluate our system, we collected 1,980 genuine and forged signature recordings from 66 different subjects, captured using a smartwatch device. Applying our signature verification system on the collected dataset, we show that it significantly outperforms two other state-of-the-art systems, obtaining an EER of 2.36% and an AUC of 98.52%.","Volume 2 Issue 3, September 2018"
115,10.1145/3264930,"Mingkuan Li, Ning Liu, Qun Niu, Chang Liu, S.-H. Gary Chan, Chengying Gao",SweepLoc: Automatic Video-based Indoor Localization by Camera Sweeping,"Indoor localization based on visual landmarks has received much attention in commercial sites with rich features (e.g., shopping malls, museums) recently because landmarks are relatively stable over a long time. Prior arts often require a user to take multiple independent images around his/her location, and manually confirm shortlisted landmarks. The process is sophisticated, inconvenient, slow, unnatural and error-prone. To overcome these limitations, we propose SweepLoc, a novel, efficient and automatic video-based indoor localization system. SweepLoc mimics our natural scanning around to identify nearby landmarks in an unfamiliar site to localize.
In SweepLoc, a user simply takes a short video clip (about 6 to 8 seconds) of his/her surroundings by sweeping the camera. Using correlation and scene continuity between successive video frames, it automatically and efficiently selects key frames (where potential landmarks are centered) and subsequently reduces the decision error on landmarks. With identified landmarks, SweepLoc formulates an optimization problem to locate the user, taking compass noise and floor map constraint into account. We have implemented SweepLoc in Android platform. Our extensive experimental results in a food plaza and a premium mall demonstrate that SweepLoc is fast (less than 1 second to localize), and achieves substantially better accuracy as compared with the state-of-the-art approaches (reducing the localization error by 30%).","Volume 2 Issue 3, September 2018"
116,10.1145/3264931,"Xiang Li, Daqing Zhang, Jie Xiong, Yue Zhang, Shengjie Li, Yasha Wang, Hong Mei",Training-Free Human Vitality Monitoring Using Commodity Wi-Fi Devices,"Device-free sensing using ubiquitous Wi-Fi signals has recently attracted lots of attention. Among the sensed information, two important basic contexts are (i) whether a target is still or not and (ii) where the target is located. Continuous monitoring of these contexts provides us with rich datasets to obtain important high-level semantics of the target such as living habits, physical conditions and emotions. However, even to obtain these two basic contexts, offline training and calibration are needed in traditional methods, limiting the real-life adoption of the proposed sensing systems. In this paper, using the commodity Wi-Fi infrastructure, we propose a training-free human vitality sensing platform, WiVit. It could capture these two contexts together with the target's movements speed information in real-time without any human effort in offline training or calibration. Based on our extensive experiments in three typical indoor environments, the precision of activity detection is higher than 98% and the area detection accuracy is close to 100%. Moreover, we implement a short-term activity recognition system on our platform to recognize 4 types of actions, and we can reach an average accuracy of 94.2%. We also take a feasibility study of monitoring long-term activities of daily living to show our platform's potential applications in practice.","Volume 2 Issue 3, September 2018"
117,10.1145/3264932,"Zhengxiong Li, Yuehang Wang, Aditya Singh Rathore, Chen Song, Nikhila Nyayapathi, Tri Vu, Jun Xia, Wenyao Xu",PAvessel: Practical 3D Vessel Structure Sensing through Photoacoustic Effects with Its Applications in Palm Biometrics,"The blood vessels are the most critical part of the human circulatory system. Information acquired on the structure and status of blood vessels drives the development of numerous medical and biometric applications. Therefore, it is of paramount importance to find an effective way to sense vessel structures. Traditional methods, including infrared and Doppler sensing modalities, are limited by optical diffusion and ultrasonic scattering that are not good at vessel sensing with high performance. In comparison, we argue photoacoustic (PA) sensing is an emerging technique that can image 3D vessel structure deep in tissue with high-resolution visualization, maintaining the advantages of both optical and ultrasound methods. In this work, we propose and develop PAvessel, a practical 3D vessel structure sensing system based on PA effects. The entire sensing system comprises two key components, PA sensing hardware and PA sensing software. Specifically, the hardware mainly consists of a linear ultrasound transducer array, an ultrasound data acquisition system, and a neodymium-doped yttrium aluminum garnet (Nd:YAG) laser. After receiving the PA raw data, we use the advanced image reconstruction and 3D photoacoustic vein model to establish the 3D vessel structure model. We validated its effectiveness, cost-effectiveness and high resolution of PAvessel in the evaluation. The system achieves 52% higher signal-to-noise ratio (SNR) compared to the other methods. Furthermore, considering the 3D palm vein contains high dimensional human features and is almost impossible to forge, we also explored its applications in palm biometrics. In a pilot study with 10 participants, PAvessel, combined with a 3D vessel structure matching algorithm (EMD-VT), has proven to possess high accuracy and robustness as a biometric. PAvessel achieves the precision and recall of 98.33% and 97.37%, respectively.","Volume 2 Issue 3, September 2018"
118,10.1145/3266002,"Zhiqing Luo, Wei Wang, Jiang Xiao, Qianyi Huang, Tao jiang, Qian Zhang",Authenticating On-Body Backscatter by Exploiting Propagation Signatures,"The vision of battery-free communication has made backscatter a compelling technology for on-body wearable and implantable devices. Recent advances have facilitated the communication between backscatter tags and on-body smart devices. These studies have focused on the communication dimension, while the security dimension remains vulnerable. It has been demonstrated that wireless connectivity can be exploited to send unauthorized commands or fake messages that result in device malfunctioning. The key challenge in defending these attacks stems from the minimalist design in backscatter. Thus, in this paper, we explore the feasibility of authenticating an on-body backscatter tag without modifying its signal or protocol. We present SecureScatter, a physical-layer solution that delegates the security of backscatter to an on-body smart device. To this end, we profile the on-body propagation paths of backscatter links, and construct highly sensitive propagation signatures to identify on-body backscatter links. We implement our design in a software radio and evaluate it with different backscatter tags that work at 2.4 GHz and 900 MHz. Results show that our system can identify on-body devices at 93.23% average true positive rate and 3.18% average false positive rate.","Volume 2 Issue 3, September 2018"
119,10.1145/3264934,"Mohamed Maouche, Sonia Ben Mokhtar, Sara Bouchenak",HMC: Robust Privacy Protection of Mobility Data against Multiple Re-Identification Attacks,"With the wide propagation of handheld devices, more and more mobile sensors are being used by end users on a daily basis. Those sensors could be leveraged to gather useful mobility data for city planners, business analysts and researches. However, gathering and exploiting mobility data raises many privacy threats. Sensitive information such as one's home or work place, hobbies, religious beliefs, political or sexual preferences can be inferred from the gathered data. In the last decade, Location Privacy Protection Mechanisms (LPPMs) have been proposed to protect user data privacy. However existing LPPMs fail at effectively protecting the users as most of them reason on local mobility features: micro-mobility (e.g., individual geographical coordinates) while ignoring higher level mobility features, which may allow attackers to discriminate between users. In this paper we propose HMC the first LPPM that reasons on the overall user mobility abstracted using heat maps. We evaluate HMC using four real mobility traces and multiple privacy and utility metrics. The results show that with HMC, across all the datasets 87% of mobile users are successfully protected against re-identification attacks, while others LPPMs only achieve a protection ranging from 43% to 79%. By considering only users protected with a high utility, the proportion of users stays high for HMC with 75%, while for others LPPMs it goes down to proportions between 4% and 43%.","Volume 2 Issue 3, September 2018"
120,10.1145/3264935,"Shrirang Mare, Reza Rawassizadeh, Ronald Peterson, David Kotz",SAW: Wristband-based Authentication for Desktop Computers,"Token-based proximity authentication methods that authenticate users based on physical proximity are effortless, but lack explicit user intentionality, which may result in accidental logins. For example, a user may get logged in when she is near a computer or just passing by, even if she does not intend to use that computer. Lack of user intentionality in proximity-based methods makes them less suitable for multi-user shared computer environments, despite their desired usability benefits over passwords. We present an authentication method for desktops called Seamless Authentication using Wristbands (SAW), which addresses the lack of intentionality limitation of proximity-based methods. SAW uses a low-effort user input step for explicitly conveying user intentionality, while keeping the overall usability of the method better than password-based methods. In SAW, a user wears a wristband that acts as the user's identity token, and to authenticate to a desktop, the user provides a low-effort input by tapping a key on the keyboard multiple times or wiggling the mouse with the wristband hand. This input to the desktop conveys that someone wishes to log in to the desktop, and SAW verifies the user who wishes to log in by confirming the user's proximity and correlating the received keyboard or mouse inputs with the user's wrist movement, as measured by the wristband. In our feasibility user study (n=17), SAW proved quick to authenticate (within two seconds), with a low false-negative rate of 2.5% and worst-case false-positive rate of 1.8%. In our user perception study (n=16), a majority of the participants rated it as more usable than passwords.","Volume 2 Issue 3, September 2018"
121,10.1145/3264936,"Hidenori Matsui, Takahiro Hashizume, Koji Yatani",Al-light: An Alcohol-Sensing Smart Ice Cube,"Inappropriate alcohol drinking may cause health and social problems. Although controlling the intake of alcohol is effective to solve the problem, it is laborious to track consumption manually. A system that automatically records the amount of alcohol consumption has a potential to improve behavior in drinking activities. Existing devices and systems support drinking activity detection and liquid intake estimation, but our target scenario requires the capability of determining the alcohol concentration of a beverage. We present Al-light, a smart ice cube to detect the alcohol concentration level of a beverage using an optical method. Al-light is the size of 31.9 x 38.6 x 52.6 mm and users can simply put it into a beverage for estimation. It embeds near infrared (1450 nm) and visible LEDs, and measures the magnitude of light absorption. Our device design integrates prior technology in a patent which exploits different light absorption properties between water and ethanol to determine alcohol concentration. Through our revisitation studies, we found that light at the wavelength of 1450 nm has strong distinguishability even with different types of commercially-available beverages. Our quantitative examinations on alcohol concentration estimation revealed that Al-light was able to achieve the estimation accuracy of approximately 2 % v/v with 13 commercially-available beverages. Although our current approach needs a regressor to be trained for a particular ambient light condition or the sensor to be calibrated using measurements with water, it does not require beverage-dependent models unlike prior work. We then discuss four applications our current prototype supports and future research directions.","Volume 2 Issue 3, September 2018"
122,10.1145/3264937,"Abhinav Mehrotra, Mirco Musolesi",Using Autoencoders to Automatically Extract Mobility Features for Predicting Depressive States,"Recent studies have shown the potential of exploiting GPS data for passively inferring people's mental health conditions. However, feature extraction for characterizing human mobility remains a heuristic process that relies on the domain knowledge of the condition under consideration. Moreover, we do not have guarantees that these ""hand-crafted"" metrics are able to effectively capture mobility behavior of users. Indeed, informative emerging patterns in the data might not be characterized by them. This is also a complex and often time-consuming task, since it usually consists of a lengthy trial-and-error process.
In this paper, we investigate the potential of using autoencoders for automatically extracting features from the raw input data. Through a series of experiments we show the effectiveness of autoencoder-based features for predicting depressive states of individuals compared to ""hand-crafted"" ones. Our results show that automatically extracted features lead to an improvement of the performance of the prediction models, while, at the same time, reducing the complexity of the feature design task. Moreover, through an extensive experimental performance analysis, we demonstrate the optimal configuration of the key parameters at the basis of the proposed approach.","Volume 2 Issue 3, September 2018"
123,10.1145/3264938,"Jimmy Moore, Pascal Goffin, Miriah Meyer, Philip Lundrigan, Neal Patwari, Katherine Sward, Jason Wiese","Managing In-home Environments through Sensing, Annotating, and Visualizing Air Quality Data","Air quality is important, varies across time and space, and is largely invisible. Pioneering past work deploying air quality monitors in residential environments found that study participants improved their awareness of and engagement with air quality. However, these systems fielded a single monitor and did not support user-specified annotations, inhibiting their utility. We developed MAAV -- a system to Measure Air quality, Annotate data streams, and Visualize real-time PM2.5 levels -- to explore how participants engage with an air quality system addressing these challenges. MAAV supports collecting data from multiple air quality monitors, annotating that data through multiple modalities, and sending text message prompts when it detects a PM2.5 spike. MAAV also features an interactive tablet interface for displaying measurement data and annotations. Through six long-term field deployments (20-47 weeks, mean 37.7 weeks), participants found these system features important for understanding the air quality in and around their homes. Participants gained new insights from between-monitor comparisons, reflected on past PM2.5 spikes with the help of their annotations, and adapted their system usage as they familiarized themselves with their air quality data and MAAV. These results yield important insights for designing residential sensing systems that integrate into users' everyday lives.","Volume 2 Issue 3, September 2018"
124,10.1145/3264939,"Skanda Muralidhar, Marianne Schmid Mast, Daniel Gatica-Perez",A Tale of Two Interactions: Inferring Performance in Hospitality Encounters from Cross-Situation Social Sensing,"People behave differently in different situations. With the advances in ubiquitous sensing technologies, it is now easier to capture human behavior across multiple situations automatically and unobtrusively. We investigate human behavior across two situations that are ubiquitous in hospitality (job interview and reception desk) with the objective of inferring performance on the job. Utilizing a dataset of 338 dyadic interactions, played by students from a hospitality management school, we first study the connections between automatically extracted nonverbal cues, linguistic content, and various perceived variables of soft skills and performance in these two situations. A correlation analysis reveals connection between perceived variables and nonverbal cues displayed during job interviews, and perceived performance on the job. We then propose a computational framework, with nonverbal cues and linguistic style from the two interactions as features, to infer the perceived performance and soft skills in the reception desk situation as a regression task. The best inference performance, with R2 = 0.40, is achieved using a combination of nonverbal cues extracted from the reception desk setting and the human-rated interview scores. We observe that some behavioral cues (greater speaking turn duration and head nods) are positively correlated to higher ratings for all perceived variables across both situations. The best performance using verbal content is achieved by fusion of LIWC and Doc2Vec features with R2 = 0.25 for perceived performance. Our work has implications for the creation of behavioral training systems with focus on specific behaviors for hospitality students.","Volume 2 Issue 3, September 2018"
125,10.1145/3264940,"Tomoya Nakatani, Takuya Maekawa, Masumi Shirakawa, Takahiro Hara",Estimating the Physical Distance between Two Locations with Wi-Fi Received Signal Strength Information Using Obstacle-aware Approach,"This study presents a new method for estimating the physical distance between two locations using Wi-Fi signals from APs observed by Wi-Fi signal receivers such as smartphones. We assume that a Wi-Fi signal strength vector is observed at location A and another Wi-Fi signal strength vector is observed at location B. With these two Wi-Fi signal strength vectors, we attempt to estimate the physical distance between locations A and B. In this study, we estimate the physical distance based on supervised machine learning and do not use labeled training data collected in an environment of interest. Note that, because signal propagation is greatly affected by obstacles such as walls, precisely estimating the distance between locations A and B is difficult when there is a wall between locations A and B. Our method first estimates whether or not there is a wall between locations A and B focusing on differences in signal propagation properties between 2.4 GHz and 5 GHz signals, and then estimates the physical distance using a neural network depending on the presence of walls. Because our approach is based on Wi-Fi signal strengths and does not require a site survey in an environment of interest, we believe that various context-aware applications can be easily implemented based on the distance estimation technique such as low-cost indoor navigation, the analysis and discovery of communities and groups, and Wi-Fi geo-fencing. Our experiment revealed that the proposed method achieved an MAE of about 3-4 meters and the performance is almost identical to an environment-dependent method, which is trained on labeled data collected in the same environment.","Volume 2 Issue 3, September 2018"
126,10.1145/3264941,"Eshed Ohn-Bar, João Guerreiro, Kris Kitani, Chieko Asakawa",Variability in Reactions to Instructional Guidance during Smartphone-Based Assisted Navigation of Blind Users,"'Turn slightly to the left' the navigational system announces, with the aim of directing a blind user to merge into a corridor. Yet, due to long reaction time, the user turns too late and proceeds into the wrong hallway. Observations of such user behavior in real-world navigation settings motivate us to study the manner in which blind users react to the instructional feedback of a turn-by-turn guidance system. We found little previous work analyzing the extent of the variability among blind users in reaction to different instructional guidance during assisted navigation. To gain insight into how navigational interfaces can be better designed to accommodate the information needs of different users, we conduct a data-driven analysis of reaction variability as defined by motion and timing measures. Based on continuously tracked user motion during real-world navigation with a deployed system, we find significant variability between users in their reaction characteristics. Specifically, the statistical analysis reveals significant variability during the crucial elements of the navigation (e.g., turning and encountering obstacles). With the end-user experience in mind, we identify the need to not only adjust interface timing and content to each user's personal walking pace, but also their individual navigation skill and style. The design implications of our study inform the development of assistive systems which consider such user-specific behavior to ensure successful navigation.","Volume 2 Issue 3, September 2018"
127,10.1145/3264942,"Gaurav Paruthi, Shriti Raj, Seungjoo Baek, Chuyao Wang, Chuan-che Huang, Yung-Ju Chang, Mark W. Newman",Heed: Exploring the Design of Situated Self-Reporting Devices,"In-situ self-reporting is a widely used data collection technique for understanding people's behavior in context. Characteristics of smartphones such as their high proliferation, close proximity to their users, and heavy use have made them a popular choice for applications that require frequent self-reporting. Newer device categories such as wearables and voice assistants offer their own advantages, providing an opportunity to explore a wider range of self-reporting approaches. In this paper, we focus on exploring the design space of Situated Self-Reporting (SSR) devices. We present the Heed system, consisting of simple, low-cost, and low-power SSR devices that are distributed in the environment of the user and can be appropriated for reporting measures such as stress, sleepiness, and activities. In two real-world studies with 10 and 7 users, we compared and analyzed the use of smartphone and Heed devices to uncover differences in their use due to the influence of factors such as situational and social context, notification types, and physical design. Our findings show that Heed devices complemented smartphones in the coverage of activities, locations and interaction preferences. While the advantage of Heed was its single-purpose and dedicated location, smartphones provided mobility and flexibility of use.","Volume 2 Issue 3, September 2018"
128,10.1145/3264943,"Bariş Serim, Ken Pfeuffer, Hans Gellersen, Giulio Jacucci",Visual Attention-Based Access: Granting Access Based on Users' Joint Attention on Shared Workspaces,"During collaboration, individual users' capacity to maintain awareness, avoid duplicate work and prevent conflicts depends on the extent to which they are able to monitor the workspace. Existing access control models disregard this contextual information by managing access strictly based on who performs the action. As an alternative approach, we propose managing access by taking the visual attention of collaborators into account. For example, actions that require consensus can be limited to collaborators' joint attention, editing another user's personal document can require her visual supervision and private information can become unavailable when another user is looking. We prototyped visual attention-based access for 3 collaboration scenarios on a large vertical display using head orientation input as a proxy for attention. The prototype was deployed for an exploratory user study, where participants in pairs were tasked to assign visual attention-based access to various actions. The results reveal distinct motivations for their use such as preventing accidents, maintaining individual control and facilitating group awareness. Visual attention-based access has been perceived as more convenient but also less certain when compared to traditional access control. We conclude that visual attention-based access can be a useful addition to groupware to flexibly facilitate awareness and prevent conflicts.","Volume 2 Issue 3, September 2018"
129,10.1145/3264944,"Muhammad Shahzad, Shaohu Zhang",Augmenting User Identification with WiFi Based Gesture Recognition,"Over the last few years, researchers have proposed several WiFi based gesture recognition systems that can recognize predefined gestures performed by users at runtime. As most environments are inhabited by multiple users, the true potential of WiFi based gesture recognition can be unleashed only when each user can independently define the actions that the system should take when the user performs a certain predefined gesture. To enable this, a gesture recognition system should not only be able to recognize any given predefined gesture, but should also be able to identify the user that performed it. Unfortunately, none of the prior WiFi based gesture recognition systems can identify the user performing the gesture. In this paper, we propose WiID, a WiFi and gesture based user identification system that can identify the user as soon as he/she performs a predefined gesture at runtime. WiID integrates with the WiFi based gesture recognition systems as an add-on module whose sole objective is to identify the users that perform the predefined gestures. The design of WiID is based on our novel result which states that the timeseries of the frequencies that appear in WiFi channel's frequency response while performing a given gesture are different in the samples of that gesture performed by different users, and are similar in the samples of that gesture performed by the same user. We implemented and extensively evaluated WiID in a variety of environments using a comprehensive data set comprising over 25,000 gesture samples.","Volume 2 Issue 3, September 2018"
130,10.1145/3264945,"Qun Song, Chaojie Gu, Rui Tan",Deep Room Recognition Using Inaudible Echos,"Recent years have seen the increasing need of location awareness by mobile applications. This paper presents a room-level indoor localization approach based on the measured room's echos in response to a two-millisecond single-tone inaudible chirp emitted by a smartphone's loudspeaker. Different from other acoustics-based room recognition systems that record full-spectrum audio for up to ten seconds, our approach records audio in a narrow inaudible band for 0.1 seconds only to preserve the user's privacy. However, the short-time and narrowband audio signal carries limited information about the room's characteristics, presenting challenges to accurate room recognition. This paper applies deep learning to effectively capture the subtle fingerprints in the rooms' acoustic responses. Our extensive experiments show that a two-layer convolutional neural network fed with the spectrogram of the inaudible echos achieve the best performance, compared with alternative designs using other raw data formats and deep models. Based on this result, we design a RoomRecognize cloud service and its mobile client library that enable the mobile application developers to readily implement the room recognition functionality without resorting to any existing infrastructures and add-on hardware. Extensive evaluation shows that RoomRecognize achieves 99.7%, 97.7%, 99%, and 89% accuracy in differentiating 22 and 50 residential/office rooms, 19 spots in a quiet museum, and 15 spots in a crowded museum, respectively. Compared with the state-of-the-art approaches based on support vector machine, RoomRecognize significantly improves the Pareto frontier of recognition accuracy versus robustness against interfering sounds (e.g., ambient music).","Volume 2 Issue 3, September 2018"
131,10.1145/3264946,"Jiajie Tan, Wangkit Wong, Xinyu Zhu, Hang Wu, S.-H. Gary Chan",Cooperative Target Tracking and Signal Propagation Learning Using Mobile Sensors,"Target tracking refers to positioning mobile objects over time. The targets may be hospital patients, park visitors, mall shoppers, warehouse assets, etc. We consider a novel cooperative system to track targets, where a target carries low-cost RF tag which not only beacons its ID, but also receives and rebroadcasts beacons of tags within a certain hop away. Mobile sensors, equipped with localization and communication modules, are used to capture and forward the beacons to a server to track the targets. Such multi-hop approach greatly extends the sensing range of the mobile sensors, or equivalently, the beaconing range of the tags, leading to cost-effective deployment.
We propose Mosent, a highly accurate multi-hop system using mobile sensors for target tracking. To account for complex signal propagation in different indoor and outdoor environment, we represent the received signal strength (RSS) matrix overcoming the assumption on propagation model. Given sensor locations, beacons detected by the sensors and RSS matrix, Mosent jointly considers temporal and spatial information to track targets using a modified particle filter. Mosent has an optional, independent and offline module to learn spatial signal propagation in terms of RSS matrix using cooperative mobile sensors equipped with beaconing transceivers. We have implemented Mosent and conducted extensive experiments. Our results show that Mosent achieves 4.37m and 9.46m tracking error in the campus and the shopping mall, respectively, which outperforms other state-of-the-art approaches with significantly lower tracking error (often by more than 30%).","Volume 2 Issue 3, September 2018"
132,10.1145/3264947,"Yonglong Tian, Guang-He Lee, Hao He, Chen-Yu Hsu, Dina Katabi",RF-Based Fall Monitoring Using Convolutional Neural Networks,"Falls are the top reason for fatal and non-fatal injuries among seniors. Existing solutions are based on wearable fall-alert sensors, but medical research has shown that they are ineffective, mostly because seniors do not wear them. These revelations have led to new passive sensors that infer falls by analyzing Radio Frequency (RF) signals in homes. Seniors can go about their lives as usual without the need to wear any device. While passive monitoring has made major advances, current approaches still cannot deal with the complexities of real-world scenarios. They typically train and test their classifiers on the same people in the same environments, and cannot generalize to new people or new environments. Further, they cannot separate motions from different people and can easily miss a fall in the presence of other motions.
To overcome these limitations, we introduce Aryokee, an RF-based fall detection system that uses convolutional neural networks governed by a state machine. Aryokee works with new people and environments unseen in the training set. It also separates different sources of motion to increase robustness. Results from testing Aryokee with over 140 people performing 40 types of activities in 57 different environments show a recall of 94% and a precision of 92% in detecting falls.","Volume 2 Issue 3, September 2018"
133,10.1145/3264948,"Zhen Tu, Runtong Li, Yong Li, Gang Wang, Di Wu, Pan Hui, Li Su, Depeng Jin",Your Apps Give You Away: Distinguishing Mobile Users by Their App Usage Fingerprints,"Understanding mobile app usage has become instrumental to service providers to optimize their online services. Meanwhile, there is a growing privacy concern that users' app usage may uniquely reveal who they are. In this paper, we seek to understand how likely a user can be uniquely re-identified in the crowd by the apps she uses. We systematically quantify the uniqueness of app usage via large-scale empirical measurements. By collaborating with a major cellular network provider, we obtained a city-scale anonymized dataset on mobile app traffic (1.37 million users, 2000 apps, 9.4 billion network connection records). Through extensive analysis, we show that the set of apps that a user has installed is already highly unique. For users with more than 10 apps, 88% of them can be uniquely re-identified by 4 random apps. The uniqueness level is even higher if we consider when and where the apps are used. We also observe that user attributes (e.g., gender, social activity, and mobility patterns) all have an impact on the uniqueness of app usage. Our work takes the first step towards understanding the unique app usage patterns for a large user population, paving the way for further research to develop privacy-protection techniques and building personalized online services.","Volume 2 Issue 3, September 2018"
134,10.1145/3264949,"Florian Wahl, Oliver Amft",Data and Expert Models for Sleep Timing and Chronotype Estimation from Smartphone Context Data and Simulations,"We present a sleep timing estimation approach that combines data-driven estimators with an expert model and uses smartphone context data. Our data-driven methodology comprises a classifier trained on features from smartphone sensors. Another classifier uses time as input. Expert knowledge is incorporated via the human circadian and homeostatic two process model. We investigate the two process model as output filter on classifier results and as fusion method to combine sensor and time classifiers. We analyse sleep timing estimation performance, in data from a two-week free-living study of 13 participants and sensor data simulations of arbitrary sleep schedules, amounting to 98280 nights. Five intuitive sleep parameters were derived to control the simulation. Moreover, we investigate model personalisation, by retraining classifiers based on participant feedback. The joint data and expert model yields an average relative estimation error of -2±62 min for sleep onset and -5±70 min for wake (absolute errors 40±48 min and 42±57 min, mean median absolute deviation 22 min and 15 min), which significantly outperforms data-driven methods. Moreover, the data and expert models combination remains robust under varying sleep schedules. Personalising data models with user feedback from the last two days showed the largest performance gain of 57% for sleep onset and 59% for wake up. Our power-efficient smartphone app makes convenient everyday sleep monitoring finally realistic.","Volume 2 Issue 3, September 2018"
135,10.1145/3264950,"Lei Wang, Kang Huang, Ke Sun, Wei Wang, Chen Tian, Lei Xie, Qing Gu",Unlock with Your Heart: Heartbeat-based Authentication on Commercial Mobile Phones,"In this paper, we propose to use the vibration of the chest in response to the heartbeat as a biometric feature to authenticate the user on mobile devices. We use the built-in accelerometer to capture the heartbeat signals on commercial mobile phones. The user only needs to press the phone on his/her chest, and the system can identify the user within a few heartbeats. To reliably extract heartbeat features, we design a two-step alignment scheme that can handle the natural variability in human heart rates. We further use an adaptive template selection scheme to authenticate the user under different body postures and body states. Based on heartbeat signals collected on twenty users, the experimental results show that our method can achieve an authentication accuracy of 96.49% and the heartbeat features are stable over a period of three months.","Volume 2 Issue 3, September 2018"
136,10.1145/3264951,"Weichen Wang, Gabriella M. Harari, Rui Wang, Sandrine R. Müller, Shayan Mirjafari, Kizito Masaba, Andrew T. Campbell",Sensing Behavioral Change over Time: Using Within-Person Variability Features from Mobile Sensing to Predict Personality Traits,"Personality traits describe individual differences in patterns of thinking, feeling, and behaving (""between-person"" variability). But individuals also show changes in their own patterns over time (""within-person"" variability). Existing approaches to measuring within-person variability typically rely on self-report methods that do not account for fine-grained behavior change patterns (e.g., hour-by-hour). In this paper, we use passive sensing data from mobile phones to examine the extent to which within-person variability in behavioral patterns can predict self-reported personality traits. Data were collected from 646 college students who participated in a self-tracking assignment for 14 days. To measure variability in behavior, we focused on 5 sensed behaviors (ambient audio amplitude, exposure to human voice, physical activity, phone usage, and location data) and computed 4 within-person variability features (simple standard deviation, circadian rhythm, regularity index, and flexible regularity index). We identified a number of significant correlations between the within-person variability features and the self-reported personality traits. Finally, we designed a model to predict the personality traits from the within-person variability features. Our results show that we can predict personality traits with good accuracy. The resulting predictions correlate with self-reported personality traits in the range of r = 0.32, MAE = 0.45 (for Openness in iOS users) to r = 0.69, MAE = 0.55 (for Extraversion in Android users). Our results suggest that within-person variability features from smartphone data has potential for passive personality assessment.","Volume 2 Issue 3, September 2018"
137,10.1145/3264952,"Tan Kiat Wee, Eduardo Cuervo, Rajesh Balan",FocusVR: Effective 8 Usable VR Display Power Management,"In this paper, we present the design and implementation of FocusVR, a system for effectively and efficiently reducing the power consumption of Virtual Reality (VR) devices by smartly dimming their displays. These devices are becoming increasingly common with large companies such as Facebook (Oculus Rift), and HTC and Valve (Vive), recently releasing high quality VR devices to the consumer market. However, these devices require increasingly higher screen resolutions and refresh rates to be effective, and this in turn, leads to high display power consumption costs. We show how the use of smart dimming techniques, vignettes and color mapping, can significantly reduce the power consumption of VR displays with minimal impact on usability. In particular, we describe the implementation of FocusVR in both Android and the Unity game engine and then present detailed measurement results across 3 different VR devices -- the Gear VR, the DK2, and the Vive. In addition, we present the results of 3 user studies, with 68 participants in total, that tested the usability of FocusVR. Overall, we show that FocusVR is able to save up to 80% of the display power and up to 50% of the overall system power, with negligible impact to usability.","Volume 2 Issue 3, September 2018"
138,10.1145/3264953,"Tong Xin, Bin Guo, Zhu Wang, Pei Wang, Jacqueline Chi Kei Lam, Victor Li, Zhiwen Yu",FreeSense: A Robust Approach for Indoor Human Detection Using Wi-Fi Signals,"Human detection aims to monitor how people are moving in an area of interest. There are many potential applications such as asset security monitoring, emergency management, and elderly care, etc. With the development of wireless sensing technique, Wi-Fi-based human detection method carries great potential due to advantages of pervasive accessibility and coverage flexibility. Previous studies have investigated the detection of human movements via signal variations. However, affected by noises, such as multi-path effect and device difference, existing approaches cannot achieve high accuracy and low false alarm rate at the same time. In this paper, we propose FreeSense, a novel Wi-Fi-based approach for human detection. Different from previous studies that characterize the variation of temporal wireless signals or calculate the deviation of Channel State Information (CSIs) from a normal profile, we will detect human movements by identifying whether there is any phase difference between the amplitude waveforms of multiple receiving antennas. In addition, we also model the sensing coverage for movements of different granularities in open space and propose a method to estimate the coverage range. Extensive experiments demonstrate that FreeSense can achieve an average false positive rate (FP) of 0.53% and an average false negative rate (FN) of 1.40%. The coverage range estimation method can achieve an average accuracy of 1.36 m, sufficient to guide the deployment of devices for human detection indoors.","Volume 2 Issue 3, September 2018"
139,10.1145/3264954,"Shuochao Yao, Yiran Zhao, Huajie Shao, Chao Zhang, Aston Zhang, Shaohan Hu, Dongxin Liu, Shengzhong Liu, Lu Su, Tarek Abdelzaher",SenseGAN: Enabling Deep Learning for Internet of Things with a Semi-Supervised Framework,"Recent proliferation of Internet of Things (IoT) devices with enhanced computing and sensing capabilities has revolutionized our everyday life. The massive data from these ubiquitous devices motivate the creation of intelligent IoT systems that can collectively learn. However, labelling data for learning purposes is extremely time-consuming, which greatly hinders deployment. In this paper, we describe a semi-supervised deep learning framework, called SenseGAN, that can leverage abundant unlabelled sensing data thereby minimizing the need for labelling effort. SenseGAN jointly trains three components with an adversarial game: (i) a classifier for predicting labels of input sensing data; (ii) a generator for generating sensing data samples based on the input labels; and (iii) a discriminator for differentiating the joint data/label distribution between real samples and partially generated samples from either the classifier or the generator. The classifier and the generator try to generate fake data/labels that can fool the discriminator. The adversarial game among the three components can mutually boost their performance, which helps the classifier learn to predict correct labels with unlabelled data in return. SenseGAN can effectively handle multimodal sensing inputs and easily stabilize the adversarial training process, which helps improve the performance of the classifier. Experiments on three IoT applications demonstrate the substantial improvements in accuracy and F1 score under SenseGAN, compared with supervised counterparts trained only on the labelled portion of the data, as well as other supervised and semi-supervised baselines. For these three applications, SenseGAN requires only 10% of the originally labelled data, to attain nearly the same accuracy as a deep learning classifier trained on the fully labelled dataset.","Volume 2 Issue 3, September 2018"
140,10.1145/3264955,"Sang Ho Yoon, Luis Paredes, Ke Huo, Karthik Ramani",MultiSoft: Soft Sensor Enabling Real-Time Multimodal Sensing with Contact Localization and Deformation Classification,"We introduce MultiSoft, a multilayer soft sensor capable of sensing real-time contact localization, classification of deformation types, and estimation of deformation magnitudes. We propose a multimodal sensing pipeline that carries out both inverse problem solving and machine learning tasks. Specifically, we employ an electrical impedance tomography (EIT) for contact localization and a support vector machine (SVM) for classifying deformations and regressing their magnitudes. We propose a deformation-aware system which enables maintaining a persistent single-point contact localization throughout the deformation. By updating a time-varying distribution of conductivity change caused by deformations, a single-point contact localization can be maintained and restored to support interaction using both contact localization and deformations.We devise a multilayer structure to fabricate a highly stretchable and flexible soft sensor with a short sensor settlement after excitations. Through a series of experiments and evaluations, we validate both raw sensor and multimodal sensing performance with the proposed method. We further demonstrate applicability and feasibility of MultiSoft with example applications.","Volume 2 Issue 3, September 2018"
141,10.1145/3264956,"Chuang-Wen You, Ya-Fang Lin, Yaliang Chuang, Ya-Han Lee, Pei-Yi Hsu, Shih-Yao Lin, Chih-Chun Chang, Yi-Ju Chung, Yi-Ling Chen, Ming-Chyi Huang, Ping-Hsuan Shen, Hsin-Tung Tseng, Hao-Chuan Wang",SoberMotion: Leveraging the Force of Probation Officers to Reduce the Risk of DUI Recidivism,"In this study, we sought to assist probation officers in their efforts to reduce the risk that offenders on probation would re-commit the offense of driving under the influence (DUI) of alcohol. We prototyped a support system called SoberMotion, in which a breathalyzer is connected to the offender's smart phone via Bluetooth. Development of the system was based on pilot interviews with probation officers, psychiatrists, and offenders aimed at identifying the challenges and opportunities associated with this type of technology-based support mechanism. A corresponding phone app logs alcohol use behavior and identifies situations in which offenders should evaluate their sobriety before operating a vehicle. We conducted a two-month field study involving eight DUI offenders on probation, with the aim of evaluating the feasibility of the SoberMotion system. Our results indicate that most of the participants who drank alcohol while following the program performed multiple alcohol screening tests before operating a vehicle in order to avoid re-committing DUI. Responses collected via qualitative interviews indicate that SoberMotion is an effective approach to extending the power of probation officers seeking to reduce the risk of DUI recidivism.","Volume 2 Issue 3, September 2018"
142,10.1145/3264957,"Yanwei Yu, Hongjian Wang, Zhenhui Li",Inferring Mobility Relationship via Graph Embedding,"Inferring social relationships from user location data has become increasingly important for real-world applications, such as recommendation, advertisement targeting, and transportation scheduling. Most existing mobility relationship measures are based on pairwise meeting frequency, that it, the more frequently two users meet (i.e., co-locate at the same time), the more likely that they are friends. However, such frequency-based methods suffer greatly from data sparsity challenge. Due to data collection limitation and bias in the real world (e.g., check-in data), the observed meeting events between two users might be very few. On the other hand, existing methods focus too much on the interactions between two users, but fail to incorporate the whole social network structure. For example, the relationship propagation is not well utilized in existing methods. In this paper, we propose to construct a user graph based on their spatial-temporal interactions and employ graph embedding technique to learn user representations from such a graph. The similarity measure of such representations can well describe mobility relationship and it is particularly useful to describe the similarity for user pairs with low or even zero meeting frequency. Furthermore, we introduce semantic information on meeting events by using point-of-interest (POI) categorical information. Additionally, when part of the social graph is available as friendship ground truth, we can easily encode such online social network information through a joint graph embedding. Experiments on two real-world datasets demonstrate the effectiveness of our proposed method.","Volume 2 Issue 3, September 2018"
143,10.1145/3264958,"Youwei Zeng, Dan Wu, Ruiyang Gao, Tao Gu, Daqing Zhang",FullBreathe: Full Human Respiration Detection Exploiting Complementarity of CSI Phase and Amplitude of WiFi Signals,"Human respiration detection based on Wi-Fi signals does not require users to carry any device, hence it has drawn a lot of attention due to better user acceptance and great potential for real-world deployment. However, recent studies show that respiration sensing performance varies in different locations due to the nature of Wi-Fi radio wave propagation in indoor environments, i.e., respiration detection may experience poor performance at certain locations which we call ""blind spots"". In this paper, we aim to address the blind spot problem to ensure full coverage of respiration detection. Basically, the amplitude and phase of Wi-Fi channel state information (CSI) are orthogonal and complementary to each other, so they can be combined to eliminate the blind spots. However, accurate CSI phase cannot be obtained from commodity Wi-Fi due to the clock-unsynchronized transceivers. Thus, we apply conjugate multiplication (CM) of CSI between two antennas to remove the phase offset and construct two orthogonal signals--new ""amplitude and phase"" which are still complementary to each other. In this way, we can ensure full human respiration detection. Based on these ideas, We design and implement a real-time respiration detection system with commodity Wi-Fi devices. We conduct extensive experiments to validate our model and design. The results show that, with only one transceiver pair and without leveraging multiple sub-carriers, our system enables full location coverage with no blind spot, showing great potential for real deployment.","Volume 2 Issue 3, September 2018"
144,10.1145/3264959,"Xiang Zhang, Lina Yao, Salil S. Kanhere, Yunhao Liu, Tao Gu, Kaixuan Chen",MindID: Person Identification from Brain Waves through Attention-based Recurrent Neural Network,"Person identification technology recognizes individuals by exploiting their unique, measurable physiological and behavioral characteristics. However, the state-of-the-art person identification systems have been shown to be vulnerable, e.g., anti-surveillance prosthetic masks can thwart face recognition, contact lenses can trick iris recognition, vocoder can compromise voice identification and fingerprint films can deceive fingerprint sensors. EEG (Electroencephalography)-based identification, which utilizes the user's brainwave signals for identification and offers a more resilient solution, has recently drawn a lot of attention. However, the state-of-the-art systems cannot achieve similar accuracy as the aforementioned methods. We propose MindID, an EEG-based biometric identification approach, with the aim of achieving high accuracy and robust performance. At first, the EEG data patterns are analyzed and the results show that the Delta pattern contains the most distinctive information for user identification. Next, the decomposed Delta signals are fed into an attention-based Encoder-Decoder RNNs (Recurrent Neural Networks) structure which assigns varying attention weights to different EEG channels based on their importance. The discriminative representations learned from the attention-based RNN are used to identify the user through a boosting classifier. The proposed approach is evaluated over 3 datasets (two local and one public). One local dataset (EID-M) is used for performance assessment and the results illustrate that our model achieves an accuracy of 0.982 and significantly outperforms the state-of-the-art and relevant baselines. The second local dataset (EID-S) and a public dataset (EEG-S) are utilized to demonstrate the robustness and adaptability, respectively. The results indicate that the proposed approach has the potential to be widely deployed in practical settings.","Volume 2 Issue 3, September 2018"
145,10.1145/3264960,"Yanxia Zhang, Jeffrey Olenick, Chu-Hsiang Chang, Steve W. J. Kozlowski, Hayley Hung",TeamSense: Assessing Personal Affect and Group Cohesion in Small Teams through Dyadic Interaction and Behavior Analysis with Wearable Sensors,"Continuous monitoring with unobtrusive wearable social sensors is becoming a popular method to assess individual affect states and team effectiveness in human research. A large number of applications have demonstrated the effectiveness of applying wearable sensing in corporate settings; for example, in short periodic social events or in a university campus. However, little is known of how we can automatically detect individual affect and group cohesion for long duration missions. Predicting negative affect states and low cohesiveness is vital for team missions. Knowing team members' negative states allows timely interventions to enhance their effectiveness. This work investigates whether sensing social interactions and individual behaviors with wearable sensors can provide insights into assessing individual affect states and group cohesion. We analyzed wearable sensor data from a team of six crew members who were deployed on a four-month simulation of a space exploration mission at a remote location. Our work proposes to recognize team members' affect states and group cohesion as a binary classification problem using novel behavior features that represent dyadic interaction and individual activities. Our method aggregates features from individual members into group levels to predict team cohesion. Our results show that the behavior features extracted from the wearable social sensors provide useful information in assessing personal affect and team cohesion. Group task cohesion can be predicted with a high performance of over 0.8 AUC. Our work demonstrates that we can extract social interactions from sensor data to predict group cohesion in longitudinal missions. We found that quantifying behavior patterns including dyadic interactions and face-to-face communications are important in assessing team process.","Volume 2 Issue 3, September 2018"
146,10.1145/3264961,"Tongqing Zhou, Zhiping Cai, Bin Xiao, Leye Wang, Ming Xu, Yueyue Chen",Location Privacy-Preserving Data Recovery for Mobile Crowdsensing,"Data recovery techniques such as compressive sensing are commonly used in mobile crowdsensing (MCS) applications to infer the information of unsensed regions based on data from nearby participants. However, the participants' locations are exposed when they report geo-tagged data to an application server. While there are considerable location protection approaches for MCS, they fail to maintain the correlation of sensory data, leading to the existence of unrecoverable data. None of the previous approaches can achieve both data recovery and data privacy preservation. We propose a novel location privacy-preserving data recovery method in this paper. Based on our discovery that the adjacency relations of non-zero elements are key to the missing data recovery in a crowdsensing data matrix, we design a correlation-preserving location obfuscation scheme to hide the participants' locations under effective camouflage. We also design an encrypted data recovery scheme based on the homomorphic encryption in order to avoid location privacy leakage from sensory data. Location obfuscation and data encryption preserve the participants' privacy, while the correlation-preserving and homomorphic properties of our method ensure data recovery accuracy. Evaluations of real-world datasets show that our privacy-preserving method can effectively obfuscate locations (e.g., yielding an average location distortion of 1.7km in a 2.4km x 4km area for successful location hiding), and it can efficiently achieve similar data recovery accuracy to compressive sensing (which has no privacy protection).","Volume 2 Issue 3, September 2018"
147,10.1145/3264962,"Yongpan Zou, Meng Zhao, Zimu Zhou, Jiawei Lin, Mo Li, Kaishun Wu",BiLock: User Authentication via Dental Occlusion Biometrics,"User authentication on smart devices is indispensable to keep data privacy and security. It is especially significant for emerging wearable devices such as smartwatches considering data sensitivity in them. However, conventional authentication methods are not applicable for wearables due to constraints of size and hardware, which makes present wearable devices lack convenient, secure and low-cost authentication schemes. To tackle this problem, we reveal a novel biometric authentication mechanism which makes use of sounds of human dental occlusion (i.e., tooth click). We demonstrate its feasibility by comprehensive measurement study, and design a prototype-BiLock with two Android platforms. Extensive real-world experiments have been conducted to evaluate the accuracy, robustness and security of BiLock in different environments. The results show that BiLock can achieve less than 5% average false reject rate and 0.95% average false accept rate even in a noisy environment. Comparative experiments also demonstrate that BiLock possesses advantages in robustness to noise and security against replay and observation attacks over existing voiceprinting schemes.","Volume 2 Issue 3, September 2018"
148,10.1145/3214260,"Karan Ahuja, Rahul Islam, Varun Parashar, Kuntal Dey, Chris Harrison, Mayank Goel","EyeSpyVR: Interactive Eye Sensing Using Off-the-Shelf, Smartphone-Based VR Headsets","Low cost virtual reality (VR) headsets powered by smartphones are becoming ubiquitous. Their unique position on the user's face opens interesting opportunities for interactive sensing. In this paper, we describe EyeSpyVR, a software-only eye sensing approach for smartphone-based VR, which uses a phone's front facing camera as a sensor and its display as a passive illuminator. Our proof-of-concept system, using a commodity Apple iPhone, enables four sensing modalities: detecting when the VR head set is worn, detecting blinks, recognizing the wearer's identity, and coarse gaze tracking - features typically found in high-end or specialty VR headsets. We demonstrate the utility and accuracy of EyeSpyVR in a series of studies with 70 participants, finding a worn detection of 100%, blink detection rate of 95.3%, family user identification accuracy of 81.4%, and mean gaze tracking error of 10.8° when calibrated to the wearer (12.9° without calibration). These sensing abilities can be used by developers to enable new interactive features and more immersive VR experiences on existing, off-the-shelf hardware.","Volume 2 Issue 2, June 2018"
149,10.1145/3214261,"Christoph Anderson, Isabel Hübener, Ann-Kathrin Seipp, Sandra Ohly, Klaus David, Veljko Pejovic",A Survey of Attention Management Systems in Ubiquitous Computing Environments,"Today's information and communication devices provide always-on connectivity, instant access to an endless repository of information, and represent the most direct point of contact to almost any person in the world. Despite these advantages, devices such as smartphones or personal computers lead to the phenomenon of attention fragmentation, continuously interrupting individuals' activities and tasks with notifications. Attention management systems aim to provide active support in such scenarios, managing interruptions, for example, by postponing notifications to opportune moments for information delivery. In this article, we review attention management system research with a particular focus on ubiquitous computing environments. We first examine cognitive theories of attention and extract guidelines for practical attention management systems. Mathematical models of human attention are at the core of these systems, and in this article, we review sensing and machine learning techniques that make such models possible. We then discuss design challenges towards the implementation of such systems, and finally, we investigate future directions in this area, paving the way for new approaches and systems supporting users in their attention management.","Volume 2 Issue 2, June 2018"
150,10.1145/3214262,"Noah Apthorpe, Yan Shvartzshnaider, Arunesh Mathur, Dillon Reisman, Nick Feamster",Discovering Smart Home Internet of Things Privacy Norms Using Contextual Integrity,"The proliferation of Internet of Things (IoT) devices for consumer ""smart"" homes raises concerns about user privacy. We present a survey method based on the Contextual Integrity (CI) privacy framework that can quickly and efficiently discover privacy norms at scale. We apply the method to discover privacy norms in the smart home context, surveying 1,731 American adults on Amazon Mechanical Turk. For $2,800 and in less than six hours, we measured the acceptability of 3,840 information flows representing a combinatorial space of smart home devices sending consumer information to first and third-party recipients under various conditions. Our results provide actionable recommendations for IoT device manufacturers, including design best practices and instructions for adopting our method for further research.","Volume 2 Issue 2, June 2018"
151,10.1145/3214263,"Nivedita Arora, Steven L. Zhang, Fereshteh Shahmiri, Diego Osorio, Yi-Cheng Wang, Mohit Gupta, Zhengjun Wang, Thad Starner, Zhong Lin Wang, Gregory D. Abowd",SATURN: A Thin and Flexible Self-powered Microphone Leveraging Triboelectric Nanogenerator,"We demonstrate the design, fabrication, evaluation, and use of a self-powered microphone that is thin, flexible, and easily manufactured. Our technology is referred to as a Self-powered Audio Triboelectric Ultra-thin Rollable Nanogenerator (SATURN) microphone. This acoustic sensor takes advantage of the triboelectric nanogenerator (TENG) to transform vibrations into an electric signal without applying an external power source. The sound quality of the SATURN mic, in terms of acoustic sensitivity, frequency response, and directivity, is affected by a set of design parameters that we explore based on both theoretical simulation and empirical evaluation. The major advantage of this audio material sensor is that it can be manufactured simply and deployed easily to convert every-day objects and physical surfaces into microphones which can sense audio. We explore the space of potential applications for such a material as part of a self-sustainable interactive system.","Volume 2 Issue 2, June 2018"
152,10.1145/3214264,"Rafael Ballagas, Sarthak Ghosh, James Landay",The Design Space of 3D Printable Interactivity,"The capabilities of 3D printers are rapidly progressing towards fabrication of fully interactive products. For designers to reason about the best way to achieve their interaction design goals, it is helpful to not only know what exists in the literature, but to also understand the design space of options. Such an understanding can help in comparison, analysis, selection of suitable technology, and also in the generation of new ideas. In this article, we survey the state of the art in 3D printing fully functional sensors and actuators to support explicit interaction techniques. We classify and organize the surveyed works around the following parameters: mechanism, designed affordances, interaction primitives, and output modality. The design space is presented in the form of a multidimensional matrix known as a Zwicky box. Using the tables, we can make observations about the existing literature and also identify gaps in this design space. Many such gaps can potentially lead to exciting new research or engineering opportunities.","Volume 2 Issue 2, June 2018"
153,10.1145/3214265,"Hancheng Cao, Jie Feng, Yong Li, Vassilis Kostakos",Uniqueness in the City: Urban Morphology and Location Privacy,"We investigate the potential for privacy leaks when users reveal their nearby Points-of-Interest (POIs). Specifically, we investigate whether and how a person's location can be reverse-engineered when that person simply reveals their nearby POI types (e.g. 2 schools and 3 restaurants). We approach our analysis by introducing a ""Location Re-identification"" algorithm that is computationally efficient. Using data from Open Street Map, we conduct our analysis on datasets of multiple representative cities: New York City, Melbourne, Vancouver, Zurich and Shanghai. Our analysis indicates that urban morphology has a clear link to location privacy, and highlights a number of urban factors that contribute to location privacy. Our findings can be used in any systems or platforms where users reveal their proximal POIs, such as recommendation systems, advertising platforms, and appstores.","Volume 2 Issue 2, June 2018"
154,10.1145/3214266,"Siyuan Cao, He Wang",Enabling Public Cameras to Talk to the Public,"This paper asks: Is it possible for cameras in public areas, say ceiling cameras in a museum, to send personalized messages to people without knowing any addresses of their phones? We define this kind of problem as Private Human Addressing and develop a real-time end-to-end system called PHADE to solve it. Unlike traditional data transmission protocols that need to first learn the destination's address, our cameras rely on viewing user's motion patterns, and use the uniqueness of these patterns as the address for communication. Once receiving the wireless broadcast from the cameras, the user's phone can locally compare the ""motion address"" of the packet against its own motion sensor data, and accept the packet upon a ""good"" match.
In addition to requiring no data from users, our system transforms the motion patterns into low-dimensional codes to prevent leakage of user's walking behaviors. Thus, a hacker who collects all the broadcast messages would still not be able to infer the motion patterns of users. Real-world experiments show that PHADE discriminates 2, 4, 6, 8, 10 people with 98%, 95%, 90%, 90%, 87% correctness and about 3 seconds constant delay. Since abundant and accurate information can be extracted from videos, PHADE would find applications in various contexts. Extended to localization system and audio guide, PHADE achieves a median error of 0.19m and 99.7% matching correctness, respectively. PHADE can also deliver messages based on human gestures. There is no need to deploy any extra infrastructures or to require users to rent any dedicated device.","Volume 2 Issue 2, June 2018"
155,10.1145/3214267,"Tim Duente, Justin Schulte, Max Pfeiffer, Michael Rohs",MuscleIO: Muscle-Based Input and Output for Casual Notifications,"Receiving and reacting to notifications on mobile devices can be cumbersome. We propose MuscleIO, the use of electrical muscle stimulation (EMS) for notification output and electromyography (EMG) for reacting to notifications. Our approach provides a one-handed, eyes-free, and low-effort way of dealing with notifications. We built a prototype that interleaves muscle input and muscle output signals using the same electrodes. EMS and EMG alternate such that the EMG input signal is measured in the gaps of the EMS output signal, so voluntary muscle contraction is measured during muscle stimulation.
Notifications are represented as EMS signals and are accepted or refused either by a directional or a time-based EMG response. A lab user study with 12 participants shows that the directional EMG response is superior to the time-based response in terms of reaction time, error rate, and user preference. Furthermore, the directional approach is the fastest and the most intuitive for users compared to a button-based smartwatch interface as a baseline.","Volume 2 Issue 2, June 2018"
156,10.1145/3214268,"Xiaoran Fan, Han Ding, Sugang Li, Michael Sanzari, Yanyong Zhang, Wade Trappe, Zhu Han, Richard E. Howard",Energy-Ball: Wireless Power Transfer for Batteryless Internet of Things through Distributed Beamforming,"Wireless power transfer (WPT) promises to deliver energy to devices that are otherwise hard to charge or replace batteries for. This paper presents a new power transfer approach by aligning the phases of a collection of radio frequency (RF) energy chargers at the target receiver device. Our approach can ship energy over tens of meters and to mobile targets. More importantly, our approach leads to a highly asymmetric energy density distribution in the charging area: the energy density at the target receiver is much higher than the energy density at other locations. It is a departure from existing beamforming based WPT systems that have high energy along the energy beam path. Such a technology can enable a large array of batteryless Internet of Things applications and render them much more robust and long-running. Thanks to its asymmetric energy distribution, our approach potentially can be scaled up to ship higher level of energy over longer distances.
In this paper, we design, prototype, and evaluate the proposed energy transfer approach, referred to as Energy-Ball. We implement an Energy-Ball testbed that consists of 17 N210 and 4 B210 Universal Software Radio Peripheral (USRP) nodes, yielding a 20 x 20 m2 energy delivery area. We conduct carefully designed experiments on the testbed. We demo that the energy density of Energy-Ball at the target spot is considerably higher than the energy density elsewhere, with the peak to average power ratio of 8.72. We show that Energy-Ball can transfer energy to any point within the area. When the receiver moves at a speed of 0.5 m/s, Energy-Ball can transfer 80% of optimal power to the mobile receiver. Further, our results also show Energy-Ball can deliver over 0.6mw RF power that enables batteryless sensors at any point across the area.","Volume 2 Issue 2, June 2018"
157,10.1145/3214269,"H. M. Sajjad Hossain, MD Abdullah Al Haiz Khan, Nirmalya Roy",DeActive: Scaling Activity Recognition with Active Deep Learning,"Deep learning architectures have been applied increasingly in multi-modal problems which has empowered a large number of application domains needing much less human supervision in the process. As unlabeled data are abundant in most of the application domains, deep architectures are getting increasingly popular to extract meaningful information out of these large volume of data. One of the major caveat of these architectures is that the training phase demands both computational time and system resources much higher than shallow learning algorithms and it is posing a difficult challenge for the researchers to implement the architectures in low-power resource constrained devices. In this paper, we propose a deep and active learning enabled activity recognition model, DeActive, which is optimized according to our problem domain and reduce the resource requirements. We incorporate active learning in the process to minimize the human supervision along with the effort needed for compiling ground truth. The DeActive model has been validated using real data traces from a retirement community center (IRB #HP-00064387) and 4 public datasets. Our experimental results show that our model can contribute better accuracy while ensuring less amount of resource usages in reduced time compared to other traditional deep learning approaches in activity recognition.","Volume 2 Issue 2, June 2018"
158,10.1145/3214270,"Yiqing Hu, Yan Xiong, Wenchao Huang, Xiang-Yang Li, Panlong Yang, Yanan Zhang, Xufei Mao",Lightitude: Indoor Positioning Using Uneven Light Intensity Distribution,"In this paper, we propose an indoor positioning system, Lightitude, which utilizes the already existed, uneven indoor light intensity distribution established by densely deployed indoor lights as the medium. As common indoor lights cannot act as landmarks due to lack of unique features (e.g., unique intensity or flicker frequency), systems that exploiting the received light intensity (RLI) usually impose strong constraints on user's motion and make ideal assumptions about the indoor environment. Different from these approaches, we first propose a realistic light intensity model to reconstruct the RLI distribution given any motion (position, orientation) of the receiver, thus RLI collected with every motion of the receiver could be used for positioning. Then we design a particle-filter-based positioning module, which harnesses user's natural mobility to eliminate the ambiguity of a single RLI. Experiment results show that Lightitude achieves mean accuracy 1.93m and 1.98m in an office (720m2) and a library (960m2) respectively. Lightitude is still robust against interferences like sunlight, shading of human-body and several user behaviors.","Volume 2 Issue 2, June 2018"
159,10.1145/3214271,"Corey Brian Jackson, Yang Wang",Addressing The Privacy Paradox through Personalized Privacy Notifications,"Privacy behaviors of individuals are often inconsistent with their stated attitudes, a phenomenon known as the ""privacy paradox."" These inconsistencies may lead to troublesome or regrettable experiences. To help people address these privacy inconsistencies, we propose a personalized privacy notification approach that juxtaposes users' general privacy attitudes towards specific technologies and the potential privacy riskiness of particular instances of such technology, right when users make decisions about whether and/or how to use the technology under consideration. Highlighting the privacy inconsistencies to users was designed to nudge them in making decisions in a way that aligns with their privacy attitudes.
To illustrate this approach, we chose the domain of mobile apps and designed a privacy discrepancy interface that highlights this discrepancy between users' general privacy attitudes towards mobile apps and the potential privacy riskiness of a particular app, nudging them to make app installation and/or permission granting decisions reflecting their privacy attitudes. To evaluate this interface, we conducted an online experiment simulating the process of installing Android apps. We compared the privacy discrepancy approach with several existing privacy notification approaches. Our results suggest that the behaviors of participants who used the privacy discrepancy interface better reflected their privacy attitudes than the other approaches.","Volume 2 Issue 2, June 2018"
160,10.1145/3214272,"Simon Klakegg, Jorge Goncalves, Chu Luo, Aku Visuri, Alexey Popov, Niels van Berkel, Zhanna Sarsenbayeva, Vassilis Kostakos, Simo Hosio, Scott Savage, Alexander Bykov, Igor Meglinski, Denzil Ferreira",Assisted Medication Management in Elderly Care Using Miniaturised Near-Infrared Spectroscopy,"Near-infrared spectroscopy (NIRS) measures the light reflected from objects to infer highly detailed information about their molecular composition. Traditionally, NIRS has been an instrument reserved for laboratory usage, but recently affordable and smaller devices for NIRS have proliferated. Pairing this technology with the ubiquitous smartphone opens up a plethora of new use cases. In this paper, we explore one such use case, namely medication management in a nursing home/elderly care centre. First, we conducted a qualitative user study with nurses working in an elderly care centre to examine the protocols and workflows involved in administering medication, and the nurses' perceptions on using this technology. Based on our findings, we identify the main impact areas that would benefit from introducing miniaturised NIRS. Finally, we demonstrate via a user study in a realistic scenario that miniaturised NIRS can be effectively used for medication management when leveraging appropriate machine learning techniques. Specifically, we assess the performance of multiple pre-processing and classification algorithms for a selected set of pharmaceuticals. In addition, we compare our solution with currently used methods for pharmaceutical identification in a local care centre. We hope that our reflection on the multiple aspects associated with the introduction of this device in an elderly care setting can help both academics and practitioners working on related problems.","Volume 2 Issue 2, June 2018"
161,10.1145/3214273,"Rafal Kocielnik, Lillian Xiao, Daniel Avrahami, Gary Hsieh",Reflection Companion: A Conversational System for Engaging Users in Reflection on Physical Activity,"Mobile, wearable and other connected devices allow people to collect and explore large amounts of data about their own activities, behavior, and well-being. Yet, learning from-, and acting upon such data remain a challenge. The process of reflection has been identified as a key component of such learning. However, most tools do not explicitly design for reflection, carrying an implicit assumption that providing access to self-tracking data is sufficient. In this paper, we present Reflection Companion, a mobile conversational system that supports engaging reflection on personal sensed data, specifically physical activity data collected with fitness trackers. Reflection Companion delivers daily adaptive mini-dialogues and graphs to users' mobile phones to promote reflection. To generate our system's mini dialogues, we conducted a set of workshops with fitness trackers users, producing a diverse corpus of 275 reflection questions synthesized into a set of 25 reflection mini dialogues. In a 2-week field deployment with 33 active Fitbit users, we examined our system's ability to engage users in reflection through dialog. Results suggest that the mini-dialogues were successful in triggering reflection and that this reflection led to increased motivation, empowerment, and adoption of new behaviors. As a strong indicator of our system's value, 16 of the 33 participants elected to continue using the system for two additional weeks without compensation. We present our findings and describe implications for the design of technology-supported dialog systems for reflection on data.","Volume 2 Issue 2, June 2018"
162,10.1145/3214274,"Sumeet Kumar, Hakan Erdogmus, Bob Iannucci, Martin Griss, João Diogo Falcão",Rethinking the Future of Wireless Emergency Alerts: A Comprehensive Study of Technical and Conceptual Improvements,"The Wireless Emergency Alerting (WEA) service is a standards-based transport and presentation channel used nationwide in the United States. The service can deliver short text warnings to wireless subscribers through a cell broadcast mechanism. For emergency situations in which a broadcast modality and a single, short text message are sufficient to convey information, the WEA service can be efficient and effective. However, the content to be delivered may necessitate more than a single, unchanging short message. In this research, we first examine the WEA service from the perspective of alert originators. We then use the insights gained to explore the efficacy of a range of potential extensions to the service. The extensions mainly address the importance of user context and the ability to create awareness through careful attention to the integrity of the vital information. We evaluated these extensions using a WEA emulation testbed in two public usability trials. We present an analysis of the broad range of improvements as a basis for further research into improving the service. We conclude that (1) precise geo-targeting augmented with location information and maps is an important aspect of capturing users' context, and (2) presenting information in a digested form can markedly improve the actionability and the accuracy of interpretation.","Volume 2 Issue 2, June 2018"
163,10.1145/3214275,"Ho-Man Colman Leung, Chi-Wing Fu, Pheng-Ann Heng",TwistIn: Tangible Authentication of Smart Devices via Motion Co-analysis with a Smartwatch,"Smart devices contain sensitive information that has to be guarded against unauthorized access through authentication. Existing authentication methods become obsolete as they are designed either for logging-in one device at a time or are ineffective in a multi-user multi-device environment. This paper presents TwistIn, a simple gesture that takes a smartwatch as an authentication token for fast access and control of other smart devices. Our mechanism is particularly useful for devices such as smartphones, smart glasses, and small IoT objects. To log in a device, one simply need to pick it up and twist it a few times. Then, by co-analyzing the motion data from the device and the watch, our method can extend the user authentication on the watch to the device. This is a simple and tangible interaction that takes only one to two seconds to perform. Furthermore, to account for user variation in wrist bending, we decompose wrist and forearm rotations via an optimization to improve the method accuracy. We implemented TwistIn, collected thousands of gesture samples, and conducted various experiments to evaluate our prototype system and show that it achieved over 95% detection accuracy.","Volume 2 Issue 2, June 2018"
164,10.1145/3214276,"Callum Parker, Martin Tomitsch, Judy Kay",Does the Public Still Look at Public Displays?: A Field Observation of Public Displays in the Wild,"Public displays are widely used for displaying information in public space, such as shopping centres. They are typically programmed to display advertisements or general information about the space in which they are situated. Due to recent advances in technology, public displays are becoming ubiquitous in space around cities and can potentially enable new interactions with public space. However, despite these advances, research reports that public displays are often found to be: (1) generally irrelevant to the space in which they are situated; and (2) ignored by passers-by. Although much research has focused on tackling these issues, a gap remains regarding knowledge about how public displays in the wild are currently being used at a time when people are increasingly relying on their smartphones as a main source for accessing information and for connecting with others. The study reported in this article aims to address this gap by presenting new insights about the current practices of non-research public displays and their role in a hyperconnected society. To achieve this, we provide results from a field observation study of non-research public displays and contextualise our findings within an analysis of related work. This article makes three main contributions: (1) identifying how user engagement with public displays has changed over the past 10 years; (2) understanding how the pervasiveness of smartphones and other connected devices has modified whether users notice public displays and their interactions with public displays; and (3) outlining design recommendations and opportunities towards making public displays more relevant in a hyperconnected society.","Volume 2 Issue 2, June 2018"
165,10.1145/3214277,"Liangying Peng, Ling Chen, Zhenan Ye, Yi Zhang",AROMA: A Deep Multi-Task Learning Based Simple and Complex Human Activity Recognition Method Using Wearable Sensors,"Human activity recognition (HAR) is a promising research issue in ubiquitous and wearable computing. However, there are some problems existing in traditional methods: 1) They treat HAR as a single label classification task, and ignore the information from other related tasks, which is helpful for the original task. 2) They need to predesign features artificially, which are heuristic and not tightly related to HAR task. To address these problems, we propose AROMA (human activity recognition using deep multi-task learning). Human activities can be divided into simple and complex activities. They are closely linked. Simple and complex activity recognitions are two related tasks in AROMA. For simple activity recognition task, AROMA utilizes a convolutional neural network (CNN) to extract deep features, which are task dependent and non-handcrafted. For complex activity recognition task, AROMA applies a long short-term memory (LSTM) network to learn the temporal context of activity data. In addition, there is a shared structure between the two tasks, and the object functions of these two tasks are optimized jointly. We evaluate AROMA on two public datasets, and the experimental results show that AROMA is able to yield a competitive performance in both simple and complex activity recognitions.","Volume 2 Issue 2, June 2018"
166,10.1145/3214278,"Swadhin Pradhan, Ghufran Baig, Wenguang Mao, Lili Qiu, Guohai Chen, Bo Yang",Smartphone-based Acoustic Indoor Space Mapping,"Constructing a map of indoor space has many important applications, such as indoor navigation, VR/AR, construction, safety, facility management, and network condition prediction. Existing indoor space mapping requires special hardware (e.g., indoor LiDAR equipment) and well-trained operators. In this paper, we develop a smartphone-based indoor space mapping system that lets a regular user quickly map an indoor space by simply walking around while holding a phone in his/her hand. Our system accurately measures the distance to nearby reflectors, estimates the user's trajectory, and pairs different reflectors the user encounters during the walk to automatically construct the contour. Using extensive evaluation, we show our contour construction is accurate: the median errors are 1.5 cm for a single wall and 6 cm for multiple walls (due to longer trajectory and the higher number of walls). We show that our system provides a median error of 30 cm and a 90-percentile error of 1 m, which is significantly better than the state-of-the-art smartphone acoustic mapping system BatMapper [64], whose corresponding errors are 60 cm and 2.5 m respectively, even after multiple walks. We further show that the constructed indoor contour can be used to predict wireless received signal strength (RSS).","Volume 2 Issue 2, June 2018"
167,10.1145/3214279,"Saumay Pushp, Yunxin Liu, Mengwei Xu, Changyoung Koh, Junehwa Song",PrivacyShield: A Mobile System for Supporting Subtle Just-in-time Privacy Provisioning through Off-Screen-based Touch Gestures,"Current in-situ privacy solution approaches are inadequate in protecting sensitive information. They either require extra configuration effort or lack the ability to configure user desired privacy settings. Based on in-depth discussions during a design workshop, we propose PrivacyShield, a mobile system for providing subtle just-in-time privacy provisioning. PrivacyShield leverages the screen I/O device (screen digitizer) of smartphones to recognize gesture commands, even when the phone's screen is turned off. Based on gesture command inputs, various privacy-protection policies can be configured on-the-fly. We develop a novel stroke-based approach to address the challenges in segmenting and recognizing gesture command inputs, which helps the system in achieving good usability and performance. PrivacyShield also provides developers with APIs to enable just-in-time privacy provisioning in their applications. We have implemented an energy efficient PrivacyShield prototype on the Android platform, including smartphones with and without a low-power co-processor. Evaluation results show that our gesture segmentation algorithm is fast enough for real-time performance (introducing less than 200ms processing latency) and accurate (achieving an accuracy of 95% for single-character gestures and 89% for even three-character gestures). We also build a non-touch-screen-based just-in-time privacy provisioning prototype called the wrist gesture method. We compare the performance of the two prototypes by doing a 6-week field study with 12 participants and show why a simplistic solution falls short in providing privacy configurations. We also report the participants' perceptions and reactions after the field study.","Volume 2 Issue 2, June 2018"
168,10.1145/3214280,"Jing Qian, Arielle Chapin, Alexandra Papoutsaki, Fumeng Yang, Klaas Nelissen, Jeff Huang",Remotion: A Motion-Based Capture and Replay Platform of Mobile Device Interaction for Remote Usability Testing,"Remotion is an end-to-end system for capturing and replaying rich mobile device interactions, comprising both on-screen video and physical device motions. The blueprints and software provided here allow an interface to be instrumented with Remotion's capture and visualization system. Remotion is able to mimic mobile device motion through a software 3D graphical visualization and a robotic mount that replicates the movements of a mobile device from afar. Deployed together, experimenters can emulate the mobile device postures of a remote user as if they were in the room. This is important since many usability studies are carried remotely and the contribution and scale of those studies are irreplaceable. We compared how HCI experts (""analysts"") observed remote users behavioral data across three replay platforms: a traditional live time-series of motion, Remotion's software visualization, and Remotion's hardware visualization. We found that Remotion can assist analysts to infer the user's attention, emotional state, habits, and active hand posture; Remotion also has a reduced effect on mental demand for analysts when analyzing the remote user's contextual information.","Volume 2 Issue 2, June 2018"
169,10.1145/3214281,"Fazlay Rabbi, Taiwoo Park, Biyi Fang, Mi Zhang, Youngki Lee",When Virtual Reality Meets Internet of Things in the Gym: Enabling Immersive Interactive Machine Exercises,"With the advent of immersive virtual reality (VR) head-mounted displays (HMD), we envision that immersive VR will revolutionize the personal fitness experience in our daily lives. Toward this vision, we present JARVIS, a virtual exercise assistant that is able to provide an immersive and interactive gym exercise experience to a user. JARVIS is enabled by the synergy between Internet of Things (IoT) and immersive VR. JARVIS employs miniature IoT sensing devices removably attachable to exercise machines to track a multitude of exercise information including exercise types, repetition counts, and progress within each repetition in real time. Based on the tracked exercise information, JARVIS shows the user the proper way of doing the exercise in the virtual exercise environment, thereby helping the user to better focus on the target muscle group. We have conducted both in-lab experiments and a pilot user study to evaluate the performance and effectiveness of JARVIS, respectively. Our in-lab experiments with fifteen participants show that JARVIS is able to segment exercise repetitions with an average accuracy of 97.96% and recognize exercise types with an average accuracy of 99.08%. Our pilot user study with ten participants shows statistically significant improvements in perceived enjoyment, competence, and usefulness with JARVIS compared to a traditional machine exercise setting (p &lt; 0.05). Finally, our surface electromyography (sEMG) signal analysis conducted during the pilot user study shows statistically significant improvement in terms of muscle activation (p &lt; 0.01), indicating the potential of JARVIS in providing an engaging and effective guidance for machine exercises.","Volume 2 Issue 2, June 2018"
170,10.1145/3214282,"Vaishnavi Ranganathan, Sidhant Gupta, Jonathan Lester, Joshua R. Smith, Desney Tan",RF Bandaid: A Fully-Analog and Passive Wireless Interface for Wearable Sensors,"This paper presents a passive wireless RF sensor platform (RFSP), with only analog components, that harvests energy from an RF source and reflects data as a direct subcarrier modulation, thus making it battery free. A fully-analog architecture results in an ultra-low power device (under 200 μW) with a low component count, reducing the physical footprint. We envision such a platform to enable medical sensing systems that fit on a small bandaid like flexible structure, require no-battery, or charging and are able to provide continuous physiological monitoring. To realize this vision, we have developed and optimized a novel RF architecture that 1) directly maps sensor output to frequency modulation and transmits it to a remote receiver processing unit (RPU). This direct frequency mapping allows all further digitization and computation to be moved to the RPU -- reducing power and size requirements on the RFSP; 2) harvests energy from the carrier signal transmitted by a simple continuous wave transmitter, thereby requiring no batteries or supercap; and 3) uses backscatter to communicate with the RPU enabling ultra-low power requirements. The total power consumption of our prototype device leveraging this architecture was measured to be between 35 μW and 160 μW. We demonstrate that the RFSP can harvest sufficient power, sense, and communicate continuously without necessity for energy storage at a distance of 4 m from a transmitter emitting a 915 MHz continuous wave at 26 dBm (0.39 W). Prior backscatter systems typically have power budgets of 1 mW and require energy storage (battery or supercap), RFSP's sub 200 μW power consumption provides a significant improvement and longer range for a given TX power. To demonstrate applicability to real-world health sensing and the flexibility to adapt to different sensors, this paper presents results from breathing, heart rate, temperature, and sound sensing applications.","Volume 2 Issue 2, June 2018"
171,10.1145/3214283,"Carlos Ruiz, Shijia Pan, Adeola Bannis, Xinlei Chen, Carlee Joe-Wong, Hae Young Noh, Pei Zhang",IDrone: Robust Drone Identification through Motion Actuation Feedback,"Swarms of Unmanned Aerial Vehicles (drones) could provide great benefit when used for disaster response and indoor search and rescue scenarios. In these harsh environments where GPS availability cannot be ensured, prior work often relies on cameras for control and localization. This creates the challenge of identifying each drone, i.e., finding the association between each physical ID (such as their radio address) and their visual ID (such as an object tracker output). To address this problem, prior work relies on visual cues such as LEDs or colored markers to provide unique information for identification. However, these methods often increase deployment difficulty, are sensitive to environmental changes, not robust to distance and might require hardware changes.
In this paper, we present IDrone, a robust physical drone identification system through motion matching and actuation feedback. The intuition is to (1) identify each drone by matching the motion detected through their inertial sensors and from an external camera, and (2) control the drones so they move in unique patterns that allow for fast identification, while minimizing the risk of collision involved in controlling drones with uncertain identification. To validate our approach, we conduct both simulation and real experimentation with autonomous drones for the simplified case of a stationary Spotter (powerful drone equipped with the camera). Overall, our initial results show that our approach offers a great tradeoff between fast identification and small collision probability. In particular, IDrone achieves faster identification time than safety-based baseline actuation (one-at-a-time), and significantly higher survival rate compared to fast, non-safety-based baseline actuation (random motion).","Volume 2 Issue 2, June 2018"
172,10.1145/3214284,"Asif Salekin, Jeremy W. Eberle, Jeffrey J. Glenn, Bethany A. Teachman, John A. Stankovic",A Weakly Supervised Learning Framework for Detecting Social Anxiety and Depression,"Although social anxiety and depression are common, they are often underdiagnosed and undertreated, in part due to difficulties identifying and accessing individuals in need of services. Current assessments rely on client self-report and clinician judgment, which are vulnerable to social desirability and other subjective biases. Identifying objective, nonburdensome markers of these mental health problems, such as features of speech, could help advance assessment, prevention, and treatment approaches. Prior research examining speech detection methods has focused on fully supervised learning approaches employing strongly labeled data. However, strong labeling of individuals high in symptoms or state affect in speech audio data is impractical, in part because it is not possible to identify with high confidence which regions of a long speech indicate the person's symptoms or affective state. We propose a weakly supervised learning framework for detecting social anxiety and depression from long audio clips. Specifically, we present a novel feature modeling technique named NN2Vec that identifies and exploits the inherent relationship between speakers' vocal states and symptoms/affective states. Detecting speakers high in social anxiety or depression symptoms using NN2Vec features achieves F-1 scores 17% and 13% higher than those of the best available baselines. In addition, we present a new multiple instance learning adaptation of a BLSTM classifier, named BLSTM-MIL. Our novel framework of using NN2Vec features with the BLSTM-MIL classifier achieves F-1 scores of 90.1% and 85.44% in detecting speakers high in social anxiety and depression symptoms.","Volume 2 Issue 2, June 2018"
173,10.1145/3214285,"Zhanna Sarsenbayeva, Niels van Berkel, Eduardo Velloso, Vassilis Kostakos, Jorge Goncalves",Effect of Distinct Ambient Noise Types on Mobile Interaction,"The adverse effect of ambient noise on humans has been extensively studied in fields like cognitive science, indicating a significant impact on cognitive performance, behaviour, and emotional state. Surprisingly, the effect of ambient noise has not been studied in the context of mobile interaction. As smartphones are ubiquitous by design, smartphone users are exposed to a wide variety of ambient noises while interacting with their devices. In this paper, we present a structured analysis of the effect of six distinct ambient noise types on typical smartphone usage tasks. The evaluated ambient noise types include variants of music, urban noise and speech. We analyse task completion time and errors, and find that different ambient noises affect users differently. For example, while speech and urban noise slow down text entry, being exposed to music reduces completion time in target acquisition tasks. Our study contributes to the growing research area on situational impairments, and we compare our results to previous work on the effect of cold-induced situational impairments. Our results can be used to support smartphone users through adaptive interfaces which respond to the ongoing context of the user.","Volume 2 Issue 2, June 2018"
174,10.1145/3214286,"Chen Song, Zhengxiong Li, Wenyao Xu, Chi Zhou, Zhanpeng Jin, Kui Ren",My Smartphone Recognizes Genuine QR Codes!: Practical Unclonable QR Code via 3D Printing,"Additive manufacturing, or 3D printing, has been widely applied in product manufacturing. However, the emerging unauthorized access of 3D printing data, as well as the growth in the pervasiveness and capability of 3D printing devices have raised serious concerns about 3D printing product anti-counterfeit. Electronic product tags are the current standard for authentication purposes; however, often this technology is neither secure nor cost-effective, and fails to take advantage of other unique 3D printing features. Considering the great usability of the QR code, we are motivated to enhance the QR code for the practical and cost-effective 3D printing product identification. Particularly, we bring up the all-in-one design, all-in-one manufacturing concept incorporating the QR code in the complete 3D printing paradigm. In detail, we explore the possibility of leveraging the random and uncontrollable process variations in the 3D printing system to generate a unique fingerprint for the integrated QR code. To this end, we present an end-to-end 3D-printed QR code verification framework, which does not change the original QR protocol and functionality. The entire solution can be implemented with commodity 3D printers and smartphones. Specifically, we first investigate the inevitable and random process variations in the 3D printing mechanism and analyze the causality between the variations and detectable geometric deformation. We further develop a fingerprint extraction algorithm taking into account both the QR code property and the 3D printer characteristics. The system evaluation indicates that our solution is secure and robust in multiple scenarios.","Volume 2 Issue 2, June 2018"
175,10.1145/3214287,"Deepak Vasisht, Anubhav Jain, Chen-Yu Hsu, Zachary Kabelac, Dina Katabi",Duet: Estimating User Position and Identity in Smart Homes Using Intermittent and Incomplete RF-Data,"Although past work on RF-based indoor localization has delivered important advances, it typically makes assumptions that hinder its adoption in smart home applications. Most localization systems assume that users carry their phones on them at home, an assumption that has been proven highly inaccurate in past measurements. The few localization systems that do not require the user to carry a device on her, cannot tell the identity of the person; yet identification is essential to most smart home applications. This paper focuses on addressing these issues so that smart homes can benefit from recent advances in indoor localization.
We introduce Duet, a multi-modal system that takes as input measurements from both device-based and device-free localization. Duet introduces a new framework that combines probabilistic inference with first order logic to reason about the users' most likely locations and identities in light of the measurements. We implement Duet and compare it with a baseline that uses state-of-art WiFi-based localization. The results of two weeks of monitoring in two smart environments show that Duet accurately localizes and identifies the users for 94% and 96% of the time in the two places. In contrast, the baseline is accurate 17% and 42% respectively.","Volume 2 Issue 2, June 2018"
176,10.1145/3214288,"Chuyu Wang, Lei Xie, Wei Wang, Yingying Chen, Yanling Bu, Sanglu Lu",RF-ECG: Heart Rate Variability Assessment Based on COTS RFID Tag Array,"As an important indicator of autonomic regulation for circulatory function, Heart Rate Variability (HRV) is widely used for general health evaluation. Apart from using dedicated devices (e.g, ECG) in a wired manner, current methods search for a ubiquitous manner by either using wearable devices, which suffer from low accuracy and limited battery life, or applying wireless techniques (e.g., FMCW), which usually utilize dedicated devices (e.g., USRP) for the measurement. To address these issues, we present RF-ECG based on Commercial-Off-The-Shelf (COTS) RFID, a wireless approach to sense the human heartbeat through an RFID tag array attached on the chest area in the clothes. In particular, as the RFID reader continuously interrogates the tag array, two main effects are captured by the tag array: the reflection effect representing the RF-signal reflected from the heart movement due to heartbeat; the moving effect representing the tag movement caused by chest movement due to respiration. To extract the reflection signal from the noisy RF-signals, we develop a mechanism to capture the RF-signal variation of the tag array caused by the moving effect, aiming to eliminate the signals related to respiration. To estimate the HRV from the reflection signal, we propose a signal reflection model to depict the relationship between the RF-signal variation from the tag array and the reflection effect associated with the heartbeat. A fusing technique is developed to combine multiple reflection signals from the tag array for accurate estimation of HRV. Experiments with 15 volunteers show that RF-ECG can achieve a median error of 3% of Inter-Beat Interval (IBI), which is comparable to existing wired techniques.","Volume 2 Issue 2, June 2018"
177,10.1145/3214289,"Shichao Yue, Hao He, Hao Wang, Hariharan Rahul, Dina Katabi",Extracting Multi-Person Respiration from Entangled RF Signals,"Recent advances in wireless systems have demonstrated the possibility of tracking a person's respiration using the RF signals that bounce off her body. The resulting breathing signal can be used to infer the person's sleep quality and stages; it also allows for monitoring sleep apnea and other sleep disordered breathing (SDB); all without any body contact. Unfortunately however past work fails when people are close to each other, e.g., a couple sharing the same bed. In this case, the breathing signals of nearby individuals interfere with each other and super-impose in the received signal.
This paper presents DeepBreath, the first RF-based respiration monitoring system that can recover the breathing signals of multiple individuals even when they are separated by zero distance. To design DeepBreath, we model interference due to multiple reflected RF signals and demonstrate that the original breathing can be recovered via independent component analysis (ICA). We design a full system that eliminates interference and recovers the original breathing signals. We empirically evaluate DeepBreath using 21 nights of sleep and over 150 hours of data from 13 couples who share the bed. Our results show that DeepBreath is very accurate. Specifically, the differences between the breathing signals it recovers and the ground truth are on par with the difference between the same breathing signal measured at the person's chest and belly.","Volume 2 Issue 2, June 2018"
178,10.1145/3214290,"Xiao Zhang, Yongqiang Lyu, Xiaomin Luo, Jingyu Zhang, Chun Yu, Hao Yin, Yuanchun Shi",Touch Sense: Touch Screen Based Mental Stress Sense,"Non-intrusive and sensitive measurement of users' stress is very crucial for computers to dynamically understand and respond to users' mental status while users are naturally interacting with them, such as context-aware reminding, smart assistant, health monitoring etc. Compared to others, physiological measures are known as more sensitive and reliable ones. However, most of the current physiological methods need explicit and obtrusive sensors that deter natural human-computer interactions. In this study, we propose a photoplethysmogram-based mental stress measuring method through infrared touchscreen, which, from the best of our knowledge, is the first to integrate with the touch modality to enable natural, sensitive and reliable measurement. We designed and conducted two user experiments with touch-and-hold mode and tap mode respectively. By using person-independent classifiers to handle the photoplethysmographic parameters, the results reached a 97% and 87% average stress recognition accuracy for static test and interaction test respectively.","Volume 2 Issue 2, June 2018"
179,10.1145/3214291,"Yun C. Zhang, James M. Rehg",Watching the TV Watchers,"Studies have linked excessive TV watching to obesity in adults and children. In addition, TV content represents an important source of visual exposure to cues which can effect a broad set of health-related behaviors. This paper presents a ubiquitous sensing system which can detect moments of screen-watching during daily life activities. We utilize machine learning techniques to analyze video captured by a head-mounted wearable camera. Although wearable cameras do not directly provide a measure of visual attention, we show that attention to screens can be reliably inferred by detecting and tracking the location of screens within the camera's field-of-view. We utilize a computational model of the head movements associated with TV watching to identify TV watching events. We have evaluated our method on 13 hours of TV watching videos recorded from 16 participants in a home environment. Our model achieves a precision of 0.917 and a recall of 0.945 in identifying attention to screens. We validated the third-person annotations used to determine accuracy and further evaluated our system in a multi-device environment using gold standard attention measurements obtained from a wearable eye-tracker. Finally, we tested our system in a natural environment. Our system achieves a precision of 0.87 and a recall of 0.82 on challenging videos capturing the daily life activities of participants.","Volume 2 Issue 2, June 2018"
180,10.1145/3191733,"Mohamed Abdelaal, Daniel Reichelt, Frank Dürr, Kurt Rothermel, Lavinia Runceanu, Susanne Becker, Dieter Fritsch",ComNSense: Grammar-Driven Crowd-Sourcing of Point Clouds for Automatic Indoor Mapping,"Recently, point clouds have been efficiently utilized for medical imaging, modeling urban environments, and indoor modeling. In this realm, several mobile platforms, such as Google Tango and Apple ARKit, have been released leveraging 3D mapping, augmented reality, etc. In modeling applications, these modern mobile devices opened the door for crowd-sourcing point clouds to distribute the overhead of data collection. However, uploading these large points clouds from resources-constrained mobile devices to the back-end servers consumes excessive energy. Accordingly, participation rates in such crowd-sensing systems can be negatively influenced. To tackle this challenge, this paper introduces our ComNSense approach that dramatically reduces the energy consumption of processing and uploading point clouds. To this end, ComNSense reports only a set of extracted geometrical data to the servers. To optimize the geometry extraction, ComNSense leverages formal grammars which encode design-time knowledge, i.e. structural information. To demonstrate the effectiveness of ComNSense, we performed several experiments of collecting point clouds from two different buildings to extract the walls location, as a case study. We also assess the performance of ComNSense relative to a grammar-free method. The results showed a significant reduction of the energy consumption while achieving a comparable detection accuracy.","Volume 2 Issue 1, March 2018"
181,10.1145/3191734,"Rummana Bari, Roy J. Adams, Md. Mahbubur Rahman, Megan Battles Parsons, Eugene H. Buder, Santosh Kumar",rConverse: Moment by Moment Conversation Detection Using a Mobile Respiration Sensor,"Monitoring of in-person conversations has largely been done using acoustic sensors. In this paper, we propose a new method to detect moment-by-moment conversation episodes by analyzing breathing patterns captured by a mobile respiration sensor. Since breathing is affected by physical and cognitive activities, we develop a comprehensive method for cleaning, screening, and analyzing noisy respiration data captured in the field environment at individual breath cycle level. Using training data collected from a speech dynamics lab study with 12 participants, we show that our algorithm can identify each respiration cycle with 96.34% accuracy even in presence of walking. We present a Conditional Random Field, Context-Free Grammar (CRF-CFG) based conversation model, called rConverse, to classify respiration cycles into speech or non-speech, and subsequently infer conversation episodes. Our model achieves 82.7% accuracy for speech/non-speech classification and it identifies conversation episodes with 95.9% accuracy on lab data using a leave-one-subject-out cross-validation. Finally, the system is validated against audio ground-truth in a field study with 32 participants. rConverse identifies conversation episodes with 71.7% accuracy on 254 hours of field data. For comparison, the accuracy from a high-quality audio-recorder on the same data is 71.9%.","Volume 2 Issue 1, March 2018"
182,10.1145/3191735,"Larry Chan, Vedant Das Swain, Christina Kelley, Kaya de Barbaro, Gregory D. Abowd, Lauren Wilcox",Students' Experiences with Ecological Momentary Assessment Tools to Report on Emotional Well-being,"Ecological Momentary Assessment (EMA) methods have emerged as an approach that enhances the ecological validity of data collected for the study of human behavior and experience. In particular, EMA methods are used to capture individuals' experiences (e.g., symptoms, affect, and behaviors) in real-world contexts and in near-real time. However, work investigating participants' experiences in EMA studies and in particular, how these experiences may influence the collected data, is limited. We conducted in-depth focus groups with 32 participants following an EMA study on mental well-being in college students. In doing so, we probed how the elicitation of high-quality, reflective responses is related to the design of EMA interactions. Through our study, we distilled three primary considerations for designing EMA interactions, based on observations of 1) response strategies to repeated questions, 2) the perceived burden of EMA prompts, and 3) challenges to the validity and robustness of EMA data. We present these considerations in the context of two microinteraction-based EMA approaches that we tested: lock-screen EMA and image-based question prompts. We conclude by characterizing design tensions in the presentation and delivery of EMA prompts, and outline directions for future work to address these tensions.","Volume 2 Issue 1, March 2018"
183,10.1145/3191736,"Keum San Chun, Sarnab Bhattacharya, Edison Thomaz",Detecting Eating Episodes by Tracking Jawbone Movements with a Non-Contact Wearable Sensor,"Eating is one of the most fundamental human activities, and because of the important role it plays in our lives, it has been extensively studied. However, an objective and usable method for dietary intake tracking remains unrealized despite numerous efforts by researchers over the last decade. In this work, we present a new wearable computing approach for detecting eating episodes. Using a novel multimodal sensing strategy combining accelerometer and range sensing, the approach centers on a discreet and lightweight instrumented necklace that captures head and jawbone movements without direct contact with the skin. An evaluation of the system with 32 participants comprised of three phases resulted in eating episodes detected with 95.2% precision and 81.9% recall in controlled studies and 78.2% precision and 72.5% recall in the free-living study. This research add technical contributions to the fields of wearable computing, human activity recognition, and mobile health.","Volume 2 Issue 1, March 2018"
184,10.1145/3191737,"Jiska Classen, Daniel Wegemer, Paul Patras, Tom Spink, Matthias Hollick","Anatomy of a Vulnerable Fitness Tracking System: Dissecting the Fitbit Cloud, App, and Firmware","Fitbit fitness trackers record sensitive personal information, including daily step counts, heart rate profiles, and locations visited. By design, these devices gather and upload activity data to a cloud service, which provides aggregate statistics to mobile app users. The same principles govern numerous other Internet-of-Things (IoT) services that target different applications. As a market leader, Fitbit has developed perhaps the most secure wearables architecture that guards communication with end-to-end encryption. In this article, we analyze the complete Fitbit ecosystem and, despite the brand's continuous efforts to harden its products, we demonstrate a series of vulnerabilities with potentially severe implications to user privacy and device security. We employ a range of techniques, such as protocol analysis, software decompiling, and both static and dynamic embedded code analysis, to reverse engineer previously undocumented communication semantics, the official smartphone app, and the tracker firmware. Through this interplay and in-depth analysis, we reveal how attackers can exploit the Fitbit protocol to extract private information from victims without leaving a trace, and wirelessly flash malware without user consent. We demonstrate that users can tamper with both the app and firmware to selfishly manipulate records or circumvent Fitbit's walled garden business model, making the case for an independent, user-controlled, and more secure ecosystem. Finally, based on the insights gained, we make specific design recommendations that can not only mitigate the identified vulnerabilities, but are also broadly applicable to securing future wearable system architectures.","Volume 2 Issue 1, March 2018"
185,10.1145/3191738,"Andrew Clayphan, Anthony Collins, Judy Kay, Nathan Slawitschka, Jenny Horder",Comparing a Single-Touch Whiteboard and a Multi-Touch Tabletop for Collaboration in School Museum Visits,"This paper explores two important classes of large screen displays, single-touch whiteboards and multi-touch tabletops, for the context of collaborative learning by school groups at a museum. To do this, we designed MuseWork, as a worksheet activity, with two phases: first, students explore the museum, individually or in pairs, guided by our tablet worksheet app; then, in groups, they collaborate to create a poster at a large-screen display, using our device-customised MuseWork interfaces. Our goal was to gain insights about the implications for engagement and collaboration when groups use these devices; single-touch whiteboards are important as they are widely available in classrooms and multi-touch tabletops are an emerging technology. Our research questions asked: 1) whether MuseWork enabled groups to complete the collaborative task at both devices and 2) how the whiteboard and tabletop each affect key aspects of collaboration. We report a between-subjects study of 67 students, aged 10--14 years, from 2 schools, in 12 groups. Our results, based on qualitative and quantitative data, indicate the MuseWork interface for each device proved effective, with groups completing the activity and satisfied with the result and the experience (RQ1). Comparisons of groups using each device (RQ2) give new insights in terms of the products of the collaborative activity, and the strategies groups spontaneously developed for group co-ordination and device use. Our contributions are insights from the first in-the-field study of children collaborating at single-touch interactive whiteboards and multi-touch tabletops.","Volume 2 Issue 1, March 2018"
186,10.1145/3191739,"Xiaoyi Fan, Wei Gong, Jiangchuan Liu",TagFree Activity Identification with RFIDs,"Human activity identification plays a critical role in many Internet-of-Things applications, which is typically achieved through attaching tracking devices, e.g., RFID tags, to human bodies. The attachment can be inconvenient and considered intrusive. A tag-free solution instead deploys stationary tags as references, and analyzes the backscattered signals that could be affected by human activities in close proximity. The information offered by today's RFID tags however are quite limited, and the typical raw data (RSSI and phase angles) are not necessarily good indicators of human activities (being either insensitive or unreliable as revealed by our realworld experiments). As such, existing tag-based activity identification solutions are far from being satisfactory, not to mention tag-free. It is also well known that the accuracy of the readings can be noticeably affected by multipath, which unfortunately is inevitable in an indoor environment and is complicated with multiple reference tags.
In this paper, we however argue that multipath indeed brings rich information that can be explored to identify fine-grained human activities. Our experiments suggest that both the backscattered signal power and angle are correlated with human activities, impacting multiple paths with different levels. We present TagFree, the first RFID-based device-free activity identification system by analyzing the multipath signals. Different from conventional solutions that directly rely on the unreliable raw data, TagFree gathers massive angle information as spectrum frames from multiple tags, and preprocesses them to extract key features. It then analyzes their patterns through a deep learning framework. Our TagFree is readily deployable using off-the-shelf RFID devices and a prototype has been implemented using a commercial Impinj reader. Our extensive experiments demonstrate the superiority of our TagFree on activity identification in multipath-rich environments.","Volume 2 Issue 1, March 2018"
187,10.1145/3191740,"Benjamin Finley, Tapio Soikkeli",Mobile Device Type Substitution,"Mobile users today interact with a variety of mobile device types including smartphones, tablets, smartwatches, and others. However research on mobile device type substitution has been limited in several respects including a lack of detailed and robust analyses. Therefore, in this work we study mobile device type substitution through analysis of multidevice usage data from a large US-based user panel. Specifically, we use regression analysis over paired user groups to test five device type substitution hypotheses. We find that both tablets and PCs are partial substitutes for smartphones with tablet and PC ownership decreasing smartphone usage by about 12.5 and 13 hours/month respectively. Additionally, we find that tablets and PCs also prompt about 20 and 57 hours/month respectively of additional (non-substituted) usage. We also illustrate significant inter-user diversity in substituted and additional usage. Overall, our results can help in understanding the relative positioning of different mobile device types and in parameterizing higher level mobile ecosystem models.","Volume 2 Issue 1, March 2018"
188,10.1145/3191741,"Cole Gleason, Dragan Ahmetovic, Saiph Savage, Carlos Toxtli, Carl Posthuma, Chieko Asakawa, Kris M. Kitani, Jeffrey P. Bigham",Crowdsourcing the Installation and Maintenance of Indoor Localization Infrastructure to Support Blind Navigation,"Indoor navigation systems can make unfamiliar buildings more accessible for people with vision impairments, but their adoption is hampered by the effort of installing infrastructure and maintaining it over time. Most solutions in this space require augmenting the environment with add-ons, such as Bluetooth beacons. Installing and calibrating such infrastructure requires time and expertise. Once installed, localization accuracy often degrades over time as batteries die, beacons go missing, or otherwise stop working. Even localization systems installed by experts can become unreliable weeks, months, or years after the installation. To address this problem, we created LuzDeploy: a physical crowdsourcing system that organizes non-experts for the installation and long-term maintenance of a Bluetooth-based navigation system. LuzDeploy simplifies the tasks required to install and maintain the localization infrastructure, thus making a crowdsourcing approach feasible for non-experts. We report on a field deployment where 127 participants installed and maintained a blind navigation system over several months in a 7-story building, completing 455 tasks in total. We compare the accuracy of the system installed by participants to an installation completed by experts with specialized equipment. LuzDeploy aims to improve the sustainability of indoor navigation systems to encourage widespread adoption outside of research settings.","Volume 2 Issue 1, March 2018"
189,10.1145/3191742,"Wei Gong, Jiangchuan Liu",SiFi: Pushing the Limit of Time-Based WiFi Localization Using a Single Commodity Access Point,"There has been a booming interest in developing WiFi localization using multi-antenna (MIMO) access points (APs). Recent advances have demonstrated promising results that break the meter-accuracy barrier using commodity APs. Yet these state-of-the-art solutions require either multiple APs that are not necessarily available in practice, or multiple-channel measurements that disrupt normal data communication. In this paper, we present SiFi, a single AP-based indoor localization system that for the first time achieves sub-meter accuracy with a single channel only. The SiFi design is based on a key observation: with MIMO, the multiple (typically three) antennas of an AP are frequency-locked; although the accurate Time-of-Arrival (ToA) estimation on commodity APs is fundamentally limited by the imperfect time and frequency synchronization between the transmitter and receiver, there should be only one value for the ToA distortion that can cause three direct-path ToAs of the antennas to intersect at a single point, i.e., the position of the target. We develop the theoretical foundations of SiFi and demonstrate its realworld implementation with off-the-shelf WiFi cards. Our implementation introduces no hardware modification and is fully compatible with concurrent data transmission. It achieves a median accuracy of 0.93 m, which significantly outperforms the best known single AP single channel solution.","Volume 2 Issue 1, March 2018"
190,10.1145/3191743,"Andreas Grammenos, Cecilia Mascolo, Jon Crowcroft","You Are Sensing, but Are You Biased?: A User Unaided Sensor Calibration Approach for Mobile Sensing","Mobile devices are becoming pervasive to our daily lives: they follow us everywhere and we use them for much more than just communication. These devices are also equipped with a myriad of different sensors that have the potential to allow the tracking of human activities, user patterns, location, direction and much more. Following this direction, many movements including sports, quantified self, and mobile health ones are starting to heavily rely on this technology, making it pivotal that the sensors offer high accuracy.
However, heterogeneity in hardware manufacturing, slight substrate differences, electronic interference as well as external disturbances are just few of the reasons that limit sensor output accuracy which in turn hinders sensor usage in applications which need very high granularity and precision, such as quantified-self applications. Although, calibration of sensors is a widely studied topic in literature to the best of our knowledge no publicly available research exists that specifically tackles the calibration of mobile phones and existing methods that can be adapted for use in mobile devices not only require user interaction but they are also not adaptive to changes. Additionally, alternative approaches for performing more granular and accurate sensing exploit body-wide sensor networks using mobile phones and additional sensors; as one can imagine these techniques can be bulky, tedious, and not particularly user friendly. Moreover, existing techniques for performing data corrections post-acquisition can produce inconsistent results as they miss important context information provided from the device itself; which when used, has been shown to produce better results without a imposing a significant power-penalty.
In this paper we introduce a novel multiposition calibration scheme that is specifically targeted at mobile devices Our scheme exploits machine learning techniques to perform an adaptive, power-efficient auto-calibration procedure with which achieves high output sensor accuracy when compared to state of the art techniques without requiring any user interaction or special equipment beyond device itself Moreover, the energy costs associated with our approach are lower than the alternatives (such as Kalman filter based solutions) and the overall power penalty is &lt; 5% when compared against power usage that is exhibited when using uncalibrated traces, thus, enabling our technique to be used efficiently on a wide variety of devices Finally, our evaluation illustrates that calibrated signals offer a tangible benefit in classification accuracy, ranging from 3 to 10%, over uncalibrated ones when using state of the art classifiers, on the other hand when using simpler SVM classifiers the classification improvement is boosted ranging from 8% to 12% making lower performing classifiers much more reliable Additionally, we show that for similar activities which are hard to distinguish otherwise, we reach an accuracy of &gt; 95% when using neural network classifiers and &gt; 88% when using SVM classifiers where uncalibrated data classification only reaches ~ 85% and ~ 80% respectively This can be a make or break factor in the use of accelerometer and gyroscope data in applications requiring high accuracy e g sports, health, games and others","Volume 2 Issue 1, March 2018"
191,10.1145/3191744,"Chenyu Huang, Huangxun Chen, Lin Yang, Qian Zhang",BreathLive: Liveness Detection for Heart Sound Authentication with Deep Breathing,"Nowadays, considerable number of devices have been proposed to monitor cardiovascular health. To protect medical data on these devices from unauthorized access, researchers have proposed ECG-based and heart sound-based authentication methods. However, their vulnerabilities to replay attacks have recently been revealed. In this paper, we leverage liveness detection to enhance heart sound-based authentication against replay attacks. We utilize the inherent correlation between sounds and chest motion caused by deep breathing to realize a reliable liveness detection system, BreathLive. To be specific, BreathLive captures breathing sounds and chest motion simultaneously, and then eliminates signal delay caused by any imperfections of device components. Next, it extracts a set of features to characterize the correlation between sounds and motion signals, and uses them to train the classifier. We implement and evaluated BreathLive under different attacking scenarios and contexts. The results show that BreathLive achieves an equal error rate of 4.0%, 6.4% and 8.3% for random impersonation attacks, advanced impersonation attacks and advanced replay attacks respectively, which indicates its effectiveness in defending against different attacks. Also the extensive experiments prove the system can be robust to different contexts with a small training set.","Volume 2 Issue 1, March 2018"
192,10.1145/3191745,"Sinh Huynh, Seungmin Kim, JeongGil Ko, Rajesh Krishna Balan, Youngki Lee",EngageMon: Multi-Modal Engagement Sensing for Mobile Games,"Understanding the engagement levels players have with a game is a useful proxy for evaluating the game design and user experience. This is particularly important for mobile games as an alternative game is always just an easy download away. However, engagement is a subjective concept and usually requires fine-grained highly disruptive interviews or surveys to determine accurately. In this paper, we present EngageMon, a first-of-its-kind system that uses a combination of sensors from the smartphone (touch events), a wristband (photoplethysmography and electrodermal activity sensor readings), and an external depth camera (skeletal motion information) to accurately determine the engagement level of a mobile game player. Our design was guided by feedback obtained from interviewing 22 mobile game developers, testers, and designers. We evaluated EngageMon using data collected from 64 participants (54 in a lab-setting study and another 10 in a more natural setting study) playing six games from three different categories including endless runner, 3D motorcycle racing, and casual puzzle. Using all three sets of sensors, EngageMon was able to achieve an average accuracy of 85% and 77% under cross-sample and cross-subject evaluations respectively. Overall, EngageMon can accurately determine the engagement level of mobiles users while they are actively playing a game.","Volume 2 Issue 1, March 2018"
193,10.1145/3191746,"Renhe Jiang, Xuan Song, Zipei Fan, Tianqi Xia, Quanjun Chen, Qi Chen, Ryosuke Shibasaki",Deep ROI-Based Modeling for Urban Human Mobility Prediction,"Rapidly developing location acquisition technologies have provided us with big GPS trajectory data, which offers a new means of understanding people's daily behaviors as well as urban dynamics. With such data, predicting human mobility at the city level will be of great significance for transportation scheduling, urban regulation, and emergency management. In particular, most urban human behaviors are related to a small number of important regions, referred to as Regions-of-Interest (ROIs). Therefore, in this study, a deep ROI-based modeling approach is proposed for effectively predicting urban human mobility. Urban ROIs are first discovered from historical trajectory data, and urban human mobility is designated using two types of ROI labels (ISROI and WHICHROI). Then, urban mobility prediction is modeled as a sequence classification problem for each type of label. Finally, a deep-learning architecture built with recurrent neural networks is designed as an effective sequence classifier. Experimental results demonstrate that the superior performance of our proposed approach to the baseline models and several real-world practices show the applicability of our approach to real-world urban computing problems.","Volume 2 Issue 1, March 2018"
194,10.1145/3191747,"Jacob W. Kamminga, Duc V. Le, Jan Pieter Meijers, Helena Bisby, Nirvana Meratnia, Paul J.M. Havinga",Robust Sensor-Orientation-Independent Feature Selection for Animal Activity Recognition on Collar Tags,"Fundamental challenges faced by real-time animal activity recognition include variation in motion data due to changing sensor orientations, numerous features, and energy and processing constraints of animal tags. This paper aims at finding small optimal feature sets that are lightweight and robust to the sensor's orientation. Our approach comprises four main steps. First, 3D feature vectors are selected since they are theoretically independent of orientation. Second, the least interesting features are suppressed to speed up computation and increase robustness against overfitting. Third, the features are further selected through an embedded method, which selects features through simultaneous feature selection and classification. Finally, feature sets are optimized through 10-fold cross-validation. We collected real-world data through multiple sensors around the neck of five goats. The results show that activities can be accurately recognized using only accelerometer data and a few lightweight features. Additionally, we show that the performance is robust to sensor orientation and position. A simple Naive Bayes classifier using only a single feature achieved an accuracy of 94 % with our empirical dataset. Moreover, our optimal feature set yielded an average of 94 % accuracy when applied with six other classifiers. This work supports embedded, real-time, energy-efficient, and robust activity recognition for animals.","Volume 2 Issue 1, March 2018"
195,10.1145/3191748,"Thivya Kandappu, Archan Misra, Shih-Fen Cheng, Randy Tandriansyah, Hoong Chuin Lau",Obfuscation At-Source: Privacy in Context-Aware Mobile Crowd-Sourcing,"By effectively reaching out to and engaging larger population of mobile users, mobile crowd-sourcing has become a strategy to perform large amount of urban tasks. The recent empirical studies have shown that compared to the pull-based approach, which expects the users to browse through the list of tasks to perform, the push-based approach that actively recommends tasks can greatly improve the overall system performance. As the efficiency of the push-based approach is achieved by incorporating worker's mobility traces, privacy is naturally a concern. In this paper, we propose a novel, 2-stage and user-controlled obfuscation technique that provides a trade off-amenable framework that caters to multi-attribute privacy measures (considering the per-user sensitivity and global uniqueness of locations). We demonstrate the effectiveness of our approach by testing it using the real-world data collected from the well-established TA$Ker platform. More specifically, we show that one can increase its location entropy by 23% with only modest changes to the real trajectories while imposing an additional 24% (&lt; 1 min) of detour overhead on average. Finally, we present insights derived by carefully inspecting various parameters that control the whole obfuscation process.","Volume 2 Issue 1, March 2018"
196,10.1145/3191749,"Myeongcheol Kwak, Youngmong Park, Junyoung Kim, Jinyoung Han, Taekyoung Kwon",An Energy-efficient and Lightweight Indoor Localization System for Internet-of-Things (IoT) Environments,"Each and every spatial point in an indoor space has its own distinct and stable fingerprint, which arises owing to the distortion of the magnetic field induced by the surrounding steel and iron structures. This phenomenon makes many indoor positioning techniques rely on the magnetic field as an important source of localization. Most of the existing studies, however, have leveraged smartphones that have a relatively high computational power and many sensors. Thus, their algorithmic complexity is usually high, especially for commercial location-based services. In this paper, we present an energy-efficient and lightweight system that utilizes the magnetic field for indoor positioning in Internet of Things (IoT) environments. We propose a new hardware design of an IoT device that has a BLE interface and two sensors (magnetometer and accelerometer), with the lifetime of one year when using a coin-size battery. We further propose an augmented particle filter framework that features a robust motion model and a localization heuristic with small sensory data. The prototype-based evaluation shows that the proposed system achieves a median accuracy of 1.62 m for an office building, while exhibiting low computational complexity and high energy efficiency.","Volume 2 Issue 1, March 2018"
197,10.1145/3191750,"Yuxiang Lin, Wei Dong, Yuan Chen",Calibrating Low-Cost Sensors by a Two-Phase Learning Approach for Urban Air Quality Measurement,"Urban air quality information, e.g., PM2.5 concentration, is of great importance to both the government and society. Recently, there is a growing interest in developing low-cost sensors, installed on moving vehicles, for fine-grained air quality measurement. However, low-cost mobile sensors typically suffer from low accuracy and thus need careful calibration to preserve a high measurement quality. In this paper, we propose a two-phase data calibration method consisting of a linear part and a nonlinear part. We use MLS (multiple least square) to train the linear part, and use RF (random forest) to train the nonlinear part. We propose an automatic feature selection algorithm based on AIC (Akaike information criterion) for the linear model, which helps avoid overfitting due to the inclusion of inappropriate features. We evaluate our method extensively. Results show that our method outperforms existing approaches, achieving an overall accuracy improvement of 16.4% in terms of PM2.5 levels compared with state-of-the-art approach.","Volume 2 Issue 1, March 2018"
198,10.1145/3191751,"Rui Liu, Cory Cornelius, Reza Rawassizadeh, Ronald Peterson, David Kotz",Vocal Resonance: Using Internal Body Voice for Wearable Authentication,"We observe the advent of body-area networks of pervasive wearable devices, whether for health monitoring, personal assistance, entertainment, or home automation. For many devices, it is critical to identify the wearer, allowing sensor data to be properly labeled or personalized behavior to be properly achieved. In this paper we propose the use of vocal resonance, that is, the sound of the person's voice as it travels through the person's body -- a method we anticipate would be suitable for devices worn on the head, neck, or chest. In this regard, we go well beyond the simple challenge of speaker recognition: we want to know who is wearing the device. We explore two machine-learning approaches that analyze voice samples from a small throat-mounted microphone and allow the device to determine whether (a) the speaker is indeed the expected person, and (b) the microphone-enabled device is physically on the speaker's body. We collected data from 29 subjects, demonstrate the feasibility of a prototype, and show that our DNN method achieved balanced accuracy 0.914 for identification and 0.961 for verification by using an LSTM-based deep-learning model, while our efficient GMM method achieved balanced accuracy 0.875 for identification and 0.942 for verification.","Volume 2 Issue 1, March 2018"
199,10.1145/3191752,"Liang Liu, Wu Liu, Yu Zheng, Huadong Ma, Cheng Zhang",Third-Eye: A Mobilephone-Enabled Crowdsensing System for Air Quality Monitoring,"Air pollution has raised people's public health concerns in major cities, especially for Particulate Matter under 2.5μm (PM2.5) due to its significant impact on human respiratory and circulation systems. In this paper, we present the design, implementation, and evaluation of a mobile application, Third-Eye, that can turn mobile phones into high-quality PM2.5 monitors, thereby enabling a crowdsensing way for fine-grained PM2.5 monitoring in the city. We explore two ways, crowdsensing and web crawling, to efficiently build large-scale datasets of the outdoor images taken by mobile phone, weather data, and air-pollution data. Then, we leverage two deep learning models, Convolutional Neural Network (CNN) for images and Long Short Term Memory (LSTM) network for weather and air-pollution data, to build an end-to-end framework for training PM2.5 inference models. Our App has been downloaded more than 2,000 times and runs more than 1 year. The real user data based evaluation shows that Third-Eye achieves 17.38 μg/m3 average error and 81.55% classification accuracy, which outperforms 5 state-of-the-art methods, including three scattered interpolations and two image based estimation methods. The results also demonstrate how Third-Eye offers substantial enhancements over typical portable PM2.5 monitors by simultaneously improving accessibility, portability, and accuracy.","Volume 2 Issue 1, March 2018"
200,10.1145/3191753,"Jin Lu, Chao Shang, Chaoqun Yue, Reynaldo Morillo, Shweta Ware, Jayesh Kamath, Athanasios Bamis, Alexander Russell, Bing Wang, Jinbo Bi",Joint Modeling of Heterogeneous Sensing Data for Depression Assessment via Multi-task Learning,"Depression is a common mood disorder that causes severe medical problems and interferes negatively with daily life. Identifying human behavior patterns that are predictive or indicative of depressive disorder is important. Clinical diagnosis of depression relies on costly clinician assessment using survey instruments which may not objectively reflect the fluctuation of daily behavior. Self-administered surveys, such as the Quick Inventory of Depressive Symptomatology (QIDS) commonly used to monitor depression, may show disparities from clinical decision. Smartphones provide easy access to many behavioral parameters, and Fitbit wrist bands are becoming another important tool to assess variables such as heart rates and sleep efficiency that are complementary to smartphone sensors. However, data used to identify depression indicators have been limited to a single platform either iPhone, or Android, or Fitbit alone due to the variation in their methods of data collection. The present work represents a large-scale effort to collect and integrate data from mobile phones, wearable devices, and self reports in depression analysis by designing a new machine learning approach. This approach constructs sparse mappings from sensing variables collected by various tools to two separate targets: self-reported QIDS scores and clinical assessment of depression severity. We propose a so-called heterogeneous multi-task feature learning method that jointly builds inference models for related tasks but of different types including classification and regression tasks. The proposed method was evaluated using data collected from 103 college students and could predict the QIDS score with an R2 reaching 0.44 and depression severity with an F1-score as high as 0.77. By imposing appropriate regularizers, our approach identified strong depression indicators such as time staying at home and total time asleep.","Volume 2 Issue 1, March 2018"
201,10.1145/3191754,"Kai Lukoff, Cissy Yu, Julie Kientz, Alexis Hiniker",What Makes Smartphone Use Meaningful or Meaningless?,"Prior research indicates that many people wish to limit aspects of their smartphone use. Why is it that certain smartphone use feels so meaningless? We examined this question by using interviews, the experience sampling method, and mobile logging of 86,402 sessions of app use. One motivation for use (habitual use to pass the time) and two types of use (entertainment and passive social media) were associated with a lower sense of meaningfulness. In interviews, participants reported feeling a loss of autonomy when using their phone in these ways. These reports were corroborated by experience sampling data showing that motivation to achieve a specific purpose declined over the course of app use, particularly for passive social media and entertainment usage. In interviews, participants pointed out that even when smartphone use itself was meaningless, it could sometimes still be meaningful in the context of broader life as a 'micro escape' from negative situations. We discuss implications for how mobile apps can be used and designed to reduce meaningless experiences.","Volume 2 Issue 1, March 2018"
202,10.1145/3191755,"Yongsen Ma, Gang Zhou, Shuangquan Wang, Hongyang Zhao, Woosub Jung",SignFi: Sign Language Recognition Using WiFi,"We propose SignFi to recognize sign language gestures using WiFi. SignFi uses Channel State Information (CSI) measured by WiFi packets as the input and a Convolutional Neural Network (CNN) as the classification algorithm. Existing WiFi-based sign gesture recognition technologies are tested on no more than 25 gestures that only involve hand and/or finger gestures. SignFi is able to recognize 276 sign gestures, which involve the head, arm, hand, and finger gestures, with high accuracy. SignFi collects CSI measurements to capture wireless signal characteristics of sign gestures. Raw CSI measurements are pre-processed to remove noises and recover CSI changes over sub-carriers and sampling time. Pre-processed CSI measurements are fed to a 9-layer CNN for sign gesture classification. We collect CSI traces and evaluate SignFi in the lab and home environments. There are 8,280 gesture instances, 5,520 from the lab and 2,760 from the home, for 276 sign gestures in total. For 5-fold cross validation using CSI traces of one user, the average recognition accuracy of SignFi is 98.01%, 98.91%, and 94.81% for the lab, home, and lab+home environment, respectively. We also run tests using CSI traces from 5 different users in the lab environment. The average recognition accuracy of SignFi is 86.66% for 7,500 instances of 150 sign gestures performed by 5 different users.","Volume 2 Issue 1, March 2018"
203,10.1145/3191756,"Balz Maag, Zimu Zhou, Lothar Thiele",W-Air: Enabling Personal Air Pollution Monitoring on Wearables,"Accurate, portable and personal air pollution sensing devices enable quantification of individual exposure to air pollution, personalized health advice and assistance applications. Wearables are promising (e.g., on wristbands, attached to belts or backpacks) to integrate commercial off-the-shelf gas sensors for personal air pollution sensing. Yet previous research lacks comprehensive investigations on the accuracies of air pollution sensing on wearables. In response, we proposed W-Air, an accurate personal multi-pollutant monitoring platform for wearables. We discovered that human emissions introduce non-linear interference when low-cost gas sensors are integrated into wearables, which is overlooked in existing studies. W-Air adopts a sensor-fusion calibration scheme to recover high-fidelity ambient pollutant concentrations from the human interference. It also leverages a neural network with shared hidden layers to boost calibration parameter training with fewer measurements and utilizes semi-supervised regression for calibration parameter updating with little user intervention. We prototyped W-Air on a wristband with low-cost gas sensors. Evaluations demonstrated that W-Air reports accurate measurements both with and without human interference and is able to automatically learn and adapt to new environments.","Volume 2 Issue 1, March 2018"
204,10.1145/3191757,"Alessandro Montanari, Zhao Tian, Elena Francu, Benjamin Lucas, Brian Jones, Xia Zhou, Cecilia Mascolo",Measuring Interaction Proxemics with Wearable Light Tags,"The proxemics of social interactions (e.g., body distance, relative orientation) influences many aspects of our everyday life: from patients' reactions to interaction with physicians, successes in job interviews, to effective teamwork. Traditionally, interaction proxemics has been studied via questionnaires and participant observations, imposing high burden on users, low scalability and precision, and often biases.
In this paper we present Protractor, a novel wearable technology for measuring interaction proxemics as part of non-verbal behavior cues with fine granularity. Protractor employs near-infrared light to monitor both the distance and relative body orientation of interacting users. We leverage the characteristics of near-infrared light (i.e., line-of-sight propagation) to accurately and reliably identify interactions; a pair of collocated photodiodes aid the inference of relative interaction angle and distance. We achieve robustness against temporary blockage of the light channel (e.g., by the user's hand or clothes) by designing sensor fusion algorithms that exploit inertial sensors to obviate the absence of light tracking results.
We fabricated Protractor tags and conducted real-world experiments. Results show its accuracy in tracking body distances and relative angles. The framework achieves less than 6° error 95% of the time for measuring relative body orientation and 2.3-cm - 4.9-cm mean error in estimating interaction distance. We deployed Protractor tags to track user's non-verbal behaviors when conducting collaborative group tasks. Results with 64 participants show that distance and angle data from Protractor tags can help assess individual's task role with 84.9% accuracy, and identify task timeline with 93.2% accuracy.","Volume 2 Issue 1, March 2018"
205,10.1145/3191758,"Arsalan Mosenia, Jad F. Bechara, Tao Zhang, Prateek Mittal, Mung Chiang",ProCMotive: Bringing Programmability and Connectivity into Isolated Vehicles,"In recent years, numerous vehicular technologies, e.g., cruise control and steering assistant, have been proposed and deployed to improve the driving experience, passenger safety, and vehicle performance. Despite the existence of several novel vehicular applications in the literature, there still exists a significant gap between resources needed for a variety of vehicular (in particular, data-dominant, latency-sensitive, and computationally-heavy) applications and the capabilities of already-in-market vehicles. To address this gap, different smartphone-/Cloud-based approaches have been proposed that utilize the external computational/storage resources to enable new applications. However, their acceptance and application domain are still very limited due to programmability, wireless connectivity, and performance limitations, along with several security/privacy concerns.
In this paper, we present a novel reference architecture that can potentially enable rapid development of various vehicular applications while addressing shortcomings of smartphone-/Cloud-based approaches. The architecture is formed around a core component, called SmartCore, a privacy/security-friendly programmable dongle that brings general-purpose computational and storage resources to the vehicle and hosts in-vehicle applications. Based on the proposed architecture, we develop an application development framework for vehicles, that we call ProCMotive. ProCMotive enables developers to build customized vehicular applications along the Cloud-to-edge continuum, i.e., different functions of an application can be distributed across SmartCore, the user's personal devices, and the Cloud.
In order to highlight potential benefits that the framework provides, we design and develop two different vehicular applications based on ProCMotive, namely, Amber Response and Insurance Monitor. We evaluate these applications using real-world data and compare them with state-of-the-art technologies.","Volume 2 Issue 1, March 2018"
206,10.1145/3191759,"Masato Nomiyama, Toshiki Takeuchi, Hiroyuki Onimaru, Tomohiro Tanikawa, Takuji Narumi, Michitaka Hirose",Xnavi: Travel Planning System Based on Experience Flows,"Though an increasing number of people is now involved in travel planning owing to the spread of the internet, it is still difficult for travelers to plan trips on their own. It is especially difficult for tourists using automobiles because they have several choices of accessible places. To make itineraries easily, travelers require a travel planning system that suggests two types of experiences: experiences characterizing the travel area and experiences stemming from a flow between the former experiences. Existing systems do not list specific spontaneous experiences of interest to travelers. In response, Xnavi, a travel planning system for drivers based on experience flows, is proposed, which provides these types of experiences. To recommend experience flows, Xnavi extracts experience keywords related to the travel area using natural language processing based on the TF-IDF method and also extracts flows of tourist attractions' attributes based on association analysis of driving histories. Trials of the proposed method and a user study were conducted. The results show that Xnavi is effective at suggesting experiences and satisfying tourists with their plans.","Volume 2 Issue 1, March 2018"
207,10.1145/3191760,"Pablo E. Paredes, Yijun Zhou, Nur Al-Huda Hamdan, Stephanie Balters, Elizabeth Murnane, Wendy Ju, James A. Landay",Just Breathe: In-Car Interventions for Guided Slow Breathing,"Motivated by the idea that slow breathing practices could transform the automobile commute from a depleting, mindless activity into a calming, mindful experience, we introduce the first guided slow breathing intervention for drivers. We describe a controlled in-lab experiment (N=24) that contrasts the effectiveness and impact of haptic and voice guidance modalities at slowing drivers' breathing pace, which is a known modulator of stress. The experiment was conducted in two simulated driving environments (city, highway) while driving in one of two driving modes (autonomous, manual). Results show that both haptic and voice guidance systems can reduce drivers' breathing rate and provide a sustained post-intervention effect without affecting driving safety. Subjectively, most participants (19/24) preferred the haptic stimuli as they found it more natural to follow, less distracting, and easier to engage and disengage from, compared to the voice stimuli. Finally, while most participants found guided breathing to be a positive experience, a few participants in the autonomous driving condition found slow breathing to be an unusual activity inside the car. In this paper, we discuss such considerations, offer guidelines for designing in-car breathing interventions, and propose future research that extends our work to on-road studies. Altogether, this paper serves as foundational work on guided breathing interventions for automobile drivers.","Volume 2 Issue 1, March 2018"
208,10.1145/3191761,"Gaurav Paruthi, Shriti Raj, Natalie Colabianchi, Predrag Klasnja, Mark W. Newman",Finding the Sweet Spot(s): Understanding Context to Support Physical Activity Plans,"Creating actionable plans has been shown to be helpful in promoting physical activity. However, little rèsearch has been done on how best to support the creation and execution of plans. In this paper, we interviewed 16 participants to study the role that context plays in the formulation and execution of plans for physical activity. Our findings highlight nuanced ways that contextual factors interact with each other and with individual differences to impact planning. We propose the notion of sweet spots to encapsulate how particular contextual factors converge to create optimal states for performing physical activities. The concept of sweet spots helped us to better understand the creation and execution of plans made by our participants. We present design guidelines to show how sweet spots can help support physical activity planning and guide the design of context-based tools for planning support.","Volume 2 Issue 1, March 2018"
209,10.1145/3191762,"Champika Ranasinghe, Jakub Krukar, Christian Kray",Visualizing Location Uncertainty on Mobile Devices: Cross-Cultural Differences in Perceptions and Preferences,"Location uncertainty is often ignored but a key context parameter for location-based services. The standard way of visualizing location uncertainty on mobile devices is using a concentric circle. However, the impact of different visual variables (shape, size, boundary, middle dot, color) of this standard visualization on users is not well understood. There is a potential for misinterpretation, particularly across cultures. We ran a study that was previously conducted in Germany (N=32) in Sri Lanka (N=20) to investigate how users perceive different visualizations of location uncertainty on mobile devices. In particular, we investigated the impact of the four graphic dimensions, shape, boundary, middle dot and size. We identified consistencies and inconsistencies concerning perceptions of users regarding visualizations of location uncertainty across cultures. We also quantified the impact of different visualizations on the perception of users. Based on the consistencies between different visualizations and between the two cultures, we derived guidelines for visualizing location uncertainty that help developers in aligning location uncertainty with the perceptions of users. We also highlight the need for further research on cultural differences (and similarities) regarding how visualizations of location uncertainty impact the perceptions of users.","Volume 2 Issue 1, March 2018"
210,10.1145/3191763,"Jan Riemann, Martin Schmitz, Alexander Hendrich, Max Mühlhäuser",FlowPut: Environment-Aware Interactivity for Tangible 3D Objects,"Tangible interaction has shown to be beneficial in a wide variety of scenarios since it provides more direct manipulation and haptic feedback. Further, inherently three-dimensional information is represented more naturally by a 3D object than by a flat picture on a screen. Yet, today's tangibles have often pre-defined form factors and limited input and output facilities. To overcome this issue, the combination of projection and depth cameras is used as a fast and flexible way of non-intrusively adding input and output to tangibles. However, tangibles are often quite small and hence the space for output and interaction on their surface is limited. Therefore, we propose FlowPut: an environment-aware framework that utilizes the space available on and around a tangible object for projected visual output. By means of an optimization-based layout approach, FlowPut considers the environment of the objects to avoid interference between projection and real-world objects. Moreover, we contribute an occlusion resilient object recognition and tracking for tangible objects based on their 3D model and a point-cloud based multi-touch detection, that allows sensing touches also on the side of a tangible. Flowput is validated through a series of technical experiments, a user study, and two example applications.","Volume 2 Issue 1, March 2018"
211,10.1145/3191764,"Florian Schaule, Jan Ole Johanssen, Bernd Bruegge, Vivian Loftness",Employing Consumer Wearables to Detect Office Workers' Cognitive Load for Interruption Management,"Office workers' productivity and well-being are reduced by interruptions, especially if they occur during an inconvenient moment. Interruptions in phases of high cognitive load are more disruptive than in phases of low cognitive load. Based on an explorative study, we suppose the presence of social codes that signal office workers' interruptibility. We propose a system that utilizes the cognitive load of an office worker to indicate situations suitable for interruptions. The cognitive load is inferred from office workers' physiological state measured by a consumer smartwatch. The system adapts an externally mounted smart device to indicate if the office worker is interruptible. To predict the cognitive load, we trained a classifier with ten office workers and achieved an accuracy between 66% and 86%. In order to validate the classifier's accurateness in an office setting, we performed a verification study with five office workers: We systematically triggered interruptions for each subject over an interval of half a day of office work. The classifier was able to infer the level of cognitive load for three office workers. This result supports our hypotheses that inferring cognitive load using a consumer smartwatch is a viable concept.","Volume 2 Issue 1, March 2018"
212,10.1145/3191765,"Weinan Shi, Chun Yu, Xin Yi, Zhen Li, Yuanchun Shi",TOAST: Ten-Finger Eyes-Free Typing on Touchable Surfaces,"Touch typing on flat surfaces (e.g. interactive tabletop) is challenging due to lack of tactile feedback and hand drifting. In this paper, we present TOAST, an eyes-free keyboard technique for enabling efficient touch typing on touch-sensitive surfaces. We first formalized the problem of keyboard parameter (e.g. location and size) estimation based on users' typing data. Through a user study, we then examined users' eyes-free touch typing behavior on an interactive tabletop with only asterisk feedback. We fitted the keyboard model to the typing data, results suggested that the model parameters (keyboard location and size) changed not only between different users, but also within the same user along with time. Based on the results, we proposed a Markov-Bayesian algorithm for input prediction, which considers the relative location between successive touch points within each hand respectively. Simulation results showed that based on the pooled data from all users, this model improved the top-1 accuracy of the classical statistical decoding algorithm from 86.2% to 92.1%. In a second user study, we further improved TOAST with dynamical model parameter adaptation, and evaluated users' text entry performance with TOAST using realistic text entry tasks. Participants reached a pick-up speed of 41.4 WPM with a character-level error rate of 0.6%. And with less than 10 minutes of practice, they reached 44.6 WPM without sacrificing accuracy. Participants' subjective feedback also indicated that TOAST offered a natural and efficient typing experience.","Volume 2 Issue 1, March 2018"
213,10.1145/3191766,"Vivek K. Singh, Rushil Goyal, Shenghao Wu",Riskalyzer: Inferring Individual Risk-Taking Propensity Using Phone Metadata,"An individual's risk-taking propensity is ""the stable tendency to choose options with a lower probability of success, but greater rewards"". This risk propensity plays a central role in decision making by customers as well as managers, and is a mediator in behavior associated with security, privacy, health, finance, and well-being. Most common approach to understanding an individual's risk propensity remain lab-based games and surveys. Administering such surveys and games is a manual, time, and money intensive process that is also fraught with multiple biases. Recently, smartphones are increasingly seen as large-scale sensors of human activity, recording data related to physical and social aspects of people's lives. Building on this trend we investigate the potential of passive phone-based data for automatically inferring an individual's risk propensity. Specifically, we describe a novel approach to model an individual's risk propensity based on her mobile phone usage. Based on a 10-week field + lab study involving 50 participants, we report that: (1) multiple phone-based features (e.g., average gyradius) are intricately associated with participants' risk propensity; and (2) a phone-based model outperforms demography-based models by 39% in terms of accuracy of predicting risk propensity. In organizational terms, a better understanding of risk behavior could contribute significantly to risk management programs. At the same time, such results could open doors for more nuanced understanding of the underlying human risk phenomena and their interconnections with social and mobility behavior.","Volume 2 Issue 1, March 2018"
214,10.1145/3191767,"Vijay Srinivasan, Christian Koehler, Hongxia Jin",RuleSelector: Selecting Conditional Action Rules from User Behavior Patterns,"Modern smartphones and ubiquitous computing systems collect a wealth of context data from users. Conditional action rules, as popularized by the IFTTT (If-This-Then-That) platform, are a popular way for users to automate frequently repeated tasks or receive smart reminders, due to the intelligibility and control that rules provide to users. A key drawback of IFTTT systems is that they place the burden of manually specifying action rules on the user. While multiple rule mining algorithms have been proposed in existing work to automatically discover action rules, they generate hundreds of action rules, and the problem of how to present a small subset of rules to smartphone users and allow them to interactively select action rules remains unsolved. In this work, we take the first step towards solving this problem by designing and implementing RuleSelector, the first interactive rule selection tool to allow smartphone users to browse, modify, and select action rules from a small set of summarized rules presented to the user. We propose novel rule selection metrics to address the needs of smartphone users, and analyze the performance of RuleSelector using data from 200 users. We also perform a qualitative user study in order to evaluate how users use the RuleSelector tool and perceive the selected rules, and present the insights gained and design recommendations for future rule selection systems. Our users rated the selected rules from useful to very useful, and an important finding of our study is that users prefer an interactive rule selection system such as RuleSelector that automatically suggests rules, but allows users to select and modify the suggested rules. Finally, we examine the promise of RuleSelector in other ubiquitous computing systems such as smart homes and smart TVs by applying our tool to public context datasets from these domains.","Volume 2 Issue 1, March 2018"
215,10.1145/3191768,"Jiayao Tan, Xiaoliang Wang, Cam-Tu Nguyen, Yu Shi",SilentKey: A New Authentication Framework through Ultrasonic-based Lip Reading,"This paper presents SilentKey, a new authentication framework to identify mobile device users through ultrasonic-based lip reading. The main idea is to generate ultrasonic signals from a mobile phone and analyze the fine-grained impact of mouth motions on the reflected signal. The new framework is effective since people have unique characteristics when performing mouth motions, which represent not only what people input, but also how they input. SilentKey is robust against attacks since the input cannot be recorded or imitated. We implement a prototype and demonstrate the effectiveness of the system by fifty volunteers. Such a non-intrusive identification mechanism provides a natural user interface which can also be applied by people with speaking or viewing difficulties.","Volume 2 Issue 1, March 2018"
216,10.1145/3191769,"Lie Ming Tang, Jochen Meyer, Daniel A. Epstein, Kevin Bragg, Lina Engelen, Adrian Bauman, Judy Kay",Defining Adherence: Making Sense of Physical Activity Tracker Data,"Increasingly, people are collecting detailed personal activity data from commercial trackers. Such data should be able to give important insights about their activity levels. However, people do not wear or carry tracking devices all day, every day and this means that tracker data is typically incomplete. This paper aims to provide a systematic way to take account of this incompleteness, by defining adherence, a measure of data completeness, based on how much people wore their tracker. We show the impact of different adherence definitions on 12 diverse datasets, for 753 users, with over 77,000 days with data, interspersed with over 73,000 days without data. For example, in one data set, one adherence measure gives an average step count of 6,952 where another gives 9,423. Our results show the importance of adherence when analysing and reporting activity tracker data. We provide guidelines for defining adherence, analysing its impact and reporting it along with the results of the tracker data analysis. Our key contribution is the foundation for analysis of physical activity data, to take account of data incompleteness.","Volume 2 Issue 1, March 2018"
217,10.1145/3191770,"Milka Trajkova, Francesco Cafaro",Takes Tutu to Ballet: Designing Visual and Verbal Feedback for Augmented Mirrors,"Mirrors have been a core feature in ballet studios for over five hundred years. While physical mirrors provide real-time feedback, they do not inform dancers of their errors. Thus, technologies such as motion tracking have been used to augment what a physical mirror can provide. Current augmented mirrors, however, only implement one mode of communication, usually visual, and do not provide a holistic feedback to dancers that includes all the feedback elements commonly used in ballet classes. We conducted a mixed-method study with 16 novices and 16 expert dancers in which we compared two different modes of communication (visual and verbal), two different types of feedback (value and corrective) and two levels of guidance (mirror, or no mirror). Participants' ballet technique scores were evaluated by a remote teacher on eight ballet combinations (tendue, adagio, pirouette, saute, plié, degage, frappe and battement tendue). We report quantitative and qualitative results that show how the level of guidance, mode of communication, and type of feedback, needs to be tuned in different ways for novices and experts.","Volume 2 Issue 1, March 2018"
218,10.1145/3191771,"Tran Huy Vu, Archan Misra, Quentin Roy, Kenny Choo Tsu Wei, Youngki Lee",Smartwatch-based Early Gesture Detection 8 Trajectory Tracking for Interactive Gesture-Driven Applications,"The paper explores the possibility of using wrist-worn devices (specifically, a smartwatch) to accurately track the hand movement and gestures for a new class of immersive, interactive gesture-driven applications. These interactive applications need two special features: (a) the ability to identify gestures from a continuous stream of sensor data early--i.e., even before the gesture is complete, and (b) the ability to precisely track the hand's trajectory, even though the underlying inertial sensor data is noisy. We develop a new approach that tackles these requirements by first building a HMM-based gesture recognition framework that does not need an explicit segmentation step, and then using a per-gesture trajectory tracking solution that tracks the hand movement only during these predefined gestures. Using an elaborate setup that allows us to realistically study the table-tennis related hand movements of users, we show that our approach works: (a) it can achieve 95% stroke recognition accuracy. Within 50% of gesture, it can achieve a recall value of 92% for 10 novice users and 93% for 15 experienced users from a continuous sensor stream; (b) it can track hand movement during such strokeplay with a median accuracy of 6.2 cm.","Volume 2 Issue 1, March 2018"
219,10.1145/3191772,"Raghav H. Venkatnarayan, Muhammad Shahzad",Gesture Recognition Using Ambient Light,"There is a growing interest in the scientific community to develop techniques for humans to communicate with the computing that is embedding into our environments. Researchers are already exploring ubiquitous modalities, such as radio frequency signals, to develop gesture recognition systems. In this paper, we explore another such modality, namely ambient light, and develop LiGest, an ambient light based gesture recognition system. The key property of LiGest is that it is agnostic to lighting conditions, position and orientation of user, and who performs the gestures. The general idea behind LiGest is that when a user performs different gestures, the shadows of the user move in unique patterns. LiGest first learns these patterns using training samples and then recognizes unknown samples by matching them with the learnt patterns. To capture these patterns, LiGest uses a grid of light sensors deployed on floor. While the general idea behind LiGest seems straightforward, it is actually very challenging to put it into practice because the intensity, size, and number of shadows of a user are not fixed and depend highly on the position and orientation of a user as well as on the intensity, position, and number of light sources. We developed a prototype of LiGest using commercially available light sensors and extensively evaluated it with the help of 20 volunteers. Our results show that LiGest achieves an average accuracy of 96.36% across all volunteers.","Volume 2 Issue 1, March 2018"
220,10.1145/3191773,"Chuyu Wang, Jian Liu, Yingying Chen, Lei Xie, Hong Bo Liu, Sanclu Lu",RF-Kinect: A Wearable RFID-based Approach Towards 3D Body Movement Tracking,"The rising popularity of electronic devices with gesture recognition capabilities makes the gesture-based human-computer interaction more attractive. Along this direction, tracking the body movement in 3D space is desirable to further facilitate behavior recognition in various scenarios. Existing solutions attempt to track the body movement based on computer version or wearable sensors, but they are either dependent on the light or incurring high energy consumption. This paper presents RF-Kinect, a training-free system which tracks the body movement in 3D space by analyzing the phase information of wearable RFID tags attached on the limb. Instead of locating each tag independently in 3D space to recover the body postures, RF-Kinect treats each limb as a whole, and estimates the corresponding orientations through extracting two types of phase features, Phase Difference between Tags (PDT) on the same part of a limb and Phase Difference between Antennas (PDA) of the same tag. It then reconstructs the body posture based on the determined orientation of limbs grounded on the human body geometric model, and exploits Kalman filter to smooth the body movement results, which is the temporal sequence of the body postures. The real experiments with 5 volunteers show that RF-Kinect achieves 8.7° angle error for determining the orientation of limbs and 4.4cm relative position error for the position estimation of joints compared with Kinect 2.0 testbed.","Volume 2 Issue 1, March 2018"
221,10.1145/3191774,"Liang Wang, Wen Cheng, Lijia Pan, Tao Gu, Tianheng Wu, Xianping Tao, Jian Lu",SpiderWalk: Circumstance-aware Transportation Activity Detection Using a Novel Contact Vibration Sensor,"This paper presents the design and implementation of the SpiderWalk system for circumstance-aware transportation activity detection using a novel contact vibration sensor. Different from existing systems that only report the type of activity, our system detects not only the activity but also its circumstances (e.g., road surface, vehicle, and shoe types) to provide better support for applications such as activity logging, location tracking, and smart persuasive applications. Inspired by but different from existing audio-based context detection approaches using microphones, the SpiderWalk system is designed and implemented using an ultra-sensitive, flexible contact vibration sensor which mimics the spiders' sensory slit organs. By sensing vibration patterns from the soles of shoes, the system can accurately detect transportation activities with rich circumstance information while resisting undesirable external signals from other sources or speech that may cause the data assignment and privacy preserving issues. Moreover, our system is implemented by reusing existing audio devices and can be used by an unmodified smartphone, making it ready for large-scale deployments. Finally, a novel temporal and spatial correlated classification approach is proposed to accurately detect the complex combinations of transportation activities and circumstances based on the output of each individual classifiers. Experiments conducted on a real-world data set suggest our system can accurately detect different transportation activities and their circumstances with an average detection accuracy of 93.8% with resource overheads comparable to existing audio- and GPS-based systems.","Volume 2 Issue 1, March 2018"
222,10.1145/3191775,"Rui Wang, Weichen Wang, Alex daSilva, Jeremy F. Huckins, William M. Kelley, Todd F. Heatherton, Andrew T. Campbell",Tracking Depression Dynamics in College Students Using Mobile Phone and Wearable Sensing,"There are rising rates of depression on college campuses. Mental health services on our campuses are working at full stretch. In response researchers have proposed using mobile sensing for continuous mental health assessment. Existing work on understanding the relationship between mobile sensing and depression, however, focuses on generic behavioral features that do not map to major depressive disorder symptoms defined in the standard mental disorders diagnostic manual (DSM-5). We propose a new approach to predicting depression using passive sensing data from students' smartphones and wearables. We propose a set of symptom features that proxy the DSM-5 defined depression symptoms specifically designed for college students. We present results from a study of 83 undergraduate students at Dartmouth College across two 9-week terms during the winter and spring terms in 2016. We identify a number of important new associations between symptom features and student self reported PHQ-8 and PHQ-4 depression scores. The study captures depression dynamics of the students at the beginning and end of term using a pre-post PHQ-8 and week by week changes using a weekly administered PHQ-4. Importantly, we show that symptom features derived from phone and wearable sensors can predict whether or not a student is depressed on a week by week basis with 81.5% recall and 69.1% precision.","Volume 2 Issue 1, March 2018"
223,10.1145/3191776,"Shuai Wang, Tian He, Desheng Zhang, Yuanchao Shu, Yunhuai Liu, Yu Gu, Cong Liu, Haengju Lee, Sang H. Son",BRAVO: Improving the Rebalancing Operation in Bike Sharing with Rebalancing Range Prediction,"Bike sharing systems, which provide a convenient commute choice for short trips, have emerged rapidly in many cities. While bike sharing has greatly facilitated people's commutes, those systems are facing a costly maintenance issue -- rebalancing bikes among stations. We observe that existing systems frequently suffer situations such as no-bike-to-borrow (empty) or no-dock-to-return (full) due to existing ad hoc rebalancing practice. To address this issue, we provide systematic analysis on user trip data, station status data, rebalancing data, and meteorology data, and propose BRAVO - the first practical data-driven bike rebalancing app for operators to improve bike sharing service while reducing the maintenance cost. Specifically, leveraging experiences from two-round round-the-clock field studies and comprehensive information from four data sets, a data-driven model is proposed to capture and predict the safe rebalancing range for each station. Based on this safe rebalancing range, BRAVO computes the optimal rebalancing amounts for the full and empty stations to minimize the rebalancing cost. BRAVO is evaluated with 24-month data from Capital, Hangzhou and NiceRide bikeshare systems. The experiment results show that given the same user demand, BRAVO reduces 28% of the station visits and 37% of the rebalancing amounts.","Volume 2 Issue 1, March 2018"
224,10.1145/3191777,"Xiaoyang Xie, Fan Zhang, Desheng Zhang",PrivateHunt: Multi-Source Data-Driven Dispatching in For-Hire Vehicle Systems,"Recently, for-hire vehicle services (FHV, e.g., Uber and Lyft) have become essential to people's daily transportation. Similar to taxis, how to effectively dispatch these FHV based on demand and supply is important for both FHV passengers and drivers. Based on real-world multi-source data, we identify two new challenges for FHV dispatching: (i) diverse demand: FHV passengers are a mix of passengers previously using taxis, buses, subways, or private vehicles; (ii) uncertain supply: FHV drivers join and leave the FHV system with spatiotemporal dynamics. As a result, the state-of-the-art taxi dispatching techniques cannot be applied to FHV systems. In this paper, we design the first FHV dispatching system PrivateHunt based on extremely large-scale urban transportation data from New York City and Shenzhen in China. In particular, we present (i) a passenger demand model based on taxi, bus, subway, and private vehicle data; (ii) a driver supply model based on small-scale FHV data; (iii) a dispatching technique for FHV vehicles based on proposed demand/supply models to reduce idle driving time. We implement PrivateHunt based on 14 thousand taxis, 13 thousand buses, and 8-line subway system and 10 thousand private vehicles. The experimental results show that our data-driven dispatching strategy significantly outperforms the state-of-the-art dispatching strategies without data-driven FHV insights.","Volume 2 Issue 1, March 2018"
225,10.1145/3191778,"Fengli Xu, Tong Xia, Hancheng Cao, Yong Li, Funing Sun, Fanchao Meng",Detecting Popular Temporal Modes in Population-scale Unlabelled Trajectory Data,"With the rapid process of urbanization, revealing the underlying mechanisms behind urban mobility has become a crucial research problem. The movements of urban dwellers are often constituted by their daily routines, and exhibit distinct and contextual temporal modes, i.e., the patterns of individuals allocating their time across different locations. In this paper, we investigate a novel problem of detecting popular temporal modes in population-scale unlabelled trajectory data. Our key finding is that the detected temporal modes capture the semantic feature of human's living style, and is able to unravel meaningful correlations between urban mobility and human behavior.
Specifically, we represent the temporal mode of a trajectory as a partition of the time duration, where the time slices associated with same locations are partitioned into same subsets. Such abstraction decouples the temporal modes from actual physical locations, and allows individuals with similar temporal modes yet completely different physical locations to have similar representations. Based on this insight, we propose a pipeline system composed of three components: 1) noise handler that eliminates the noises in the raw mobility records, 2) representation extractor for temporal modes, and 3) popular temporal modes detector. By applying our system on three real-world mobility datasets, we demonstrate that our system effectively detects the popular temporal modes embedded in population-scale mobility datasets, which is easy to be interpreted and can be justified through the associated PoIs and mobile applications usage. More importantly, our further experiments reveal insightful correlations between the popular temporal modes and individuals' social economic status, i.e. occupation information, which sheds light on the mechanisms behind urban mobility.","Volume 2 Issue 1, March 2018"
226,10.1145/3191779,"Li Yan, Haiying Shen, Zhuozhao Li, Ankur Sarker, John A. Stankovic, Chenxi Qiu, Juanjuan Zhao, Chengzhong Xu",Employing Opportunistic Charging for Electric Taxicabs to Reduce Idle Time,"For electric taxicabs, the idle time spent on cruising for passengers, seeking chargers, and charging is wasteful. Previous works can only save cruising time through better routing, or charger seeking and charging time through proper charger deployment, but not for both. With the advancement of wireless charging techniques, efficient opportunistic charging of electric vehicles at their parked positions becomes possible. This enables a taxicab to get charged while waiting for the next passenger. In this paper, we present an opportunistic wireless charger deployment scheme in a city, which both maximizes the taxicabs' opportunity of picking up passengers at the chargers and supports the taxicabs' continuous operability on roads, while minimizing the total deployment cost. We studied a metropolitan-scale taxicab dataset on several factors important for deploying wireless chargers and determining the numbers of the chargers in the regions: the number of passengers, the functionalities of buildings, and the frequency of passenger appearance in a region, and taxicab traffic flows in a city. Then, we formulate a multi-objective optimization problem and find the solution. Our trace-driven experiments demonstrate the superior performance of our scheme over other representative methods in terms of reducing idle time and supporting the operability of the taxicabs.","Volume 2 Issue 1, March 2018"
227,10.1145/3191780,"Yu Yang, Fan Zhang, Desheng Zhang",SharedEdge: GPS-Free Fine-Grained Travel Time Estimation in State-Level Highway Systems,"Estimating travel time on the highway in real time is of great importance for transportation services. Previous work has been mainly focusing on the city scale for a particular transportation system, e.g., taxi, bus, and metro. Little research has been conducted to estimate fine-grained real-time travel time in state-level highway systems. This is because the traditional solutions based on probe vehicles or loop sensors cannot scale to state-level highway systems due to their large spatial coverage. Recently, the adoption of Electric Toll Collection (ETC) systems (e.g. EZ-pass) brings a new opportunity to estimate the real-time travel time in the highway systems with little marginal cost. However, the key challenge is that ETC data only record the coarse-grained total travel time between a pair of toll stations rather than fine-grained travel time in each individual highway edge. To address this challenge, we design SharedEdge to estimate the fine-grained edge travel time with large-scale streaming ETC data. The key novelty is that we estimate real-time fine-grained travel time (i.e., edge travel time) without using fine-grained data (i.e. GPS trajectories or loop sensor data), by a few techniques based on Bayesian Graphical models and Expectation Maximization. More importantly, we implement our SharedEdge in the Guangdong Province, China with an ETC system covering 69 highways and 773 toll stations with a length of 7, 000 km. Based on this implementation, we evaluate SharedEdge in details by comparing it with some baselines and the state-of-the-art models. The evaluation results show that SharedEdge outperforms other methods in terms of travel time estimation accuracy when compared with the ground truth obtained by 114 thousand GPS-equipped vehicles.","Volume 2 Issue 1, March 2018"
228,10.1145/3191781,"Zhice Yang, Jiansong Zhang, Zeyu Wang, Qian Zhang",Lightweight Display-to-device Communication Using Electromagnetic Radiation and FM Radio,"This paper presents Shadow, a novel display-to-device communication system working in radio frequency. It leverages Electromagnetic Radiation (EMR) signals emanating from displays to transmit information. Specifically, Shadow modulates the high-frequency electric signals flowing in the display interface and makes the leaked EMR signals fall into the FM band. In this way, nearby mobile devices can receive information from the display through FM receivers. Compared with other display-to-device communication approaches, Shadow does not rely on cameras, and is thus more lightweight and requires fewer user actions. Furthermore, Shadow's transmissions do not incur any degradation in the display quality, as they only take place in the Blanking Interval, which will not be shown on the display panel. Shadow requires no modification to existing hardware. The prototype is implemented with commodity display systems and mobile devices. Results show that it can achieve 1.5 kbps at distances of up to 20 cm from the display panel.","Volume 2 Issue 1, March 2018"
229,10.1145/3191782,"Xuehan Ye, Yongcai Wang, Yuhe Guo, Wei Hu, Deying Li",Accurate and Efficient Indoor Location by Dynamic Warping in Sequence-Type Radio-map,"An efficient way to overcome the calibration challenge and RSS dynamics in radio-map-based indoor localization is to collect radio signal strength (RSS) along indoor paths and conduct localization by sequence matching. But such sequence-based indoor localization suffers problems including indoor path combinational explosion, random RSS miss-of-detection during user movement, and user moving speed disparity in online and offline phases. To address these problems, this paper proposes an undirected graph model, called WarpMap to efficiently calibrate and store the sequence-type radio-map. It reduces RSS sequence signature storage complexity from O(2N) to O(N) where N is the number of path crosses. An efficient on-line candidate path extraction algorithm is developed in it to find a set of the most possible candidate paths for matching with the on-line collected RSS sequence. Then, to determine the user's exact location, a sub-sequence dynamic time warping (SDTW) algorithm is proposed, which matches the online collected RSS sequence with the sequential RSS signatures of the candidate paths. We show the SDTW algorithm is highly efficient and adaptive, which localizes user without backtracking of warping path. Extensive experiments in office environments verified the efficiency and accuracy of WarpMap, which can be calibrated within thirty minutes by one person for 1100m2 area and provides overall nearly 20% accuracy improvements than the state-of-the-art of radio-map method.","Volume 2 Issue 1, March 2018"
230,10.1145/3191783,"Nan Yu, Wei Wang, Alex X. Liu, Lingtao Kong",QGesture: Quantifying Gesture Distance and Direction with WiFi Signals,"Many HCI applications, such as volume adjustment in a gaming system, require quantitative gesture measurement for metrics such as movement distance and direction. In this paper, we propose QGesture, a gesture recognition system that uses CSI values provided by COTS WiFi devices to measure the movement distance and direction of human hands. To achieve high accuracy in measurements, we first use phase correction algorithm to remove the phase noise in CSI measurements. We then propose a robust estimation algorithm, called LEVD, to estimate and remove the impact of environmental dynamics. To separate gesture movements from daily activities, we design simple gestures with unique characteristics as preambles to determine the start of the gesture. Our experimental results show that QGesture achieves an average accuracy of 3 cm in the measurement of movement distance and more than 95% accuracy in the movement direction detection in the one-dimensional case. Furthermore, it achieves an average absolute direction error of 15 degrees and an average accuracy of 3.7 cm in the measurement of movement distance in the two-dimensional case.","Volume 2 Issue 1, March 2018"
231,10.1145/3191784,"Tong Zhan, Wenzhong Li, Xu Chen, Sanglu Lu",Capturing the Shifting Shapes: Enabling Efficient Screen-Camera Communication with a Pattern-based Dynamic Barcode,"With the increasing availability of LCD displays and phone cameras in today's environment, screen-camera communication using dynamic barcode has emerged as a convenient infrastructure-free form to establish impromptu communication channel among mobile devices. Due to the short wavelengths and narrow beams of visible light, screen-camera communication is highly directional, low-interference and secure, which envisions a wide range of application scenarios. Conventional screen-camera communication systems encode data bits with color in dynamic barcodes, which suffers from the frame mixture problem caused by the rolling shutter effect of CMOS camera in high capturing rate. In this paper, we propose a novel design of dynamic barcode called ShiftCode that encodes data bits with shifting shape patterns, which provide a new way to expand the barcode capacity for screen-camera communications. ShiftCode adopts a pattern-based layout design to embed multiple data bits in a symbol representation. With such layout, it exploits a decoding mechanism to solve the frame mixture problem and achieves high frame capturing rate. It further intruduces a two-level reliability technique for intra-frame error correction and inter-frame redundancy, which reduces the overhead and delay of retransmission. The proposed ShiftCode is implemented on the Android platform, and extensive experiments show that it achieves at least two-fold improvement on goodput compared with the conventional screen-camera communication systems.","Volume 2 Issue 1, March 2018"
232,10.1145/3191785,"Fusang Zhang, Daqing Zhang, Jie Xiong, Hao Wang, Kai Niu, Beihong Jin, Yuxiang Wang",From Fresnel Diffraction Model to Fine-grained Human Respiration Sensing with Commodity Wi-Fi Devices,"Non-intrusive respiration sensing without any device attached to the target plays a particular important role in our everyday lives. However, existing solutions either require dedicated hardware or employ special-purpose signals which are not cost-effective, significantly limiting their real-life applications. Also very few work concerns about the theory behind and can explain the large performance variations in different scenarios. In this paper, we employ the cheap commodity Wi-Fi hardware already ubiquitously deployed around us for respiration sensing. For the first time, we utilize the Fresnel diffraction model to accurately quantify the relationship between the diffraction gain and human target's subtle chest displacement and thus successfully turn the previously considered ""destructive"" obstruction diffraction in the First Fresnel Zone (FFZ) into beneficial sensing capability. By not just considering the chest displacement at the frontside as the existing solutions, but also the subtle displacement at the backside, we achieve surprisingly matching results with respect to the theoretical plots and become the first to clearly explain the theory behind the performance distinction between lying and sitting for respiration sensing. With two cheap commodity Wi-Fi cards each equipped with just one antenna, we are able to achieve higher than 98% accuracy of respiration rate monitoring at more than 60% of the locations in the FFZ. Furthermore, we are able to present the detail heatmap of the sensing capability at each location inside the FFZ to guide the respiration sensing so users clearly know where are the good positions for respiration monitoring and if located at a bad position, how to move just slightly to reach a good position.","Volume 2 Issue 1, March 2018"
233,10.1145/3191786,"Huichu Zhang, Yu Zheng, Yong Yu",Detecting Urban Anomalies Using Multiple Spatio-Temporal Data Sources,"Urban anomalies, such as abnormal movements of crowds and accidents, may result in loss of life or property if not handled properly. It would be of great value for governments if anomalies can be automatically alerted in their early stage. However, detecting anomalies in urban area has two main challenges. First, the criteria to determine an anomaly on different occasions (e.g. rainy days vs. sunny days, or holidays vs. workdays) and in different places (e.g. tourist attractions vs. office areas) are distinctly different, as these occasions and places have their own definitions on normal patterns. Second, urban anomalies often exhibit complex forms (e.g. road closure may cause decrease in taxi flow and increase in bike flow). We need an algorithm that not only models the anomaly degree of individual data source but also the combination of changes in multiple data sources. In this paper, we propose a two-step method to tackle those challenges. In the first step, we use a similarity-based algorithm to estimate an anomaly score for each individual data source in each region and time slot based on the values of historically similar regions. Those scores are fed into the second step, where we propose an algorithm based on one-class Support Vector Machine to capture rare patterns occurred in multiple data sources, nearby regions or time slots, and give a final, integrated anomaly score for each region. Evaluations based on both synthetic and real world datasets show the advantages of our method beyond baseline techniques such as distance-based, probability-based methods.","Volume 2 Issue 1, March 2018"
234,10.1145/3191787,"Maotian Zhang, Qian Dai, Panlong Yang, Jie Xiong, Chang Tian, Chaocan Xiang",iDial: Enabling a Virtual Dial Plate on the Hand Back for Around-Device Interaction,"Smart wearable devices have become pervasive and are playing a more important role in our everyday lives. However, the small screen size and very few buttons make the interaction and control cumbersome and inconvenient. Previous solutions to mitigate this problem either require extra dedicated hardware, or instrument the user's fingers with special purpose sensors, limiting their real-life applications. We present iDial, a novel real time approach that enables a virtual dial plate on the hand back, extending the interaction beyond the small screen of wearable devices. iDial only employs the already built-in microphone and motion sensors of the commercial-off-the-shelf (COTS) device to facilitate interactions between user and wearable, without any extra hardware involved. The key idea is to exploit the acoustic signatures extracted from passive subtle acoustic signals to accurately recognize the virtual keys input on the skin of the hand back. We innovatively locate the virtual keys on the 4 pieces of metacarpal bones to significantly reduce the possibility of casual inputs. iDial also takes advantages of the motion sensor fusion already available inside the wearable to achieve robustness against the ambient noise and human voices efficiently. We design and implement iDial on the Samsung Gear S2 smartwatch. Our extensive experiments show that iDial is able to achieve an average recognition accuracy of 96.7%, and maintain high accuracies across varying user behaviors and different environments. iDial achieves a below 0.5s end-to-end latency with all the computations and processes happening at the cheap commodity wearable.","Volume 2 Issue 1, March 2018"
235,10.1145/3191788,"Yu Zhang, Tao Gu, Chu Luo, Vassilis Kostakos, Aruna Seneviratne",FinDroidHR: Smartwatch Gesture Input with Optical Heartrate Monitor,"We present FinDroidHR, a novel gesture input technique for off-the-shelf smartwatches. Our technique is designed to detect 10 hand gestures on the hand wearing a smartwatch. The technique is enabled by analysing features of the Photoplethysmography (PPG) signal that optical heart-rate sensors capture. In a study with 20 participants, we show that FinDroidHR achieves 90.55% accuracy and 90.73% recall. Our work is the first study to explore the feasibility of using optical sensors on the off-the-shelf wearable devices to recognise gestures. Without requiring bespoke hardware, FinDroidHR can be readily used on existing smartwatches.","Volume 2 Issue 1, March 2018"
236,10.1145/3161601,"Olivier Augereau, Charles Lima Sanches, Koichi Kise, Kai Kunze",Wordometer Systems for Everyday Life,"We present in this paper a detailed comparison of different algorithms and devices to determine the number of words read in everyday life. We call our system the “Wordometer”. We used three kinds of eye tracking systems in our experiment: mobile video-oculography (MVoG); stationary video-oculography (SVoG); and electro-oculography (EoG). By analyzing the movement of the eyes we were able to estimate the number of words that a user read. Recently, inexpensive eye trackers have appeared on the market. Thus, we undertook a large-scale experiment that compared three devices that can be used for daily reading on a screen: the Tobii Eye X SVoG; the JINS MEME EoG; and the Pupil MVoG. We found that the accuracy of the everyday life devices and professional devices was similar when used with the Wordometer. We analyzed the robustness of the systems for special reading behaviors: rereading and skipping.
With the MVoG, SVoG and EoG systems, we obtained estimation errors respectively, 7.2%, 13.0%, and 10.6% in our main experiment. In all our experiments, we obtained 300 recordings by 14 participants, which amounted to 109,097 read words.","Volume 1 Issue 4, December 2017"
237,10.1145/3161175,"Nikola Banovic, John Krumm",Warming Up to Cold Start Personalization,"Smart agents face abandonment if they are unable to provide value to the users from the very first interaction. Existing smart agents take time to learn about new users before they can offer them personalized services. We present a method for learning personalization information about users quickly and without placing unnecessary hardship on them. Our method enables smart agents to pick which questions to ask the user when they first interact to maximize the agent's overall knowledge about the user. We demonstrate our method on two publically available US census datasets containing 172 user variables from 1,799,394 training and 1,618,489 testing users. The questions selected using our method improve the agent's accuracy when inferring information about future users, including information that they did not ask about. Our work enables smart agents that assist the user with personalized services soon after they start interacting.","Volume 1 Issue 4, December 2017"
238,10.1145/3161161,"Joan-Isaac Biel, Nathalie Martin, David Labbe, Daniel Gatica-Perez",Bites‘n’Bits: Inferring Eating Behavior from Contextual Mobile Data,"We collect and analyze mobile data about everyday eating occasions to study eating behavior in relation to its context (time, location, social context, related activities and physical activity). Our contributions are three-fold. First, we deployed a data collection campaign with 122 Swiss university students, resulting in 1208 days of food data, 3414 meal occasions, 1034 snacking occasions, 5097 photos, and 998 days of physical activity. Second, we analyzed the collected data and report findings associated to the compliance, snacks vs. meals patterns, physical activity, and contextual differences between snacks and meals. Third, we addressed a novel ubicomp task, namely the classification of eating occasions (meals vs. snacks) in everyday life. We show that a machine learning method using time of day, time since last intake, and location is able to discriminate eating occasions with 84% accuracy, which significantly outperforms a baseline method based only on time.","Volume 1 Issue 4, December 2017"
239,10.1145/3161160,"Daniel Buschek, Julia Kinshofer, Florian Alt",A Comparative Evaluation of Spatial Targeting Behaviour Patterns for Finger and Stylus Tapping on Mobile Touchscreen Devices,"Models of 2D targeting error patterns have been applied as a valuable computational tool for analysing finger touch behaviour on mobile devices, improving touch accuracy and inferring context. However, their use in stylus input is yet unexplored. This paper presents the first empirical study and analyses of such models for tapping with a stylus. In a user study (N = 28), we collected targeting data on a smartphone, both for stationary use (sitting) and walking. We compare targeting patterns between index finger input and three stylus variations -- two stylus widths and nib types as well as the addition of a hover cursor. Our analyses reveal that stylus targeting patterns are user-specific, and that offset models improve stylus tapping accuracy, but less so than for finger touch. Input method has a stronger influence on targeting patterns than mobility, and stylus width is more influential than the hover cursor. Stylus models improve finger accuracy as well, but not vice versa. The extent of the stylus accuracy advantage compared to the finger depends on screen location and mobility. We also discuss patterns related to mobility and gliding of the stylus on the screen. We conclude with implications for target sizes and offset model applications.","Volume 1 Issue 4, December 2017"
240,10.1145/3161184,"Ceara Byrne, Jay Zuerndorfer, Larry Freil, Xiaochuang Han, Andrew Sirolly, Scott Cilliland, Thad Starner, Melody Jackson",Predicting the Suitability of Service Animals Using Instrumented Dog Toys,"Working dogs1 are significantly beneficial to society; however, a substantial number of dogs are released from time consuming and expensive training programs because of unsuitability in behavior. Early prediction of successful service dog placement could save time, resources, and funding. Our research focus is to explore whether aspects of canine temperament can be detected from interactions with sensors, and to develop classifiers that correlate sensor data to predict the success (or failure) of assistance dogs in advanced training. In a 2-year longitudinal study, our team tested a cohort of dogs entering advanced training in the Canine Companions for Independence (CCI) Program with 2 instrumented dog toys: a silicone ball and a silicone tug sensor. We then create a logistic model tree classifier to predict service dog success using only 5 features derived from dog-toy interactions. During randomized 10-fold cross validation where 4 of the 40 dogs were kept in an independent test set for each fold, our classifier predicts the dogs' outcomes with 87.5% average accuracy. We assess the reliability of our model by performing the testing routine 10 times over 1.5 years for a single suitable working dog, which predicts that the dog would pass each time. We calculate the resource benefit of identifying dogs who will fail early in their training, and the value for a cohort of 40 dogs using our toys and our methods for prediction is over $70,000. With CCI's 6 training centers, annual savings could be upwards of $5 million per year.","Volume 1 Issue 4, December 2017"
241,10.1145/3161191,"Liqiong Chang, Jie Xiong, Ju Wang, Xiaojiang Chen, Yu Wang, Zhanyong Tang, Dingyi Fang",RF-Copybook: A Millimeter Level Calligraphy Copybook based on commodity RFID,"As one of the best ways to learn and appreciate the Chinese culture, Chinese calligraphy is widely practiced and learned all over the world. Traditional calligraphy learners spend a great amount of time imitating the image templates of reputed calligraphers. In this paper, we propose an RF-based Chinese calligraphy template, named RF-Copybook, to precisely monitor the writing process of the learner and provide detail instructions to improve the learner's imitating behavior. With two RFID tags attached on the brush pen and three antennas equipped at the commercial RFID reader side, RF-Copybook tracks the pen's 3-dimensional movements precisely. The key intuition behind RF-Copybook's idea is that: (i) when there is only direct path signal between the tag and the antenna, the phase measured at the reader changes linearly with the distance, (ii) the reader offers very fine-grained phase readings, thus a millimeter level accuracy of antenna-tag distance can be obtained, (iii) by combing multiple antenna-tag distances, we can quantify the writing process with stroke based feature models. Extensive experiments show that RF-Copybook is robust against the environmental noise and achieves high accuracies across different environments in the estimation of the brush pen's elevation angle, nib's moving speed and position.","Volume 1 Issue 4, December 2017"
242,10.1145/3161173,"Kaifei Chen, Jonathan Fürst, John Kolb, Hyung-Sin Kim, Xin Jin, David E. Culler, Randy H. Katz",SnapLink: Fast and Accurate Vision-Based Appliance Control in Large Commercial Buildings,"As the number and heterogeneity of appliances in smart buildings increases, identifying and controlling them becomes challenging. Existing methods face various challenges when deployed in large commercial buildings. For example, voice command assistants require users to memorize many control commands. Attaching Bluetooth dongles or QR codes to appliances introduces considerable deployment overhead. In comparison, identifying an appliance by simply pointing a smartphone camera at it and controlling the appliance using a graphical overlay interface is more intuitive. We introduce SnapLink, a responsive and accurate vision-based system for mobile appliance identification and interaction using image localization. Compared to the image retrieval approaches used in previous vision-based appliance control systems, SnapLink exploits 3D models to improve identification accuracy and reduce deployment overhead via quick video captures and a simplified labeling process. We also introduce a feature sub-sampling mechanism to achieve low latency at the scale of a commercial building. To evaluate SnapLink, we collected training videos from 39 rooms to represent the scale of a modern commercial building. It achieves a 94% successful appliance identification rate among 1526 test images of 179 appliances within 120 ms average server processing time. Furthermore, we show that SnapLink is robust to viewing angle and distance differences, illumination changes, as well as daily changes in the environment. We believe the SnapLink use case is not limited to appliance control: it has the potential to enable various new smart building applications.","Volume 1 Issue 4, December 2017"
243,10.1145/3161159,"Longbiao Chen, Xiaoliang Fan, Leye Wang, Daqing Zhang, Zhiyong Yu, Jonathan Li, Thi-Mai-Trang Nguyen, Gang Pan, Cheng Wang",RADAR: Road Obstacle Identification for Disaster Response Leveraging Cross-Domain Urban Data,"Typhoons and hurricanes cause extensive damage to coast cities annually, demanding urban authorities to take effective actions in disaster response to reduce losses. One of the first priority in disaster response is to identify and clear road obstacles, such as fallen trees and ponding water, and restore road transportation in a timely manner for supply and rescue. Traditionally, identifying road obstacles is done by manual investigation and reporting, which is labor intensive and time consuming, hindering the timely restoration of transportation. In this work, we propose RADAR, a low-cost and real-time approach to identify road obstacles leveraging large-scale vehicle trajectory data and heterogeneous road environment sensing data. First, based on the observation that road obstacles may cause abnormal slow motion behaviors of vehicles in the surrounding road segments, we propose a cluster direct robust matrix factorization (CDRMF) approach to detect road obstacles by identifying the collective anomalies of slow motion behaviors from vehicle trajectory data. Then, we classify the detected road obstacles leveraging the correlated spatial and temporal features extracted from various road environment data, including satellite images and meteorological records. To address the challenges of heterogeneous features and sparse labels, we propose a semi-supervised approach combining co-training and active learning (CORAL). Real experiments on Xiamen City show that our approach accurately detects and classifies the road obstacles during the 2016 typhoon season with precision and recall both above 90%, and outperforms the state-of-the-art baselines.","Volume 1 Issue 4, December 2017"
244,10.1145/3161417,"Yehoshua Shuki Cohen, Erez Shmueli",Money Drives: Can Monetary Incentives based on Real-Time Monitoring Improve Driving Behavior?,"This paper examines the effectiveness of monetary incentives based on real-time monitoring as means to improve driving behavior of company car drivers. We conducted a 5-months 60-drivers field study with one of the largest public transportation companies in Israel. Driving behavior was measured continuously using In-Vehicle Data Recorders (IVDR) that were pre-installed in the vehicles, enabling naturalistic, objective and concise measurements. The driving behavior measurements were then used to examine two different monetary incentive schemes: (1) a simple individual incentive scheme where each driver was rewarded based on his own improvement in driving behavior, and (2) a peer-reward scheme where each driver was rewarded based on the improvement of his peers. Drivers were also provided with daily feedback about their improvement and the reward they gained using text messages and a dedicated smartphone app. We find that the two incentive schemes presented an average improvement of 25% in driving behavior, whereas the control group (that did not use any monetary incentive) presented no improvement at all. Surprisingly and in contrast to the reported superiority of the peer-reward scheme in previous studies, we find the individual scheme to perform better in our setting (31% vs. 15% improvement). Finally, we find that the monetary incentive schemes were able to reduce fuel consumption significantly, suggesting that such incentives can serve as a sustainable mechanism for improving driving behavior in real-world applications.","Volume 1 Issue 4, December 2017"
245,10.1145/3161190,"Mariella Dimiccoli, Juan Marín, Edison Thomaz",Mitigating Bystander Privacy Concerns in Egocentric Activity Recognition with Deep Learning and Intentional Image Degradation,"Recent advances in wearable camera technology and computer vision algorithms have greatly enhanced the automatic capture and recognition of human activities in real-world settings. While the appeal and utility of wearable camera devices for human-behavior understanding is indisputable, privacy concerns have limited the broader adoption of this method. To mitigate this problem, we propose a deep learning-based approach that recognizes everyday activities in egocentric photos that have been intentionally degraded in quality to preserve the privacy of bystanders. An evaluation on 2 annotated datasets collected in the field with a combined total of 84,078 egocentric photos showed activity recognition performance with accuracy between 79% and 88% across 17 and 21 activity classes when the images were subjected to blurring (mean filter k=20). To confirm that image degradation does indeed raise the perception of bystander privacy, we conducted a crowd sourced validation study with 640 participants; it showed a statistically significant positive relationship between the amount of image degradation and participants' willingness to be captured by wearable cameras. This work contributes to the field of privacy-sensitive activity recognition with egocentric photos by highlighting the trade-off between perceived bystander privacy protection and activity recognition performance.","Volume 1 Issue 4, December 2017"
246,10.1145/3161198,"Erin Griffiths, Salah Assana, Kamin Whitehouse",Privacy-preserving Image Processing with Binocular Thermal Cameras,"Today, cameras and digital image processing are transforming industries and the human environment with rich, informative sensing. However, image processing is not utilized nearly as much in homes where concerns about image privacy dominate. In a preliminary study with 200 participants, we found 21% would reject a camera based system even if the system was designed to not report images as they could still be collected if the camera system was hacked. In this paper, we demonstrate a hardware-based approach for privacy-preserving image processing: the ability to automatically extract information from imaging sensors without the risk of compromising image privacy, even if the system is hacked. The basic idea is to limit both the memory available on board the camera and the data rate of camera communication to prevent a full image from ever being extracted. As a proof of concept, we prototype a system, called Lethe, that tracks and identifies individuals by height with a thermal camera as they move from room to room. Our results show that Lethe can detect the presence of individuals with 96.9% accuracy and determine their direction of travel with 99.7% accuracy. Additionally, Lethe can identify individuals 96.0% of the time with a 5cm (~2in) or greater difference in walking height and 92.9% with a 2.5cm (~1in) or greater difference. Finally, Lethe performs this processing with only 33 bytes of memory (or 0.69% of the full thermal image).","Volume 1 Issue 4, December 2017"
247,10.1145/3161165,"Daniel Groeger, Jürgen Steimle",ObjectSkin: Augmenting Everyday Objects with Hydroprinted Touch Sensors and Displays,"Augmenting everyday objects with interactive input and output surfaces is a long-standing topic in ubiquitous computing and HCI research. Existing approaches, however, fail to leverage the objects' full potential, particularly in highly curved organic geometries and in diverse visuo-haptic surface properties. We contribute ObjectSkin, a fabrication technique for adding conformal interactive surfaces to rigid and flexible everyday objects. It enables multi-touch sensing and display output that seamlessly integrates with highly curved and irregular geometries. The approach is based on a novel water-transfer process for interactive surfaces. It leverages off-the-shelf hobbyist equipment to fabricate thin, conformal, and translucent electronic circuits that preserve the surface characteristics of everyday objects. It offers two methods, for rapid low-fidelity and versatile high-fidelity prototyping, and is applicable to a wide variety of materials. Results from a series of technical experiments provide insights into the supported object geometries, compatible object materials, and robustness. Seven example cases demonstrate how ObjectSkin makes it possible to leverage geometries, surface properties, and unconventional objects for prototyping novel interactions for ubiquitous computing.","Volume 1 Issue 4, December 2017"
248,10.1145/3161411,"Bin Guo, Jing Li, Vincent W. Zheng, Zhu Wang, Zhiwen Yu",CityTransfer: Transferring Inter- and Intra-City Knowledge for Chain Store Site Recommendation based on Multi-Source Urban Data,"Chain businesses have been dominating the market in many parts of the world. It is important to identify the optimal locations for a new chain store. Recently, numerous studies have been done on chain store location recommendation. These studies typically learn a model based on the features of existing chain stores in the city and then predict what other sites are suitable for running a new one. However, these models do not work when a chain enterprise wants to open business in a new city where there is not enough data about this chain store. To solve the cold-start problem, we propose CityTransfer, which transfers chain store knowledge from semantically-relevant domains (e.g., other cities with rich knowledge, similar chain enterprises in the target city) for chain store placement recommendation in a new city. In particular, CityTransfer is a two-fold knowledge transfer framework based on collaborative filtering, which consists of the transfer rating prediction model, the inter-city knowledge association method and the intra-city semantic extraction method. Experiments using data of chain hotels from four different cities crawled from Ctrip (a popular travel reservation website in China) and the urban characters extracted from several other data sources validate the effectiveness of our approach on store site recommendation.","Volume 1 Issue 4, December 2017"
249,10.1145/3161194,"Suiming Guo, Chao Chen, Yaxiao Liu, Ke Xu, Dah Ming Chiu",Modelling Passengers' Reaction to Dynamic Prices in Ride-on-demand Services: A Search for the Best Fare,"In emerging ride-on-demand (RoD) services such as Uber and Didi (in China), dynamic prices play an important role in regulating supply and demand, trying to improve the service quality for both drivers and passengers. In this paper, we take a new perspective to study RoD services besides the supply or demand, and focus on passengers' reaction to dynamic prices. Passengers' reaction can be regarded as a process of searching for the best price before getting on a car, and the searching process reflects passengers' demand elasticity -- “how eager they are requesting a ride”. We collect data of passengers' reaction from a real RoD service provider in China, and analyze the patterns of passengers' reaction. The analysis results show that both the dynamic prices and passengers' demand elasticity influence their reaction. We then adopt and extend a previous model for sequential search from a known distribution to understand passengers' reaction, and use our data to obtain the search costs under various circumstances, which could be interpreted as passengers' demand elasticity. Insights on the search cost and other relevant quantities are discussed. Our expectation is that the result of the study should be helpful not only for service providers in designing dynamic pricing algorithms, but also for passengers and policy makers in understanding the effects and implications of dynamic pricing.","Volume 1 Issue 4, December 2017"
250,10.1145/3161189,"Takahiro Hashizume, Takuya Arizono, Koji Yatani",Auth ‘n’ Scan: Opportunistic Photoplethysmography in Mobile Fingerprint Authentication,"Recent commodity smartphones have biometric sensing capabilities, allowing their daily use for authentication and identification. This increasing use of biometric systems motivates us to design an opportunistic way to sense user's additional physiological or behavioral data. We define this concurrent physiological or behavioral data sensing during biometric authentication or identification as dual-purpose biometrics. As an instance of dual-purpose biometrics, we develop photoplethysmography (PPG) sensing during mobile fingerprint authentication, called Auth ‘n’ Scan. Our system opportunistically extracts cardiovascular information, such as a heart rate and its variability, while users perform phone unlock of a smartphone. To achieve this sensing, our Auth ‘n’ Scan system attaches four PPG units around a fingerprint sensor. The system also performs noise removal and signal selection to accurately estimate cardiovascular information. This paper presents the hardware implementation and signal processing algorithm of our Auth ‘n’ Scan prototype. We also report our system evaluations with 10 participants, showing that, despite a little low precision (a standard deviation of 3--7), estimation of heart rates with high accuracy (under a mean error of 1) is possible from PPG data of five seconds and longer if their baseline information is given. We discuss the feasibility of opportunistic PPG sensing in mobile fingerprint authentication.","Volume 1 Issue 4, December 2017"
251,10.1145/3161177,"Malcolm Haynes, Thad Starner",Effects of Lateral Eye Displacement on Comfort While Reading from a Video Display Terminal,"Some small field-of-view (FOV) head worn displays (HWD), like Epson's Moverio BT-300, are mounted directly in the user's line of sight. In contrast, Google Glass is mounted “out of the way” and above the line of sight. Other displays like the Vuzix M100 or Optinvent ORA-1 allow the user to adjust the display position, and some users have expressed a desire for the display to be laterally displaced toward the ear, out of the main line of sight. How far toward the ear can a small FOV display be mounted and still be used comfortably? Using a 30-minute reading task and an emulated display with the FOV of a typical smart phone (9.2°x 16.3°), we study a user's perceived comfort level while reading at four horizontally displaced positions. We ask participants to rate their comfort every five minutes using a 5-point Likert scale knob (5 being most comfortable), for a total of seven measurements. Scores are summed over the seven measurements to form a summed comfort score. We find that 0° (Md = 34.0; p«0.001), 10° (Md = 33.5; p«c0.001), and 20° (Md = 33.5; p«c0.001) are more comfortable than 30° (Md = 29.5) and that 0° (p&lt;0.01) and 10° (p&lt;0.01) are more comfortable than 20°. Reading performance and workload measures were numerically similar across all conditions. Given the main results of the experiment, post-hoc analysis on other measurements such as preference and asthenopia, and participant comments, we suggest that small FOV displays should be mounted at lateral displacement angles of 20° and less for sustained use.","Volume 1 Issue 4, December 2017"
252,10.1145/3161167,"Chih-Hsiang Hsu, Chia-Lun Ku, Yung-Ju Chang, Yu-Shuen Wang, Uyn-Dinh Trân, Wen-Hao Cheng, Chu-Yuan Yang, Ching-Yu Hsieh, Chun-Cheng Lin",iTour: Making Tourist Maps GPS-Enabled,"Although tourist maps are useful resources for people to visit scenic areas, they are also commonly distorted and omit details according to the purposes and functions of a map. In this paper, we present iTour, a semi-automatic system that turns tourist maps into digital maps. By involving users in matching the road network of a tourist map and the paired standard map, our system computes road network correspondence between the two maps. By doing so, users can navigate on such GPS-enabled tourist maps using mobile devices. This transformation creates the possibility of augmenting a large number of tourist maps with digital map features. To evaluate the performance of matching road networks, we compared the presented semi-automatic interface to a manual interface. The results showed that the semi-automatic interface saved participants significant effort in generating correspondence and was perceived to require significantly less time by the participants. In addition, we conducted a field study of the iTour in comparison to using a tourist map and Google Maps together. Our results showed that iTour helped participants find their way during travel. The participants provided positive feedback on the combination of tourist maps and GPS location because of its highlights of important landmarks, showing users' locations relative to those landmarks, and saving the effort of switching tourist maps and Google Maps.","Volume 1 Issue 4, December 2017"
253,10.1145/3161185,"Xingyu Huang, Yong Li, Yue Wang, Xinlei Chen, Yu Xiao, Lin Zhang",CTS: A Cellular-based Trajectory Tracking System with GPS-level Accuracy,"GPS has been widely used for locating mobile devices on the road map. Due to its high power consumption and poor signal penetration, GPS is unfortunately unsuitable to be used for continuously tracking low-power devices. Compared with GPS-based positioning, cellular-infrastructure-based positioning consumes much less energy, and works in any place covered by the cellular networks. However, the challenges of cellular positioning come from the relatively low accuracy and sampling rate. In this paper, we propose a novel cellular-based trajectory tracking system, namely CTS. It achieves GPS-level accuracy by combining trilateration-based cellular positioning, stationary state detection, and Hidden-Markov-Model-based path recovery. In particular, CTS utilizes basic characteristics of cellular sectors to produce more credible inferences for device locations.
To evaluate the performance of CTS, we collaborated with a mobile operator and deployed the system the city of Urumchi, Xinjiang Province of China. We collected the location data of 489,032 anonymous mobile subscribers from cellular networks during 24 hours, and retrieved 201 corresponding GPS trajectories. Our experimental results show that CTS achieves GPS-level accuracy in 95.7% of cases, which significantly outperforms the state-of-the-art solutions.","Volume 1 Issue 4, December 2017"
254,10.1145/3161409,"Zengshi Huang, Naijie Gu, Jianlin Hao, Jie Shen",3DLoc: 3D Features for Accurate Indoor Positioning,"A variety of indoor applications require both accurate location and orientation, such as indoor navigation and augmented reality. This paper presents 3DLoc, with which you can find your location and orientation by pointing your smartphone camera at 3D features e.g., doors and entrances. Different from the previous image-based localization of matching features via SIFT or SURF, 3DLoc takes advantage of rules for 3D features, including the ratio between height and width, the orientation and the distribution on the 2D floor map. The features around users are regarded as a unique 3D signature for the location. Based on prior researches on vanishing points and indoor geometric reasoning, we propose an algorithm to extract the signature from captured images and robustly decode the signature to accurate location and orientation. In terms of efficiency and user-friendliness, a series of optimizations are adopted through fusion of smartphone sensors and vision. We conduct experiments on different floors of a typical office building via the prototype built on Huawei P7 and iPhone 5S. Ninety percent of errors for location and orientation are within 25cm and two de4rees, respectively. With a 2D floor map provided, KB (-KiloByte-) level storage is required for the additional 3D information.","Volume 1 Issue 4, December 2017"
255,10.1145/3161197,"Ryo Imai, Kota Tsubouchi, Tatsuya Konishi, Masamichi Shimosaka",Early Destination Prediction with Spatio-temporal User Behavior Patterns,"Predicting user behavior makes it possible to provide personalized services. Destination prediction (e.g. predicting a future location) can be applied to various practical applications. An example of destination prediction is personalized GIS services, which are expected to provide alternate routes to enable users to avoid congested roads. However, the destination prediction problem requires critical trade-offs between timing and accuracy. In this paper, we focus on early destination prediction as the central issue, as early recognition in destination prediction has not been fully explored. As an alternative to the traditional two basic approaches with trajectory tracking that narrow down the candidates with respect to the trip progress, and Next Place Prediction (NPP) that infers the future location of a user from user habits, we propose a new probabilistic model based on both conventional models. The advantage of our model is that it drastically narrows down the destination candidates efficiently at the early stage of a trip, owing to the staying information derived from the NPP approach. In other words, our approach achieves high prediction accuracy by considering both approaches at the same time. To implement our model, we employ SubSynE for state-of-the-art prediction based on trajectory tracking as well as a multi-class logistic regression based on user contexts. Despite the simplicity of our model, the proposed method provides improved performance compared to conventional approaches based on the experimental results using the GPS logs of 1,646 actual users from the commercial services.","Volume 1 Issue 4, December 2017"
256,10.1145/3161163,"Vikram Iyer, Elyas Bayati, Rajalakshmi Nandakumar, Arka Majumdar, Shyamnath Gollakota",Charging a Smartphone Across a Room Using Lasers,"We demonstrate a novel laser-based wireless power delivery system that can charge mobile devices such as smartphones across a room. The key challenges in achieving this are multi-fold: delivering greater than a watt of power across the room, minimizing the exposure of the resulting high-power lasers to human tissue, and finally ensuring that the design meets the form-factor requirements of a smartphone and requires minimal instrumentation to the environment. This paper presents a novel, and to the best of our knowledge, the first design, implementation and evaluation of an end-to-end power delivery system that satisfies all the above requirements. Our results show that we can deliver more than 2 W at ranges of 4.3 m and 12.2 m for a smartphone (25 cm2) and table-top form factor (100 cm2) receiver respectively. Further, extensive characterization of our safety system shows that we can turn off our laser source much before a human moving at a maximum speed of 44 m/s can even enter the high-power laser beam area.","Volume 1 Issue 4, December 2017"
257,10.1145/3161179,"Landu Jiang, Xinye Lin, Xue Liu, Chongguang Bi, Guoliang Xing",SafeDrive: Detecting Distracted Driving Behaviors Using Wrist-Worn Devices,"Distracted driving causes a large number of fatalities every year and is now becoming an important issue in the traffic safety study. In this paper, we present SafeDrive, a driving safety system that leverages wearable wrist sensing techniques to detect and analyze driver distracted behaviors. Existing wrist-worn sensing approaches, however, do not address challenges under real driving environments, such as less distinguishable gesture patterns due to in-vehicle physical constraints, various gesture hallmarks produced by different drivers and significant noise introduced by various driving conditions. In response, SafeDrive adopts a semi-supervised machine learning model for in-vehicle distracting activity detection. To improve the detection accuracy, we provide online updated classifiers by collecting real-time gesture data, while at the same time utilize smartphone sensing to generate soft hints filtering out anomalies and non-distracted hand movements. In the evaluation, we conduct extensive real-road experiments involving 20 participants (10 males and 10 females) and 5 vehicles (a sedan, a minivan and three SUVs). Our approach can achieve an average classification accuracy of over 90% with a error rate of a few percent, which demonstrate that SafeDrive is robust to real driving environments, and has great potential to help drivers shape safe driving habits.","Volume 1 Issue 4, December 2017"
258,10.1145/3161199,"Haojian Jin, Zhijian Yang, Swarun Kumar, Jason I. Hong",Towards Wearable Everyday Body-Frame Tracking using Passive RFIDs,"We introduce RF-Wear, an accurate and wearable solution to track movements of a user's body using passive RFIDs embedded in their clothing. RF-Wear processes wireless signals reflected off these tags to a compact single-antenna RFID reader in the user's pocket. In doing so, RF-Wear enables a first-of-its-kind body-frame tracking mechanism that is lightweight and convenient for day-to-day use, without relying on external infrastructure. At the heart of RF-Wear is a novel primitive that computes angles between different parts of the user's body using the RFID tags attached to them. RF-Wear achieves this by treating groups of RFID tags as an array of antennas whose orientation can be computed accurately relative to the handheld reader. By computing the orientation of individual body parts, we demonstrate how RF-Wear reconstructs the real-time posture of the user's entire body frame. Our solution overcomes multiple challenges owing to the interactions of wireless signals with the body, the 3-D nature of human joints and the flexibility of fabric on which RFIDs are placed. We implement and evaluate a prototype of RF-Wear on commercial RFID readers and tags and demonstrate its performance in body-frame tracking. Our results reveal a mean error of 8--12° in tracking angles at joints that rotate along one degree-of-freedom, and 21°- azimuth, 8°- elevation for joints supporting two degrees-of-freedom.","Volume 1 Issue 4, December 2017"
259,10.1145/3161168,"Mohamed Khamis, Daniel Buschek, Tobias Thieron, Florian Alt, Andreas Bulling",EyePACT: Eye-Based Parallax Correction on Touch-Enabled Interactive Displays,"The parallax effect describes the displacement between the perceived and detected touch locations on a touch-enabled surface. Parallax is a key usability challenge for interactive displays, particularly for those that require thick layers of glass between the screen and the touch surface to protect them from vandalism. To address this challenge, we present EyePACT, a method that compensates for input error caused by parallax on public displays. Our method uses a display-mounted depth camera to detect the user's 3D eye position in front of the display and the detected touch location to predict the perceived touch location on the surface. We evaluate our method in two user studies in terms of parallax correction performance as well as multi-user support. Our evaluations demonstrate that EyePACT (1) significantly improves accuracy even with varying gap distances between the touch surface and the display, (2) adapts to different levels of parallax by resulting in significantly larger corrections with larger gap distances, and (3) maintains a significantly large distance between two users' fingers when interacting with the same object. These findings are promising for the development of future parallax-free interactive displays.","Volume 1 Issue 4, December 2017"
260,10.1145/3161201,"Kundan Krishna, Deepali Jain, Sanket V. Mehta, Sunav Choudhary",An LSTM Based System for Prediction of Human Activities with Durations,"Human activity prediction is an interesting problem with a wide variety of applications like intelligent virtual assistants, contextual marketing, etc. One formulation of this problem is jointly predicting human activities (viz. eating, commuting, etc.) with associated durations. Herein a deep learning system is proposed for this problem. Given a sequence of past activities and durations, the system estimates the probabilities for future activities and their durations. Two distinct Long-Short Term Memory (LSTM) networks are developed that cater to different assumptions about the data and achieve different modeling complexities and prediction accuracies. The networks are trained and tested with two real-world datasets, one being publicly available while the other collected from a field experiment. Modeling on the segment level public dataset mitigates the cold-start problem. Experiments indicate that compared to traditional approaches based on sequence mining or hidden Markov modeling, LSTM networks perform significantly better. The ability of LSTM networks to detect long term correlations in activity data is also demonstrated. The trained models are each less than 500KB in size and can be deployed to run in real-time on a mobile device without any dependencies on the cloud. This can help applications like mobile personal assistants by providing predictive context.","Volume 1 Issue 4, December 2017"
261,10.1145/3161193,John Krumm,Urban Impulses: Evoked Responses From Local Event Stimuli,"In modeling human behavior, we expect people to make noticeable reactions to the events they witness. For people at a scheduled event like a concert or sports game, we can measure reactions by looking at geotagged social media posts. We work from a database of known events from a commercial ticket broker and a database of geotagged tweets to show how we can derive impulse response functions of tweet counts as event responses. Tweet counts typically rise in anticipation of the event and gradually fall after the event starts. We draw an analogy between evoked responses in functional magnetic resonance imaging (fMRI) from mental stimuli and social media responses from local event stimuli. Our analysis of event and tweet data shows that our derived impulse responses are statistically significant and that we can use the functions to accurately predict reactions to some event types. We give examples of impulse response functions derived from repeated events at different venues.","Volume 1 Issue 4, December 2017"
262,10.1145/3161166,"Christian Lander, Markus löchtefeld, Antonio Krüger",hEYEbrid: A hybrid approach for mobile calibration-free gaze estimation,"We introduce hEYEbrid, a calibration-free method for spontaneous and long-term eye gaze tracking, with competitive gaze estimation. It is based on a hybrid concept that combines infrared eye images with corneal imaging. For this, two eye cameras are mounted on a glasses frame. In this way, the pupil can be tracked quickly with high precision. This information is translated into the corneal image, which is used to create a connection to the environment, acting like a scene camera. In a user study with 20 participants, we evaluated our approach against an extended version of the system, called 3C-hEYEbrid, and a state-of-the-art head-mounted Pupil Labs eye tracker. We show that hEYEbrid provides accurate gaze estimation in unconstrained environments and is robust against calibration drift (e.g. caused by taking off and putting on the device). In addition, we present a mobile and wearable implementation of hEYEbrid and 3C-hEYEbrid, that is also usable with a monocular Pupil Labs eye tracker. It connects the head-mounted device to a mobile phone, enabling gaze estimation in real time. hEYEbrid represents a significant step towards pervasive gaze-based interfaces.","Volume 1 Issue 4, December 2017"
263,10.1145/3161170,"Moon-Hwan Lee, Yea-Kyung Row, Oosung Son, Uichin Lee, Jaejeung Kim, Jungi Jeong, Seungryoul Maeng, Tek-Jin Nam",Flower-Pop: Facilitating Casual Group Conversations With Multiple Mobile Devices,"We explore the potential use of mobile devices as a collaborative sensing system that can proactively mediate casual group conversations. In this study, we aim to investigate (i) the impacts of a mobile system's passive and active conversation facilitation and (ii) the ways in which sociocultural aspects that affect casual group conversation should be considered in the design of proactive mobile systems. Toward this goal, we developed Flower-Pop, a mobile system that monitors group conversations and visualizes interaction patterns using metaphorical expressions based on blossoms. This system provides passive facilitation as well as active facilitation modes such as proactive conversation visualization and photo sharing. The active modes can encourage inactive participants to share photos and select random people to speak. Focusing on Korea, our field study showed that Flower-Pop's mediation created smooth topic/speaker transitions and encouraged less-active speakers to better engage in group conversation. We also found that the sociocultural aspects of casual group conversation, such as the location's characteristics, social relations, and the group's interests, affected participants' use of the Flower-Pop system. Based on our findings, we discuss methods for designing mobile systems for conversation facilitation and outline how opportune sociocultural factors could be identified based on mobile devices.","Volume 1 Issue 4, December 2017"
264,10.1145/3161412,"Xinye Lin, Yixin Chen, Xiao-Wen Chang, Xue Liu, Xiaodong Wang",SHOW: Smart Handwriting on Watches,"Smart watch is becoming a new gateway through which people stay connected and track everyday activities, and text-entry on it is becoming a frequent need. With the two de facto solutions: tap-on-screen and voice input, text-entry on the watch remains a tedious task because 1. Tap-on-screen is error prone due to the small screen; 2. Voice input is strongly constrained by the surroundings and suffers from privacy leak. In this paper, we propose SHOW, which enables the user to input as they handwrite on horizontal surfaces, and the only requirement is to use the elbow as the support point. SHOW captures the gyroscope and accelerometer traces and deduces the user's handwriting thereafter. SHOW differs from previous work of gesture recognition in that: 1. it employs a novel rotation injection technique to substantially reduce the effort of data collection; 2. it does not require whole-arm posture, hence is better suited to space-limited places (e.g. vehicles). Our experiments show that SHOW can effectively generate 60 traces from one real handwriting trace and achieve high accuracy at 99.9% when recognizing the 62 different characters written by 10 volunteers. Furthermore, having more screen space after removing the virtual keyboard, SHOW can display 4x candidate words for autocompletion. Aided by the tolerance of character ambiguity and accurate character recognition, SHOW achieves over 70% lower mis-recognition-rate, 43% lower no-response-rate in both daily and general purposed text-entry scenarios, and 33.3% higher word suggestion coverage than the tap-on-screen method using a virtual QWERTY keyboard.","Volume 1 Issue 4, December 2017"
265,10.1145/3161196,"Chris Xiaoxuan Lu, Bowen Du, Hongkai Wen, Sen Wang, Andrew Markham, Ivan Martinovic, Yiran Shen, Niki Trigoni",Snoopy: Sniffing Your Smartwatch Passwords via Deep Sequence Learning,"Demand for smartwatches has taken off in recent years with new models which can run independently from smartphones and provide more useful features, becoming first-class mobile platforms. One can access online banking or even make payments on a smartwatch without a paired phone. This makes smartwatches more attractive and vulnerable to malicious attacks, which to date have been largely overlooked. In this paper, we demonstrate Snoopy, a password extraction and inference system which is able to accurately infer passwords entered on Android/Apple watches within 20 attempts, just by eavesdropping on motion sensors. Snoopy uses a uniform framework to extract the segments of motion data when passwords are entered, and uses novel deep neural networks to infer the actual passwords. We evaluate the proposed Snoopy system in the real-world with data from 362 participants and show that our system offers a ~ 3-fold improvement in the accuracy of inferring passwords compared to the state-of-the-art, without consuming excessive energy or computational resources. We also show that Snoopy is very resilient to user and device heterogeneity: it can be trained on crowd-sourced motion data (e.g. via Amazon Mechanical Turk), and then used to attack passwords from a new user, even if they are wearing a different model.
This paper shows that, in the wrong hands, Snoopy can potentially cause serious leaks of sensitive information. By raising awareness, we invite the community and manufacturers to revisit the risks of continuous motion sensing on smart wearable devices.","Volume 1 Issue 4, December 2017"
266,10.1145/3161171,"Zheng Lu, Yunhe Feng, Wenjun Zhou, Xiaolin Li, Qing Cao",Inferring Correlation between User Mobility and App Usage in Massive Coarse-grained Data Traces,"With the rapid growth in smartphone usage, it has been more and more important to understand the patterns of mobile data consumption by users. In this paper, we present an empirical study of the correlation between user mobility and app usage patterns. In particular, we focus on users' moving speed as the key mobility metric, and try to answer the following question: are there any notable relations between moving speed and the app usage patterns? Our study is based on a real-world, large-scale dataset of 2G phone network data request records. A critical challenge was that the raw data records are rather coarse-grained. More specifically, unlike GPS traces, the exact locations of users were not readily available. We inferred users' approximate locations according to their interactions with nearby cell towers, whose locations were known. We proposed a novel method to filter out noises and perform reliable speed estimation. We verify our methodology with out of sample data and show its improvement in speed estimation accuracy. We then examined several aspects of mobile data usage patterns, including the data volume, the access frequency, and the app categories, to reveal the correlation between these patterns and users' moving speed. Experimental results based on our large-scale real-world datasets revealed that users under different mobility categories not only have different smartphone usage motivations but also have different ways of using their smartphones.","Volume 1 Issue 4, December 2017"
267,10.1145/3161176,"Kohei Matsumura, David S. Kirk",On Active Passengering: Supporting In-Car Experiences,"We describe the development of an interactive car window system designed to support passengers in engaging with the external environment during a journey. Through advances in embedded digital technologies, cars increasingly have a potential to become interactive spaces, in which passengers will find it possible to interact with the external environment through in-car interfaces. However the utility and benefit of such interactive systems for passengers has not been well studied. There is a need therefore, to study the design and use of these technologies, as they are emerging. We thus investigated how digital technology might support passengers' interactions with the external environment. Through a focus group (n=6) and interviews (n=5) we investigated passengers' attitudes towards, and practices during, ordinary car journeys. From this scoping study we formulated five design considerations for designing/implementing a prototype interactive car-window system. This system was then evaluated through an in-lab user study (n=8). Qualitative thematic analysis of interviews during the user study suggested a variety of orientations towards ‘passengering’, the act of being a passenger, on a journey. Herein we critically examine the role of our interactive technology in supporting desired experiences of ‘active passengering’.","Volume 1 Issue 4, December 2017"
268,10.1145/3161183,"Sameera Palipana, David Rojas, Piyush Agrawal, Dirk Pesch",FallDeFi: Ubiquitous Fall Detection using Commodity Wi-Fi Devices,"Falling or tripping among elderly people living on their own is recognized as a major public health worry that can even lead to death. Fall detection systems that alert caregivers, family members or neighbours can potentially save lives. In the past decade, an extensive amount of research has been carried out to develop fall detection systems based on a range of different detection approaches, i.e, wearable and non-wearable sensing and detection technologies. In this paper, we consider an emerging non-wearable fall detection approach based on WiFi Channel State Information (CSI). Previous CSI based fall detection solutions have considered only time domain approaches. Here, we take an altogether different direction, time-frequency analysis as used in radar fall detection. We use the conventional Short-Time Fourier Transform (STFT) to extract time-frequency features and a sequential forward selection algorithm to single out features that are resilient to environment changes while maintaining a higher fall detection rate. When our system is pre-trained, it has a 93% accuracy and compared to RTFall and CARM, this is a 12% and 15% improvement respectively. When the environment changes, our system still has an average accuracy close to 80% which is more than a 20% to 30% and 5% to 15% improvement respectively.","Volume 1 Issue 4, December 2017"
269,10.1145/3161169,"Katrin Plaumann, Milos Babic, Tobias Drey, Witali Hepting, Daniel Stooss, Enrico Rukzio",Improving Input Accuracy on Smartphones for Persons who are Affected by Tremor using Motion Sensors,"Having a hand tremor often complicates interactions with touchscreens on mobile devices. Due to the uncontrollable oscillations of both hands, hitting targets can be hard, and interaction can be slow. Correcting input needs additional time and mental effort. We propose a method for automatically correcting such inputs based on motion data, gathered both with the devices' sensors and a small wearable sensor on the finger used for tapping. The development was informed by interviews with persons with tremor. Two empirical studies showed that our method, involving both smartphone and finger motion sensors without changing the user interface, allows users with tremor to select objects with up to 40 % fewer misses.","Volume 1 Issue 4, December 2017"
270,10.1145/3161174,"Valentin Radu, Catherine Tong, Sourav Bhattacharya, Nicholas D. Lane, Cecilia Mascolo, Mahesh K. Marina, Fahim Kawsar",Multimodal Deep Learning for Activity and Context Recognition,"Wearables and mobile devices see the world through the lens of half a dozen low-power sensors, such as, barometers, accelerometers, microphones and proximity detectors. But differences between sensors ranging from sampling rates, discrete and continuous data or even the data type itself make principled approaches to integrating these streams challenging. How, for example, is barometric pressure best combined with an audio sample to infer if a user is in a car, plane or bike? Critically for applications, how successfully sensor devices are able to maximize the information contained across these multi-modal sensor streams often dictates the fidelity at which they can track user behaviors and context changes. This paper studies the benefits of adopting deep learning algorithms for interpreting user activity and context as captured by multi-sensor systems. Specifically, we focus on four variations of deep neural networks that are based either on fully-connected Deep Neural Networks (DNNs) or Convolutional Neural Networks (CNNs). Two of these architectures follow conventional deep models by performing feature representation learning from a concatenation of sensor types. This classic approach is contrasted with a promising deep model variant characterized by modality-specific partitions of the architecture to maximize intra-modality learning. Our exploration represents the first time these architectures have been evaluated for multimodal deep learning under wearable data -- and for convolutional layers within this architecture, it represents a novel architecture entirely. Experiments show these generic multimodal neural network models compete well with a rich variety of conventional hand-designed shallow methods (including feature extraction and classifier construction) and task-specific modeling pipelines, across a wide-range of sensor types and inference tasks (four different datasets). Although the training and inference overhead of these multimodal deep approaches is in some cases appreciable, we also demonstrate the feasibility of on-device mobile and wearable execution is not a barrier to adoption. This study is carefully constructed to focus on multimodal aspects of wearable data modeling for deep learning by providing a wide range of empirical observations, which we expect to have considerable value in the community. We summarize our observations into a series of practitioner rules-of-thumb and lessons learned that can guide the usage of multimodal deep learning for activity and context detection.","Volume 1 Issue 4, December 2017"
271,10.1145/3161162,"Gabriel Reyes, Jason Wu, Nikita Juneja, Maxim Goldshtein, W. Keith Edwards, Gregory D. Abowd, Thad Starner",SynchroWatch: One-Handed Synchronous Smartwatch Gestures Using Correlation and Magnetic Sensing,"SynchroWatch is a one-handed interaction technique for smartwatches that uses rhythmic correlation between a user's thumb movement and on-screen blinking controls. Our technique uses magnetic sensing to track the synchronous extension and reposition of the thumb, augmented with a passive magnetic ring. The system measures the relative changes in the magnetic field induced by the required thumb movement and uses a time-shifted correlation approach with a reference waveform for detection of synchrony. We evaluated the technique during three distraction tasks with varying degrees of hand and finger movement: active walking, browsing on a computer, and relaxing while watching online videos. Our initial offline results suggest that intentional synchronous gestures can be distinguished from other movement. A second evaluation using a live implementation of the system running on a smartwatch suggests that this technique is viable for gestures used to respond to notifications or issue commands. Finally, we present three demonstration applications that highlight the technique running in real-time on the smartwatch.","Volume 1 Issue 4, December 2017"
272,10.1145/3161187,"Sherry Ruan, Jacob O. Wobbrock, Kenny Liou, Andrew Ng, James A. Landay",Comparing Speech and Keyboard Text Entry for Short Messages in Two Languages on Touchscreen Phones,"With the ubiquity of mobile touchscreen devices like smartphones, two widely used text entry methods have emerged: small touch-based keyboards and speech recognition. Although speech recognition has been available on desktop computers for years, it has continued to improve at a rapid pace, and it is currently unknown how today's modern speech recognizers compare to state-of-the-art mobile touch keyboards, which also have improved considerably since their inception. To discover both methods' “upper-bound performance,” we evaluated them in English and Mandarin Chinese on an Apple iPhone 6 Plus in a laboratory setting. Our experiment was carried out using Baidu's Deep Speech 2, a deep learning-based speech recognition system, and the built-in Qwerty (English) or Pinyin (Mandarin) Apple iOS keyboards. We found that with speech recognition, the English input rate was 2.93 times faster (153 vs. 52 WPM), and the Mandarin Chinese input rate was 2.87 times faster (123 vs. 43 WPM) than the keyboard for short message transcription under laboratory conditions for both methods. Furthermore, although speech made fewer errors during entry (5.30% vs. 11.22% corrected error rate), it left slightly more errors in the final transcribed text (1.30% vs. 0.79% uncorrected error rate). Our results show that comparatively, under ideal conditions for both methods, upper-bound speech recognition performance has greatly improved compared to prior systems, and might see greater uptake in the future, although further study is required to quantify performance in non-laboratory settings for both methods.","Volume 1 Issue 4, December 2017"
273,10.1145/3161186,"Samiha Samrose, Ru Zhao, Jeffery White, Vivian Li, Luis Nova, Yichen Lu, Mohammad Rafayet Ali, Mohammed Ehsan Hoque",CoCo: Collaboration Coach for Understanding Team Dynamics during Video Conferencing,"We present and discuss a fully-automated collaboration system, CoCo, that allows multiple participants to video chat and receive feedback through custom video conferencing software. After a conferencing session, a virtual feedback assistant provides insights on the conversation to participants. CoCo automatically pulls audial and visual data during conversations and analyzes the extracted streams for affective features, including smiles, engagement, attention, as well as speech overlap and turn-taking. We validated CoCo with 39 participants split into 10 groups. Participants played two back-to-back team-building games, Lost at Sea and Survival on the Moon, with the system providing feedback between the two. With feedback, we found a statistically significant change in balanced participation---that is, everyone spoke for an equal amount of time. There was also statistically significant improvement in participants' self-evaluations of conversational skills awareness, including how often they let others speak, as well as of teammates' conversational skills. The entire framework is available at https://github.com/ROC-HCI/CollaborationCoach_PostFeedback.","Volume 1 Issue 4, December 2017"
274,10.1145/3161172,"Nazmus Saquib, Ayesha Bose, Dwyane George, Sepandar Kamvar",Sensei: Sensing Educational Interaction,"We present Sensei, the first system designed to understand social interaction and learning in an early-childhood classroom using a distributed sensor network. Our unobtrusive sensors measure proximity between each node in a dynamic range-based mesh network. The sensors can be worn in the shoes, attached to selected landmarks in the classroom, and placed on Montessori materials. This data, accessible to teachers in a web dashboard, enables teachers to derive deeper insights from their classrooms. Sensei is currently deployed in three Montessori schools and we have evaluated the effectiveness of the system with teachers. Our user studies have shown that the system enhances teachers' capabilities and helps discover insights that would have otherwise been lost. From our evaluation interviews, we have established three major use cases of the system. Sensei augments teachers' manual observations, helps them plan individualized curriculum for each student, and identifies their needs for more interaction with some children. Further, the anonymized data can be used in large-scale research in early childhood development.","Volume 1 Issue 4, December 2017"
275,10.1145/3161408,"Ankur Sarker, Haiying Shen, John A. Stankovic",MORP: Data-Driven Multi-Objective Route Planning and Optimization for Electric Vehicles,"The Wireless Power Transfer (WPT) system that enables in-motion charging (or wireless charging) for Electric Vehicles (EVs) has been introduced to resolve battery-related issues (such as long charging time, high cost, and short driving range) and increase the wide-acceptance of EVs. In this paper, we study the WPT system with the objectives of minimizing energy consumption, travel time, charging monetary cost on the way, and range anxiety for online EVs. Specifically, we propose the Multi-Objective Route Planner system (MORP) to guide EVs for the multi-objective routing. MORP incorporates two components: traffic state prediction and optimal route determination. For the traffic state prediction, we conducted analysis on a traffic dataset and observed spatial-temporal features of traffic patterns. Accordingly, we introduce the horizontal space-time Autoregressive Integrated Moving Average (ARIMA) model to predict vehicle counts (i.e., traffic volume) for locations with available historical traffic data. And, we use the spatial-temporal ordinary kriging method to predict vehicle counts for locations without historical traffic data. Based on vehicle counts, we use the non-parametric kernel regression method to predict velocity of road sections, which is used to predict travel time and then, energy consumption of a route of an EV with the help of the proposed energy consumption model. We also estimate charging monetary cost and EV related range anxiety based on unit energy cost, predicted travel time and energy consumption, and current onboard energy. We design four different cost functions (travel time, energy consumption, charging monetary cost, and range anxiety) of routing and formulate a multi-objective routing optimization problem. We use the predicted parameters as inputs of the optimization problem and find the optimal route using the adaptive epsilon constraint method. We evaluate our proposed MORP system in four different aspects (including traffic prediction, velocity prediction, energy consumption prediction, and EV routing). From the experimental studies, we find the effectiveness of the proposed MORP system in different aspects of the online EV routing system.","Volume 1 Issue 4, December 2017"
276,10.1145/3161178,"Taylan Sen, Md Kamrul Hasan, Zach Teicher, Mohammed Ehsan Hoque",Automated Dyadic Data Recorder (ADDR) Framework and Analysis of Facial Cues in Deceptive Communication,"We developed an online framework that can automatically pair two crowd-sourced participants, prompt them to follow a research protocol, and record their audio and video on a remote server. The framework comprises two web applications: an Automatic Quality Gatekeeper for ensuring only high quality crowd-sourced participants are recruited for the study, and a Session Controller which directs participants to play a research protocol, such as an interrogation game. This framework was used to run a research study for analyzing facial expressions during honest and deceptive communication using a novel interrogation protocol. The protocol gathers two sets of nonverbal facial cues in participants: features expressed during questions relating to the interrogation topic and features expressed during control questions. The framework and protocol were used to gather 151 dyadic conversations (1.3 million video frames). Interrogators who were lied to expressed the smile-related lip corner puller cue more often than interrogators who were being told the truth, suggesting that facial cues from interrogators may be useful in evaluating the honesty of witnesses in some contexts. Overall, these results demonstrate that this framework is capable of gathering high quality data which can identify statistically significant results in a communication study.","Volume 1 Issue 4, December 2017"
277,10.1145/3161416,"Lee Stearns, Uran Oh, Leah Findlater, Jon E. Froehlich",TouchCam: Realtime Recognition of Location-Specific On-Body Gestures to Support Users with Visual Impairments,"On-body interaction, which employs the user's own body as an interactive surface, offers several advantages over existing touchscreen devices: always-available control, an expanded input space, and additional proprioceptive and tactile cues that support non-visual use. While past work has explored a variety of approaches such as wearable depth cameras, bio-acoustics, and infrared reflectance (IR) sensors, these systems do not instrument the gesturing finger, do not easily support multiple body locations, and have not been evaluated with visually impaired users (our target). In this paper, we introduce TouchCam, a finger wearable to support location-specific, on-body interaction. TouchCam combines data from infrared sensors, inertial measurement units, and a small camera to classify body locations and gestures using supervised learning. We empirically evaluate TouchCam's performance through a series of offline experiments followed by a realtime interactive user study with 12 blind and visually impaired participants. In our offline experiments, we achieve high accuracy (&gt;96%) at recognizing coarse-grained touch locations (e.g., palm, fingers) and location-specific gestures (e.g., tap on wrist, left swipe on thigh). The follow-up user study validated our real-time system and helped reveal tradeoffs between various on-body interface designs (e.g., accuracy, convenience, social acceptability). Our findings also highlight challenges to robust input sensing for visually impaired users and suggest directions for the design of future on-body interaction systems.","Volume 1 Issue 4, December 2017"
278,10.1145/3161407,"Hamish Tennent, Dylan Moore, Wendy Ju",Character Actor: Design and Evaluation of Expressive Robot Car Seat Motion,"How might an actuated car seat become an expressive robot? To explore the possibilities of this novel interaction, we conducted a full design exploration from prototyping to validation, drawing on methods for embodied physical interaction design. First, we applied physical and digital puppeteering techniques to explore how a car seat can display emotional affect through movement with limited degrees of freedom in a semi-structured design workshop. Second, prototyped emotions were formalized with the Laban Effort framework and translated into computer animations. Third, we tested if lay users understood the expressions communicated by the animations in an online validation study on Amazon Mechanical Turk.
Participants generally agreed with our interpretation of six prototyped expressive states for the robot car seat (Neutral, Aggressive, Confident, Cool, Excited, and Quirky), and reported quantitative and qualitative reactions to each including perceived safety, which varied across conditions. Participants reported more implied cognition for higher valence expressions, and also were more likely to agree with our design intent. This specific case of physical interaction design and evaluation serves as a vignette for how to design and validate novel physical expressions in non-anthropomorphic robot interfaces.","Volume 1 Issue 4, December 2017"
279,10.1145/3161182,"Yuki Uno, Hao Qiu, Toru Sai, Shunta Iguchi, Yota Mizutani, Takayuki Hoshi, Yoshihiro Kawahara, Yasuaki Kakehi, Makoto Takamiya",Luciola: A Millimeter-Scale Light-Emitting Particle Moving in Mid-Air Based On Acoustic Levitation and Wireless Powering,"In this paper, we present an approach to realize the levitation of a small object with an embedded electronic circuit. Luciola is a light-emitting particle with a diameter of 3.5mm and a weight of 16.2mg moving in mid-air in a 10.4cm x 10.4cm x 5.4cm space through acoustic levitation using two 40-kHz 17 x 17 ultrasonic transducer arrays placed face-to-face at a distance of 20cm and wirelessly powered by 12.3-MHz resonant inductive coupling. The novelty of this paper is the acoustically levitated electronic object by the combined application of ultrasonic levitation and wireless powering to the levitated electronic object. A new shape of the levitated object and a new placement of the receiver coil to simultaneously realize acoustic levitation and wireless powering are proposed, achieving a stable wireless powering to a rotating levitated object at the bottom of an acoustic potential. To enable the levitation of a particle, a custom IC chip is essential in reducing the size and weight of the particle. In the design of the custom IC chip, a new voltage detector circuit enabling an accurate voltage detection and a correct output during the start-up is proposed to achieve an intermittent lighting of the LED to increase the maximum distance between the transmitter and the receiver coil. Luciola is applied to a self-luminous pixel in a mid-air display and drawings of characters in mid-air are demonstrated.","Volume 1 Issue 4, December 2017"
280,10.1145/3161195,"Stephen Uzor, Lynne Baillie",Exploring the Communication of Progress in Home-based Falls Rehabilitation using Exergame Technologies,"Little is known on how to effectively represent rehabilitation progress, over a period of time, using exercise game (exergame) technologies. Progress in falls rehabilitation, which consists of improved performance in balance and muscle strength, is essential to assuring seniors of a reduced risk of falling. In this paper, we build on our previous research into exergames for falls, and we investigate how an exergame system can be used to communicate long-term progress to seniors. Using a multiphase user-centered requirements gathering process, we first investigated stakeholder perspectives regarding progress in self-managed rehabilitation. Following this we describe the home-based evaluation of our prototype exergame system, which highlights rehabilitation progress, with seniors, over a period of 2 months. Progress, in our system is communicated using charts of exercise performance and frequency, as well as medals awarded for achieving longer-term rehabilitation milestones. We report on seniors' opinions and preferences regarding the potential of our exergame system to communicate this rehabilitation progress in a meaningful way. Finally we discuss implications for design, based on our studies, to inform the development of more effective exergame systems for long-term unassisted rehabilitation in the home.","Volume 1 Issue 4, December 2017"
281,10.1145/3161192,"Yonatan Vaizman, Nadir Weibel, Gert Lanckriet",Context Recognition In-the-Wild: Unified Model for Multi-Modal Sensors and Multi-Label Classification,"Automatic recognition of behavioral context (location, activities, body-posture etc.) can serve health monitoring, aging care, and many other domains. Recognizing context in-the-wild is challenging because of great variability in behavioral patterns, and it requires a complex mapping from sensor features to predicted labels. Data collected in-the-wild may be unbalanced and incomplete, with cases of missing labels or missing sensors. We propose using the multiple layer perceptron (MLP) as a multi-task model for context recognition. Based on features from multi-modal sensors, the model simultaneously predicts many diverse context labels. We analyze the advantages of the model's hidden layers, which are shared among all sensors and all labels, and provide insight to the behavioral patterns that these hidden layers may capture. We demonstrate how recognition of new labels can be improved when utilizing a model that was trained for an initial set of labels, and show how to train the model to withstand missing sensors. We evaluate context recognition on the previously published ExtraSensory Dataset, which was collected in-the-wild. Compared to previously suggested models, the MLP improves recognition, even with fewer parameters than a linear model. The ability to train a good model using data that has incomplete, unbalanced labeling and missing sensors encourages further research with uncontrolled, in-the-wild behavior.","Volume 1 Issue 4, December 2017"
282,10.1145/3161180,"Virag Varga, Gergely Vakulya, Alanson Sample, Thomas R. Gross",Enabling Interactive Infrastructure with Body Channel Communication,"Body channel communication (BCC) uses the human body to carry signals, and therefore provides communication and localization that are directly tied to human presence and actions. Previous BCC systems were expensive, could operate only in a laboratory, or only focused on special use cases. We present here an end-to-end BCC system that is designed for ambient intelligence. We introduce the BCC infrastructure that consists of portable devices (e.g., a simple sphere), mobile devices (e.g., a smartwatch-like wristband), and stationary devices (e.g., floor/wall tiles). We also describe the core technology that is used in each of these units. The TouchCom hardware-software platform is a simple transceiver with software-centered processing. The focus on software (even the implementation of the physical layer is based on software) allows the adaptivity that is necessary to operate a BCC-based system in practice. The paper describes the design and a prototype implementation of the TouchCom-based interactive infrastructure and provides evidence that this BCC infrastructure works for different persons and different setups. The system provides moderate bandwidth (about 3.5 kb/s) that is suitable for several usage scenarios like games, localization, and identification. The implemented demonstrations illustrate the benefits these applications gain when touching an object is tied to communication.","Volume 1 Issue 4, December 2017"
283,10.1145/3161188,"Tianben Wang, Daqing Zhang, Yuanqing Zheng, Tao Gu, Xingshe Zhou, Bernadette Dorizzi",C-FMCW Based Contactless Respiration Detection Using Acoustic Signal,"Recent advances in ubiquitous sensing technologies have exploited various approaches to monitoring vital signs. One of the vital signs is human respiration which typically requires reliable monitoring with low error rate in practice. Previous works in respiration monitoring however either incur high cost or suffer from poor error rate. In this paper, we propose a Correlation based Frequency Modulated Continuous Wave method (C-FMCW) which is able to achieve high ranging resolution. Based on C-FMCW, we present the design and implementation of an audio-based highly-accurate system for human respiration monitoring, leveraging on commodity speaker and microphone widely available in home environments. The basic idea behind the audio-based method is that when a user is close to a pair of speaker and microphone, body movement during respiration causes periodic audio signal changes, which can be extracted to obtain the respiration rate. However, several technical challenges exist when applying C-FMCW to detect respiration with commodity acoustic devices. First, the sampling frequency offset between speakers and microphones if not being corrected properly would cause high ranging errors. Second, the uncertain starting time difference between the speaker and microphone varies over time. Moreover, due to multipath effect, weak periodic components due to respiration can easily be overwhelmed by strong static components in practice. To address those challenges, we 1) propose an algorithm to compensate dynamically acoustic signal and counteract the offset between speaker and microphone; 2) co-locate speaker and microphone and use the received signal without reflection (self-interference) as a reference to eliminate the starting time difference; and 3) leverage the periodicity of respiration to extract weak periodic components with autocorrelation. Extensive experimental results show that our system detects respiration in real environments with the median error lower than 0.35 breaths/min, outperforming the state-of-the-arts.","Volume 1 Issue 4, December 2017"
284,10.1145/3161164,"Chatchai Wangwiwattana, Xinyi Ding, Eric C. Larson","PupilNet, Measuring Task Evoked Pupillary Response using Commodity RGB Tablet Cameras: Comparison to Mobile, Infrared Gaze Trackers for Inferring Cognitive Load","Pupillary diameter monitoring has been proven successful at objectively measuring cognitive load that might otherwise be unobservable. This paper compares three different algorithms for measuring cognitive load using commodity cameras. We compare the performance of modified starburst algorithm (from previous work) and propose two new algorithms: 2 Level Snakuscules and a convolutional neural network which we call PupilNet. In a user study with eleven participants, our comparisons show PupilNet outperforms other algorithms in measuring pupil dilation, is robust to various lighting conditions, and robust to different eye colors. We show that the difference between PupilNet and a gold standard head-mounted gaze tracker varies only from -2.6% to 2.8%. Finally, we also show that PupilNet gives similar conclusions about cognitive load during a longer duration typing task.","Volume 1 Issue 4, December 2017"
285,10.1145/3161415,"Yang Xu, Wei Yang, Jianxin Wang, Xing Zhou, Hong Li, Liusheng Huang",WiStep: Device-free Step Counting with WiFi Signals,"Inspired by the emerging WiFi-based applications, in this paper, we leverage ubiquitous WiFi signals and propose a device-free step counting system, called WiStep. Based on the multipath propagation model, when a person is walking, her torso and limbs move at different speeds, which modulates wireless signals to the propagation paths with different lengths and thus introduces different frequency components into the received Channel State Information (CSI). To count walking steps, we first utilize time-frequency analysis techniques to segment and recognize the walking movement, and then dynamically select the sensitive subcarriers with largest amplitude variances from multiple CSI streams. Wavelet decomposition is applied to extract the detail coefficients corresponding to the frequencies induced by feet or legs, and compress the data so as to improve computing speed. Short-time energy of the coefficients is then calculated as the metric for step counting. Finally, we combine the results derived from the selected subcarriers to produce a reliable step count estimation. In contrast to counting steps based on the torso frequency analysis, WiStep can count the steps of in-place walking even when the person's torso speed is null. We implement WiStep on commodity WiFi devices in two different indoor scenarios, and various influence factors are taken into consideration when evaluating the performance of WiStep. The experimental results demonstrate that WiStep can realize overall step counting accuracies of 90.2% and 87.59% respectively in these two scenarios, and it is resilient to the change of scenarios.","Volume 1 Issue 4, December 2017"
286,10.1145/3161181,"Shuochao Yao, Yiran Zhao, Huajie Shao, Aston Zhang, Chao Zhang, Shen Li, Tarek Abdelzaher",RDeepSense: Reliable Deep Mobile Computing Models with Uncertainty Estimations,"Recent advances in deep learning have led various applications to unprecedented achievements, which could potentially bring higher intelligence to a broad spectrum of mobile and ubiquitous applications. Although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices, they overlooked the reliability of mobile computing models. Reliability measurements such as predictive uncertainty estimations are key factors for improving the decision accuracy and user experience. In this work, we propose RDeepSense, the first deep learning model that provides well-calibrated uncertainty estimations for resource-constrained mobile and embedded devices. RDeepSense enables the predictive uncertainty by adopting a tunable proper scoring rule as the training criterion and dropout as the implicit Bayesian approximation, which theoretically proves its correctness. To reduce the computational complexity, RDeepSense employs efficient dropout and predictive distribution estimation instead of the model ensemble or sampling-based method for inference operations. We evaluate RDeepSense with four mobile sensing applications using Intel Edison devices. Results show that RDeepSense can reduce around 90% of the energy consumption while producing superior uncertainty estimations and preserving at least the same model accuracy compared with other state-of-the-art methods.","Volume 1 Issue 4, December 2017"
287,10.1145/3161413,"Donghan Yu, Yong Li, Fengli Xu, Pengyu Zhang, Vassilis Kostakos",Smartphone App Usage Prediction Using Points of Interest,"In this paper we present the first population-level, city-scale analysis of application usage on smartphones. Using deep packet inspection at the network operator level, we obtained a geo-tagged dataset with more than 6 million unique devices that launched more than 10,000 unique applications across the city of Shanghai over one week. We develop a technique that leverages transfer learning to predict which applications are most popular and estimate the whole usage distribution based on the Point of Interest (POI) information of that particular location. We demonstrate that our technique has an 83.0% hitrate in successfully identifying the top five popular applications, and a 0.15 RMSE when estimating usage with just 10% sampled sparse data. It outperforms by about 25.7% over the existing state-of-the-art approaches. Our findings pave the way for predicting which apps are relevant to a user given their current location, and which applications are popular where. The implications of our findings are broad: it enables a range of systems to benefit from such timely predictions, including operating systems, network operators, appstores, advertisers, and service providers.","Volume 1 Issue 4, December 2017"
288,10.1145/3161200,"Shuo Zhang, Khaled Alanezi, Mike Gartrell, Richard Han, Qin Lv, Shivakant Mishra",Understanding Group Event Scheduling via the OutWithFriendz Mobile Application,"The wide adoption of smartphones and mobile applications has brought significant changes to not only how individuals behave in the real world, but also how groups of users interact with each other when organizing group events. Understanding how users make event decisions as a group and identifying the contributing factors can offer important insights for social group studies and more effective system and application design for group event scheduling.
In this work, we have designed a new mobile application called OutWithFriendz, which enables users of our mobile app to organize group events, invite friends, suggest and vote on event time and venue. We have deployed OutWithFriendz at both Apple App Store and Google Play, and conducted a large-scale user study spanning over 500 users and 300 group events. Our analysis has revealed several important observations regarding group event planning process including the importance of user mobility, individual preferences, host preferences, and group voting process.","Volume 1 Issue 4, December 2017"
289,10.1145/3161414,"Xiao Zhang, Wenzhong Li, Xu Chen, Sanglu Lu",MoodExplorer: Towards Compound Emotion Detection via Smartphone Sensing,"Social psychology and neuroscience had confirmed that emotion state exerts a significant effect on human communication, perception, social behavior and decision making. With the wide availability of smartphones equipped with microphone, accelerometer, GPS, and other source of sensors, it is worthwhile to explore the possibility of automatic emotion detection via smartphone sensing. Particularly, we focus on a novel research problem that tries to detect the compound emotion (a set of multiple dimensional basic emotions) of smartphone users. We observe that users' self-reported emotional states have high correlation with their smartphone usage patterns and sensing data. Based on the observations, we exploit a feature extraction and selection algorithm to find the most significant features. We further adopt a factor graph model to tackle the correlations between features and emotion labels, and propose a machine learning algorithm for compound emotion detection based on the smartphone sensing data. The proposed mechanism is implemented as an APP called MoodExplorer in Android platform. Extensive experiments conducted on the smartphone data collected from 30 university students show that MoodExplorer can recognize users' compound emotions with 76.0% exact match on average.","Volume 1 Issue 4, December 2017"
290,10.1145/3161410,"Yongtuo Zhang, Wen Hu, Weitao Xu, Chun Tung Chou, Jiankun Hu",Continuous Authentication Using Eye Movement Response of Implicit Visual Stimuli,"Smart head-worn or head-mounted devices, including smart glasses and Virtual Reality (VR) headsets, are gaining popularity. Online shopping and in-app purchase from such headsets are presenting new e-commerce opportunities to the app developers. For convenience, users of these headsets may store account login, bank account and credit card details in order to perform quick in-app purchases. If the device is unattended, then an attacker, which can include insiders, can make use of the stored account and banking details to perform their own in-app purchases at the expense of the legitimate owner. To better protect the legitimate users of VR headsets (or head mounted displays in general) from such threats, in this paper, we propose to use eye movement to continuously authenticate the current wearer of the VR headset. We built a prototype device which allows us to apply visual stimuli to the wearer and to video the eye movements of the wearer at the same time. We use implicit visual stimuli (the contents of existing apps) which evoke eye movements from the headset wearer but without distracting them from their normal activities. This is so that we can continuously authenticate the wearer without them being aware of the authentication running in the background. We evaluated our proposed system experimentally with 30 subjects. Our results showed that the achievable authentication accuracy for implicit visual stimuli is comparable to that of using explicit visual stimuli. We also tested the time stability of our proposed method by collecting eye movement data on two different days that are two weeks apart. Our authentication method achieved an Equal Error Rate of 6.9% (resp. 9.7%) if data collected from the same day (resp. two weeks apart) were used for testing. In addition, we considered active impersonation attacks where attackers trying to imitate legitimate users' eye movements. We found that for a simple (resp. complex) eye tracking scene, a successful attack could be realised after on average 5.67 (13.50) attempts and our proposed authentication algorithm gave a false acceptance rate of 14.17% (3.61%). These results show that active impersonating attacks can be prevented using complex scenes and an appropriate limit on the number of authentication attempts. Lastly, we carried out a survey to study the user acceptability to our proposed implicit stimuli. We found that on a 5-point Likert scale, at least 60% of the respondents either agreed or strongly agreed that our proposed implicit stimuli were non-intrusive.","Volume 1 Issue 4, December 2017"
291,10.1145/3130898,"Yomna Abdelrahman, Eduardo Velloso, Tilman Dingler, Albrecht Schmidt, Frank Vetere",Cognitive Heat: Exploring the Usage of Thermal Imaging to Unobtrusively Estimate Cognitive Load,"Current digital systems are largely blind to users’ cognitive states. Systems that adapt to users’ states show great potential for augmenting cognition and for creating novel user experiences. However, most approaches for sensing cognitive states, and cognitive load specifically, involve obtrusive technologies, such as physiological sensors attached to users’ bodies. This paper present an unobtrusive indicator of the users’ cognitive load based on thermal imaging that is applicable in real-world. We use a commercial thermal camera to monitor a person’s forehead and nose temperature changes to estimate their cognitive load. To assess the effect of different levels of cognitive load on facial temperature we conducted a user study with 12 participants. The study showed that different levels of the Stroop test and the complexity of reading texts affect facial temperature patterns, thereby giving a measure of cognitive load. To validate the feasibility for real-time assessments of cognitive load, we conducted a second study with 24 participants, we analyzed the temporal latency of temperature changes. Our system detected temperature changes with an average latency of 0.7 seconds after users were exposed to a stimulus, outperforming latency in related work that used other thermal imaging techniques. We provide empirical evidence showing how to unobtrusively detect changes in cognitive load in real-time. Our exploration of exposing users to different content types gives rise to thermal-based activity tracking, which facilitates new applications in the field of cognition-aware computing.","Volume 1 Issue 3, September 2017"
292,10.1145/3130899,"Parastoo Abtahi, David Y. Zhao, Jane L. E., James A. Landay",Drone Near Me: Exploring Touch-Based Human-Drone Interaction,"Personal drones are becoming more mainstream and are used for a variety of tasks, such as delivery and photography. The exposed blades in conventional drones raise serious safety concerns. To address this, commercial drones have been moving towards a safe-to-touch design or have increased safety by adding propeller guards. The affordances of safe-to-touch drones enable new types of touch-based human-drone interaction. Various applications have been explored, such as augmented sports and haptic feedback in virtual reality; however, it is unclear if individuals feel comfortable using direct touch and manipulation when interacting with safe-to-touch drones. A previous elicitation study showed how users naturally interact with drones. We replicated this study with an unsafe and a safe-to-touch drone, to find out if participants will instinctively use touch as a means of interacting with the safe-to-touch drone. We found that 58% of the participants used touch, and across all tasks 39% of interactions were touch-based. The proposed touch interactions were in agreement for 67% of the tasks, and users reported that interacting with the safe-to-touch drone was significantly less mentally demanding than the unsafe drone.","Volume 1 Issue 3, September 2017"
293,10.1145/3131904,"Mozhgan Azimpourkivi, Umut Topkara, Bogdan Carbunar",Camera Based Two Factor Authentication Through Mobile and Wearable Devices,"We introduce Pixie, a novel, camera based two factor authentication solution for mobile and wearable devices. A quick and familiar user action of snapping a photo is sufficient for Pixie to simultaneously perform a graphical password authentication and a physical token based authentication, yet it does not require any expensive, uncommon hardware. Pixie establishes trust based on both the knowledge and possession of an arbitrary physical object readily accessible to the user, called trinket. Users choose their trinkets similar to setting a password, and authenticate by presenting the same trinket to the camera. The fact that the object is the trinket, is secret to the user. Pixie extracts robust, novel features from trinket images, and leverages a supervised learning classifier to effectively address inconsistencies between images of the same trinket captured in different circumstances.
Pixie achieved a false accept rate below 0.09% in a brute force attack with 14.3 million authentication attempts, generated with 40,000 trinket images that we captured and collected from public datasets. We identify master images, that match multiple trinkets, and study techniques to reduce their impact.
In a user study with 42 participants over 8 days in 3 sessions we found that Pixie outperforms text based passwords on memorability, speed, and user preference. Furthermore, Pixie was easily discoverable by new users and accurate under field use. Users were able to remember their trinkets 2 and 7 days after registering them, without any practice between the 3 test dates.","Volume 1 Issue 3, September 2017"
294,10.1145/3130901,"David Beattie, Lynne Baillie, Martin Halvey",Exploring How Drivers Perceive Spatial Earcons in Automated Vehicles,"Automated vehicles seek to relieve the human driver from primary driving tasks, but this substantially diminishes the connection between driver and vehicle compared to manual operation. At present, automated vehicles lack any form of continual, appropriate feedback to re-establish this connection and offer a feeling of control. We suggest that auditory feedback can be used to support the driver in this context. A preliminary field study that explored how drivers respond to existing auditory feedback in manual vehicles was first undertaken. We then designed a set of abstract, synthesised sounds presented spatially around the driver, known as Spatial Earcons, that represented different primary driving sounds e.g. acceleration. To evaluate their effectiveness, we undertook a driving simulator study in an outdoor setting using a real vehicle. Spatial Earcons performed as well as Existing Vehicle Sounds during automated and manual driving scenarios. Subjective responses suggested Spatial Earcons produced an engaging driving experience. This paper argues that entirely new synthesised primary driving sounds, such as Spatial Earcons, can be designed for automated vehicles to replace Existing Vehicle Sounds. This creates new possibilities for presenting primary driving information in automated vehicles using auditory feedback, in order to re-establish a connection between driver and vehicle.","Volume 1 Issue 3, September 2017"
295,10.1145/3130902,"Abdelkareem Bedri, Richard Li, Malcolm Haynes, Raj Prateek Kosaraju, Ishaan Grover, Temiloluwa Prioleau, Min Yan Beh, Mayank Goel, Thad Starner, Gregory Abowd",EarBit: Using Wearable Sensors to Detect Eating Episodes in Unconstrained Environments,"Chronic and widespread diseases such as obesity, diabetes, and hypercholesterolemia require patients to monitor their food intake, and food journaling is currently the most common method for doing so. However, food journaling is subject to self-bias and recall errors, and is poorly adhered to by patients. In this paper, we propose an alternative by introducing EarBit, a wearable system that detects eating moments. We evaluate the performance of inertial, optical, and acoustic sensing modalities and focus on inertial sensing, by virtue of its recognition and usability performance. Using data collected in a simulated home setting with minimum restrictions on participants’ behavior, we build our models and evaluate them with an unconstrained outside-the-lab study. For both studies, we obtained video footage as ground truth for participants activities. Using leave-one-user-out validation, EarBit recognized all the eating episodes in the semi-controlled lab study, and achieved an accuracy of 90.1% and an F1-score of 90.9% in detecting chewing instances. In the unconstrained, outside-the-lab evaluation, EarBit obtained an accuracy of 93% and an F1-score of 80.1% in detecting chewing instances. It also accurately recognized all but one recorded eating episodes. These episodes ranged from a 2 minute snack to a 30 minute meal.","Volume 1 Issue 3, September 2017"
296,10.1145/3130903,"R. N. Brewer, M. R. Morris, S. E. Lindley",How to Remember What to Remember: Exploring Possibilities for Digital Reminder Systems,"Digital reminder systems typically use time and place as triggers to remind people to perform activities. In this paper, we investigate how digital reminder systems could better support the process of remembering in a wider range of situations. We report findings from a survey and one-week diary study, which reveal that people want to remember to perform a broad spectrum of activities in the future, many of which cannot be supported by simple time- and location-based reminders. In addition to these examples of prospective memory, or ‘remembering intentions’ [53], we also find that people want support in ‘retrieving’ [53] information and details, especially those encountered through social interactions or intended for use in conversations with others. Drawing on our analysis of what people want to remember and how they try to support this, we draw implications for the design of intelligent reminder systems such as digital assistants (e.g. Microsoft’s Cortana) and smart speaker systems (e.g. Amazon Echo), and highlight the possibilities afforded by drawing on conversation and giving material form to digital reminders.","Volume 1 Issue 3, September 2017"
297,10.1145/3131900,"Matthias Budde, Andrea Schankin, Julien Hoffmann, Marcel Danz, Till Riedel, Michael Beigl",Participatory Sensing or Participatory Nonsense?: Mitigating the Effect of Human Error on Data Quality in Citizen Science,"Citizen Science with mobile and wearable technology holds the possibility of unprecedented observation systems. Experts and policy makers are torn between enthusiasm and scepticism regarding the value of the resulting data, as their decision making traditionally relies on high-quality instrumentation and trained personnel measuring in a standardized way. In this paper, we (1) present an empirical behavior taxonomy of errors exhibited in non-expert smartphone-based sensing, based on four small exploratory studies, and discuss measures to mitigate their effects. We then present a large summative study (N=535) that compares instructions and technical measures to address these errors, both from the perspective of improvements to error frequency and perceived usability. Our results show that (2) technical measures without explanation notably reduce the perceived usability and (3) technical measures and instructions nicely complement each other: Their combination achieves a significant reduction in observed error rates while not affecting the user experience negatively.","Volume 1 Issue 3, September 2017"
298,10.1145/3130905,"Andrew M. Carek, Jordan Conant, Anirudh Joshi, Hyolim Kang, Omer T. Inan",SeismoWatch: Wearable Cuffless Blood Pressure Monitoring Using Pulse Transit Time,"The current norm for measuring blood pressure (BP) at home is using an automated BP cuff based on oscillometry. Despite providing a viable and familiar method of tracking BP at home, oscillometric devices can be both cumbersome and inaccurate with the inconvenience of the hardware typically limiting measurements to once or twice per day. To address these limitations, a wrist-watch BP monitor was developed to measure BP through a simple maneuver: holding the watch against the sternum to detect micro-vibrations of the chest wall associated with the heartbeat. As a pulse wave propagates from the heart to the wrist, an accelerometer and optical sensor on the watch measure the travel time -- pulse transit time (PTT) -- to estimate BP. In this paper, we conducted a study to test the accuracy and repeatability of our device. After calibration, the diastolic pressure estimations reached a root-mean-square error of 2.9 mmHg. The watch-based system significantly outperformed (p&lt;0.05) conventional pulse arrival time (PAT) based wearable blood pressure estimations -- the most commonly used method for wearable BP sensing in the existing literature and commercial devices. Our device can be a convenient means for wearable BP monitoring outside of clinical settings in both health-conscious and hypertensive populations.","Volume 1 Issue 3, September 2017"
299,10.1145/3130906,"Yuanying Chen, Wei Dong, Yi Gao, Xue Liu, Tao Gu",Rapid: A Multimodal and Device-free Approach Using Noise Estimation for Robust Person Identification,"Device-free human sensing is a key technology to support many applications such as indoor navigation and activity recognition. By exploiting WiFi signals reflected by human body, there have been many WiFi-based device-free human sensing applications. Among these applications, person identification is a fundamental technology to enable user-specific services. In this paper, we present Rapid, a system that can perform robust person identification in a device-free and low-cost manner, using fine-grained channel information (i.e., CSI) of WiFi and acoustic information from footstep sound. In order to achieve high accuracy in real-life scenarios with both system and environment noise, we perform noise estimation and include two different confidence values to quantify the impact of noise to both CSI and acoustic measurements. Based on an accurate gait analysis, we then adaptively fuse CSI and acoustic measurements to achieve robust person identification. We implement low-cost Rapid nodes and evaluate our system using experiments at multiple locations with a total of 1800 gait instances from 20 volunteers, and the results show that Rapid identifies a subject with an average accuracy of 92% to 82% from a group of 2 to 6 subjects, respectively.","Volume 1 Issue 3, September 2017"
300,10.1145/3132029,"Saksham Chitkara, Nishad Gothoskar, Suhas Harish, Jason I. Hong, Yuvraj Agarwal",Does this App Really Need My Location?: Context-Aware Privacy Management for Smartphones,"The enormous popularity of smartphones, their rich sensing capabilities, and the data they have about their users have lead to millions of apps being developed and used. However, these capabilities have also led to numerous privacy concerns. Platform manufacturers, as well as researchers, have proposed numerous ways of mitigating these concerns, primarily by providing fine-grained visibility and privacy controls to the user on a per-app basis. In this paper, we show that this per-app permission approach is suboptimal for many apps, primarily because most data accesses occur due to a small set of popular third-party libraries which are common across multiple apps. To address this problem, we present the design and implementation of ProtectMyPrivacy (PmP) for Android, which can detect critical contextual information at runtime when privacy-sensitive data accesses occur. In particular, PmP infers the purpose of the data access, i.e. whether the data access is by a third-party library or by the app itself for its functionality. Based on crowdsourced data, we show that there are in fact a set of 30 libraries which are responsible for more than half of private data accesses. Controlling sensitive data accessed by these libraries can therefore be an effective mechanism for managing their privacy. We deployed our PmP app to 1,321 real users, showing that the number of privacy decisions that users have to make are significantly reduced. In addition, we show that our users are better protected against data leakage when using our new library-based blocking mechanism as compared to the traditional app-level permission mechanisms.","Volume 1 Issue 3, September 2017"
301,10.1145/3131902,"Eunji Chong, Katha Chanda, Zhefan Ye, Audrey Southerland, Nataniel Ruiz, Rebecca M. Jones, Agata Rozga, James M. Rehg",Detecting Gaze Towards Eyes in Natural Social Interactions and Its Use in Child Assessment,"Eye contact is a crucial element of non-verbal communication that signifies interest, attention, and participation in social interactions. As a result, measures of eye contact arise in a variety of applications such as the assessment of the social communication skills of children at risk for developmental disorders such as autism, or the analysis of turn-taking and social roles during group meetings. However, the automated measurement of visual attention during naturalistic social interactions is challenging due to the difficulty of estimating a subject’s looking direction from video. This paper proposes a novel approach to eye contact detection during adult-child social interactions in which the adult wears a point-of-view camera which captures an egocentric view of the child’s behavior. By analyzing the child’s face regions and inferring their head pose we can accurately identify the onset and duration of the child’s looks to their social partner’s eyes. We introduce the Pose-Implicit CNN, a novel deep learning architecture that predicts eye contact while implicitly estimating the head pose. We present a fully automated system for eye contact detection that solves the sub-problems of end-to-end feature learning and pose estimation using deep neural networks. To train our models, we use a dataset comprising 22 hours of 156 play session videos from over 100 children, half of whom are diagnosed with Autism Spectrum Disorder. We report an overall precision of 0.76, recall of 0.80, and an area under the precision-recall curve of 0.79, all of which are significant improvements over existing methods.","Volume 1 Issue 3, September 2017"
302,10.1145/3132031,"Meghan Clark, Mark W. Newman, Prabal Dutta","Devices and Data and Agents, Oh My: How Smart Home Abstractions Prime End-User Mental Models","With the advent of DIY smart homes and the Internet of Things comes the emergence of user interfaces for domestic human-building interaction. However, the design trade-offs between the different representations of a smart home’s capabilities are still not well-understood. In this work, we examine how four different smart home abstractions affect end users’ mental models of a hypothetical system. We develop four questionnaires, each of which describes the same hypothetical smart home using a different abstraction, and then we collect responses depicting desired smart home applications from over 1,500 Mechanical Turk workers. We find that the choice of abstraction strongly primes end users’ responses. In particular, the purely device-oriented abstraction results in the most limited scenarios, suggesting that if we want users to associate smart home technologies with valuable high-level applications we should shift the UI paradigm for the Internet of Things from device-oriented control to other abstractions that inspire a greater diversity of interactions.","Volume 1 Issue 3, September 2017"
303,10.1145/3130910,"Christopher Clarke, Alessio Bellino, Augusto Esteves, Hans Gellersen",Remote Control by Body Movement in Synchrony with Orbiting Widgets: an Evaluation of TraceMatch,"In this work we consider how users can use body movement for remote control with minimal effort and maximum flexibility. TraceMatch is a novel technique where the interface displays available controls as circular widgets with orbiting targets, and where users can trigger a control by mimicking the displayed motion. The technique uses computer vision to detect circular motion as a uniform type of input, but is highly appropriable as users can produce matching motion with any part of their body. We present three studies that investigate input performance with different parts of the body, user preferences, and spontaneous choice of movements for input in realistic application scenarios. The results show that users can provide effective input with their head, hands and while holding objects, that multiple controls can be effectively distinguished by the difference in presented phase and direction of movement, and that users choose and switch modes of input seamlessly.","Volume 1 Issue 3, September 2017"
304,10.1145/3130911,"Nediyana Daskalova, Karthik Desingh, Alexandra Papoutsaki, Diane Schulze, Han Sha, Jeff Huang",Lessons Learned from Two Cohorts of Personal Informatics Self-Experiments,"Self-experiments allow people to investigate their own individual outcomes from behavior change, often with the aid of personal tracking devices. The challenge is to design scientifically valid self-experiments that can reach conclusive results. In this paper, we aim to understand how novices run self-experiments when they are provided with a structured lesson in experimental design. We conducted a study on self-experimentation with two cohorts of students, where a total of 34 students performed a self-experiment of their choice. In the first cohort, students were given only two restrictions: a specific number of variables to track and a set duration for the study. The findings from this cohort helped us generate concrete guidelines for running a self-experiment, and use them as the format for the next cohort. A second cohort of students used these guidelines to conduct their own self-experiments in a more structured manner. Based on the findings from both cohorts, we propose a set of guidelines for running successful self-experiments that address the pitfalls encountered by students in the study, such as inadequate study design and analysis methods. We also discuss broader implications for future self-experimenters and designers of tools for self-experimentation.","Volume 1 Issue 3, September 2017"
305,10.1145/3132025,"Tilman Dingler, Albrecht Schmidt, Tonja Machulla",Building Cognition-Aware Systems: A Mobile Toolkit for Extracting Time-of-Day Fluctuations of Cognitive Performance,"People’s alertness fluctuates across the day: at some times we are highly focused while at others we feel unable to concentrate. So far, extracting fluctuation patterns has been time and cost-intensive. Using an in-the-wild approach with 12 participants, we evaluated three cognitive tasks regarding their adequacy as a mobile and economical assessment tool of diurnal changes in mental performance. Participants completed the five-minute test battery on their smartphones multiple times a day for a period of 1-2 weeks. Our results show that people’s circadian rhythm can be obtained under unregulated non-laboratory conditions. Along with this validation study, we release our test battery as an open source library for future work towards cognition-aware systems as well as a tool for psychological and medical research. We discuss ways of integrating the toolkit and possibilities for implicitly measuring performance variations in common applications. The ability to detect systematic patterns in alertness levels will allow cognition-aware systems to provide in-situ assistance in accordance with users’ current cognitive capabilities and limitations.","Volume 1 Issue 3, September 2017"
306,10.1145/3130913,"Afsaneh Doryab, Victoria Bellotti, Alaaeddine Yousfi, Shuobi Wu, John M. Carroll, Anind K. Dey",If It’s Convenient: Leveraging Context in Peer-to-Peer Variable Service Transaction Recommendations,"Peer-to-Peer Variable Service Transaction (P2P-VST) systems enable people to offer and receive help with a wide range of task types. However, such services are hampered by the difficulty of finding relevant and convenient opportunities for transactions in a timely fashion. Many transaction opportunities are missed as a consequence of members not being aware of offers and/or requests from people nearby or en route that match their needs and/or abilities. In this paper, we explore the impact of context-awareness on P2P-VSTs to address this problem. Using mobile technology and an in situ study, we evaluate how recommending service requests targeted at a person’s context impacts their willingness to enter a transaction. Our results show that, even when people have not actively volunteered for a service, they are significantly more likely to accept a transaction opportunity if it is convenient for them in terms of time and location. These findings demonstrate how context-aware technology holds the promise of increasing the efficiency and activity level in P2P-VST systems.","Volume 1 Issue 3, September 2017"
307,10.1145/3130914,"Ujwal Gadiraju, Alessandro Checco, Neha Gupta, Gianluca Demartini",Modus Operandi of Crowd Workers: The Invisible Role of Microtask Work Environments,"The ubiquity of the Internet and the widespread proliferation of electronic devices has resulted in flourishing microtask crowdsourcing marketplaces, such as Amazon MTurk. An aspect that has remained largely invisible in microtask crowdsourcing is that of work environments; defined as the hardware and software affordances at the disposal of crowd workers which are used to complete microtasks on crowdsourcing platforms. In this paper, we reveal the significant role of work environments in the shaping of crowd work. First, through a pilot study surveying the good and bad experiences workers had with UI elements in crowd work, we revealed the typical issues workers face. Based on these findings, we then deployed over 100 distinct microtasks on CrowdFlower, addressing workers in India and USA in two identical batches. These tasks emulate the good and bad UI element designs that characterize crowdsourcing microtasks. We recorded hardware specifics such as CPU speed and device type, apart from software specifics including the browsers used to complete tasks, operating systems on the device, and other properties that define the work environments of crowd workers. Our findings indicate that crowd workers are embedded in a variety of work environments which influence the quality of work produced. To confirm and validate our data-driven findings we then carried out semi-structured interviews with a sample of Indian and American crowd workers from this platform. Depending on the design of UI elements in microtasks, we found that some work environments support crowd workers more than others. Based on our overall findings resulting from all the three studies, we introduce ModOp, a tool that helps to design crowdsourcing microtasks that are suitable for diverse crowd work environments. We empirically show that the use of ModOp results in reducing the cognitive load of workers, thereby improving their user experience without affecting the accuracy or task completion time.","Volume 1 Issue 3, September 2017"
308,10.1145/3131895,"Petko Georgiev, Sourav Bhattacharya, Nicholas D. Lane, Cecilia Mascolo",Low-resource Multi-task Audio Sensing for Mobile and Embedded Devices via Shared Deep Neural Network Representations,"Continuous audio analysis from embedded and mobile devices is an increasingly important application domain. More and more, appliances like the Amazon Echo, along with smartphones and watches, and even research prototypes seek to perform multiple discriminative tasks simultaneously from ambient audio; for example, monitoring background sound classes (e.g., music or conversation), recognizing certain keywords (‘Hey Siri' or ‘Alexa'), or identifying the user and her emotion from speech. The use of deep learning algorithms typically provides state-of-the-art model performances for such general audio tasks. However, the large computational demands of deep learning models are at odds with the limited processing, energy and memory resources of mobile, embedded and IoT devices.
In this paper, we propose and evaluate a novel deep learning modeling and optimization framework that specifically targets this category of embedded audio sensing tasks. Although the supported tasks are simpler than the task of speech recognition, this framework aims at maintaining accuracies in predictions while minimizing the overall processor resource footprint. The proposed model is grounded in multi-task learning principles to train shared deep layers and exploits, as input layer, only statistical summaries of audio filter banks to further lower computations.
We find that for embedded audio sensing tasks our framework is able to maintain similar accuracies, which are observed in comparable deep architectures that use single-task learning and typically more complex input layers. Most importantly, on an average, this approach provides almost a 2.1× reduction in runtime, energy, and memory for four separate audio sensing tasks, assuming a variety of task combinations.","Volume 1 Issue 3, September 2017"
309,10.1145/3130916,"Jorge Goncalves, Simo Hosio, Niels van Berkel, Furqan Ahmed, Vassilis Kostakos",CrowdPickUp: Crowdsourcing Task Pickup in the Wild,"We develop and evaluate a new ubiquitous crowdsourcing platform called CrowdPickUp, that combines the advantages of mobile and situated crowdsourcing to overcome their respective limitations. In a 19-day long field study with 70 participants, we evaluate the quality of work that CrowdPickUp produces. In particular, we measure quality in terms of worker performance in a variety of tasks (requiring local knowledge, location-based, general) while using a number of different quality control mechanisms, and also capture workers’ perceptions of the platform. Our findings show that workers of CrowdPickUp contributed data of comparable quality to previously presented crowdsourcing deployments while at the same time allowing for a wide breadth of tasks to be deployed. Finally, we offer insights towards the continued exploration of this research agenda.","Volume 1 Issue 3, September 2017"
310,10.1145/3130917,"Nitesh Goyal, Susan R. Fussell",Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking,"Sensemaking tasks are difficult to accomplish with limited time and attentional resources because analysts are faced with a constant stream of new information. While this information is often important, the timing of the interruptions may detract from analyst's work. In an ideal world, there would be no interruptions. But that is not the case in real world sensemaking tasks. So, in this study, we explore the value of timing interruptions based on an analyst's state of arousal as detected by Electrodermal activity derived form galvanic skin response (EDA). In a laboratory study, we compared performance when interruptions were timed to occur during increasing arousal, decreasing arousal, at random intervals or not at all. Analysts performed significantly better when interruptions occurred during periods of increasing arousal than when they were random. Further, analysts rated process component of team experience significantly higher also during periods of increasing arousal than when they were random. Self-reported workload was not impacted by interruptions timing. We discuss how system designs could leverage inexpensive off-the-shelf wrist sensors to improve interruption timing.","Volume 1 Issue 3, September 2017"
311,10.1145/3130918,"Benjamin H. Groh, Frank Warschun, Martin Deininger, Thomas Kautz, Christine Martindale, Bjoern M. Eskofier",Automated Ski Velocity and Jump Length Determination in Ski Jumping Based on Unobtrusive and Wearable Sensors,"Although ski jumping is a widely investigated sport, competitions and training sessions are rarely supported by state-of-the-art technology. Supporting technologies could focus on a continuous velocity determination and visualization for competitions as well as on an analysis of the velocity development and the jump length for training sessions. In the literature, there are several approaches for jump analysis. However, the majority of these approaches aim for a biomechanical analysis instead of a support system for frequent use. They do not fulfill the requirements of unobtrusiveness and usability that are necessary for a long-term application in competitions and training. In this paper, we propose an algorithm for ski velocity calculation and jump length determination based on the processing of unobtrusively obtained ski jumping data. Our algorithm is evaluated with data from eleven athletes in two different acquisitions. The results show an error of the velocity measurement at take-off of (which equals -3.0 % ± 4.7 % in reference to the estimated average take-off velocity) compared to a light barrier system. The error of the jump length compared to a video-based system is 0.8 m ± 2.9 m (which equals 0.9 % ± 3.4 % of the average jump length of the training jumps in this work). Although our proposed system does not outperform existing camera-based methods of jump length measurements at competitions, it provides an affordable and unobtrusive support for competitions and has the potential to simplify analyses in standard training.","Volume 1 Issue 3, September 2017"
312,10.1145/3130919,"Weixi Gu, Yuxun Zhou, Zimu Zhou, Xi Liu, Han Zou, Pei Zhang, Costas J. Spanos, Lin Zhang",SugarMate: Non-intrusive Blood Glucose Monitoring with Smartphones,"Inferring abnormal glucose events such as hyperglycemia and hypoglycemia is crucial for the health of both diabetic patients and non-diabetic people. However, regular blood glucose monitoring can be invasive and inconvenient in everyday life. We present SugarMate, a first smartphone-based blood glucose inference system as a temporary alternative to continuous blood glucose monitors (CGM) when they are uncomfortable or inconvenient to wear. In addition to the records of food, drug and insulin intake, it leverages smartphone sensors to measure physical activities and sleep quality automatically. Provided with the imbalanced and often limited measurements, a challenge of SugarMate is the inference of blood glucose levels at a fine-grained time resolution. We propose Md3RNN, an efficient learning paradigm to make full use of the available blood glucose information. Specifically, the newly designed grouped input layers, together with the adoption of a deep RNN model, offer an opportunity to build blood glucose models for the general public based on limited personal measurements from single-user and grouped-users perspectives. Evaluations on 112 users demonstrate that Md3RNN yields an average accuracy of 82.14%, significantly outperforming previous learning methods those are either shallow, generically structured, or oblivious to grouped behaviors. Also, a user study with the 112 participants shows that SugarMate is acceptable for practical usage.","Volume 1 Issue 3, September 2017"
313,10.1145/3130920,"Bin Guo, Yi Ouyang, Cheng Zhang, Jiafan Zhang, Zhiwen Yu, Di Wu, Yu Wang",CrowdStory: Fine-Grained Event Storyline Generation by Fusion of Multi-Modal Crowdsourced Data,"Event summarization based on crowdsourced microblog data is a promising research area, and several researchers have recently focused on this field. However, these previous works fail to characterize the fine-grained evolution of an event and the rich correlations among posts. The semantic associations among the multi-modal data in posts are also not investigated as a means to enhance the summarization performance. To address these issues, this study presents CrowdStory, which aims to characterize an event as a fine-grained, evolutionary, and correlation-rich storyline. A crowd-powered event model and a generic event storyline generation framework are first proposed, based on which a multi-clue--based approach to fine-grained event summarization is presented. The implicit human intelligence (HI) extracted from visual contents and community interactions is then used to identify inter-clue associations. Finally, a cross-media mining approach to selective visual story presentation is proposed. The experiment results indicate that, compared with the state-of-the-art methods, CrowdStory enables fine-grained event summarization (e.g., dynamic evolution) and correctly identifies up to 60% strong correlations (e.g., causality) of clues. The cross-media approach shows diversity and relevancy in visual data selection.","Volume 1 Issue 3, September 2017"
314,10.1145/3130921,"Seongmin Ham, Jihyung Lee, Kyunghan Lee",QuickTalk: An Association-Free Communication Method for IoT Devices in Proximity,"IoT devices are in general considered to be straightforward to use. However, we find that there are a number of situations where the usability becomes poor. The situations include but not limited to the followings: 1) when initializing an IoT device, 2) when trying to control an IoT device which is initialized by another person, and 3) when trying to control an IoT device out of many of the same type. We tackle these situations by proposing a new association-free communication method, QuickTalk. QuickTalk lets a user device such as a smartphone pinpoint and activate an IoT device with the help of an IR transmitter and communicate with the pinpointed IoT device through the broadcast channel of WiFi without a conventional association process. This nature, QuickTalk allows a user device to immediately give a command to a specific IoT device in proximity even when the IoT device is uninitialized, unassociated with the control interface of the user, or associated but visually indistinguishable from others of the same kind. Our experiments of QuickTalk implemented on Raspberry Pi 2 devices show that QuickTalk does its job quickly and intuitively. The end-to-end delay of QuickTalk for transmitting an IoT command is on average about 0.74 seconds, and is upper bounded by 2.5 seconds. We further confirm that even when an IoT device has ongoing data sessions with other devices, which disturb the broadcast channel, QuickTalk can still reliably communicate with the IoT device at the cost of minor throughput degradation.","Volume 1 Issue 3, September 2017"
315,10.1145/3130922,"Tian Hao, Chongguang Bi, Guoliang Xing, Roxane Chan, Linlin Tu",MindfulWatch: A Smartwatch-Based System For Real-Time Respiration Monitoring During Meditation,"With a wealth of scientifically proven health benefits, meditation was enjoyed by about 18 million people in the U.S. alone, as of 2012. Yet, there remains a stunning lack of convenient tools for promoting long-term and effective meditation practice. In this paper, we present MindfulWatch, a practical smartwatch-based sensing system that monitors respiration in real-time during meditation -- offering essential biosignals that can potentially be used to empower various future applications such as tracking changes in breathing pattern, offering real-time guidance, and providing an accurate bio-marker for meditation research. To this end, MindfulWatch is designed to be convenient for everyday use with no training required. Operating solely on a smartwatch, MindfulWatch can immediately reach the growing population of smartwatch users, making it ideal for longitudinal data collection for meditation studies. Specifically, it utilizes motion sensors to sense the subtle “micro” wrist rotation (0.01 rad/s) induced by respiration. To accurately capture breathing, we developed a novel self-adaptive model that tracks changes in both breathing pattern and meditation posture over time. MindfulWatch was evaluated based on data from 36 real-world meditation sessions (8.7 hours, 11 subjects). The results suggest that MindfulWatch offers reliable real-time respiratory timing measurement (70% errors under 0.5 seconds).","Volume 1 Issue 3, September 2017"
316,10.1145/3132024,"Christian Holz, Edward J. Wang",Glabella: Continuously Sensing Blood Pressure Behavior using an Unobtrusive Wearable Device,"We propose Glabella, a wearable device that continuously and unobtrusively monitors heart rates at three sites on the wearer’s head. Our glasses prototype incorporates optical sensors, processing, storage, and communication components, all integrated into the frame to passively collect physiological data about the user without the need for any interaction. Glabella continuously records the stream of reflected light intensities from blood flow as well as inertial measurements of the user’s head. From the temporal differences in pulse events across the sensors, our prototype derives the wearer’s pulse transit time on a beat-to-beat basis.
Numerous efforts have found a significant correlation between a person’s pulse transit time and their systolic blood pressure. In this paper, we leverage this insight to continuously observe pulse transit time as a proxy for the behavior of systolic blood pressure levels—at a substantially higher level of convenience and higher rate than traditional blood pressure monitors, such as cuff-based oscillometric devices. This enables our prototype to model the beat-to-beat fluctuations in the user’s blood pressure over the course of the day and record its short-term responses to events, such as postural changes, exercise, eating and drinking, resting, medication intake, location changes, or time of day.
During our in-the-wild evaluation, four participants wore a custom-fit Glabella prototype device over the course of five days throughout their daytime job and regular activities. Participants additionally measured their radial blood pressure three times an hour using a commercial oscillometric cuff. Our analysis shows a high correlation between the pulse transit times computed on our devices with participants’ heart rates (mean r = 0.92, SE = 0.03, angular artery) and systolic blood pressure values measured using the oscillometric cuffs (mean r = 0.79, SE = 0.15, angular-superficial temporal artery, considering participants’ self-administered cuff-based measurements as ground truth). Our results indicate that Glabella has the potential to serve as a socially-acceptable capture device, requiring no user input or behavior changes during regular activities, and whose continuous measurements may prove informative to physicians as well as users’ self-tracking activities.","Volume 1 Issue 3, September 2017"
317,10.1145/3130924,"Chen-Yu Hsu, Aayush Ahuja, Shichao Yue, Rumen Hristov, Zachary Kabelac, Dina Katabi",Zero-Effort In-Home Sleep and Insomnia Monitoring using Radio Signals,"Insomnia is the most prevalent sleep disorder in the US. In-home insomnia monitoring is important for both diagnosis and treatment. Existing solutions, however, require the user to either maintain a sleep diary or wear a sensor while sleeping. Both can be quite cumbersome. This paper introduces EZ-Sleep, a new approach for monitoring insomnia and sleep. EZ-Sleep has three properties. First, it is zero effort, i.e., it neither requires the user to wear a sensor nor to record any data. It monitors the user remotely by analyzing the radio signals that bounce off her body. Second, it delivers new features unavailable with other devices such as automatically detecting where the user sleeps and her exact bed schedule, while simultaneously monitoring multiple users in different beds. Third, it is highly accurate. Its average error in measuring sleep latency and total sleep time is 4.9 min and 10.3 min, respectively.","Volume 1 Issue 3, September 2017"
318,10.1145/3131892,"Hayeon Jeong, Heepyung Kim, Rihun Kim, Uichin Lee, Yong Jeong",Smartwatch Wearing Behavior Analysis: A Longitudinal Study,"Smartwaches are the representative wearable or body-worn devices that provide convenient and easy information access. There is a growing body of research work on enabling novel interaction techniques and understanding user experiences of smartwatches. However, there is still lack of user experience research on wearing behaviors of smartwatches, which is critical for wearable device and service design. In this work, we investigate how college students wear smartwatches and what factors affect wearing behaviors by analyzing a longitudinal activity dataset collected from 50 smartwatch users for 203 days. Our results show that there are several temporal usage patterns and distinct groups of usage patterns. The factors affecting wearing behaviors are contextual, nuanced, and multifaceted. Our findings provide diverse design implications for improving wearability of smartwatches and leveraging smartwatches for behavioral changes.","Volume 1 Issue 3, September 2017"
319,10.1145/3130926,"Avinash Kalyanaraman, Dezhi Hong, Elahe Soltanaghaei, Kamin Whitehouse",Forma Track: Tracking People based on Body Shape,"Knowledge of a person’s whereabouts in the home is key to context-aware applications, but many people do not want to carry or wear a tag or mobile device in the home. Therefore, many tracking systems are now using so-called weak biometrics such as height, weight, and width. In this paper, we propose to use body shape as a weak biometric, differentiating people based on features such as head size, shoulder size, or torso size. The basic idea is to scan the body with a radar sensor and to compute the reflection profile: the amount of energy that reflects back from each part of the body. Many people have different body shapes even if they have the same height, weight, or width, which makes body shape a stronger biometric. We built a proof-of-concept system called FormaTrack to test this approach, and evaluate using eight participants of varying height and weight. We collected over 2800 observations while capturing a wide range of factors such as clothing, hats, shoes, and backpacks. Results show that FormaTrack can achieve a precision, recall, direction and identity accuracy (over all possible groups of 2 people) of 100%, 99.86%, 99.7% and 95.3% respectively. Results indicate that FormaTrack can achieve over 99% tracking accuracy with 2 people in a home with 5 or more rooms.","Volume 1 Issue 3, September 2017"
320,10.1145/3130927,"Aftab Khan, James Nicholson, Thomas Plötz",Activity Recognition for Quality Assessment of Batting Shots in Cricket using a Hierarchical Representation,"Quality assessment in cricket is a complex task that is performed by understanding the combination of individual activities a player is able to perform and by assessing how well these activities are performed. We present a framework for inexpensive and accessible, automated recognition of cricketing shots. By means of body-worn inertial measurement units, movements of batsmen are recorded, which are then analysed using a parallelised, hierarchical recognition system that automatically classifies relevant categories of shots as required for assessing batting quality. Our system then generates meaningful visualisations of key performance parameters, including feet positions, attack/defence, and distribution of shots around the ground. These visualisations are the basis for objective skill assessment thereby focusing on specific personal improvement points as identified through our system. We evaluated our framework through a deployment study where 6 players engaged in batting exercises. Based on the recorded movement data we could automatically identify 20 classes of unique batting shot components with an average F1-score greater than 88%. This analysis is the basis for our detailed analysis of our study participants’ skills. Our system has the potential to rival expensive vision-based systems but at a fraction of the cost.","Volume 1 Issue 3, September 2017"
321,10.1145/3130928,"Inyeop Kim, Gyuwon Jung, Hayoung Jung, Minsam Ko, Uichin Lee",Let’s FOCUS: Mitigating Mobile Phone Use in College Classrooms,"With the increasingly frequent appearance of mobile phones in college classrooms, there have been growing concerns regarding their negative aspects including distractive off-task multitasking. In this work, we design and evaluate Let’s FOCUS, a software-based intervention service that assists college students in self-regulating their mobile phone use in classrooms. Our preliminary survey study (with 47 professors and 283 students) reveals that it is critical to encourage voluntary participation by framing intervention as a learning tool and to raise awareness regarding appropriate mobile phone usage by establishing social norms in colleges. Let’s FOCUS introduces a virtual limiting space for each class (or a virtual classroom) where the students can explicitly restrict their mobile phone use voluntarily. Furthermore, it promotes students’ willing participation by leveraging social facilitation and context-aware reminders associated with virtual classrooms. We conducted a campus-wide campaign for approximately six weeks to evaluate the feasibility of the proposed approach. The results confirm that 379 students used the app to limit 9,335 hours of mobile phone usage over 233 classrooms. Let’s FOCUS was used in diverse learning contexts and for different purposes and its social learning and context-awareness features significantly motivated prolonged participation. We present the design considerations of software-based intervention.","Volume 1 Issue 3, September 2017"
322,10.1145/3130932,"Jaejeung Kim, Chiwoo Cho, Uichin Lee",Technology Supported Behavior Restriction for Mitigating Self-Interruptions in Multi-device Environments,"The interruptions people experience may be initiated from digital devices but also from oneself, an action which is termed “self-interruption.” Prior work mostly focused on understanding work-related self-interruptions and designing tools for mitigating them in work contexts. However, self-interruption to off-tasks (e.g., viewing social networking sites, and playing mobile games) has received little attention in the HCI community thus far. We conducted a formative study about self-interruptions to off-tasks and coping strategies in multi-device working environments. Off-task usage was considered a serious roadblock to productivity, and yet, the habitual usage and negative triggers made it challenging to manage off-task usage. To mitigate these concerns, we developed “PomodoLock,” a self-interruption management tool that allows users voluntarily to set a timer for a fixed period, during which it selectively blocks interruption sources across multiple devices. To understand the effect of restricting access to self-interruptive sources such as applications and websites, we conducted a three-week field trial (n=40) where participants were asked to identify disrupting apps and sites to be blocked, but the multi-device blocking feature was only provided to the experimental group. Our study results showed the perceived coercion and the stress of the experimental group were lower despite its behavioral restriction with multi-device blocking. Qualitative study results from interviews and surveys confirm that multi-device blocking significantly reduced participants’ mental effort for managing self-interruptions, thereby leading to a reduction in the overall stress level. The findings suggest that when the coerciveness of behavioral restriction is appropriately controlled, coercive design can positively assist users in achieving their goals.","Volume 1 Issue 3, September 2017"
323,10.1145/3131893,"Keunseo Kim, Hengameh Zabihi, Heeyoung Kim, Uichin Lee",TrailSense: A Crowdsensing System for Detecting Risky Mountain Trail Segments with Walking Pattern Analysis,"Trail surface information is critical in preventing from the mountain accidents such as falls and slips. In this paper, we propose a new mobile crowdsensing system that automatically infers whether trail segments are risky to climb by using sensor data collected from multiple hikers’ smartphones. We extract cyclic gait-based features from walking motion data to train machine learning models, and multiple hikers’ results are then aggregated for robust classification. We evaluate our system with two real-world datasets. First, we collected data from 14 climbers for a mountain trail which includes 13 risky segments. The average accuracy of individuals is approximately 80%, but after clustering the results, our system can accurately identify all the risky segments. We then collected an additional dataset from five climbers in two different mountain trails, which have 10 risky segments in total. Our results show that the model trained in one trail can be used to accurately identify all the risky segments in the other trail, which documents the generalizability of our system.","Volume 1 Issue 3, September 2017"
324,10.1145/3130931,"Lawrence H. Kim, Sean Follmer",UbiSwarm: Ubiquitous Robotic Interfaces and Investigation of Abstract Motion as a Display,"As robots increasingly enter our everyday life, we envision a future in which robots are ubiquitous and interact with both ourselves and our environments. This paper introduces the concept of ubiquitous robotic interfaces (URIs), multi-robot interfaces capable of mobility, manipulation, sensing, display and interaction. URIs interact directly with the user and indirectly through surrounding objects. A key aspect of URIs is their ability to display information to users either by collectively forming shapes or through their movements. In this paper, we focus on the use of URIs to display information in ubiquitous settings. We first investigate the use of abstract motion as a display for URIs by studying human perception of abstract multi-robot motion. With ten small robots, we produced 42 videos of bio-inspired abstract motion by varying three parameters (7 x 2 x 3): bio-inspired behavior, speed and smoothness. In a crowdsourced between-subjects study, 1067 subjects were recruited to watch the videos and describe their perception through Likert scales and free text. Study results suggest that different bio-inspired behaviors elicit significantly different responses in arousal, dominance, hedonic and pragmatic qualities, animacy, urgency and willingness to attend. On the other hand, speed significantly affects valence, arousal, hedonic quality, urgency and animacy while smoothness affects hedonic quality, animacy, attractivity and likeability. We discuss how these results inform URI designers to formulate appropriate motion for different interaction scenarios and use these results to derive our own example applications using our URI platform, UbiSwarm.","Volume 1 Issue 3, September 2017"
325,10.1145/3130930,"Young-Ho Kim, Jae Ho Jeon, Bongshin Lee, Eun Kyoung Choe, Jinwook Seo",OmniTrack: A Flexible Self-Tracking Approach Leveraging Semi-Automated Tracking,"We now see an increasing number of self-tracking apps and wearable devices. Despite the vast number of available tools, however, it is still challenging for self-trackers to find apps that suit their unique tracking needs, preferences, and commitments. Furthermore, people are bounded by the tracking tools’ initial design because it is difficult to modify, extend, or mash up existing tools. In this paper, we present OmniTrack, a mobile self-tracking system, which enables self-trackers to construct their own trackers and customize tracking items to meet their individual tracking needs. To inform the OmniTrack design, we first conducted semi-structured interviews (N = 12) and analyzed existing mobile tracking apps (N = 62). We then designed and developed OmniTrack as an Android mobile app, leveraging a semi-automated tracking approach that combines manual and automated tracking methods. We evaluated OmniTrack through a usability study (N = 10) and improved its interfaces based on the feedback. Finally, we conducted a 3-week deployment study (N = 21) to assess if people can capitalize on OmniTrack’s flexible and customizable design to meet their tracking needs. From the study, we showed how participants used OmniTrack to create, revise, and appropriate trackers—ranging from a simple mood tracker to a sophisticated daily activity tracker. We discuss how OmniTrack positively influences and supports self-trackers’ tracking practices over time, and how to further improve OmniTrack by providing more appropriate visualizations and sharable templates, incorporating external contexts, and supporting researchers’ unique data collection needs.","Volume 1 Issue 3, September 2017"
326,10.1145/3130933,"Jarrod Knibbe, Paul Strohmeier, Sebastian Boring, Kasper Hornbæk",Automatic Calibration of High Density Electric Muscle Stimulation,"Electric muscle stimulation (EMS) can enable mobile force feedback, support pedestrian navigation, or confer object affordances. To date, however, EMS is limited by two interlinked problems. (1) EMS is low resolution -- achieving only coarse movements and constraining opportunities for exploration. (2) EMS requires time consuming, expert calibration -- confining these interaction techniques to the lab. EMS arrays have been shown to increase stimulation resolution, but as calibration complexity increases exponentially as more electrodes are used, we require heuristics or automated procedures for successful calibration. We explore the feasibility of using electromyography (EMG) to auto-calibrate high density EMS arrays. We determine regions of muscle activity during human-performed gestures, to inform stimulation patterns for EMS-performed gestures. We report on a study which shows that auto-calibration of a 60-electrode array is feasible: achieving 52% accuracy across six gestures, with 82% accuracy across our best three gestures. By highlighting the electrode-array calibration problem, and presenting a first exploration of a potential solution, this work lays the foundations for high resolution, wearable and, perhaps one day, ubiquitous EMS beyond the lab.","Volume 1 Issue 3, September 2017"
327,10.1145/3130934,"Yuki Kubo, Ryosuke Takada, Buntarou Shizuki, Shin Takahashi",Exploring Context-Aware User Interfaces for Smartphone-Smartwatch Cross-Device Interaction,"In this study, we explore context-aware cross-device interactions between a smartphone and smartwatch. We present 24 contexts, and then examine and prioritize suitable user interfaces (UIs) for each. In addition, we present example applications, including a map, notification management system, multitasking application, music player, and video chat application, each of which has its own context-aware UIs. To support these context-aware UIs, we investigate the performance of our context recognizer in which recognition is based on machine-learning using the accelerometers in a smartphone and smartwatch. We conduct seven different evaluations using four machine-learning algorithms: J48 decision tree, sequential minimal optimization (SMO)-based support vector machine (SVM), random forest, and multilayer perceptron. With each algorithm, we conduct a long-interval experiment to examine the level of accuracy at which each context is recognized using data previously collected for training. The results show that SMO-based SVM is suitable for recognizing the 24 contexts considered in this study.","Volume 1 Issue 3, September 2017"
328,10.1145/3130938,"Sugang Li, Xiaoran Fan, Yanyong Zhang, Wade Trappe, Janne Lindqvist, Richard E. Howard",Auto++: Detecting Cars Using Embedded Microphones in Real-Time,"In this work, we propose a system that detects approaching cars for smartphone users. In addition to detecting the presence of a vehicle, it can also estimate the vehicle’s driving direction, as well as count the number of cars around the user. We achieve these goals by processing the acoustic signal captured by microphones embedded in the user’s mobile phone. The largest challenge we faced involved addressing the fact that vehicular noise is predominantly due to tire-road friction, and therefore lacked strong (frequency) formant or temporal structure. Additionally, outdoor environments have complex acoustic noise characteristics, which are made worse when the signal is captured by non-professional grade microphones embedded in smartphones. We address these challenges by monitoring a new feature: maximal frequency component that crosses a threshold. We extract this feature with a blurred edge detector. Through detailed experiments, we found our system to be robust across different vehicles and environmental conditions, and thereby support unsupervised car detection and counting. We evaluated our system using audio tracks recorded from seven different models of cars, including SUVs, medium-sized sedans, compact cars, and electric cars. We also tested our system with the user walking in various outdoor environments including parking lots, campus roads, residential areas, and shopping centers. Our results show that we can accurately and robustly detect cars with low CPU and memory requirements.","Volume 1 Issue 3, September 2017"
329,10.1145/3130937,"Tianxing Li, Xi Xiong, Yifei Xie, George Hito, Xing-Dong Yang, Xia Zhou",Reconstructing Hand Poses Using Visible Light,"Free-hand gestural input is essential for emerging user interactions. We present Aili, a table lamp reconstructing a 3D hand skeleton in real time, requiring neither cameras nor on-body sensing devices. Aili consists of an LED panel in a lampshade and a few low-cost photodiodes embedded in the lamp base. To reconstruct a hand skeleton, Aili combines 2D binary blockage maps from vantage points of different photodiodes, which describe whether a hand blocks light rays from individual LEDs to all photodiodes. Empowering a table lamp with sensing capability, Aili can be seamlessly integrated into the existing environment. Relying on such low-level cues, Aili entails lightweight computation and is inherently privacy-preserving. We build and evaluate an Aili prototype. Results show that Aili’s algorithm reconstructs a hand pose within 7.2 ms on average, with 10.2° mean angular deviation and 2.5-mm mean translation deviation in comparison to Leap Motion. We also conduct user studies to examine the privacy issues of Leap Motion and solicit feedback on Aili’s privacy protection. We conclude by demonstrating various interaction applications Aili enables.","Volume 1 Issue 3, September 2017"
330,10.1145/3130940,"Xiang Li, Daqing Zhang, Qin Lv, Jie Xiong, Shengjie Li, Yue Zhang, Hong Mei",IndoTrack: Device-Free Indoor Human Tracking with Commodity Wi-Fi,"Indoor human tracking is fundamental to many real-world applications such as security surveillance, behavioral analysis, and elderly care. Previous solutions usually require dedicated device being carried by the human target, which is inconvenient or even infeasible in scenarios such as elderly care and break-ins. However, compared with device-based tracking, device-free tracking is particularly challenging because the much weaker reflection signals are employed for tracking. The problem becomes even more difficult with commodity Wi-Fi devices, which have limited number of antennas, small bandwidth size, and severe hardware noise.
In this work, we propose IndoTrack, a device-free indoor human tracking system that utilizes only commodity Wi-Fi devices. IndoTrack is composed of two innovative methods: (1) Doppler-MUSIC is able to extract accurate Doppler velocity information from noisy Wi-Fi Channel State Information (CSI) samples; and (2) Doppler-AoA is able to determine the absolute trajectory of the target by jointly estimating target velocity and location via probabilistic co-modeling of spatial-temporal Doppler and AoA information. Extensive experiments demonstrate that IndoTrack can achieve a 35cm median error in human trajectory estimation, outperforming the state-of-the-art systems and provide accurate location and velocity information for indoor human mobility and behavioral analysis.","Volume 1 Issue 3, September 2017"
331,10.1145/3130936,"Xinyu Li, Yanyi Zhang, Jianyu Zhang, Moliang Zhou, Shuhong Chen, Yue Gu, Yueyang Chen, Ivan Marsic, Richard A. Farneth, Randall S. Burd",Progress Estimation and Phase Detection for Sequential Processes,"Process modeling and understanding are fundamental for advanced human-computer interfaces and automation systems. Most recent research has focused on activity recognition, but little has been done on sensor-based detection of process progress. We introduce a real-time, sensor-based system for modeling, recognizing and estimating the progress of a work process. We implemented a multimodal deep learning structure to extract the relevant spatio-temporal features from multiple sensory inputs and used a novel deep regression structure for overall completeness estimation. Using process completeness estimation with a Gaussian mixture model, our system can predict the phase for sequential processes. The performance speed, calculated using completeness estimation, allows online estimation of the remaining time. To train our system, we introduced a novel rectified hyperbolic tangent (rtanh) activation function and conditional loss. Our system was tested on data obtained from the medical process (trauma resuscitation) and sports events (Olympic swimming competition). Our system outperformed the existing trauma-resuscitation phase detectors with a phase detection accuracy of over 86%, an F1-score of 0.67, a completeness estimation error of under 12.6%, and a remaining-time estimation error of less than 7.5 minutes. For the Olympic swimming dataset, our system achieved an accuracy of 88%, an F1-score of 0.58, a completeness estimation error of 6.3% and a remaining-time estimation error of 2.9 minutes.","Volume 1 Issue 3, September 2017"
332,10.1145/3130939,"Yinghui Li, Zhichao Cao, Jiliang Wang",Gazture: Design and Implementation of a Gaze based Gesture Control System on Tablets,"We present Gazture, a light-weight gaze based real-time gesture control system on commercial tablets. Unlike existing approaches that require dedicated hardware (e.g., high resolution camera), high computation overhead (powerful CPU) or specific user behavior (keeping head steady), Gazture provides gesture recognition based on easy-to-control user gaze input with a small overhead. To achieve this goal, Gazture incorporates a two-layer structure: The first layer focuses on real-time gaze estimation with acceptable tracking accuracy while incurring a small overhead. The second layer implements a robust gesture recognition algorithm while compensating gaze estimation error. To address user posture change while using mobile device, we design a online transfer function based method to convert current eye features into corresponding eye features in reference posture, which then facilitates efficient gaze position estimation. We implement Gazture on Lenovo Tab3 8 Plus tablet with Android 6.0.1, and evaluate its performance in different scenarios. The evaluation results show that Gazture can achieve a high accuracy in gesture recognition while incurring a low overhead.","Volume 1 Issue 3, September 2017"
333,10.1145/3130935,"Yuanchun Li, Baoxiong Jia, Yao Guo, Xiangqun Chen",Mining User Reviews for Mobile App Comparisons,"As the number of mobile apps keeps increasing, users often need to compare many apps, in order to choose one that best fits their needs. Fortunately, as there are so many users sharing an app market, it is likely that some other users with the same preferences have already made the comparisons and shared their opinions. For example, a user may state that an app is better in power consumption than another app in a review, then the review would help other users who care about battery life while choosing apps. This paper presents a method to identify comparative reviews for mobile apps from an app market, which can be used to provide fine-grained app comparisons based on different topics. According to experiments on 5 million reviews from Google Play and manual assessments on 900 reviews, our method is able to identify opinions accurately and provide meaningful comparisons between apps, which could in turn help users find desired apps based on their preferences.","Volume 1 Issue 3, September 2017"
334,10.1145/3130941,"Yuanchun Li, Fanglin Chen, Toby Jia-Jun Li, Yao Guo, Gang Huang, Matthew Fredrikson, Yuvraj Agarwal, Jason I. Hong",PrivacyStreams: Enabling Transparency in Personal Data Processing for Mobile Apps,"Smartphone app developers often access and use privacy-sensitive data to create apps with rich and meaningful interactions. However, it can be challenging for auditors and end-users to know what granularity of data is being used and how, thereby hindering assessment of potential risks. Furthermore, developers lack easy ways of offering transparency to users regarding how personal data is processed, even if their intentions are to make their apps more privacy friendly. To address these challenges, we introduce PrivacyStreams, a functional programming model for accessing and processing personal data as a stream. PrivacyStreams is designed to make it easy for developers to make use of personal data while simultaneously making it easier to analyze how that personal data is processed and what granularity of data is actually used. We present the design and implementation of PrivacyStreams, as well as several user studies and experiments to demonstrate its usability, utility, and support for privacy.","Volume 1 Issue 3, September 2017"
335,10.1145/3130943,"Fannie Liu, Laura Dabbish, Geoff Kaufman",Supporting Social Interactions with an Expressive Heart Rate Sharing Application,"The present work explores the social dynamics of expressive biosignals: leveraging wearable technologies to introduce sensed physiological data as a means of clarifying the emotional or psychological processes underlying our subjective experiences. We developed an Android application that linked to a wearable heart rate sensor and allowed for the direct sharing and real-time broadcasting of users’ heart rate via text messaging. We deployed this application in a two-week field study to investigate the contextual triggers, perceptions, and consequences of users’ sharing behaviors. The study (N=13) utilized a combination of Experience Sampling Methodology (ESM) and qualitative interviews to discover the situations in which users were more or less likely to share their heart rate with contacts, and the subsequent interactions that occurred after sharing. The results revealed that participants used heart rate sharing as a means to express emotions and provide daily updates, as well as simply a novel and playful form of communication. They reported a variety of communicative consequences of their sharing as well as specific logistical and psychological barriers to sharing. The implications of these results for the design of expressive biosignal sharing systems for supporting positive social interactions are discussed.","Volume 1 Issue 3, September 2017"
336,10.1145/3130942,"Ruilin Liu, Yu Yang, Daehan Kwak, Desheng Zhang, Liviu Iftode, Badri Nath",Your Search Path Tells Others Where to Park: Towards Fine-Grained Parking Availability Crowdsourcing Using Parking Decision Models,"A main challenge faced by the state-of-the-art parking sensing systems is to infer the state of the spots not covered by participants’ parking/unparking events (called background availability) when the system penetration rate is limited. In this paper, we tackle this problem by exploring an empirical phenomenon that ignoring a spot along a driver’s parking search trajectory is likely due to the unavailability. However, complications caused by drivers’ preferences, e.g. ignoring the spots too far from the driver’s destination, have to be addressed based on human parking decisions. We build a model based on a dataset of more than 55,000 real parking decisions to predict the probability that a driver would take a spot, assuming the spot is available. Then, we present a crowdsourcing system, called ParkScan, which leverages the learned parking decision model in collaboration with the hidden Markov model to estimate background parking spot availability. We evaluated ParkScan with real-world data from both off-street scenarios (i.e., two public parking lots) and an on-street parking scenario (i.e., 35 urban blocks in Seattle). Both of the experiments showed that with a 5% penetration rate, ParkScan reduces over 12.9% of availability estimation errors for all the spots during parking peak hours, compared to the baseline using only the historical data. Also, even with a single participant driver, ParkScan cuts off at least 15% of the estimation errors for the spots along the driver’s parking search trajectory.","Volume 1 Issue 3, September 2017"
337,10.1145/3130944,"Xuan Lu, Zhenpeng Chen, Xuanzhe Liu, Huoran Li, Tao Xie, Qiaozhu Mei",PRADO: Predicting App Adoption by Learning the Correlation between Developer-Controllable Properties and User Behaviors,"To survive and stand out from the fierce market competition nowadays, it is critical for app developers to know (desirably ahead of time) whether, how well, and why their apps would be adopted by users. Ideally, the adoption of an app could be predicted by factors that can be controlled by app developers in the development process, and factors that app developers are able to take actions on and improve according to the predictions. To this end, this paper proposes PRADO, an approach to measuring various aspects of user adoption, including app download and installation, uninstallation, and user ratings. PRADO employs advanced machine learning algorithms to predict user adoption based on how these metrics correlate to a comprehensive taxonomy of 108 developer-controllable features of the app. To evaluate PRADO, we use 9,824 free apps along with their behavioral data from 12.57 million Android users, demonstrating that user adoption of a new app can be accurately predicted. We also derive insights on which factors are statistically significant to user adoption, and suggest what kinds of actions can be possibly performed by developers in practice.","Volume 1 Issue 3, September 2017"
338,10.1145/3130945,"Chu Luo, Miikka Kuutila, Simon Klakegg, Denzil Ferreira, Huber Flores, Jorge Goncalves, Mika Mäntylä, Vassilis Kostakos",TestAWARE: A Laboratory-Oriented Testing Tool for Mobile Context-Aware Applications,"Although mobile context instrumentation frameworks have simplified the development of mobile context-aware applications, it remains challenging to test such applications. In this paper, we present TestAWARE that enables developers to systematically test context-aware applications in laboratory settings. To achieve this, TestAWARE is able to download, replay and emulate contextual data on either physical devices or emulators. To support both white -box and black-box testing, TestAWARE has been implemented as a novel structure with a mobile client and code library. In blackbox testing scenarios, developers can manage data replay through the mobile client, without writing testing scripts or modifying the source code of the targeted application. In white-box testing scenarios, developers can manage data replay and test functional/non-functional properties of the targeted application by writing testing scripts using the code library. We evaluated TestAWARE by quantifying its maximal data replay speed, and by conducting a user study with 13 developers. We show that TestAWARE can overcome data synchronisation challenges, and found that PC-based emulators can replay data significantly faster than physical smartphones and tablets. The user study highlights the usefulness of TestAWARE in the systematic testing of mobile context-aware applications in laboratory settings.","Volume 1 Issue 3, September 2017"
339,10.1145/3131896,"Alex Mariakakis, Jacob Baudin, Eric Whitmire, Vardhman Mehta, Megan A. Banks, Anthony Law, Lynn Mcgrath, Shwetak N. Patel",PupilScreen: Using Smartphones to Assess Traumatic Brain Injury,"Before a person suffering from a traumatic brain injury reaches a medical facility, measuring their pupillary light reflex (PLR) is one of the few quantitative measures a clinician can use to predict their outcome. We propose PupilScreen, a smartphone app and accompanying 3D-printed box that combines the repeatability, accuracy, and precision of a clinical device with the ubiquity and convenience of the penlight test that clinicians regularly use in emergency situations. The PupilScreen app stimulates the patient's eyes using the smartphone's flash and records the response using the camera. The PupilScreen box, akin to a head-mounted virtual reality display, controls the eyes' exposure to light. The recorded video is processed using convolutional neural networks that track the pupil diameter over time, allowing for the derivation of clinically relevant measures. We tested two different network architectures and found that a fully convolutional neural network was able to track pupil diameter with a median error of 0.30 mm. We also conducted a pilot clinical evaluation with six patients who had suffered a TBI and found that clinicians were almost perfect when separating unhealthy pupillary light reflexes from healthy ones using PupilScreen alone.","Volume 1 Issue 3, September 2017"
340,10.1145/3130947,"Akhil Mathur, Lakshmi Manasa Kalanadhabhatta, Rahul Majethia, Fahim Kawsar",Moving Beyond Market Research: Demystifying Smartphone User Behavior in India,"Large-scale mobile data studies can reveal valuable insights into user behavior, which in turn can assist system designers to create better user experiences. After a careful review of existing mobile data literature, we found that there have been no large-scale studies to understand smartphone usage behavior in India -- the second-largest and fastest growing smartphone market in the world. With the goal of understanding various facets of smartphone usage in India, we conducted a mixed-method longitudinal data collection study through an Android app released on Google Play. Our app was installed by 215 users, and logged 11.9 million data points from them over a period of 8 months. We analyzed this rich dataset along the lines of four broad facets of smartphone behavior -- how users use different apps, interact with notihcations, react to different contexts, and charge their smartphones -- to paint a holistic picture of smartphone usage behavior of Indian users. This quantitative analysis was complemented by a survey with 55 users and semi-structured interviews with 26 users to deeply understand their smartphone usage behavior. While our first-of-its-kind study uncovered many interesting facts about Indian smartphone users, we also found striking differences in usage behavior compared to past studies in other geographical contexts. We observed that Indian users spend significant time with their smartphones after midnight, continuously check notifications without attending to them and are extremely conscious about their smartphones’ battery. Perhaps the most dramatic finding is the nature of mobile consumerism of Indian users as shown by our results. Taken together, these and the rest of our findings demonstrate the unique characteristics that are shaping the smartphone usage behavior of Indian users.","Volume 1 Issue 3, September 2017"
341,10.1145/3130948,"Abhinav Mehrotra, Fani Tsapeli, Robert Hendley, Mirco Musolesi",MyTraces: Investigating Correlation and Causation between Users’ Emotional States and Mobile Phone Interaction,"Most of the existing work concerning the analysis of emotional states and mobile phone interaction has been based on correlation analysis. In this paper, for the first time, we carry out a causality study to investigate the causal links between users’ emotional states and their interaction with mobile phones, which could provide valuable information to practitioners and researchers. The analysis is based on a dataset collected in-the-wild. We recorded 5,118 mood reports from 28 users over a period of 20 days.
Our results show that users’ emotions have a causal impact on different aspects of mobile phone interaction. On the other hand, we can observe a causal impact of the use of specific applications, reflecting the external users’ context, such as socializing and traveling, on happiness and stress level. This study has profound implications for the design of interactive mobile systems since it identifies the dimensions that have causal effects on users’ interaction with mobile phones and vice versa. These findings might lead to the design of more effective computing systems and services that rely on the analysis of the emotional state of users, for example for marketing and digital health applications.","Volume 1 Issue 3, September 2017"
342,10.1145/3131901,"Abhinav Mehrotra, Sandrine R. Müller, Gabriella M. Harari, Samuel D. Gosling, Cecilia Mascolo, Mirco Musolesi, Peter J. Rentfrow",Understanding the Role of Places and Activities on Mobile Phone Interaction and Usage Patterns,"User interaction patterns with mobile apps and notifications are generally complex due to the many factors involved. However a deep understanding of what influences them can lead to more acceptable applications that are able to deliver information at the right time. In this paper, we present for the first time an in-depth analysis of interaction behavior with notifications in relation to the location and activity of users. We conducted an in-situ study for a period of two weeks to collect more than 36,000 notifications, 17,000 instances of application usage, 77,000 location samples, and 487 days of daily activity entries from 26 students at a UK university.
Our results show that users’ attention towards new notifications and willingness to accept them are strongly linked to the location they are in and in minor part to their current activity. We consider both users’ receptivity and attentiveness, and we show that different response behaviors are associated to different locations. These findings are fundamental from a design perspective since they allow us to understand how certain types of places are linked to specific types of interaction behavior. This information can be used as a basis for the development of novel intelligent mobile applications and services.","Volume 1 Issue 3, September 2017"
343,10.1145/3131894,"Mark Mirtchouk, Drew Lustig, Alexandra Smith, Ivan Ching, Min Zheng, Samantha Kleinberg",Recognizing Eating from Body-Worn Sensors: Combining Free-living and Laboratory Data,"Automated dietary monitoring solutions that can find when, what, and how much individuals consume are needed for many applications such as providing feedback to individuals with chronic disease. Advances in body-worn sensors have led to systems with high accuracy for finding meals and even which foods are consumed in each bite. However, most tests are done in controlled lab settings with restricted meal choices, little background noise, and subjects focused on eating. For these systems to be adopted by users it is critical that they work well in realistic situations and be able to handle confounding factors such as background noise, shared meals, and multi-tasking. Work in realistic environments usually has lower accuracy, but has challenges in determining ground truth. Most critically, there has been a significant gap between lab and free-living environments. This is compounded by data usually being collected for different individuals in each setting, making it difficult to determine how the accuracy gap can be closed. We present a multi-modality study on eating recognition, using body-worn motion (head, wrists) and audio (earbud microphone) sensors for 12 participants (6 from the lab study, 6 new to test generalizability). In contrast to the lab, where audio alone has the highest accuracy, we find now that a combination of sensing modalities (audio, motion) is needed; yet sensor placement (head vs. wrist) is not critical. We further find that lab data does generalize to other participants, but while personal free-living data improves accuracy, more data from others can actually lead to worse performance.","Volume 1 Issue 3, September 2017"
344,10.1145/3130951,"Alessandro Montanari, Cecilia Mascolo, Kerstin Sailer, Sarfraz Nawaz",Detecting Emerging Activity-Based Working Traits through Wearable Technology,"A recent trend in corporate real-estate is Activity-Based Working (ABW). The ABW concept removes designated desks but offers different work settings designed to support typical work activities. In this context there is still a need for objective data to understand the implications of these design decisions. We aim to contribute by using automated data collection to study how ABW’s principles impact office usage and dynamics.
To this aim we analyse team dynamics and employees’ tie strength in relation to space usage and organisational hierarchy using data collected with wearable devices in a company adopting ABW principles. Our findings show that the office fosters interactions across team boundaries and among the lower levels of the hierarchy suggesting a strong lateral communication. Employees also tend to have low space exploration on a daily basis which is instead more prevalent during an average week and strong social clusters seem to be resisting the ABW principles of space dynamics. With the availability of two additional data sets about social encounters in traditional offices we highlight traits emerging from the application of ABW’s principles. In particular, we observe how the absence of designated desks might be responsible for more rapid dynamics inside the office.
In more general terms, this work opens the door to new and scalable technology-based methodologies to study dynamic office usage and social interactions.","Volume 1 Issue 3, September 2017"
345,10.1145/3131897,"Rajalakshmi Nandakumar, Alex Takakuwa, Tadayoshi Kohno, Shyamnath Gollakota",CovertBand: Activity Information Leakage using Music,"This paper contributes a novel method for low-cost, covert physical sensing and, by doing so, surfaces new privacy threats. We demonstrate how a smartphone and portable speaker playing music with embedded, inaudible signals can track multiple individuals’ locations and activities both within a room and through barriers in 2D space. We achieve this by transforming a smartphone into an active sonar system that emits a combination of a sonar pulse and music and listens to the reflections off of humans in the environment. Our implementation, CovertBand, monitors minute changes to these reflections to track multiple people concurrently and to recognize different types of motion, leaking information about where people are in addition to what they may be doing. We evaluated CovertBand by running experiments in five homes in the Seattle area, showing that we can localize both single and multiple individuals through barriers. These tests show CovertBand can track walking subjects with a mean tracking error of 18 cm and subjects moving at a fixed position with an accuracy of 8 cm at up to 6 m in line-of-sight and 3 m through barriers. We test a variety of rhythmic motions such as pumping arms, jumping, and supine pelvic tilts in through-wall scenarios and show that they produce discernibly different spectrograms from walking in the acoustic reflections. In tests with 33 subjects, we also show that even in ideal scenarios, listeners were unlikely to detect a CovertBand attack.","Volume 1 Issue 3, September 2017"
346,10.1145/3131898,"Kazuya Ohara, Takuya Maekawa, Yasuyuki Matsushita",Detecting State Changes of Indoor Everyday Objects using Wi-Fi Channel State Information,"Detecting the events of indoor everyday objects such as door or window open/close events has been actively studied to implement such applications as intrusion detection, adaptive HVAC control, and monitoring an independently living elderly person. This study proposes a method for detecting the events and states of indoor everyday objects such as doors and windows without using distributed sensors attached to the objects. In this study, we achieve practical and unobtrusive event detection using a commodity Wi-Fi access point and a computer equipped with a commodity Wi-Fi module. Specifically, we detect the events using Wi-Fi channel state information (CSI), which describes how a signal propagates from a transmitter to a receiver, and is affected by such events. To handle CSI data that consists of the mixed effects of multiple indoor objects in an environment of interest, we employ independent component analysis to separate the events caused by the objects. The decomposed data are then fed into our event classifier based on convolutional and recurrent neural networks to automatically extract features from CSI data, as it is difficult to intuitively design features to be extracted from the CSI data. Moreover, we correct the neural network estimates by incorporating knowledge about the state transitions of an object using hidden Markov models. For example, because the “open” event of a door occurs only when the door is in a “closed” state. We correct impossible state transitions estimated by the neural network based on this knowledge.","Volume 1 Issue 3, September 2017"
347,10.1145/3130954,"Shijia Pan, Tong Yu, Mostafa Mirshekari, Jonathon Fagert, Amelie Bonde, Ole J. Mengshoel, Hae Young Noh, Pei Zhang",FootprintID: Indoor Pedestrian Identification through Ambient Structural Vibration Sensing,"We present FootprintID, an indoor pedestrian identification system that utilizes footstep-induced structural vibration to infer pedestrian identities for enabling various smart building applications. Previous studies have explored other sensing methods, including vision-, RF-, mobile-, and acoustic-based methods. They often require specific sensing conditions, including line-of-sight, high sensor density, and carrying wearable devices. Vibration-based methods, on the other hand, provide easy-to-install sparse sensing and utilize gait to distinguish different individuals. However, the challenge for these methods is that the signals are sensitive to the gait variations caused by different walking speeds and the floor variations caused by structural heterogeneity.
We present FootprintID, a vibration-based approach that achieves robust pedestrian identification. The system uses vibration sensors to detect footstep-induced vibrations. It then selects vibration signals and classifiers to accommodate sensing variations, taking step location and frequency into account. We utilize the physical insight on how individual step signal changes with walking speeds and introduce an iterative transductive learning algorithm (ITSVM) to achieve robust classification with limited labeled training data. When trained only on the average walking speed and tested on different walking speeds, FootprintID achieves up to 96% accuracy and a 3X improvement in extreme speeds compared to the Support Vector Machine. Furthermore, it achieves up to 90% accuracy (1.5X improvement) in uncontrolled experiments.","Volume 1 Issue 3, September 2017"
348,10.1145/3130955,"Konstantinos Papangelis, Melvin Metzger, Yiyeng Sheng, Hai-Ning Liang, Alan Chamberlain, Ting Cao",Conquering the City: Understanding perceptions of Mobility and Human Territoriality in Location-based Mobile Games,"With the increasing popularity of mobile video games, game designers and developers are starting to integrate geolocation into video games. Popular location-based games such as Ingress or Pokémon Go have millions of users, yet little is known about how the use of such games influences the nature of a user’s interaction with other users and their physical surroundings. To investigate how location-based games are integrated into a player’s daily life, how they influence a player’s mobility through the city, their perception of places and the role of human territoriality in this context, we have developed a location-based mobile multiplayer game called CityConqueror. In this paper, we present CityConqueror and the results of a study, which has focused on participants playing the game over a period of two weeks. The findings show that location-based games can be designed to give the player the illusion of playing in the context of the “real” world rather than a virtual or hybrid game reality. Our findings also suggest that location-based games can have a strong influence on a player’s mobility and perception of urban space and that human territoriality can be expressed through location-based games. Based on our findings we propose a series of design implications for the design of mobile location-based games.","Volume 1 Issue 3, September 2017"
349,10.1145/3130956,"Martin Pielot, Bruno Cardoso, Kleomenis Katevas, Joan Serrà, Aleksandar Matic, Nuria Oliver",Beyond Interruptibility: Predicting Opportune Moments to Engage Mobile Phone Users,"Many of today's mobile products and services engage their users proactively via push notifications. However, such notifications are not always delivered at the right moment, therefore not meeting products' and users' expectations. To address this challenge, we aim at developing an intelligent mobile system that automatically infers moments in which users are open to engage with suggested content. To inform the development of such a system, we carried out a field study with 337 mobile phone users. For 4 weeks, participants ran a study application on their primary phones. They were tasked to frequently report their current mood via a notification-administered experience-sampling questionnaire. In this study, however, we analyze whether they voluntarily engaged with content that we offered at the bottom of that questionnaire. In addition, the study app logged a wide range of data related to their phone use. Based on 120 Million phone-use events and 78,930 questionnaire notifications, we build a machine-learning model that before delivering a notification predicts whether a participant will click on the notification and subsequently engage with the offered content. When compared to a naïve baseline, which emulates current non-intelligent engagement strategies, our model achieves 66.6% higher success rate in its predictions. If the model also considers the user's past behavior, predictions improve 5-fold over the baseline. Based on these findings, we discuss the implications for building an intelligent service that identifies opportune moments for proactive user engagement, while, at the same time, reduces the number of undesirable interruptions.","Volume 1 Issue 3, September 2017"
350,10.1145/3130957,"Aditya Ponnada, Caitlin Haynes, Dharam Maniar, Justin Manjourides, Stephen Intille",Microinteraction Ecological Momentary Assessment Response Rates: Effect of Microinteractions or the Smartwatch?,"Mobile-based ecological-momentary-assessment (EMA) is an in-situ measurement methodology where an electronic device prompts a person to answer questions of research interest. EMA has a key limitation: interruption burden. Microinteraction-EMA(µEMA) may reduce burden without sacrificing high temporal density of measurement. In µEMA, all EMA prompts can be answered with ‘at a glance' microinteractions. In a prior 4-week pilot study comparing standard EMA delivered on a phone (phone-EMA) vs. µEMA delivered on a smartwatch (watch-µEMA), watch-µEMA demonstrated higher response rates and lower perceived burden than phone-EMA, even when the watch-µEMA interruption rate was 8 times more than phone-EMA. A new 4-week dataset was gathered on smartwatch-based EMA (i.e., watch-EMA with 6 back-to-back, multiple-choice questions on a watch) to compare whether the high response rates of watch-µEMA previously observed were a result of using microinteractions, or due to the novelty and accessibility of the smartwatch. No statistically significant differences in compliance, completion, and first-prompt response rates were observed between phone-EMA and watch-EMA. However, watch-µEMA response rates were significantly higher than watch-EMA. This pilot suggests that (1) the high compliance and low burden previously observed in watch-µEMA is likely due to the microinteraction question technique, not simply the use of the watch versus the phone, and that (2) compliance with traditional EMA (with long surveys) may not improve simply by moving survey delivery from the phone to a smartwatch.","Volume 1 Issue 3, September 2017"
351,10.1145/3130958,"Kyle Rector, Keith Salmon, Dan Thornton, Neel Joshi, Meredith Ringel Morris",Eyes-Free Art: Exploring Proxemic Audio Interfaces For Blind and Low Vision Art Engagement,"Engagement in the arts1 is an important component of participation in cultural activities, but remains a largely unaddressed challenge for people with sensory disabilities. Visual arts are generally inaccessible to people with visual impairments due to their inherently visual nature. To address this, we present Eyes-Free Art, a design probe to explore the use of proxemic audio for interactive sonic experiences with 2D art work. The proxemic audio interface allows a user to move closer and further away from a painting to experience background music, a novel sonification, sound effects, and a detailed verbal description. We conducted a lab study by creating interpretations of five paintings with 13 people with visual impairments and found that participants enjoyed interacting with the artwork. We then created a live installation with a visually impaired artist to iterate on this concept to account for multiple users and paintings. We learned that a proxemic audio interface allows for people to feel immersed in the artwork. Proxemic audio interfaces are similar to visual because they increase in detail with closer proximity, but are different because they need a descriptive verbal overview to give context. We present future research directions in the space of proxemic audio interactions.","Volume 1 Issue 3, September 2017"
352,10.1145/3130959,"Vitor F. Rey, Paul Lukowicz",Label Propagation: An Unsupervised Similarity Based Method for Integrating New Sensors in Activity Recognition Systems,"Current activity recognition systems mostly work with static, pre-trained sensor configuration. As a consequence they are not able to leverage new sensors appearing in their environment (e.g. the user buying a new wearable devices). In this work we present a method inspired by semi-supervised graph methods that can add new sensors to an existing system in an unsupervised manner. We have evaluated our method in two well known activity recognition datasets and found that it can take advantage of the information provided by new unknown sensor sources, improving the recognition performance in most cases.","Volume 1 Issue 3, September 2017"
353,10.1145/3130960,"Koustuv Saha, Larry Chan, Kaya De Barbaro, Gregory D. Abowd, Munmun De Choudhury",Inferring Mood Instability on Social Media by Leveraging Ecological Momentary Assessments,"Active and passive sensing technologies are providing powerful mechanisms to track, model, and understand a range of health behaviors and well-being states. Despite yielding rich, dense and high fidelity data, current sensing technologies often require highly engineered study designs and persistent participant compliance, making them difficult to scale to large populations and to data acquisition tasks spanning extended time periods. This paper situates social media as a new passive, unobtrusive sensing technology. We propose a semi-supervised machine learning framework to combine small samples of data gathered through active sensing, with large-scale social media data to infer mood instability (MI) in individuals. Starting from a theoretically-grounded measure of MI obtained from mobile ecological momentary assessments (EMAs), we show that our model is able to infer MI in a large population of Twitter users with 96% accuracy and F-1 score. Additionally, we show that, our model predicts self-identifying Twitter users with bipolar and borderline personality disorder to exhibit twice the likelihood of high MI, compared to that in a suitable control. We discuss the implications and the potential for integrating complementary sensing capabilities to address complex research challenges in precision medicine.","Volume 1 Issue 3, September 2017"
354,10.1145/3130961,"Asif Salekin, Zeya Chen, Mohsin Y. Ahmed, John Lach, Donna Metz, Kayla De La Haye, Brooke Bell, John A. Stankovic",Distant Emotion Recognition,"Distant emotion recognition (DER) extends the application of speech emotion recognition to the very challenging situation that is determined by variable speaker to microphone distances. The performance of conventional emotion recognition systems degrades dramatically as soon as the microphone is moved away from the mouth of the speaker. This is due to a broad variety of effects such as background noise, feature distortion with distance, overlapping speech from other speakers, and reverberation. This paper presents a novel solution for DER, addressing the key challenges by identification and deletion of features from consideration which are significantly distorted by distance, creating a novel, called Emo2vec, feature modeling and overlapping speech filtering technique, and the use of an LSTM classifier to capture the temporal dynamics of speech states found in emotions. A comprehensive evaluation is conducted on two acted datasets (with artificially generated distance effect) as well as on a new emotional dataset of spontaneous family discussions with audio recorded from multiple microphones placed in different distances. Our solution achieves an average 91.6%, 90.1% and 89.5% accuracy for emotion happy, angry and sad, respectively, across various distances which is more than a 16% increase on average in accuracy compared to the best baseline method.","Volume 1 Issue 3, September 2017"
355,10.1145/3132028,"Reham Mohamed, Moustafa Youssef",HeartSense: Ubiquitous Accurate Multi-Modal Fusion-based Heart Rate Estimation Using Smartphones,"Heart rate is one of the most important vital signals for personal health tracking. A number of smartphone-based heart rate estimation systems have been proposed over the years. However, they either depend on special hardware sensors or suffer from the high noise due to the weakness of the heart signals, affecting their accuracy in many practical scenarios.
Inspired by medical studies about the heart motion mechanics, we propose the HeartSense heart rate estimation system. Specifically, we show that the gyroscope sensor is the most sensitive sensor for measuring the heart rate. To further counter noise and handle different practical scenarios, we introduce a novel quality metric that allows us to fuse the different gyroscope axes in a probabilistic framework to achieve a robust and accurate estimate.
We have implemented and evaluated our system on different Android phones. Results using 836 experiments on different subjects in practical scenarios with a side-by-side comparison with other systems show that HeartSense can achieve 1.03 bpm median absolute error for heart rate estimation. This is better than the state-of-the-art by more than 147% in median error, highlighting HeartSense promise as a ubiquitous system for medical and personal well-being applications.","Volume 1 Issue 3, September 2017"
356,10.1145/3130963,"Zhanna Sarsenbayeva, Niels van Berkel, Aku Visuri, Sirkka Rissanen, Hannu Rintamaki, Vassilis Kostakos, Jorge Goncalves",Sensing Cold-Induced Situational Impairments in Mobile Interaction Using Battery Temperature,"Previous work has highlighted the detrimental effect of cold ambience on fine-motor skills during interaction with mobile devices. In this work, we develop a method to infer changes in finger temperature of smartphone users without the need for specialised hardware. Specifically, we demonstrate that smartphone battery temperature is a reliable gauge for determining changes to finger temperature. In addition, we show that the behaviour of smartphone battery temperature in cold settings is consistent across different smartphone models and battery configurations. Our method can be used to determine cold-induced situational impairments, and trigger interface adaptations during mobile interaction.","Volume 1 Issue 3, September 2017"
357,10.1145/3130964,"Dominik Schürmann, Sergej Dechand, Lars Wolf",OpenKeychain: An Architecture for Cryptography with Smart Cards and NFC Rings on Android,"While many Android apps provide end-to-end encryption, the cryptographic keys are still stored on the device itself and can thus be stolen by exploiting vulnerabilities. External cryptographic hardware solves this issue, but is currently only used for two-factor authentication and not for communication encryption.
In this paper, we design, implement, and evaluate an architecture for NFC-based cryptography on Android. Our high-level API provides cryptographic operations without requiring knowledge of public-key cryptography. By developing OpenKeychain, we were able to roll out this architecture for more than 100,000 users. It provides encryption for emails, messaging, and a password manager. We provide a threat model, NFC performance measurements, and discuss their impact on our architecture design. As an alternative form factor to smart cards, we created the prototype of an NFC signet ring. To evaluate the UI components and form factors, a lab study with 40 participants at a large company has been conducted. We measured the time required by the participants to set up the system and reply to encrypted emails. These measurements and a subsequent interview indicate that our NFC-based solutions are more user friendly in comparison to traditional password-protected keys.","Volume 1 Issue 3, September 2017"
358,10.1145/3132026,"Caitlyn Seim, Nick Doering, Yang Zhang, Wolfgang Stuerzlinger, Thad Starner",Passive Haptic Training to Improve Speed and Performance on a Keypad,"Learning text entry systems is challenging, yet necessary. Many layouts and keyboards exist, but they rely on laborious learning techniques. Passive haptic learning (PHL) has already demonstrated some benefit for learning the Braille text entry system. Could this computing-enabled technique be used to improve desktop keyboard typing skills? It is unknown whether passive haptic training can improve speed on a motor task (as opposed to initial learning). We use a randomized numeric keypad to examine users’ typing performance with or without passive haptic training. When users were prevented from looking at the keyboard, the PHL group demonstrated consistent accuracy (-0.011 KSPC) while those in the control group greatly increased their error (+1.26 KSPC on average). This result is consistent with the finding that PHL users looked significantly less at the keyboard. In a second, longer study, users exposed to PHL were found to significantly improve their typing speed (mean increase of 11 WPM) versus control (mean increase of 2.2 WPM).","Volume 1 Issue 3, September 2017"
359,10.1145/3130966,"Matthias Seuter, Max Pfeiffer, Gernot Bauer, Karen Zentgraf, Christian Kray",Running with Technology: Evaluating the Impact of Interacting with Wearable Devices on Running Movement,"The use of wearable devices during running has become commonplace. Although there is ongoing research on interaction techniques for use while running, the effects of the resulting interactions on the natural movement patterns have received little attention so far. While previous studies on pedestrians reported increased task load and reduced walking speed while interacting, running movement further restricts interaction and requires minimizing interferences, e.g. to avoid injuries and maximize comfort. In this paper, we aim to shed light on how interacting with wearable devices affects running movement. We present results from a motion-tracking study (N=12) evaluating changes in movement and task load when users interact with a smartphone, a smartwatch, or a pair of smartglasses while running. In our study, smartwatches required less effort than smartglasses when using swipe input, resulted in less interference with the running movement and were preferred overall. From our results, we infer a number of guidelines regarding interaction design targeting runners.","Volume 1 Issue 3, September 2017"
360,10.1145/3130967,"Marco Speicher, Sebastian Cucerca, Antonio Krüger",VRShop: A Mobile Interactive Virtual Reality Shopping Environment Combining the Benefits of On- and Offline Shopping,"In this work, we explored the main characteristics of on- and offline shops with regard to customer shopping behavior and frequency. Thus, we designed and implemented an immersive virtual reality (VR) online shopping environment. We tried to maintain the benefits of online shops, like search functionality and availability, while simultaneously focusing on shopping experience and immersion. By touching the third dimension, VR provides a more advanced form of visualization, which can increase the customer’s satisfaction and thus shopping experience. We further introduced the Virtual Reality Shopping Experience (VRSE) model based on customer satisfaction, task performance and user preference. A case study of a first VR shop prototype was conducted and evaluated with respect to the VRSE model. The results showed that the usability and user experience of our system is above average overall. In summary, searching for a product in a WebVR online shop using speech input in combination with VR output proved to be the best regarding user performance (speed, error rate) and preference (usability, user experience, immersion, motion sickness).","Volume 1 Issue 3, September 2017"
361,10.1145/3130968,"Masato Sugasaki, Masamichi Shimosaka",Robust Indoor Localization across Smartphone Models with Ellipsoid Features from Multiple RSSIs,"Localization for mobile devices has become important as the basis technology for various ubiquitous computing applications. While GPS is leveraged as the de-facto standard technology in outdoor localization, its accuracy is poor indoors. For twenty years, researchers have tried to investigate indoor localization technology using fingerprinting from received signal strength indicators (RSSIs). With the widespread use of smartphones in the last decade, device dependency (e.g. antenna characteristics) must be considered to avoid performance degradation, while most of the recent localization approaches assume that all the smartphone models have the same device characteristics.
In this paper, we propose a novel feature representation based on multiple RSSIs for compensating performance degradation against smartphone models changes. In contrast to the previous feature representation based on a single RSSI, our new feature representation, which we call Ellipsoid features, employs tuples of pair of RSSIs to eliminate device dependence in the path loss model for wave propagation. In contrast to recent advances in machine learning methods such as domain adaptation, multi-task learning, and semi-supervised learning, our approach requires no additional dataset nor retraining for the new target models. This simplicity would promote ubiquity of indoor localization in the era of smartphones. Moreover, our feature representation works well compared to the state-of-the-arts in feature representations based on multiple RSSIs even when only a small number of access points (APs) are available. Experimental result using smartphone devices including Android Nexus5, Nexus5X, Nexus6P, and Xperia X Performance shows that our approach achieves superior performance over the state-of-the-art indoor localization models as well as robust performance against device changes.","Volume 1 Issue 3, September 2017"
362,10.1145/3130969,"Xiao Sun, Li Qiu, Yibo Wu, Yeming Tang, Guohong Cao",SleepMonitor: Monitoring Respiratory Rate and Body Position During Sleep Using Smartwatch,"Respiratory rate and body position are two major physiological parameters in sleep study, and monitoring them during sleep can provide helpful information for health care. In this paper, we present SleepMonitor, a smartwatch based system which leverages the built-in accelerometer to monitor the respiratory rate and body position. To calculate respiratory rate, we design a filter to extract the weak respiratory signal from the noisy accelerometer data collected on the wrist, and use frequency analysis to estimate the respiratory rate from the data along each axis. Further, we design a multi-axis fusion approach which can adaptively adjust the estimates from the three axes and then significantly improve the estimation accuracy. To detect the body position, we apply machine learning techniques based on the features extracted from the accelerometer data. We have implemented our system on Android Wear based smartwatches and evaluated its performance in real experiments. The results show that our system can monitor respiratory rate and body position during sleep with high accuracy under various conditions.","Volume 1 Issue 3, September 2017"
363,10.1145/3130970,"Vamsi Talla, Mehrdad Hessar, Bryce Kellogg, Ali Najafi, Joshua R. Smith, Shyamnath Gollakota",LoRa Backscatter: Enabling The Vision of Ubiquitous Connectivity,"The vision of embedding connectivity into billions of everyday objects runs into the reality of existing communication technologies -- there is no existing wireless technology that can provide reliable and long-range communication at tens of microwatts of power as well as cost less than a dime. While backscatter is low-power and low-cost, it is known to be limited to short ranges. This paper overturns this conventional wisdom about backscatter and presents the first wide-area backscatter system. Our design can successfully backscatter from any location between an RF source and receiver, separated by 475 m, while being compatible with commodity LoRa hardware. Further, when our backscatter device is co-located with the RF source, the receiver can be as far as 2.8 km away. We deploy our system in a 4,800 ft2 (446 m2) house spread across three floors, a 13,024 ft2 (1210 m2) office area covering 41 rooms, as well as a one-acre (4046 m2) vegetable farm and show that we can achieve reliable coverage, using only a single RF source and receiver. We also build a contact lens prototype as well as a flexible epidermal patch device attached to the human skin. We show that these devices can reliably backscatter data across a 3,328 ft2 (309 m2) room. Finally, we present a design sketch of a LoRa backscatter IC that shows that it costs less than a dime at scale and consumes only 9.25 &amp;mgr;W of power, which is more than 1000x lower power than LoRa radio chipsets.","Volume 1 Issue 3, September 2017"
364,10.1145/3130971,"Marc Tonsen, Julian Steil, Yusuke Sugano, Andreas Bulling",InvisibleEye: Mobile Eye Tracking Using Multiple Low-Resolution Cameras and Learning-Based Gaze Estimation,"Analysis of everyday human gaze behaviour has significant potential for ubiquitous computing, as evidenced by a large body of work in gaze-based human-computer interaction, attentive user interfaces, and eye-based user modelling. However, current mobile eye trackers are still obtrusive, which not only makes them uncomfortable to wear and socially unacceptable in daily life, but also prevents them from being widely adopted in the social and behavioural sciences. To address these challenges we present InvisibleEye, a novel approach for mobile eye tracking that uses millimetre-size RGB cameras that can be fully embedded into normal glasses frames. To compensate for the cameras’ low image resolution of only a few pixels, our approach uses multiple cameras to capture different views of the eye, as well as learning-based gaze estimation to directly regress from eye images to gaze directions. We prototypically implement our system and characterise its performance on three large-scale, increasingly realistic, and thus challenging datasets: 1) eye images synthesised using a recent computer graphics eye region model, 2) real eye images recorded of 17 participants under controlled lighting, and 3) eye images recorded of four participants over the course of four recording sessions in a mobile setting. We show that InvisibleEye achieves a top person-specific gaze estimation accuracy of 1.79° using four cameras with a resolution of only 5 × 5 pixels. Our evaluations not only demonstrate the feasibility of this novel approach but, more importantly, underline its significant potential for finally realising the vision of invisible mobile eye tracking and pervasive attentive user interfaces.","Volume 1 Issue 3, September 2017"
365,10.1145/3130972,"Niels van Berkel, Jorge Goncalves, Simo Hosio, Vassilis Kostakos",Gamification of Mobile Experience Sampling Improves Data Quality and Quantity,"The Experience Sampling Method is used to capture high-quality in situ data from study participants. This method has become popular in studies involving smartphones, where it is often adapted to motivate participation through the use of gamification techniques. However, no work to date has evaluated whether gamification actually affects the quality and quantity of data collected through Experience Sampling. Our study systematically investigates the effect of gamification on the quantity and quality of experience sampling responses on smartphones. In a field study, we combine event contingent and interval contingent triggers to ask participants to describe their location. Subsequently, participants rate the quality of these entries by playing a game with a purpose. Our results indicate that participants using the gamified version of our ESM software provided significantly higher quality responses, slightly increased their response rate, and provided significantly more data on their own accord. Our findings suggest that gamifying experience sampling can improve data collection and quality in mobile settings.","Volume 1 Issue 3, September 2017"
366,10.1145/3132030,"Morgan Vigil-Hayes, Elizabeth Belding, Ellen Zegura",FiDO: A Community-based Web Browsing Agent and CDN for Challenged Network Environments,"Homes located on tribal lands, particularly in rural areas of the United States, continue to lack access to broadband Internet and cellular connectivity [19]. Inspired by previous observations of community content similarity in tribal networks, we propose FiDO, a community-based Web browsing and content delivery system that takes advantage of user mobility, opportunistic connectivity, and collaborative filtering to provide relevant Web content to members of disconnected households via opportunistic contact with cellular base stations during a daily commute. We evaluate FiDO using trace-driven simulations with network usage data collected from a tribal-operated ISP that serves the Coeur d’Alene Indian Reservation in Western Idaho. By collecting data about household Web preferences and applying a collaborative filtering technique based on the Web usage patterns of the surrounding reservation community, we are able to opportunistically browse the Web on behalf of members of disconnected households, providing an average of 69.4 Web pages (all content from a specific URL, e.g., “http://gis.cdatribe-nsn.gov/LandBuyBack/”) crawled from 73% of their top 10 most visited Web domains (e.g., “cdatribe-nsn.gov” or “cnn.com/”) per day. Moreover, this content is able to be fetched and pushed to users even when the opportunistic data rate is limited to an average of only 0.99 Mbps (σ = 0.24 Mbps) and the daily opportunistic connection time is an average of 45.9 minutes (σ = 2.3 minutes). Additionally, we demonstrate a hybrid “search and browse” approach that allocates a percentage of opportunistic resources to the download of user-specified content. By dedicating only 10% of opportunistic windows of connectivity to the download of social media content, 51% of households were able to receive all of their daily expected social media content in addition to an average of 55.3 Web pages browsed on their behalf from an average of 4 different Web domains. Critically, we demonstrate the feasibility of a collaborative and community-based Web browsing model that extends access to Web content across the last mile(s) using existing infrastructure and rural patterns of mobility.","Volume 1 Issue 3, September 2017"
367,10.1145/3130974,"Tung Vuong, Giulio Jacucci, Tuukka Ruotsalo",Watching inside the Screen: Digital Activity Monitoring for Task Recognition and Proactive Information Retrieval,"We investigate to what extent it is possible to infer a user’s work tasks by digital activity monitoring and use the task models for proactive information retrieval. Ten participants volunteered for the study, in which their computer screen was monitored and related logs were recorded for 14 days. Corresponding diary entries were collected to provide ground truth to the task detection method. We report two experiments using this data. The unsupervised task detection experiment was conducted to detect tasks using unsupervised topic modeling. The results show an average task detection accuracy of more than 70% by using rich screen monitoring data. The single-trial task detection and retrieval experiment utilized unseen user inputs in order to detect related work tasks and retrieve task-relevant information on-line. We report an average task detection accuracy of 95%, and the corresponding model-based document retrieval with Normalized Discounted Cumulative Gain of 98%. We discuss and provide insights regarding the types of digital tasks occurring in the data, the accuracy of task detection on different task types, and the role of using different data input such as application names, extracted keywords, and bag-of-words representations in the task detection process. We also discuss the implications of our results for ubiquitous user modeling and privacy.","Volume 1 Issue 3, September 2017"
368,10.1145/3130976,"Rui Wang, Weichen Wang, Min S. H. Aung, Dror Ben-Zeev, Rachel Brian, Andrew T. Campbell, Tanzeem Choudhury, Marta Hauser, John Kane, Emily A. Scherer, Megan Walsh",Predicting Symptom Trajectories of Schizophrenia using Mobile Sensing,"Continuously monitoring schizophrenia patients’ psychiatric symptoms is crucial for in-time intervention and treatment adjustment. The Brief Psychiatric Rating Scale (BPRS) is a survey administered by clinicians to evaluate symptom severity in schizophrenia. The CrossCheck symptom prediction system is capable of tracking schizophrenia symptoms based on BPRS using passive sensing from mobile phones. We present results from an ongoing randomized control trial, where passive sensing data, self-reports, and clinician administered 7-item BPRS surveys are collected from 36 outpatients with schizophrenia recently discharged from hospital over a period ranging from 2-12 months. We show that our system can predict a symptom scale score based on a 7-item BPRS within ±1.45 error on average using automatically tracked behavioral features from phones (e.g., mobility, conversation, activity, smartphone usage, the ambient acoustic environment) and user supplied self-reports. Importantly, we show our system is also capable of predicting an individual BPRS score within ±1.59 error purely based on passive sensing from phones without any self-reported information from outpatients. Finally, we discuss how well our predictive system reflects symptoms experienced by patients by reviewing a number of case studies.","Volume 1 Issue 3, September 2017"
369,10.1145/3130975,"Xiao Wang, Tong Yu, Ming Zeng, Patrick Tague",XRec: Behavior-Based User Recognition Across Mobile Devices,"As smartphones and tablets become increasingly prevalent, more customers have multiple devices. The multi-user, multi-device interactions inspire many problems worthy of investigation, among which recognizing users across devices has significant implications on recommendation, advertising and user experience. Unlike the binary classification problem in user identification on a single device, cross-device user recognition is essentially a set partition problem. The app back-end aims to divide user activities on devices hosting the app into groups each associated with one user. In this paper, we present XRec which leverages user behavioral patterns, namely when, where and how a user uses the app, to achieve the recognition. To address the user-device partition problem, we propose a classification-plus-refinement algorithm. To validate our approach, we conduct a field study with an Android app. We instrument the app to collect usage data from real users. We provide proof-of-concept experimental results to demonstrate how XRec can provide added value to mobile apps, with the ability to correctly match a user across multiple devices with 70% recall and 90% precision.","Volume 1 Issue 3, September 2017"
370,10.1145/3130977,"Peter Washington, Catalin Voss, Aaron Kline, Nick Haber, Jena Daniels, Azar Fazel, Titas De, Carl Feinstein, Terry Winograd, Dennis Wall",SuperpowerGlass: A Wearable Aid for the At-Home Therapy of Children with Autism,"We have developed a system for automatic facial expression recognition running on Google Glass, delivering real-time social cues to children with Autism Spectrum Disorder (ASD). The system includes multiple mechanisms to engage children and their parents, who administer this technology within the home. We completed an at-home design trial with 14 families that used the learning aid over a 3-month period. We found that children with ASD generally respond well to wearing the system at home and opt for the most expressive feedback choice. We further evaluated app usage, facial engagement, and model accuracy. We found that the device can act as a powerful training aid when used periodically in the home, that interactive video content from wearable therapy sessions should be augmented with sufficient context about the content to produce long-term engagement, and that the design of wearable systems for children with ASD should be heavily dependent on the functioning level of the child. We contribute general design implications for developing wearable aids used by children with ASD and other behavioral disorders as well as their parents during at-home parent-administered therapy sessions.","Volume 1 Issue 3, September 2017"
371,10.1145/3130978,"Eric Whitmire, Mohit Jain, Divye Jain, Greg Nelson, Ravi Karkar, Shwetak Patel, Mayank Goel",DigiTouch: Reconfigurable Thumb-to-Finger Input and Text Entry on Head-mounted Displays,"Input is a significant problem for wearable systems, particularly for head mounted virtual and augmented reality displays. Existing input techniques either lack expressive power or may not be socially acceptable. As an alternative, thumb-to-finger touches present a promising input mechanism that is subtle yet capable of complex interactions. We present DigiTouch, a reconfigurable glove-based input device that enables thumb-to-finger touch interaction by sensing continuous touch position and pressure. Our novel sensing technique improves the reliability of continuous touch tracking and estimating pressure on resistive fabric interfaces. We demonstrate DigiTouch’s utility by enabling a set of easily reachable and reconfigurable widgets such as buttons and sliders. Since DigiTouch senses continuous touch position, widget layouts can be customized according to user preferences and application needs. As an example of a real-world application of this reconfigurable input device, we examine a split-QWERTY keyboard layout mapped to the user’s fingers. We evaluate DigiTouch for text entry using a multi-session study. With our continuous sensing method, users reliably learned to type and achieved a mean typing speed of 16.0 words per minute at the end of ten 20-minute sessions, an improvement over similar wearable touch systems.","Volume 1 Issue 3, September 2017"
372,10.1145/3130979,"Di Wu, Dmitri I. Arkhipov, Thomas Przepiorka, Yong Li, Bin Guo, Qiang Liu",From Intermittent to Ubiquitous: Enhancing Mobile Access to Online Social Networks with Opportunistic Optimization,"Accessing online social networks in situations with intermittent Internet connectivity is a challenge. We have designed a context-aware mobile system to enable efficient offline access to online social media by prefetching, caching and disseminating content opportunistically when signal availability is detected. This system can measure, crowdsense and predict network characteristics, and then use these predictions of mobile network signal to schedule cellular access or device-to-device (D2D) communication. We propose several opportunistic optimization schemes to enhance controlled crowdsensing, resource constrained mobile prefetch, and D2D transmissions impacted by individual selfishness. Realistic tests and large-scale trace analysis show our system can achieve a significant improvement over existing approaches in situations where users experience intermittent cellular service or disrupted network connection.","Volume 1 Issue 3, September 2017"
373,10.1145/3130981,"Hao Wu, Weiwei Sun, Baihua Zheng, Li Yang, Wei Zhou",CLSTERS: A General System for Reducing Errors of Trajectories Under Challenging Localization Situations,"Trajectory data generated by outdoor activities have great potential for location based services. However, depending on the localization technique used, certain trajectory data could contain large errors. For example, the error of trajectories generated by cellular-based localization techniques is around 100m which is ten times larger than that of GPS-based trajectories. Hence, enhancing the utility of those large-error trajectories becomes a challenge. In this paper we show how to improve the quality of trajectory data having large errors. Some existing works reduce the error through hardware which requires information such as the time of arrival (TOA), received signal strength indication (RSSI), the position of cell towers, etc. Moreover, different positioning techniques will result in different hardware-based solutions and different data formats, which limit the generalizablity. Other works study a related but different problem, i.e., map matching, with the aid of road network information, to reduce the uncertainty and the noise of trajectory data. However, most of these approaches are designed for the GPS-sampled data, and hence they might not be able to achieve a similar performance when applied directly to trajectories with large errors. Motivated by this, we propose a general error reduction system namely CLSTERS for trajectories with large scale of errors. Our system is hardware independent and only requires the coordinates and the time stamp of each sample point which makes it general and ubiquitous. We present results from experiments using three real-world datasets in three different cities generated by two different localization techniques and the results show that our approach outperforms existing solutions.","Volume 1 Issue 3, September 2017"
374,10.1145/3131903,"Xiaojie Wu, Ling Chen, Mingqi Lv, Mingrui Han, Gencai Chen",Cost-Sensitive Semi-Supervised Personalized Semantic Place Label Recognition Using Multi-Context Data,"Personalized semantic place label recognition is a promising research issue in ubiquitous computing. However, there are some problems existed in the current methods: 1) They use trajectory data to learn recognition model and ignore other context data that could reflect human behaviors over places. 2) They tend to maximize accuracy and ignore the imbalanced costs caused by the similarity between semantic place labels. 3) They use supervised learning, which cannot achieve a good performance when the number of labeled places is limited. In this paper, we exploit multi-context data to construct effective features and propose a method called CEMENT (Cost-sensitive sEmi-supervised personalized seMantic place labEl recogNiTion). On one hand, CEMENT is cost-sensitive, and it calculates misclassification costs according to the semantic similarity between place labels. On the other hand, CEMENT utilizes ensemble semi-supervised learning to leverage the unlabeled data to improve the performance. Experimental results show that the proposed method has superiority over state-of-the-art methods.","Volume 1 Issue 3, September 2017"
375,10.1145/3130982,"Takahiro Yabe, Kota Tsubouchi, Yoshihide Sekimoto",CityFlowFragility: Measuring the Fragility of People Flow in Cities to Disasters using GPS Data Collected from Smartphones,"Economic loss caused by natural disasters is increasing in many cities around the world. There is an increasing demand for a method that effectively measures the fragility of people flow to appropriately plan the future investment into infrastructure. Conventional methods measure the fragility of urban systems using infrastructure data such as the road and railway networks. However, these methods are costly to perform, cannot directly measure the disruption on human activities caused by disasters, nor can they be applied for individual disasters. Here, we propose a novel method that quantifies the fragility of cities through detecting the delay in commuting activities using GPS data collected from smartphones. Because commuting activities are daily routines for many people, commuting flow has little day-to-day fluctuation, which makes it an appropriate metric for detecting anomalies and disruption in urban systems. This method can be utilized in any city in the world regardless of differences in network structures or population distribution, as long as people commute on a daily basis. We validate our method in various cities for snowfall and typhoons using real datasets in Japan, and show that intuitive results can be obtained. Our method's reliability is clarified by comparing the results with conventional metrics. We also present useful analyses and applications of CityFlowFragility for urban planning and disaster management.","Volume 1 Issue 3, September 2017"
376,10.1145/3130984,"Chouchang Jack Yang, Alanson P. Sample",EM-Comm: Touch-based Communication via Modulated Electromagnetic Emissions,"Touch-based communication offers a direct and intuitive way for users to initiate and control data transfer when using tangible and ubiquitous interfaces. However, this requires that each interactive device be instrumented with a dedicated radio transmitter, which limits many applications. While not all devices have radio hardware, all devices do emit small amounts of electromagnetic noise in the form of EMI. We argue that if properly modulated these electromagnetic emissions can be used as an untapped communication channel capable of transmitting arbitrary data.
To enable this, a spread spectrum frequency shift keying modulation scheme has been developed to encode data onto the device’s EMI. When the device is touched by a user, the data encoded EMI signal travels through their body and into our custom wrist band, consisting of a single op-amp and MCU. Our results show that we are able to turn electronic primitives such as LEDs, buttons, I/O lines, LCD screens, motors and power supplies into radio transmitters capable of touch communication. Effective data rates range from 5.8Kbps to 22 bit per image depending on the primitive used. To demonstrate this new communication technique, we develop several interactive experiences where users can retrieve complex information such as the function of buttons on a device, directions embedded into a LCD screen, and simplified device pairing. Ultimately, EM-Comm enables nearly any electronic device to be turned into a touch-based radio transmitter with only a software upgrade.","Volume 1 Issue 3, September 2017"
377,10.1145/3130983,"Su Yang, Minjie Wang, Wenshan Wang, Yi Sun, Jun Gao, Weishan Zhang, Jiulong Zhang",Predicting Commercial Activeness over Urban Big Data,"This study aims at revealing how commercial hotness of urban commercial districts (UCDs) is shaped by social contexts of surrounding areas so as to render predictive business planning. We define social contexts for a given region as the number of visitors, the region functions, the population and buying power of local residents, the average price of services, and the rating scores of customers, which are computed from heterogeneous data including taxi GPS trajectories, point of interests, geographical data, and user-generated comments. Then, we apply sparse representation to discover the impactor factor of each variable of the social contexts in terms of predicting commercial activeness of UCDs under a linear predictive model. The experiments show that a linear correlation between social contexts and commercial activeness exists for Beijing and Shanghai based on an average prediction accuracy of 77.69% but the impact factors of social contexts vary from city to city, where the key factors are rich life services, diversity of restaurants, good shopping experience, large number of local residents with relatively high purchasing power, and convenient transportation. This study reveals the underlying mechanism of urban business ecosystems, and promise social context-aware business planning over heterogeneous urban big data.","Volume 1 Issue 3, September 2017"
378,10.1145/3130985,"Cheng Zhang, Anandghan Waghmare, Pranav Kundra, Yiming Pu, Scott Gilliland, Thomas Ploetz, Thad E. Starner, Omer T. Inan, Gregory D. Abowd",FingerSound: Recognizing unistroke thumb gestures using a ring,"We introduce FingerSound, an input technology to recognize unistroke thumb gestures, which are easy to learn and can be performed through eyes-free interaction. The gestures are performed using a thumb-mounted ring comprising a contact microphone and a gyroscope sensor. A K-Nearest-Neighbor(KNN) model with a distance function of Dynamic Time Warping (DTW) is built to recognize up to 42 common unistroke gestures. A user study, where the real-time classification results were given, shows an accuracy of 92%-98% by a machine learning model built with only 3 training samples per gesture. Based on the user study results, we further discuss the opportunities, challenges and practical limitations of FingerSound when deploying it to real-world applications in the future.","Volume 1 Issue 3, September 2017"
379,10.1145/3130986,"Tengxiang Zhang, Xin Yi, Chun Yu, Yuntao Wang, Nicholas Becker, Yuanchun Shi",TouchPower: Interaction-based Power Transfer for Power-as-needed Devices,"The trend toward ubiquitous deployment of electronic devices demands novel low maintenance power schemes to decrease the burden of maintaining such a large number of devices. In this paper, we propose Interaction-based Power Transfer (IPT): a novel power scheme for power-as-needed devices (i.e., devices that only require power during interaction). IPT allows for the removal of built-in batteries on these devices, and to instead be powered up through direct contact interaction with the user (e.g. gripping a mouse, holding a pen). We prove the concept and show the potential of IPT through our TouchPower prototype. TouchPower transfers on-body power to off-body power-as-needed devices through contact between electrodes on a glove worn by the user and those on the target device during the interaction process. We design TouchPower to automatically detect the contact topology at runtime to supply power accordingly, and place electrodes on the glove so that TouchPower is compatible with various interactions with different objects. We also show the methodology of placing electrodes on the device-end, and evaluate it on a mouse and a remote controller. Results show that during interaction, TouchPower is able to provide stable power supply to these devices with only a small sacrifice in regards to interaction naturalness. At last we demonstrate six applications of TouchPower, and discuss the limitations and potential of TouchPower and IPT systems.","Volume 1 Issue 3, September 2017"
380,10.1145/3132027,"Yiran Zhao, Shuochao Yao, Shen Li, Shaohan Hu, Huajie Shao, Tarek F. Abdelzaher",VibeBin: A Vibration-Based Waste Bin Level Detection System,"This paper presents the design and implementation of VibeBin, a low-cost, non-intrusive and easy-to-install waste bin level detection system. Recent popularity of Internet-of-Things (IoT) sensors has brought us unprecedented opportunities to enable a variety of new services for monitoring and controlling smart buildings. Indoor waste management is crucial to a healthy environment in smart buildings. Measuring the waste bin fill-level helps building operators schedule garbage collection more responsively and optimize the quantity and location of waste bins. Existing systems focus on directly and intrusively measuring the physical quantities of the garbage (weight, height, volume, etc.) or its appearance (image), and therefore require careful installation, laborious calibration or labeling, and can be costly. Our system indirectly measures fill-level by sensing the changes in motor-induced vibration characteristics on the outside surface of waste bins. VibeBin exploits the physical nature of vibration resonance of the waste bin and the garbage within, and learns the vibration features of different fill-levels through a few garbage collection (emptying) cycles in a completely unsupervised manner. VibeBin identifies vibration features of different fill-levels by clustering historical vibration samples based on a custom distance metric which measures the dissimilarity between two samples. We deploy our system on eight waste bins of different types and sizes, and show that under normal usage and real waste, it can deliver accurate level measurements after just 3 garbage collection cycles. The average F-score (harmonic mean of precision and recall) of measuring empty, half, and full levels achieves 0.912. A two-week deployment also shows that the false positive and false negative events are satisfactorily rare.","Volume 1 Issue 3, September 2017"
381,10.1145/3090050,"Moses Akazue, Martin Halvey, Lynne Baillie",Using Thermal Stimuli to Enhance Photo-Sharing in Social Media,"Limited work has been undertaken to show how the emotive ability of thermal stimuli can be used for interaction purposes. One potential application area is using thermal stimuli to influence emotions in images shared online such as social media platforms. This paper presents a two-part study, which examines how the documented emotive property of thermal stimuli can be applied to enhance social media images. Participants in part-one supplied images from their personal collection or social media profiles, and were asked to augment each image with thermal stimuli based on the emotions they wanted to enhance or reduce. Part-one participants were interviewed to understand the effects they wanted augmented images to have. In part-two, these augmented images were perceived by a different set of participants in a simulated social media interface. Results showed strong agreement between the emotions augmented images were designed to evoke and the emotions they actually evoked as perceived by part-two participants. Participants in part-one selected thermal stimuli augmentation intended to modulate valence and arousal in images as a way of enhancing the realism of the images augmented. Part-two results indicate this was achieved as participants perceived thermal stimuli augmentation reduced valence in negative images and modulated valence and arousal in positive images.","Volume 1 Issue 2, June 2017"
382,10.1145/3090051,"Sangwon Bae, Denzil Ferreira, Brian Suffoletto, Juan C. Puyana, Ryan Kurtz, Tammy Chung, Anind K. Dey",Detecting Drinking Episodes in Young Adults Using Smartphone-based Sensors,"Alcohol use in young adults is common, with high rates of morbidity and mortality largely due to periodic, heavy drinking episodes (HDEs). Behavioral interventions delivered through electronic communication modalities (e.g., text messaging) can reduce the frequency of HDEs in young adults, but effects are small. One way to amplify these effects is to deliver support materials proximal to drinking occasions, but this requires knowledge of when they will occur. Mobile phones have built-in sensors that can potentially be useful in monitoring behavioral patterns associated with the initiation of drinking occasions. The objective of our work is to explore the detection of daily-life behavioral markers using mobile phone sensors and their utility in identifying drinking occasions. We utilized data from 30 young adults aged 21-28 with past hazardous drinking and collected mobile phone sensor data and daily Experience Sampling Method (ESM) of drinking for 28 consecutive days. We built a machine learning-based model that is 96.6% accurate at identifying non-drinking, drinking and heavy drinking episodes. We highlight the most important features for detecting drinking episodes and identify the amount of historical data needed for accurate detection. Our results suggest that mobile phone sensors can be used for automated, continuous monitoring of at-risk populations to detect drinking episodes and support the delivery of timely interventions.","Volume 1 Issue 2, June 2017"
383,10.1145/3090052,"Paul Baumann, Silvia Santini",Every Byte Counts: Selective Prefetching for Mobile Applications,"Quick responses to user actions are instrumental to the success of mobile applications. To ensure such responsiveness, applications often prefetch data objects before the user requests them. This way, applications can avoid the need to retrieve data through slow network connections during user interactions. However, prefetches may also harm. They increase launch delays and might cause substantial amounts of data to be downloaded through energy-hungry, cellular connections. In this paper, we propose EBC, a novel algorithm to schedule application prefetches and overcome their drawbacks. EBC computes application usage probabilities and traffic volume estimates to determine when and for which applications prefetches should be triggered. Thereby, it applies different strategies depending on whether a cellular or Wi-Fi connection is available. We evaluate the performance of EBC on two publicly available, large-scale data sets: LiveLab and Device Analyzer. Our results show that EBC can lower launch delays and ensure freshness of application content. At the same time, it reduces the amount of data downloaded through cellular connections. On the Device Analyzer data set, for instance, EBC achieves a 10% reduction in cellular traffic and a 36% better average freshness with respect to its closest competitor.","Volume 1 Issue 2, June 2017"
384,10.1145/3090053,"Simon Butscher, Maximilian Dürr, Harald Reiterer",InformationSense: Trade-offs for the Design and the Implementation of a Large Highly Deformable Cloth Display,"Deformable displays can provide two major benefits compared to rigid displays: Objects of different shapes and deformabilities, situated in our physical environment, can be equipped with deformable displays, and users can benefit from their pre-existing knowledge about the interaction with physical objects when interacting with deformable displays. In this article we present InformationSense, a large, highly deformable cloth display. The article contributes to two research areas in the context of deformable displays: It presents an approach for the tracking of large, highly deformable surfaces, and it presents one of the first UX analyses of cloth displays that will help with the design of future interaction techniques for this kind of display. The comparison of InformationSense with a rigid display interface unveiled the trade-off that while users are able to interact with InformationSense more naturally and significantly preferred InformationSense in terms of joy of use, they preferred the rigid display interfaces in terms of efficiency. This suggests that deformable displays are already suitable if high hedonic qualities are important but need to be enhanced with additional digital power if high pragmatic qualities are required.","Volume 1 Issue 2, June 2017"
385,10.1145/3090054,"Ke-Yu Chen, Rahul C. Shah, Jonathan Huang, Lama Nachman",Mago: Mode of Transport Inference Using the Hall-Effect Magnetic Sensor and Accelerometer,"In this paper, we introduce Mago, a novel system that can infer a person's mode of transport (MOT) using the Hall-effect magnetic sensor and accelerometer present in most smart devices. When a vehicle is moving, the motions of its mechanical components such as the wheels, transmission and the differential distort the earth's magnetic field. The magnetic field is distorted corresponding to the vehicle structure (e.g., bike chain or car transmission system), which manifests itself as a strong signal for sensing a person's transportation modality. We utilize this magnetic signal combined with the accelerometer and design a robust algorithm for the MOT detection. In particular, our system extracts frame-based features from the sensor data and can run in nearly real-time with only a few seconds of delay. We evaluated Mago using over 70 hours of daily commute data from 7 participants and the leave-one-out analysis of our cross-user, cross-device model reports an average accuracy of 94.4% among seven classes (stationary, bus, bike, car, train, light rail and scooter). Besides MOT, our system is able to reliably differentiate the phone's in-car position at an average accuracy of 92.9%. We believe Mago could potentially benefit many contextually-aware applications that require MOT detection such as a digital personal assistant or a life coaching application.","Volume 1 Issue 2, June 2017"
386,10.1145/3090055,"David Dobbelstein, Christian Winkler, Gabriel Haas, Enrico Rukzio",PocketThumb: a Wearable Dual-Sided Touch Interface for Cursor-based Control of Smart-Eyewear,"We present PocketThumb, a wearable touch interface for smart-eyewear that is embedded into the fabrics of the front trouser pocket. The interface is reachable from outside and inside of the pocket to allow for a combined dual-sided touch input. The user can control an absolute cursor with their thumb sliding along the fabric from the inside, while at the same time tapping or swiping with fingers from the outside to perform joint gestures. This allows for resting the hand in a comfortable and quickly accessible position, while performing interaction with a high expressiveness that is feasible in mobile scenarios. In a cursor-based target selection study, we found that our introduced dual-sided touch interaction is significantly faster in comparison to common single-sided absolute as well as relative touch interaction (~19%, resp. ~23% faster). The effect is largest in the mobile conditions standing and walking (up to ~31% faster).","Volume 1 Issue 2, June 2017"
387,10.1145/3090075,"S. Mitchell Finnigan, A. K. Clear, G. Farr-Wharton, K. Ladha, R. Comber",Augmenting Audits: Exploring the Role of Sensor Toolkits in Sustainable Buildings Management,"Audits are commonly carried out by facilities managers (FMs) to quantify the sustainability and performance of the buildings they manage, informing improvements to infrastructure for resource and cost savings, and assessing compliance with standards and legislation. The scope for what can be audited is limited by available infrastructure. In this article, we investigate the utility of a flexible sensor toolkit to enhance existing energy auditing practices. We present findings from a qualitative study with FM and student auditor participants from 3 organisations. Our study covers how these toolkits were used and integrated into auditing practices within these organisations, and the opportunities and issues for resource management that arose as a result. We conclude with design implications for toolkits to support sensor-augmented audits, make recommendations towards a deployment protocol for sensor toolkits used in this context, and develop broader considerations for how future standards and policies might be adapted to leverage this potential.","Volume 1 Issue 2, June 2017"
388,10.1145/3090076,"Yu Guan, Thomas Plötz",Ensembles of Deep LSTM Learners for Activity Recognition using Wearables,"Recently, deep learning (DL) methods have been introduced very successfully into human activity recognition (HAR) scenarios in ubiquitous and wearable computing. Especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real-life HAR applications. Even though DL-based approaches now outperform the state-of-the-art in a number of recognition tasks, still substantial challenges remain. Most prominently, issues with real-life datasets, typically including imbalanced datasets and problematic data quality, still limit the effectiveness of activity recognition using wearables. In this paper we tackle such challenges through Ensembles of deep Long Short Term Memory (LSTM) networks. LSTM networks currently represent the state-of-the-art with superior classification performance on relevant HAR benchmark datasets. We have developed modified training procedures for LSTM networks and combine sets of diverse LSTM learners into classifier collectives. We demonstrate that Ensembles of deep LSTM learners outperform individual LSTM networks and thus push the state-of-the-art in human activity recognition using wearables. Through an extensive experimental evaluation on three standard benchmarks (Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition capabilities of our approach and its potential for real-life applications of human activity recognition.","Volume 1 Issue 2, June 2017"
389,10.1145/3090077,"Jeremy Gummeson, James Mccann, Chouchang (JACK) Yang, Damith Ranasinghe, Scott Hudson, Alanson Sample",RFID Light Bulb: Enabling Ubiquitous Deployment of Interactive RFID Systems,"Radio-Frequency Identification (RFID) technology has the potential to provide inexpensive, wireless, battery-free connectivity and interactivity for objects that are traditionally not instrumented. However, these systems have not seen widespread deployment outside warehouses and supply chains, owing to the complexity of installing bulky RFID readers, antennas, and their supporting power and network infrastructure.
In this work, we leverage advances in semiconductor optics, RF antenna design and system integration to create a hybrid RFID reader and smart LED lamp, in the form factor of a standard light bulb. This makes deploying RFID readers literally as easy as screwing in a light bulb. We explore the home-scale RFID interactions enabled by these smart bulbs, including infrastructure monitoring, localization and guided navigation, and standalone lighting effects.","Volume 1 Issue 2, June 2017"
390,10.1145/3090078,"Daniel Hintze, Philipp Hintze, Rainhard D. Findling, René Mayrhofer","A Large-Scale, Long-Term Analysis of Mobile Device Usage Characteristics","Today, mobile devices like smartphones and tablets have become an indispensable part of people's lives, posing many new questions e.g., in terms of interaction methods, but also security. In this paper, we conduct a large scale, long term analysis of mobile device usage characteristics like session length, interaction frequency, and daily usage in locked and unlocked state with respect to location context and diurnal pattern. Based on detailed logs from 29,279 mobile phones and tablets representing a total of 5,811 years of usage time, we identify and analyze 52.2 million usage sessions with some participants providing data for more than four years.
Our results show that context has a highly significant effect on both frequency and extent of mobile device usage, with mobile phones being used twice as much at home compared to in the office. Interestingly, devices are unlocked for only 46 % of the interactions. We found that with an average of 60 interactions per day, smartphones are used almost thrice as often as tablet devices (23), while usage sessions on tablets are three times longer, hence are used almost for an equal amount of time throughout the day. We conclude that usage session characteristics differ considerably between tablets and smartphones. These results inform future approaches to mobile interaction as well as security.","Volume 1 Issue 2, June 2017"
391,10.1145/3090079,"Milan Jain, Amarjeet Singh, Vikas Chandan",Portable+: A Ubiquitous And Smart Way Towards Comfortable Energy Savings,"An air conditioner (AC) consumes a significant proportion of the total household power consumption. Primarily used in developing countries, decentralised AC has an inbuilt thermostat to cool the room to a temperature, manually set by the users. However, residents are incapable of specifying their goal through these thermostats - maximise their comfort or save AC energy. State-of-the-art portable thermostats emulate AC remotes and assist occupants in remotely changing the thermostat temperature, through their smartphones. We propose extending such thermostats to portable+ by adding a Comfort-Energy Trade-off (CET) knob, realised through an optimisation framework to allow users to balance their comfort and the savings without worrying about the right set temperature. Analysis based on real data, collected from a controlled experiment (across two rooms for two weeks) and an in-situ deployment (across five rooms for three months), indicates that portable+ thermostats can reduce residents’ discomfort by 23% (CET selection for maximal comfort) and save 26% energy when CET is set for maximising savings.","Volume 1 Issue 2, June 2017"
392,10.1145/3090080,"I. Johnson, J. Henderson, C. Perry, J. Schöning, B. Hecht",Beautiful…but at What Cost?: An Examination of Externalities in Geographic Vehicle Routing,"Millions of people use platforms such as Google Maps to search for routes to their desired destinations. Recently, researchers and mapping platforms have shown growing interest in optimizing routes for criteria other than travel time, e.g. simplicity, safety, and beauty. However, despite the ubiquity of algorithmic routing and its potential to define how millions of people move around the world, very little is known about the externalities that arise when adopting these new optimization criteria, e.g. potential redistribution of traffic to certain neighborhoods and increased route complexity (with its associated risks). In this paper, we undertake the first controlled examination of these externalities, doing so across multiple mapping platforms, alternative optimizations, and cities. We find, for example, that scenic routing (i.e. “beauty”-optimized routing) would remove vehicles from highways, greatly increase traffic around parks, and, in certain cases, do the same for high-income areas. Our results also highlight that the interaction between routing criteria and urban structure is complex and effects vary from city to city, an important consideration for the growing literature on alternative routing strategies. Finally, to address the lack of open implementations of alternative routing algorithms and controlled routing evaluation frameworks, we are releasing our alternative routing and evaluation platform with this paper.","Volume 1 Issue 2, June 2017"
393,10.1145/3090081,"Jan Kučera, James Scott, Nicholas Chen, Patrick Olivier, Steve Hodges",Towards Calm Displays: Matching Ambient Illumination in Bedrooms,"We present a system for making emissive computer displays (LCDs) look like they are reflective, i.e. not emitting light but instead reflecting ambient light, an effect that we call a “calm display”. We achieve this effect by using a light sensor and a one-time calibration process to drive an algorithm which controls the display's backlight intensity and gamma correction functionality to continually match the brightness and chromaticity of the ambient light. We present an experimental evaluation of our system, showing quantitatively that the color and brightness output by our system is perceptually close to that of a piece of paper under similar lighting conditions. We argue that calm displays can more easily fade into the background, and further that they are more suitable for environments such as bedrooms where glowing displays are often out-of-place. We validate these claims and more generally explore users’ perception of calm displays, through a field study of an LCD display deployed in participants’ bedrooms.","Volume 1 Issue 2, June 2017"
394,10.1145/3090082,"Liu Sicong, Zhou Zimu, Du Junzhao, Shangguan Longfei, Jun Han, Xin Wang",UbiEar: Bringing Location-independent Sound Awareness to the Hard-of-hearing People with Smartphones,"Non-speech sound-awareness is important to improve the quality of life for the deaf and hard-of-hearing (DHH) people. DHH people, especially the young, are not always satisfied with their hearing aids. According to the interviews with 60 young hard-of-hearing students, a ubiquitous sound-awareness tool for emergency and social events that works in diverse environments is desired. In this paper, we design UbiEar, a smartphone-based acoustic event sensing and notification system. Core techniques in UbiEar are a light-weight deep convolution neural network to enable location-independent acoustic event recognition on commodity smartphons, and a set of mechanisms for prompt and energy-efficient acoustic sensing. We conducted both controlled experiments and user studies with 86 DHH students and showed that UbiEar can assist the young DHH students in awareness of important acoustic events in their daily life.","Volume 1 Issue 2, June 2017"
395,10.1145/3090083,"Yiqin Lu, Chun Yu, Xin Yi, Yuanchun Shi, Shengdong Zhao",BlindType: Eyes-Free Text Entry on Handheld Touchpad by Leveraging Thumb's Muscle Memory,"Eyes-free input is desirable for ubiquitous computing, since interacting with mobile and wearable devices often competes for visual attention with other devices and tasks. In this paper, we explore eyes-free typing on a touchpad using one thumb, wherein a user taps on an imaginary QWERTY keyboard while receiving text feedback on a separate screen. Our hypothesis is that users can transfer their typing ability obtained from visible keyboards to eyes-free use. We propose two statistical decoding algorithms to infer users’ eyes-free input: the absolute algorithm and the relative algorithm. The absolute algorithm infers user input based on the absolute position of touch endpoints, while the relative algorithm infers based on the vectors between successive touch endpoints. Evaluation results showed users could achieve satisfying performance with both algorithms. Text entry rate was 17-23 WPM (words per minute) depending on the algorithm used. In comparison, a baseline cursor-based text entry method yielded only 7.66 WPM. In conclusion, our research demonstrates for the first time the feasibility of thumb-based eyes-free typing, which provides a new possibility for text entry on ubiquitous computing platforms such as smart TVs and HMDs.","Volume 1 Issue 2, June 2017"
396,10.1145/3090084,"Balz Maag, Zimu Zhou, Olga Saukh, Lothar Thiele",SCAN: Multi-Hop Calibration for Mobile Sensor Arrays,"Urban air pollution monitoring with mobile, portable, low-cost sensors has attracted increasing research interest for their wide spatial coverage and affordable expenses to the general public. However, low-cost air quality sensors not only drift over time but also suffer from cross-sensitivities and dependency on meteorological effects. Therefore calibration of measurements from low-cost sensors is indispensable to guarantee data accuracy and consistency to be fit for quantitative studies on air pollution. In this work we propose sensor array network calibration (SCAN), a multi-hop calibration technique for dependent low-cost sensors. SCAN is applicable to sets of co-located, heterogeneous sensors, known as sensor arrays, to compensate for cross-sensitivities and dependencies on meteorological influences. SCAN minimizes error accumulation over multiple hops of sensor arrays, which is unattainable with existing multi-hop calibration techniques. We formulate SCAN as a novel constrained least-squares regression and provide a closed-form expression of its regression parameters. We theoretically prove that SCAN is free from regression dilution even in presence of measurement noise. In-depth simulations demonstrate that SCAN outperforms various calibration techniques. Evaluations on two real-world low-cost air pollution sensor datasets comprising 66 million samples collected over three years show that SCAN yields 16% to 60% lower error than state-of-the-art calibration techniques.","Volume 1 Issue 2, June 2017"
397,10.1145/3090085,"Alex Mariakakis, Megan A. Banks, Lauren Phillipi, Lei Yu, James Taylor, Shwetak N. Patel",BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders,"Pancreatic cancer has one of the worst survival rates amongst all forms of cancer because its symptoms manifest later into the progression of the disease. One of those symptoms is jaundice, the yellow discoloration of the skin and sclera due to the buildup of bilirubin in the blood. Jaundice is only recognizable to the naked eye in severe stages, but a ubiquitous test using computer vision and machine learning can detect milder forms of jaundice. We propose BiliScreen, a smartphone app that captures pictures of the eye and produces an estimate of a person's bilirubin level, even at levels normally undetectable by the human eye. We test two low-cost accessories that reduce the effects of external lighting: (1) a 3D-printed box that controls the eyes' exposure to light and (2) paper glasses with colored squares for calibration. In a 70-person clinical study, we found that BiliScreen with the box achieves a Pearson correlation coefficient of 0.89 and a mean error of -0.09 ± 2.76 mg/dl in predicting a person's bilirubin level. As a screening tool, BiliScreen identifies cases of concern with a sensitivity of 89.7% and a specificity of 96.8% with the box accessory.","Volume 1 Issue 2, June 2017"
398,10.1145/3090086,"Evangelos Niforatos, Caterina Cinel, Cathleen Cortis Mack, Marc Langheinrich, Geoff Ward","Can Less be More?: Contrasting Limited, Unlimited, and Automatic Picture Capture for Augmenting Memory Recall","Today's abundance1 of cheap digital storage in the form of tiny memory cards put literally no bounds on the number of images one can capture with one's digital camera or smartphone during an event. However, prior work has shown that taking many pictures may actually make us remember less of a particular event. Does automated picture taking (lifelogging) help avoid this, yet still offer to capture meaningful pictures? In this work, we investigate the effect of capture modality (i.e., limited, unlimited, automatic, and no capture) on people's ability to recall a past event – with and without the support of the pictures captured through these modalities. Our results from a field experiment with 83 participants show that capturing fewer pictures does not necessarily lead to the capture of more relevant pictures. However, when controlling for number of pictures taken, our results show that having a limited number of pictures to capture may lead to pictures with increased memory value. At the same time, automated capture failed to produce pictures that would help remember the past experience better.","Volume 1 Issue 2, June 2017"
399,10.1145/3090087,"Blaine A. Price, Avelie Stuart, Gul Calikli, Ciaran Mccormick, Vikram Mehta, Luke Hutton, Arosha K. Bandara, Mark Levine, Bashar Nuseibeh","Logging you, Logging me: A Replicable Study of Privacy and Sharing Behaviour in Groups of Visual Lifeloggers","Low cost digital cameras in smartphones and wearable devices make it easy for people to automatically capture and share images as a visual lifelog. Having been inspired by a US campus based study that explored individual privacy behaviours of visual lifeloggers, we conducted a similar study on a UK campus, however we also focussed on the privacy behaviours of groups of lifeloggers. We argue for the importance of replicability and therefore we built a publicly available toolkit, which includes camera design, study guidelines and source code. Our results show some similar sharing behaviour to the US based study: people tried to preserve the privacy of strangers, but we found fewer bystander reactions despite using a more obvious camera. In contrast, we did not find a reluctance to share images of screens but we did find that images of vices were shared less. Regarding privacy behaviours in groups of lifeloggers, we found that people were more willing to share images of people they were interacting with than of strangers, that lifelogging in groups could change what defines a private space, and that lifelogging groups establish different rules to manage privacy for those inside and outside the group.","Volume 1 Issue 2, June 2017"
400,10.1145/3090088,"Soha Rostaminia, Addison Mayberry, Deepak Ganesan, Benjamin Marlin, Jeremy Gummeson",iLid: Low-power Sensing of Fatigue and Drowsiness Measures on a Computational Eyeglass,"The ability to monitor eye closures and blink patterns has long been known to enable accurate assessment of fatigue and drowsiness in individuals. Many measures of the eye are known to be correlated with fatigue including coarse-grained measures like the rate of blinks as well as fine-grained measures like the duration of blinks and the extent of eye closures. Despite a plethora of research validating these measures, we lack wearable devices that can continually and reliably monitor them in the natural environment. In this work, we present a low-power system, iLid, that can continually sense fine-grained measures such as blink duration and Percentage of Eye Closures (PERCLOS) at high frame rates of 100fps. We present a complete solution including design of the sensing, signal processing, and machine learning pipeline; implementation on a prototype computational eyeglass platform; and extensive evaluation under many conditions including illumination changes, eyeglass shifts, and mobility. Our results are very encouraging, showing that we can detect blinks, blink duration, eyelid location, and fatigue-related metrics such as PERCLOS with less than a few percent error.","Volume 1 Issue 2, June 2017"
401,10.1145/3090089,"Piotr Sapiezynski, Arkadiusz Stopczynski, David Kofoed Wind, Jure Leskovec, Sune Lehmann",Inferring Person-to-person Proximity Using WiFi Signals,"Today's societies are enveloped in an ever-growing telecommunication infrastructure. This infrastructure offers important opportunities for sensing and recording a multitude of human behaviors. Human mobility patterns are a prominent example of such a behavior which has been studied based on cell phone towers, Bluetooth beacons, and WiFi networks as proxies for location. While mobility is an important aspect of human behavior, it is also crucial to study physical interactions among individuals. Sensing proximity that enables social interactions on a large scale is a technical challenge and many commonly used approaches—including RFID badges or Bluetooth scanning—offer only limited scalability. Here we show that it is possible, in a scalable and robust way, to accurately infer person-to-person physical proximity from the lists of WiFi access points measured by smartphones carried by the two individuals. Based on a longitudinal dataset of approximately 800 participants with ground-truth Bluetooth proximity collected over a year, we show that our model performs better than the current state-of-the-art. Our results demonstrate the value of WiFi signals as a tool for social sensing and show how collections of WiFi data pose a potential threat to privacy.","Volume 1 Issue 2, June 2017"
402,10.1145/3090090,"Vamsi Talla, Bryce Kellogg, Shyamnath Gollakota, Joshua R. Smith",Battery-Free Cellphone,"We present the first battery-free cellphone design that consumes only a few micro-watts of power. Our design can sense speech, actuate the earphones, and switch between uplink and downlink communications, all in real time. Our system optimizes transmission and reception of speech while simultaneously harvesting power which enables the battery-free cellphone to operate continuously. The battery-free device prototype is built using commercial-off-the-shelf components on a printed circuit board. It can operate on power that is harvested from RF signals transmitted by a basestation 31 feet (9.4 m) away. Further, using power harvested from ambient light with tiny photodiodes, we show that our device can communicate with a basestation that is 50 feet (15.2 m) away. Finally, we perform the first Skype call using a battery-free phone over a cellular network, via our custom bridged basestation. This we believe is a major leap in the capability of battery-free devices and a step towards a fully functional battery-free cellphone.","Volume 1 Issue 2, June 2017"
403,10.1145/3090091,"Lie Ming Tang, Judy Kay",Harnessing Long Term Physical Activity Data—How Long-term Trackers Use Data and How an Adherence-based Interface Supports New Insights,"Increasingly, people are amassing long term physical activity data which could play an important role for reflection. However, it is not clear if and how existing trackers use their long term data and incomplete data is a potential challenge. We introduced the notion of adherence to design iStuckWithIt, a custom calendar display that integrates and embeds daily adherence (days with data and days without), hourly adherence (hours of wear each day) and goal adherence (days people achieved their activity goals). Our study of 21 long term FitBit users (average: 23 months, 17 over 1 year) began with an interview about their use and knowledge of long term physical activity data followed by a think-aloud use of iStuckWithIt and a post-interview. Our participants gained new insights about their wearing patterns and they could then use this to overcome problems of missing data, to gain insights about their physical activity and goal achievement. This work makes two main contributions: new understanding of the ways that long term trackers have used and understand their data; the design and evaluation of iStuckWithIt demonstrating that people can gain new insights through designs that embed daily, hourly adherence data with goal adherence.","Volume 1 Issue 2, June 2017"
404,10.1145/3090092,"H. Trinh, R. Asadi, D. Edge, T. Bickmore",RoboCOP: A Robotic Coach for Oral Presentations,"Rehearsing in front of a live audience is invaluable when preparing for important presentations. However, not all presenters take the opportunity to engage in such rehearsal, due to time constraints, availability of listeners who can provide constructive feedback, or public speaking anxiety. We present RoboCOP, an automated anthropomorphic robot head that acts as a coach to provide spoken feedback during presentation rehearsals at both the individual slide and overall presentation level. The robot offers conversational coaching on three key aspects of presentations: speech quality, content coverage, and audience orientation. The design of the feedback strategies was informed by findings from an exploratory study with academic professionals who were experienced in mentoring students on their presentations. In a within-subjects study comparing RoboCOP to visual feedback and spoken feedback without a robot, the robotic coach was shown to lead to significant improvement in the overall experience of presenters. Results of a second within-subjects evaluation study comparing RoboCOP with existing rehearsal practices show that our system creates a natural, interactive, and motivating rehearsal environment that leads to improved presentation quality.","Volume 1 Issue 2, June 2017"
405,10.1145/3090093,"Martin Weigel, Jürgen Steimle",DeformWear: Deformation Input on Tiny Wearable Devices,"Due to their small surfaces, wearable devices make existing techniques for touch input very challenging. This paper proposes deformation input on a tiny and soft surface as an input modality for wearable computing devices. We introduce DeformWear, tiny wearable devices that leverage single-point deformation input on various body locations. Despite the small input surface, DeformWear enables expressive and precise input using high-resolution pressure, shear, and pinch deformations. We present a first set of interaction techniques for tiny deformation-sensitive wearable devices. They enable fluid interaction in a large input space by combining multiple dimensions of deformation. We demonstrate their use in seven application examples, showing DeformWear as a standalone input device and as a companion device for smartwatches, head-mounted displays, or headphones. Results from a user study demonstrate that these tiny devices allow for precise and expressive interactions on many body locations, in standing and walking conditions.","Volume 1 Issue 2, June 2017"
406,10.1145/3090094,"Chenshu Wu, Jingao Xu, Zheng Yang, Nicholas D. Lane, Zuwei Yin",Gain Without Pain: Accurate WiFi-based Localization using Fingerprint Spatial Gradient,"Among numerous indoor localization systems proposed during the past decades, WiFi fingerprint-based localization has been one of the most attractive solutions, which is known to be free of extra infrastructure and specialized hardware. However, current WiFi fingerprinting suffers from a pivotal problem of RSS fluctuations caused by unpredictable environmental dynamics. The RSS variations lead to severe spatial ambiguity and temporal instability in RSS fingerprinting, both impairing the location accuracy. To overcome such drawbacks, we propose fingerprint spatial gradient (FSG), a more stable and distinctive form than RSS fingerprints, which exploits the spatial relationships among the RSS fingerprints of multiple neighbouring locations. As a spatially relative form, FSG is more resistant to RSS uncertainties. Based on the concept of FSG, we design novel algorithms to construct FSG on top of a general RSS fingerprint database and then propose effective FSG matching methods for location estimation. Unlike previous works, the resulting system, named ViVi, yields performance gain without the pains of introducing extra information or additional service restrictions or assuming impractical RSS models. Extensive experiments in different buildings demonstrate that ViVi achieves great performance, outperforming the best among four comparative start-of-the-art approaches by 29% in mean accuracy and 19% in 95th percentile accuracy and outweighing the worst one by 39% and 24% respectively. We envision FSG as a promising supplement and alternative to existing RSS fingerprinting for future WiFi localization.","Volume 1 Issue 2, June 2017"
407,10.1145/3090095,"Cheng Zhang, Qiuyue Xue, Anandghan Waghmare, Sumeet Jain, Yiming Pu, Sinan Hersek, Kent Lyons, Kenneth A. Cunefare, Omer T. Inan, Gregory D. Abowd",SoundTrak: Continuous 3D Tracking of a Finger Using Active Acoustics,"The small size of wearable devices limits the efficiency and scope of possible user interactions, as inputs are typically constrained to two dimensions: the touchscreen surface. We present SoundTrak, an active acoustic sensing technique that enables a user to interact with wearable devices in the surrounding 3D space by continuously tracking the finger position with high resolution. The user wears a ring with an embedded miniature speaker sending an acoustic signal at a specific frequency (e.g., 11 kHz), which is captured by an array of miniature, inexpensive microphones on the target wearable device. A novel algorithm is designed to localize the finger’s position in 3D space by extracting phase information from the received acoustic signals. We evaluated SoundTrak in a volume of space (20cm × 16cm × 11cm) around a smartwatch, and show an average accuracy of 1.3 cm. We report on results from a Fitts’ Law experiment with 10 participants as the evaluation of the real-time prototype. We also present a set of applications which are supported by this 3D input technique, and show the practical challenges that need to be addressed before widespread use.","Volume 1 Issue 2, June 2017"
408,10.1145/3090096,"Nan Zhao, Asaph Azaria, Joseph A. Paradiso",Mediated Atmospheres: A Multimodal Mediated Work Environment,"Atmosphere - the sensorial qualities of a space, shaped by the composition of light, sound, objects, people, etc. - has remarkable influence on our experiences and behavior. Manipulating it has been shown to be powerful, affecting cognitive performance, mood and even physiology, our work envisions and implements a smart office prototype, capable of digitally transforming its atmosphere - creating what we call Mediated Atmospheres (MA) - using computationally controlled lighting, video projection and sound. Additionally, we equipped this space with a modular real-time data collection infrastructure, integrating a set of biosignal sensors. Through a user study (N=29) we demonstrate MA's effects on occupants’ ability to focus and to recover from a stressful situation. Our evaluation is based on subjective measurements of perception, as well as objective measurements, extracted from recordings of heart rate variability and facial features. We compare multiple signal processing approaches for quantifying changes in occupant physiological state. Our findings show that MA significantly (p&lt;0.05) affect occupants’ perception as well as physiological response, which encouragingly correlate with occupants’ perception. Our findings is a first step towards personalized control of the ambient atmosphere to support wellbeing and productivity.","Volume 1 Issue 2, June 2017"
409,10.1145/3090097,"Ru Zhao, Vivian Li, Hugo Barbosa, Gourab Ghoshal, Mohammed Ehsan Hoque",Semi-Automated 8 Collaborative Online Training Module for Improving Communication Skills,"This paper presents a description and evaluation of the ROC Speak system, a platform that allows ubiquitous access to communication skills training. ROC Speak (available at rocspeak.com) enables anyone to go to a website, record a video, and receive feedback on smile intensity, body movement, volume modulation, filler word usage, unique word usage, word cloud of the spoken words, in addition to overall assessment and subjective comments by peers. Peer comments are automatically ranked and sorted for usefulness and sentiment (i.e., positive vs. negative). We evaluated the system with a diverse group of 56 online participants for a 10-day period. Participants submitted responses to career oriented prompts every other day. The participants were randomly split into two groups: 1) treatment - full feedback from the ROC Speak system; 2) control – written feedback from online peers. When judged by peers (p &lt; .001) and independent raters (p &lt; .05), participants from the treatment group demonstrated statistically significant improvement in overall speaking skills rating while the control group did not. Furthermore, in terms of speaking attributes, treatment group showed an improvement in friendliness (p &lt; .001), vocal variety (p &lt; .05) and articulation (p &lt; .01).","Volume 1 Issue 2, June 2017"
410,10.1145/3053330,"Artem Dementyev, Christian Holz","DualBlink: A Wearable Device to Continuously Detect, Track, and Actuate Blinking For Alleviating Dry Eyes and Computer Vision Syndrome","Increased visual attention, such as during computer use leads to less blinking, which can cause dry eyes—the leading cause of computer vision syndrome. As people spend more time looking at screens on mobile and desktop devices, computer vision syndrome is becoming epidemic in today's population, leading to blurry vision, fatigue, and a reduced quality of life.
One way to alleviate dry eyes is increased blinking. In this paper, we present a series of glasses-mounted devices that track the wearer's blink rate and, upon absent blinks, trigger blinks through actuation: light flashes, physical taps, and small puffs of air near the eye. We conducted a user study to evaluate the effectiveness of our devices and found that air puff and physical tap actuations result in a 36% increase in participants’ average blink rate. Air puff thereby struck the best compromise between effective blink actuations and low distraction ratings from participants. In a follow-up study, we found that high intensity, short puffs near the eye were most effective in triggering blinks while receiving only low-rated distraction and invasiveness ratings from participants. We conclude this paper with two miniaturized and self-contained DualBlink prototypes, one integrated into the frame of a pair of glasses and the other one as a clip-on for existing glasses. We believe that DualBlink can serve as an always-available and viable option to treat computer vision syndrome in the future.","Volume 1 Issue 1, March 2017"
411,10.1145/3053332,"Mahmoud Hassan, Florian Daiber, Frederik Wiehr, Felix Kosmalla, Antonio Krüger",FootStriker: An EMS-based Foot Strike Assistant for Running,"In running, knee-related injuries are very common. The main cause are high impact forces when striking the ground with the heel first. Mid- or forefoot running is generally known to reduce impact loads and to be a more efficient running style. In this paper, we introduce a wearable running assistant, consisting of an electrical muscle stimulation (EMS) device and an insole with force sensing resistors. It detects heel striking and actuates the calf muscles during the flight phase to control the foot angle before landing. We conducted a user study, in which we compared the classical coaching approach using slow motion video analysis as a terminal feedback to our proposed real-time EMS feedback. The results show that EMS actuation significantly outperforms traditional coaching, i.e., a decreased average heel striking rate, when using the system. As an implication, EMS feedback can generally be beneficial for the motor learning of complex, repetitive movements.","Volume 1 Issue 1, March 2017"
412,10.1145/3053331,"Can Liu, Gradeigh D. Clark, Janne Lindqvist",Guessing Attacks on User-Generated Gesture Passwords,"Touchscreens, the dominant input type for mobile phones, require unique authentication solutions. Gesture passwords have been proposed as an alternative ubiquitous authentication technique. Prior security analysis has relied on inconsistent measurements such as mutual information or shoulder surfing attacks.We present the first approach for measuring the security of gestures with guessing attacks that model real-world attacker behavior. Our major contributions are: 1) a comprehensive analysis of the weak subspace for gesture passwords, 2) a method for enumerating the size of the full theoretical gesture password space, 3) a design of a novel guessing attack against user-chosen gestures using a dictionary, and 4) a brute-force attack used for benchmarking the performance of the guessing attack. Our dictionary attack, tested on newly collected user data, achieves a cracking rate of 47.71% after two weeks of computation using 109 guesses. This is a difference of 35.78 percentage points compared to the 11.93% cracking rate of the brute-force attack. In conclusion, users are not taking full advantage of the large theoretical password space and instead choose their gesture passwords from weak subspaces. We urge for further work on addressing this challenge.","Volume 1 Issue 1, March 2017"
